{"step": 0}
{"episode_reward": 0.0, "episode": 1.0, "duration": 1.4319508075714111, "info_normalized_performance_mean": 0.11667930334806442, "info_normalized_performance_final": 0.13005051016807556, "info_performance_mean": 0.11667930334806442, "info_performance_final": 0.13005051016807556, "step": 500}
{"episode_reward": 233.35858585858608, "episode": 6.0, "duration": 1.4327073097229004, "info_normalized_performance_mean": 0.02431122586131096, "info_normalized_performance_final": 0.18877550959587097, "info_performance_mean": 0.02431122586131096, "info_performance_final": 0.18877550959587097, "step": 1000}
{"episode_reward": 48.622448979591844, "episode": 11.0, "batch_reward": 0.6562984585762024, "critic_loss": 2.6466193199157715, "actor_loss": 1.0308277606964111, "actor_target_entropy": -3.0, "actor_entropy": -7.864393711090088, "alpha_loss": -0.49132591485977173, "alpha_value": 0.10000000000000002, "duration": 1.5862252712249756, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1500}
{"episode_reward": 0.0, "episode": 16.0, "batch_reward": 0.4828416109085083, "critic_loss": 0.03231119364500046, "actor_loss": -2.157092571258545, "actor_target_entropy": -3.0, "actor_entropy": 3.543576717376709, "alpha_loss": 0.459373414516449, "alpha_value": 0.09748599514038599, "duration": 1.6583137512207031, "info_normalized_performance_mean": 0.013673470355570316, "info_normalized_performance_final": 0.04642857238650322, "info_performance_mean": 0.013673470355570316, "info_performance_final": 0.04642857238650322, "step": 2000}
{"episode_reward": 27.346938775510182, "episode": 21.0, "batch_reward": 0.5345987677574158, "critic_loss": 0.15659581124782562, "actor_loss": -4.427061080932617, "actor_target_entropy": -3.0, "actor_entropy": 2.581697940826416, "alpha_loss": 0.3985200524330139, "alpha_value": 0.09520800821454876, "duration": 1.4706652164459229, "info_normalized_performance_mean": 0.0103571442887187, "info_normalized_performance_final": 0.01785714365541935, "info_performance_mean": 0.0103571442887187, "info_performance_final": 0.01785714365541935, "step": 2500}
{"episode_reward": 20.714285714285726, "episode": 26.0, "batch_reward": 0.690094530582428, "critic_loss": 1.2516684532165527, "actor_loss": -7.08176851272583, "actor_target_entropy": -3.0, "actor_entropy": 3.739121198654175, "alpha_loss": 0.3808489739894867, "alpha_value": 0.09318815629976168, "duration": 1.4533445835113525, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 3000}
{"episode_reward": 0.0, "episode": 31.0, "batch_reward": 0.5887155532836914, "critic_loss": 1.1863614320755005, "actor_loss": -9.848987579345703, "actor_target_entropy": -3.0, "actor_entropy": 3.121340274810791, "alpha_loss": 0.29473549127578735, "alpha_value": 0.09120466827466198, "duration": 1.4825987815856934, "info_normalized_performance_mean": 0.3286275565624237, "info_normalized_performance_final": 0.6270408034324646, "info_performance_mean": 0.3286275565624237, "info_performance_final": 0.6270408034324646, "step": 3500}
{"episode_reward": 657.255102040816, "episode": 36.0, "batch_reward": 0.7501879930496216, "critic_loss": 28.477609634399414, "actor_loss": -15.083619117736816, "actor_target_entropy": -3.0, "actor_entropy": 2.771275043487549, "alpha_loss": 0.17052307724952698, "alpha_value": 0.08984726863903521, "duration": 1.4079041481018066, "info_normalized_performance_mean": 0.2585395276546478, "info_normalized_performance_final": 0.2984693944454193, "info_performance_mean": 0.2585395276546478, "info_performance_final": 0.2984693944454193, "step": 4000}
{"episode_reward": 517.0790816326536, "episode": 41.0, "batch_reward": 1.2941391468048096, "critic_loss": 19.22334861755371, "actor_loss": -29.13703727722168, "actor_target_entropy": -3.0, "actor_entropy": 2.878894805908203, "alpha_loss": -0.020702213048934937, "alpha_value": 0.0894426119103166, "duration": 1.759889841079712, "info_normalized_performance_mean": 0.16170330345630646, "info_normalized_performance_final": 0.1809752732515335, "info_performance_mean": 0.16170330345630646, "info_performance_final": 0.1809752732515335, "step": 4500}
{"episode_reward": 323.4065934065936, "episode": 46.0, "batch_reward": 1.8682607412338257, "critic_loss": 8.268375396728516, "actor_loss": -47.61906433105469, "actor_target_entropy": -3.0, "actor_entropy": 1.5440109968185425, "alpha_loss": -0.10401330888271332, "alpha_value": 0.08975763675320962, "duration": 1.7963881492614746, "info_normalized_performance_mean": 0.3967004418373108, "info_normalized_performance_final": 0.43831169605255127, "info_performance_mean": 0.3967004418373108, "info_performance_final": 0.43831169605255127, "step": 5000}
{"episode_reward": 793.400974025974, "episode": 51.0, "batch_reward": 2.3358685970306396, "critic_loss": 6.266568183898926, "actor_loss": -70.76060485839844, "actor_target_entropy": -3.0, "actor_entropy": 2.0459938049316406, "alpha_loss": -0.20733726024627686, "alpha_value": 0.09109571102173214, "duration": 1.8961901664733887, "info_normalized_performance_mean": 0.6879165768623352, "info_normalized_performance_final": 0.8184523582458496, "info_performance_mean": 0.6879165768623352, "info_performance_final": 0.8184523582458496, "step": 5500}
{"episode_reward": 1375.8333333333342, "episode": 56.0, "batch_reward": 2.6539430618286133, "critic_loss": 17.487693786621094, "actor_loss": -90.87348937988281, "actor_target_entropy": -3.0, "actor_entropy": 1.3321967124938965, "alpha_loss": -0.13984602689743042, "alpha_value": 0.09260942091594025, "duration": 1.4830458164215088, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 6000}
{"episode_reward": 0.0, "episode": 61.0, "batch_reward": 2.8691246509552, "critic_loss": 31.510005950927734, "actor_loss": -111.70744323730469, "actor_target_entropy": -3.0, "actor_entropy": 1.3477580547332764, "alpha_loss": -0.07555912435054779, "alpha_value": 0.09416597045787889, "duration": 1.6460535526275635, "info_normalized_performance_mean": 0.44234123826026917, "info_normalized_performance_final": 0.49140211939811707, "info_performance_mean": 0.44234123826026917, "info_performance_final": 0.49140211939811707, "step": 6500}
{"episode_reward": 884.6825396825398, "episode": 66.0, "batch_reward": 2.2793285846710205, "critic_loss": 96.16805267333984, "actor_loss": -118.40328979492188, "actor_target_entropy": -3.0, "actor_entropy": 1.3703476190567017, "alpha_loss": -0.2537915110588074, "alpha_value": 0.09592010538749908, "duration": 1.4863131046295166, "info_normalized_performance_mean": 0.770468533039093, "info_normalized_performance_final": 0.856249988079071, "info_performance_mean": 0.770468533039093, "info_performance_final": 0.856249988079071, "step": 7000}
{"episode_reward": 1540.9375, "episode": 71.0, "batch_reward": 3.6837754249572754, "critic_loss": 34.425376892089844, "actor_loss": -158.83663940429688, "actor_target_entropy": -3.0, "actor_entropy": 0.9657425880432129, "alpha_loss": -0.21528828144073486, "alpha_value": 0.09832739504364389, "duration": 1.4606215953826904, "info_normalized_performance_mean": 0.30102038383483887, "info_normalized_performance_final": 0.3316326439380646, "info_performance_mean": 0.30102038383483887, "info_performance_final": 0.3316326439380646, "step": 7500}
{"episode_reward": 602.0408163265312, "episode": 76.0, "batch_reward": 3.3171844482421875, "critic_loss": 41.4466552734375, "actor_loss": -171.97679138183594, "actor_target_entropy": -3.0, "actor_entropy": 1.117321491241455, "alpha_loss": -0.26051396131515503, "alpha_value": 0.10159204977172312, "duration": 1.6425800323486328, "info_normalized_performance_mean": 0.13734179735183716, "info_normalized_performance_final": 0.14918069541454315, "info_performance_mean": 0.13734179735183716, "info_performance_final": 0.14918069541454315, "step": 8000}
{"episode_reward": 274.6836595357302, "episode": 81.0, "batch_reward": 3.796680212020874, "critic_loss": 66.70262145996094, "actor_loss": -209.79884338378906, "actor_target_entropy": -3.0, "actor_entropy": 1.2412912845611572, "alpha_loss": -0.2768430709838867, "alpha_value": 0.10460975490807427, "duration": 1.5013110637664795, "info_normalized_performance_mean": 0.2858465313911438, "info_normalized_performance_final": 0.32671958208084106, "info_performance_mean": 0.2858465313911438, "info_performance_final": 0.32671958208084106, "step": 8500}
{"episode_reward": 571.6931216931218, "episode": 86.0, "batch_reward": 3.6069247722625732, "critic_loss": 82.79852294921875, "actor_loss": -228.83840942382812, "actor_target_entropy": -3.0, "actor_entropy": 1.0218980312347412, "alpha_loss": -0.24384662508964539, "alpha_value": 0.10752323833659476, "duration": 2.1618309020996094, "info_normalized_performance_mean": 0.38199087977409363, "info_normalized_performance_final": 0.4245454668998718, "info_performance_mean": 0.38199087977409363, "info_performance_final": 0.4245454668998718, "step": 9000}
{"episode_reward": 763.9818181818188, "episode": 91.0, "batch_reward": 3.209709405899048, "critic_loss": 62.305259704589844, "actor_loss": -243.71331787109375, "actor_target_entropy": -3.0, "actor_entropy": 0.15408703684806824, "alpha_loss": -0.29092884063720703, "alpha_value": 0.1101430311939657, "duration": 1.655320167541504, "info_normalized_performance_mean": 0.07402712851762772, "info_normalized_performance_final": 0.08313397318124771, "info_performance_mean": 0.07402712851762772, "info_performance_final": 0.08313397318124771, "step": 9500}
{"episode_reward": 148.0542264752793, "episode": 96.0, "batch_reward": 4.988287925720215, "critic_loss": 134.342529296875, "actor_loss": -291.48248291015625, "actor_target_entropy": -3.0, "actor_entropy": 0.42616376280784607, "alpha_loss": -0.19065973162651062, "alpha_value": 0.11287557120687937, "step": 10000}
{"duration": 21.42734694480896, "info_normalized_performance_mean": 0.35936397314071655, "info_normalized_performance_final": 0.4033094048500061, "info_performance_mean": 0.35936397314071655, "info_performance_final": 0.4033094048500061, "step": 10000}
{"episode_reward": 718.7280701754378, "episode": 101.0, "batch_reward": 4.55208683013916, "critic_loss": 34.209686279296875, "actor_loss": -295.9586486816406, "actor_target_entropy": -3.0, "actor_entropy": -0.05232369154691696, "alpha_loss": -0.20357170701026917, "alpha_value": 0.11570681654019199, "duration": 1.7488574981689453, "info_normalized_performance_mean": 0.3521008789539337, "info_normalized_performance_final": 0.3949579894542694, "info_performance_mean": 0.3521008789539337, "info_performance_final": 0.3949579894542694, "step": 10500}
{"episode_reward": 704.2016806722693, "episode": 106.0, "batch_reward": 5.596137046813965, "critic_loss": 44.30305480957031, "actor_loss": -348.4555358886719, "actor_target_entropy": -3.0, "actor_entropy": 0.16000284254550934, "alpha_loss": -0.22321440279483795, "alpha_value": 0.11844766278445322, "duration": 1.7157936096191406, "info_normalized_performance_mean": 0.4124929904937744, "info_normalized_performance_final": 0.45972222089767456, "info_performance_mean": 0.4124929904937744, "info_performance_final": 0.45972222089767456, "step": 11000}
{"episode_reward": 824.986111111112, "episode": 111.0, "batch_reward": 4.4364776611328125, "critic_loss": 43.335975646972656, "actor_loss": -341.83563232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.4672149419784546, "alpha_loss": -0.2430245578289032, "alpha_value": 0.12138890729921299, "duration": 1.8468832969665527, "info_normalized_performance_mean": 0.37985312938690186, "info_normalized_performance_final": 0.5039426684379578, "info_performance_mean": 0.37985312938690186, "info_performance_final": 0.5039426684379578, "step": 11500}
{"episode_reward": 759.7060931899643, "episode": 116.0, "batch_reward": 3.8606295585632324, "critic_loss": 150.15716552734375, "actor_loss": -350.5733642578125, "actor_target_entropy": -3.0, "actor_entropy": 0.29647114872932434, "alpha_loss": -0.2754431962966919, "alpha_value": 0.12456809514575383, "duration": 1.8709022998809814, "info_normalized_performance_mean": 0.4520833194255829, "info_normalized_performance_final": 0.503333330154419, "info_performance_mean": 0.4520833194255829, "info_performance_final": 0.503333330154419, "step": 12000}
{"episode_reward": 904.1666666666686, "episode": 121.0, "batch_reward": 5.0389509201049805, "critic_loss": 78.9421615600586, "actor_loss": -384.8362731933594, "actor_target_entropy": -3.0, "actor_entropy": 0.9016174674034119, "alpha_loss": -0.24884465336799622, "alpha_value": 0.12782871611210772, "duration": 1.5481157302856445, "info_normalized_performance_mean": 0.3984524607658386, "info_normalized_performance_final": 0.4407239854335785, "info_performance_mean": 0.3984524607658386, "info_performance_final": 0.4407239854335785, "step": 12500}
{"episode_reward": 796.9049773755664, "episode": 126.0, "batch_reward": 4.905783176422119, "critic_loss": 104.15455627441406, "actor_loss": -405.76165771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.6706490516662598, "alpha_loss": -0.26724159717559814, "alpha_value": 0.13109708679154916, "duration": 1.6338653564453125, "info_normalized_performance_mean": 0.5207291841506958, "info_normalized_performance_final": 0.5787037014961243, "info_performance_mean": 0.5207291841506958, "info_performance_final": 0.5787037014961243, "step": 13000}
{"episode_reward": 1041.458333333335, "episode": 131.0, "batch_reward": 6.3928985595703125, "critic_loss": 44.73518371582031, "actor_loss": -446.20538330078125, "actor_target_entropy": -3.0, "actor_entropy": 0.3428261876106262, "alpha_loss": -0.16442272067070007, "alpha_value": 0.1345191389084872, "duration": 1.6297504901885986, "info_normalized_performance_mean": 0.46914708614349365, "info_normalized_performance_final": 0.520588219165802, "info_performance_mean": 0.46914708614349365, "info_performance_final": 0.520588219165802, "step": 13500}
{"episode_reward": 938.294117647058, "episode": 136.0, "batch_reward": 4.999212265014648, "critic_loss": 37.201908111572266, "actor_loss": -436.02105712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6782740354537964, "alpha_loss": -0.30502334237098694, "alpha_value": 0.1377563393131139, "duration": 1.6805777549743652, "info_normalized_performance_mean": 0.10047619789838791, "info_normalized_performance_final": 0.112351194024086, "info_performance_mean": 0.10047619789838791, "info_performance_final": 0.112351194024086, "step": 14000}
{"episode_reward": 200.95238095238054, "episode": 141.0, "batch_reward": 5.393460750579834, "critic_loss": 66.21632385253906, "actor_loss": -466.7138977050781, "actor_target_entropy": -3.0, "actor_entropy": 0.36860185861587524, "alpha_loss": -0.2754703462123871, "alpha_value": 0.14119901711938584, "duration": 2.085947036743164, "info_normalized_performance_mean": 0.04341135919094086, "info_normalized_performance_final": 0.05249999836087227, "info_performance_mean": 0.04341135919094086, "info_performance_final": 0.05249999836087227, "step": 14500}
{"episode_reward": 86.82272727272714, "episode": 146.0, "batch_reward": 5.228287696838379, "critic_loss": 121.21122741699219, "actor_loss": -480.9275207519531, "actor_target_entropy": -3.0, "actor_entropy": 0.2542193830013275, "alpha_loss": -0.2739068269729614, "alpha_value": 0.14484845449202738, "duration": 1.6086676120758057, "info_normalized_performance_mean": 0.506266713142395, "info_normalized_performance_final": 0.550000011920929, "info_performance_mean": 0.506266713142395, "info_performance_final": 0.550000011920929, "step": 15000}
{"episode_reward": 1012.5333333333333, "episode": 151.0, "batch_reward": 5.077394485473633, "critic_loss": 34.13022994995117, "actor_loss": -481.98284912109375, "actor_target_entropy": -3.0, "actor_entropy": 0.6337263584136963, "alpha_loss": -0.34713634848594666, "alpha_value": 0.14884381846516428, "duration": 1.5325901508331299, "info_normalized_performance_mean": 0.3657967746257782, "info_normalized_performance_final": 0.4046874940395355, "info_performance_mean": 0.3657967746257782, "info_performance_final": 0.4046874940395355, "step": 15500}
{"episode_reward": 731.59375, "episode": 156.0, "batch_reward": 5.353186130523682, "critic_loss": 127.37582397460938, "actor_loss": -520.2094116210938, "actor_target_entropy": -3.0, "actor_entropy": 0.45239782333374023, "alpha_loss": -0.2797476649284363, "alpha_value": 0.15312613468578226, "duration": 1.6917314529418945, "info_normalized_performance_mean": 0.43479713797569275, "info_normalized_performance_final": 0.4761904776096344, "info_performance_mean": 0.43479713797569275, "info_performance_final": 0.4761904776096344, "step": 16000}
{"episode_reward": 869.5943562610225, "episode": 161.0, "batch_reward": 4.974098205566406, "critic_loss": 107.96019744873047, "actor_loss": -516.6021118164062, "actor_target_entropy": -3.0, "actor_entropy": 0.5800168514251709, "alpha_loss": -0.3278118371963501, "alpha_value": 0.15744105700186586, "duration": 1.5304715633392334, "info_normalized_performance_mean": 0.4936286211013794, "info_normalized_performance_final": 0.5471428632736206, "info_performance_mean": 0.4936286211013794, "info_performance_final": 0.5471428632736206, "step": 16500}
{"episode_reward": 987.2571428571441, "episode": 166.0, "batch_reward": 6.069952487945557, "critic_loss": 77.21204376220703, "actor_loss": -565.5325927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.025727979838848114, "alpha_loss": -0.32082489132881165, "alpha_value": 0.16195058318913164, "duration": 1.4586820602416992, "info_normalized_performance_mean": 0.21646003425121307, "info_normalized_performance_final": 0.23800000548362732, "info_performance_mean": 0.21646003425121307, "info_performance_final": 0.23800000548362732, "step": 17000}
{"episode_reward": 432.9199999999995, "episode": 171.0, "batch_reward": 5.465726852416992, "critic_loss": 61.2646598815918, "actor_loss": -569.20654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8194077610969543, "alpha_loss": -0.2858044505119324, "alpha_value": 0.16610791048061593, "duration": 1.4763805866241455, "info_normalized_performance_mean": 0.30426138639450073, "info_normalized_performance_final": 0.35653409361839294, "info_performance_mean": 0.30426138639450073, "info_performance_final": 0.35653409361839294, "step": 17500}
{"episode_reward": 608.5227272727277, "episode": 176.0, "batch_reward": 5.3768510818481445, "critic_loss": 199.75802612304688, "actor_loss": -573.6282958984375, "actor_target_entropy": -3.0, "actor_entropy": 0.23084808886051178, "alpha_loss": -0.3541487455368042, "alpha_value": 0.17026420861322453, "duration": 1.429180383682251, "info_normalized_performance_mean": 0.24631255865097046, "info_normalized_performance_final": 0.27031248807907104, "info_performance_mean": 0.24631255865097046, "info_performance_final": 0.27031248807907104, "step": 18000}
{"episode_reward": 492.625, "episode": 181.0, "batch_reward": 6.099963665008545, "critic_loss": 83.98688507080078, "actor_loss": -593.139892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.2665061950683594, "alpha_loss": -0.3239789605140686, "alpha_value": 0.17464812950535688, "duration": 1.5624744892120361, "info_normalized_performance_mean": 0.6751763820648193, "info_normalized_performance_final": 0.7341176271438599, "info_performance_mean": 0.6751763820648193, "info_performance_final": 0.7341176271438599, "step": 18500}
{"episode_reward": 1350.3529411764703, "episode": 186.0, "batch_reward": 4.987850666046143, "critic_loss": 881.8763427734375, "actor_loss": -597.5763549804688, "actor_target_entropy": -3.0, "actor_entropy": 0.5410647392272949, "alpha_loss": -0.3672490417957306, "alpha_value": 0.17954426554059624, "duration": 1.6848890781402588, "info_normalized_performance_mean": 0.33147311210632324, "info_normalized_performance_final": 0.42576923966407776, "info_performance_mean": 0.33147311210632324, "info_performance_final": 0.42576923966407776, "step": 19000}
{"episode_reward": 662.9461538461538, "episode": 191.0, "batch_reward": 5.631855010986328, "critic_loss": 105.51509094238281, "actor_loss": -633.9447021484375, "actor_target_entropy": -3.0, "actor_entropy": 0.48415812849998474, "alpha_loss": -0.25593650341033936, "alpha_value": 0.183940167779629, "duration": 1.843503475189209, "info_normalized_performance_mean": 0.8860576152801514, "info_normalized_performance_final": 0.9725274443626404, "info_performance_mean": 0.8860576152801514, "info_performance_final": 0.9725274443626404, "step": 19500}
{"episode_reward": 1772.1153846153868, "episode": 196.0, "batch_reward": 5.584510803222656, "critic_loss": 117.18522644042969, "actor_loss": -643.0178833007812, "actor_target_entropy": -3.0, "actor_entropy": 0.5998621582984924, "alpha_loss": -0.2830267548561096, "alpha_value": 0.18846913386277073, "step": 20000}
{"duration": 21.606786727905273, "info_normalized_performance_mean": 0.5157595872879028, "info_normalized_performance_final": 0.5532879829406738, "info_performance_mean": 0.5157595872879028, "info_performance_final": 0.5532879829406738, "step": 20000}
{"episode_reward": 1031.5192743764162, "episode": 201.0, "batch_reward": 6.506088733673096, "critic_loss": 136.377197265625, "actor_loss": -672.3796997070312, "actor_target_entropy": -3.0, "actor_entropy": 0.1626516580581665, "alpha_loss": -0.3104820251464844, "alpha_value": 0.19314281042515588, "duration": 1.7888636589050293, "info_normalized_performance_mean": 0.41932687163352966, "info_normalized_performance_final": 0.4555288553237915, "info_performance_mean": 0.41932687163352966, "info_performance_final": 0.4555288553237915, "step": 20500}
{"episode_reward": 838.6538461538452, "episode": 206.0, "batch_reward": 5.846474647521973, "critic_loss": 109.27842712402344, "actor_loss": -675.3729248046875, "actor_target_entropy": -3.0, "actor_entropy": 0.5688810348510742, "alpha_loss": -0.22564393281936646, "alpha_value": 0.1983231165808572, "duration": 1.895164966583252, "info_normalized_performance_mean": 0.5578559041023254, "info_normalized_performance_final": 0.5998263955116272, "info_performance_mean": 0.5578559041023254, "info_performance_final": 0.5998263955116272, "step": 21000}
{"episode_reward": 1115.711805555558, "episode": 211.0, "batch_reward": 6.500768661499023, "critic_loss": 174.2221221923828, "actor_loss": -705.6137084960938, "actor_target_entropy": -3.0, "actor_entropy": 0.42977917194366455, "alpha_loss": -0.26212289929389954, "alpha_value": 0.20335215950035065, "duration": 1.8548665046691895, "info_normalized_performance_mean": 0.2613708972930908, "info_normalized_performance_final": 0.29653680324554443, "info_performance_mean": 0.2613708972930908, "info_performance_final": 0.29653680324554443, "step": 21500}
{"episode_reward": 522.741702741702, "episode": 216.0, "batch_reward": 5.673065662384033, "critic_loss": 88.91799926757812, "actor_loss": -717.6900024414062, "actor_target_entropy": -3.0, "actor_entropy": 0.35849082469940186, "alpha_loss": -0.45514386892318726, "alpha_value": 0.20846098939862695, "duration": 1.847391128540039, "info_normalized_performance_mean": 0.24808897078037262, "info_normalized_performance_final": 0.879807710647583, "info_performance_mean": 0.24808897078037262, "info_performance_final": 0.879807710647583, "step": 22000}
{"episode_reward": 496.17788461538487, "episode": 221.0, "batch_reward": 5.971489429473877, "critic_loss": 1174.6591796875, "actor_loss": -721.3802490234375, "actor_target_entropy": -3.0, "actor_entropy": 0.9757318496704102, "alpha_loss": -0.29963377118110657, "alpha_value": 0.21383288394967692, "duration": 1.845534324645996, "info_normalized_performance_mean": 0.8626845479011536, "info_normalized_performance_final": 0.9957386255264282, "info_performance_mean": 0.8626845479011536, "info_performance_final": 0.9957386255264282, "step": 22500}
{"episode_reward": 1725.3693181818194, "episode": 226.0, "batch_reward": 5.6263427734375, "critic_loss": 83.4462890625, "actor_loss": -722.4130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.8630572557449341, "alpha_loss": -0.27886727452278137, "alpha_value": 0.21941779659149055, "duration": 1.6972277164459229, "info_normalized_performance_mean": 0.08259588479995728, "info_normalized_performance_final": 0.09019886702299118, "info_performance_mean": 0.08259588479995728, "info_performance_final": 0.09019886702299118, "step": 23000}
{"episode_reward": 165.19176136363632, "episode": 231.0, "batch_reward": 5.074403762817383, "critic_loss": 165.54232788085938, "actor_loss": -719.263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8217519521713257, "alpha_loss": -0.2949804961681366, "alpha_value": 0.22516845328541435, "duration": 1.683966875076294, "info_normalized_performance_mean": 0.230303555727005, "info_normalized_performance_final": 0.28928571939468384, "info_performance_mean": 0.230303555727005, "info_performance_final": 0.28928571939468384, "step": 23500}
{"episode_reward": 460.6071428571432, "episode": 236.0, "batch_reward": 6.699634552001953, "critic_loss": 257.37310791015625, "actor_loss": -770.1611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7871694564819336, "alpha_loss": -0.35327011346817017, "alpha_value": 0.23038976274054748, "duration": 1.8201684951782227, "info_normalized_performance_mean": 0.1908673346042633, "info_normalized_performance_final": 0.20663265883922577, "info_performance_mean": 0.1908673346042633, "info_performance_final": 0.20663265883922577, "step": 24000}
{"episode_reward": 381.73469387755176, "episode": 241.0, "batch_reward": 6.790672302246094, "critic_loss": 653.83642578125, "actor_loss": -782.2304077148438, "actor_target_entropy": -3.0, "actor_entropy": 0.74607253074646, "alpha_loss": -0.2625367045402527, "alpha_value": 0.23586093818769963, "duration": 1.7283189296722412, "info_normalized_performance_mean": 0.2351505160331726, "info_normalized_performance_final": 0.2713261544704437, "info_performance_mean": 0.2351505160331726, "info_performance_final": 0.2713261544704437, "step": 24500}
{"episode_reward": 470.30107526881665, "episode": 246.0, "batch_reward": 6.988487243652344, "critic_loss": 80.29595947265625, "actor_loss": -814.037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1374491453170776, "alpha_loss": -0.2545427978038788, "alpha_value": 0.24093521225411052, "duration": 1.8193814754486084, "info_normalized_performance_mean": 0.25860506296157837, "info_normalized_performance_final": 0.30924370884895325, "info_performance_mean": 0.25860506296157837, "info_performance_final": 0.30924370884895325, "step": 25000}
{"episode_reward": 517.2100840336127, "episode": 251.0, "batch_reward": 5.930209159851074, "critic_loss": 386.07257080078125, "actor_loss": -785.2056884765625, "actor_target_entropy": -3.0, "actor_entropy": 0.5386322140693665, "alpha_loss": -0.32812944054603577, "alpha_value": 0.2464255472119678, "duration": 1.7056679725646973, "info_normalized_performance_mean": 0.21741074323654175, "info_normalized_performance_final": 0.2410714328289032, "info_performance_mean": 0.21741074323654175, "info_performance_final": 0.2410714328289032, "step": 25500}
{"episode_reward": 434.8214285714282, "episode": 256.0, "batch_reward": 5.894000053405762, "critic_loss": 210.31521606445312, "actor_loss": -798.70654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8852491974830627, "alpha_loss": -0.2846693992614746, "alpha_value": 0.2526486803969758, "duration": 1.8320012092590332, "info_normalized_performance_mean": 0.37041664123535156, "info_normalized_performance_final": 0.40123456716537476, "info_performance_mean": 0.37041664123535156, "info_performance_final": 0.40123456716537476, "step": 26000}
{"episode_reward": 740.8333333333344, "episode": 261.0, "batch_reward": 6.339997291564941, "critic_loss": 60.08995819091797, "actor_loss": -824.248779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7240546941757202, "alpha_loss": -0.22613270580768585, "alpha_value": 0.25816197302868926, "duration": 1.9224450588226318, "info_normalized_performance_mean": 0.1596212238073349, "info_normalized_performance_final": 0.18147383630275726, "info_performance_mean": 0.1596212238073349, "info_performance_final": 0.18147383630275726, "step": 26500}
{"episode_reward": 319.24242424242385, "episode": 266.0, "batch_reward": 6.535347938537598, "critic_loss": 147.31195068359375, "actor_loss": -844.35302734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9103942513465881, "alpha_loss": -0.3176925778388977, "alpha_value": 0.26427090996801295, "duration": 1.800109624862671, "info_normalized_performance_mean": 0.19846706092357635, "info_normalized_performance_final": 0.2189137041568756, "info_performance_mean": 0.19846706092357635, "info_performance_final": 0.2189137041568756, "step": 27000}
{"episode_reward": 396.934105321202, "episode": 271.0, "batch_reward": 6.034336566925049, "critic_loss": 190.35299682617188, "actor_loss": -854.3280029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7528212070465088, "alpha_loss": -0.4301452338695526, "alpha_value": 0.2713744917565204, "duration": 1.6836435794830322, "info_normalized_performance_mean": 0.35791015625, "info_normalized_performance_final": 0.384765625, "info_performance_mean": 0.35791015625, "info_performance_final": 0.384765625, "step": 27500}
{"episode_reward": 715.8203125, "episode": 276.0, "batch_reward": 6.094275951385498, "critic_loss": 105.93829345703125, "actor_loss": -844.9323120117188, "actor_target_entropy": -3.0, "actor_entropy": 0.7249903678894043, "alpha_loss": -0.37635254859924316, "alpha_value": 0.27882688956105955, "duration": 2.0790982246398926, "info_normalized_performance_mean": 0.027005499228835106, "info_normalized_performance_final": 0.029914529994130135, "info_performance_mean": 0.027005499228835106, "info_performance_final": 0.029914529994130135, "step": 28000}
{"episode_reward": 54.010989010988965, "episode": 281.0, "batch_reward": 6.522769927978516, "critic_loss": 87.86349487304688, "actor_loss": -864.2314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.188662052154541, "alpha_loss": -0.36437568068504333, "alpha_value": 0.28528497181745555, "duration": 1.6776213645935059, "info_normalized_performance_mean": 0.16845837235450745, "info_normalized_performance_final": 0.184523805975914, "info_performance_mean": 0.16845837235450745, "info_performance_final": 0.184523805975914, "step": 28500}
{"episode_reward": 336.9166666666674, "episode": 286.0, "batch_reward": 5.995607376098633, "critic_loss": 129.33152770996094, "actor_loss": -867.1480712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.8935337066650391, "alpha_loss": -0.13745710253715515, "alpha_value": 0.29284332283566467, "duration": 1.8426282405853271, "info_normalized_performance_mean": 0.361093670129776, "info_normalized_performance_final": 0.3968099057674408, "info_performance_mean": 0.361093670129776, "info_performance_final": 0.3968099057674408, "step": 29000}
{"episode_reward": 722.1874999999994, "episode": 291.0, "batch_reward": 6.162614822387695, "critic_loss": 173.58383178710938, "actor_loss": -869.6586303710938, "actor_target_entropy": -3.0, "actor_entropy": 1.2325935363769531, "alpha_loss": -0.17403778433799744, "alpha_value": 0.2989544461930592, "duration": 1.7658326625823975, "info_normalized_performance_mean": 0.28044643998146057, "info_normalized_performance_final": 0.3035714328289032, "info_performance_mean": 0.28044643998146057, "info_performance_final": 0.3035714328289032, "step": 29500}
{"episode_reward": 560.8928571428565, "episode": 296.0, "batch_reward": 5.997219085693359, "critic_loss": 77.71672058105469, "actor_loss": -890.2637939453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9006022214889526, "alpha_loss": -0.21829523146152496, "alpha_value": 0.3056685222312857, "step": 30000}
{"duration": 21.83546471595764, "info_normalized_performance_mean": 0.6809150576591492, "info_normalized_performance_final": 0.7321428656578064, "info_performance_mean": 0.6809150576591492, "info_performance_final": 0.7321428656578064, "step": 30000}
{"episode_reward": 1361.8303571428557, "episode": 301.0, "batch_reward": 6.587282657623291, "critic_loss": 105.85584259033203, "actor_loss": -891.3369140625, "actor_target_entropy": -3.0, "actor_entropy": 1.0241270065307617, "alpha_loss": -0.29025256633758545, "alpha_value": 0.3127977165920009, "duration": 1.6594867706298828, "info_normalized_performance_mean": 0.5897856950759888, "info_normalized_performance_final": 0.6321428418159485, "info_performance_mean": 0.5897856950759888, "info_performance_final": 0.6321428418159485, "step": 30500}
{"episode_reward": 1179.5714285714273, "episode": 306.0, "batch_reward": 5.881196022033691, "critic_loss": 201.25723266601562, "actor_loss": -888.179931640625, "actor_target_entropy": -3.0, "actor_entropy": 0.9793612957000732, "alpha_loss": -0.2773051857948303, "alpha_value": 0.31963805785461247, "duration": 1.8570845127105713, "info_normalized_performance_mean": 0.7225715517997742, "info_normalized_performance_final": 0.7771428823471069, "info_performance_mean": 0.7225715517997742, "info_performance_final": 0.7771428823471069, "step": 31000}
{"episode_reward": 1445.1428571428569, "episode": 311.0, "batch_reward": 6.395513534545898, "critic_loss": 113.63922119140625, "actor_loss": -943.40478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8879046440124512, "alpha_loss": -0.21986383199691772, "alpha_value": 0.3264704065409072, "duration": 1.8249011039733887, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 31500}
{"episode_reward": 0.0, "episode": 316.0, "batch_reward": 6.271173477172852, "critic_loss": 120.77064514160156, "actor_loss": -943.9656372070312, "actor_target_entropy": -3.0, "actor_entropy": 1.1189637184143066, "alpha_loss": -0.2714858949184418, "alpha_value": 0.3350686542345371, "duration": 1.9149572849273682, "info_normalized_performance_mean": 0.2864086925983429, "info_normalized_performance_final": 0.31812170147895813, "info_performance_mean": 0.2864086925983429, "info_performance_final": 0.31812170147895813, "step": 32000}
{"episode_reward": 572.8174603174606, "episode": 321.0, "batch_reward": 5.744128227233887, "critic_loss": 150.128173828125, "actor_loss": -935.8043212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.873834490776062, "alpha_loss": -0.44926193356513977, "alpha_value": 0.34316741134348894, "duration": 1.8936147689819336, "info_normalized_performance_mean": 0.2718331515789032, "info_normalized_performance_final": 0.34203606843948364, "info_performance_mean": 0.2718331515789032, "info_performance_final": 0.34203606843948364, "step": 32500}
{"episode_reward": 543.6664162284003, "episode": 326.0, "batch_reward": 6.215725421905518, "critic_loss": 87.09429931640625, "actor_loss": -955.4304809570312, "actor_target_entropy": -3.0, "actor_entropy": 0.9831650257110596, "alpha_loss": -0.2569388449192047, "alpha_value": 0.35210934653490206, "duration": 1.7163920402526855, "info_normalized_performance_mean": 0.0963960811495781, "info_normalized_performance_final": 0.1071428582072258, "info_performance_mean": 0.0963960811495781, "info_performance_final": 0.1071428582072258, "step": 33000}
{"episode_reward": 192.7922077922076, "episode": 331.0, "batch_reward": 7.201188087463379, "critic_loss": 205.1828155517578, "actor_loss": -1003.4655151367188, "actor_target_entropy": -3.0, "actor_entropy": 0.828000009059906, "alpha_loss": -0.28690314292907715, "alpha_value": 0.3597671880548901, "duration": 1.9087769985198975, "info_normalized_performance_mean": 0.22093403339385986, "info_normalized_performance_final": 0.2611416280269623, "info_performance_mean": 0.22093403339385986, "info_performance_final": 0.2611416280269623, "step": 33500}
{"episode_reward": 441.8681318681317, "episode": 336.0, "batch_reward": 6.020800590515137, "critic_loss": 489.2829895019531, "actor_loss": -959.7376708984375, "actor_target_entropy": -3.0, "actor_entropy": 1.458975911140442, "alpha_loss": -0.20913705229759216, "alpha_value": 0.36760615708752997, "duration": 1.7466576099395752, "info_normalized_performance_mean": 0.36824631690979004, "info_normalized_performance_final": 0.4065934121608734, "info_performance_mean": 0.36824631690979004, "info_performance_final": 0.4065934121608734, "step": 34000}
{"episode_reward": 736.492673992675, "episode": 341.0, "batch_reward": 6.518965244293213, "critic_loss": 214.77719116210938, "actor_loss": -982.57470703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9067057967185974, "alpha_loss": -0.12964856624603271, "alpha_value": 0.3738762562920263, "duration": 1.8466904163360596, "info_normalized_performance_mean": 0.042759522795677185, "info_normalized_performance_final": 0.14452381432056427, "info_performance_mean": 0.042759522795677185, "info_performance_final": 0.14452381432056427, "step": 34500}
{"episode_reward": 85.51904761904764, "episode": 346.0, "batch_reward": 5.829667091369629, "critic_loss": 167.5987548828125, "actor_loss": -973.8997802734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9367031455039978, "alpha_loss": -0.22992190718650818, "alpha_value": 0.3804831783040451, "duration": 1.8597939014434814, "info_normalized_performance_mean": 0.1957230567932129, "info_normalized_performance_final": 0.2507692277431488, "info_performance_mean": 0.1957230567932129, "info_performance_final": 0.2507692277431488, "step": 35000}
{"episode_reward": 391.446153846154, "episode": 351.0, "batch_reward": 6.196352005004883, "critic_loss": 125.37196350097656, "actor_loss": -1001.9369506835938, "actor_target_entropy": -3.0, "actor_entropy": 1.1121530532836914, "alpha_loss": 0.04215486720204353, "alpha_value": 0.38589759254151296, "duration": 1.780925989151001, "info_normalized_performance_mean": 0.3634862005710602, "info_normalized_performance_final": 0.48620128631591797, "info_performance_mean": 0.3634862005710602, "info_performance_final": 0.48620128631591797, "step": 35500}
{"episode_reward": 726.972402597403, "episode": 356.0, "batch_reward": 7.228257656097412, "critic_loss": 141.31961059570312, "actor_loss": -1019.3248291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1927540302276611, "alpha_loss": -0.007445491850376129, "alpha_value": 0.3892388367824365, "duration": 1.9135029315948486, "info_normalized_performance_mean": 0.8195295929908752, "info_normalized_performance_final": 0.9203619956970215, "info_performance_mean": 0.8195295929908752, "info_performance_final": 0.9203619956970215, "step": 36000}
{"episode_reward": 1639.0588235294083, "episode": 361.0, "batch_reward": 6.043778419494629, "critic_loss": 111.9349365234375, "actor_loss": -1013.75244140625, "actor_target_entropy": -3.0, "actor_entropy": 1.0550141334533691, "alpha_loss": -0.12926003336906433, "alpha_value": 0.3931540777889417, "duration": 1.9101972579956055, "info_normalized_performance_mean": 0.47707799077033997, "info_normalized_performance_final": 0.5670995712280273, "info_performance_mean": 0.47707799077033997, "info_performance_final": 0.5670995712280273, "step": 36500}
{"episode_reward": 954.1558441558458, "episode": 366.0, "batch_reward": 5.75330114364624, "critic_loss": 145.93963623046875, "actor_loss": -993.9157104492188, "actor_target_entropy": -3.0, "actor_entropy": 1.0448148250579834, "alpha_loss": 0.010556533932685852, "alpha_value": 0.39765945207681336, "duration": 1.8727750778198242, "info_normalized_performance_mean": 0.7661334276199341, "info_normalized_performance_final": 0.8422222137451172, "info_performance_mean": 0.7661334276199341, "info_performance_final": 0.8422222137451172, "step": 37000}
{"episode_reward": 1532.266666666666, "episode": 371.0, "batch_reward": 5.950194835662842, "critic_loss": 171.57568359375, "actor_loss": -1002.5563354492188, "actor_target_entropy": -3.0, "actor_entropy": 1.0757237672805786, "alpha_loss": 0.0607316717505455, "alpha_value": 0.40029715121898596, "duration": 1.8317582607269287, "info_normalized_performance_mean": 0.901326596736908, "info_normalized_performance_final": 0.9897959232330322, "info_performance_mean": 0.901326596736908, "info_performance_final": 0.9897959232330322, "step": 37500}
{"episode_reward": 1802.6530612244926, "episode": 376.0, "batch_reward": 6.371829509735107, "critic_loss": 210.32785034179688, "actor_loss": -1016.04345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0440194606781006, "alpha_loss": -0.07393084466457367, "alpha_value": 0.40580220722032406, "duration": 1.5528383255004883, "info_normalized_performance_mean": 0.7059028744697571, "info_normalized_performance_final": 0.7743055820465088, "info_performance_mean": 0.7059028744697571, "info_performance_final": 0.7743055820465088, "step": 38000}
{"episode_reward": 1411.8055555555538, "episode": 381.0, "batch_reward": 6.921100616455078, "critic_loss": 173.31207275390625, "actor_loss": -1040.615478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.2286159992218018, "alpha_loss": -0.03832479938864708, "alpha_value": 0.41386293662424695, "duration": 1.3921914100646973, "info_normalized_performance_mean": 0.23554565012454987, "info_normalized_performance_final": 0.2549603283405304, "info_performance_mean": 0.23554565012454987, "info_performance_final": 0.2549603283405304, "step": 38500}
{"episode_reward": 471.0912698412691, "episode": 386.0, "batch_reward": 5.714902400970459, "critic_loss": 233.29806518554688, "actor_loss": -989.9529418945312, "actor_target_entropy": -3.0, "actor_entropy": 1.3353559970855713, "alpha_loss": 0.01908932998776436, "alpha_value": 0.422063223312574, "duration": 1.589228868484497, "info_normalized_performance_mean": 0.5155291557312012, "info_normalized_performance_final": 0.5617284178733826, "info_performance_mean": 0.5155291557312012, "info_performance_final": 0.5617284178733826, "step": 39000}
{"episode_reward": 1031.0582010581998, "episode": 391.0, "batch_reward": 5.409075736999512, "critic_loss": 196.55819702148438, "actor_loss": -1021.5731201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5458900928497314, "alpha_loss": -0.23973172903060913, "alpha_value": 0.4286702577760244, "duration": 1.453843116760254, "info_normalized_performance_mean": 0.3216709494590759, "info_normalized_performance_final": 0.34566327929496765, "info_performance_mean": 0.3216709494590759, "info_performance_final": 0.34566327929496765, "step": 39500}
{"episode_reward": 643.3418367346939, "episode": 396.0, "batch_reward": 6.294680595397949, "critic_loss": 672.0582885742188, "actor_loss": -1027.7659912109375, "actor_target_entropy": -3.0, "actor_entropy": 1.13141930103302, "alpha_loss": -0.019453009590506554, "alpha_value": 0.43507151116249987, "step": 40000}
{"duration": 18.247112274169922, "info_normalized_performance_mean": 0.5393359661102295, "info_normalized_performance_final": 0.58984375, "info_performance_mean": 0.5393359661102295, "info_performance_final": 0.58984375, "step": 40000}
{"episode_reward": 1078.671875, "episode": 401.0, "batch_reward": 6.886923789978027, "critic_loss": 407.3878173828125, "actor_loss": -1082.505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.3459196090698242, "alpha_loss": -0.20867034792900085, "alpha_value": 0.4436324646758354, "duration": 1.5669538974761963, "info_normalized_performance_mean": 0.0729999914765358, "info_normalized_performance_final": 0.08285713940858841, "info_performance_mean": 0.0729999914765358, "info_performance_final": 0.08285713940858841, "step": 40500}
{"episode_reward": 145.99999999999994, "episode": 406.0, "batch_reward": 6.787474632263184, "critic_loss": 282.3609619140625, "actor_loss": -1082.3558349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.052825689315796, "alpha_loss": -0.2524324655532837, "alpha_value": 0.45185612580070533, "duration": 1.6239826679229736, "info_normalized_performance_mean": 0.6172334551811218, "info_normalized_performance_final": 0.6816666722297668, "info_performance_mean": 0.6172334551811218, "info_performance_final": 0.6816666722297668, "step": 41000}
{"episode_reward": 1234.4666666666678, "episode": 411.0, "batch_reward": 6.905987739562988, "critic_loss": 179.1664276123047, "actor_loss": -1134.705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.058188796043396, "alpha_loss": 0.04595360904932022, "alpha_value": 0.46053569174558856, "duration": 1.4451391696929932, "info_normalized_performance_mean": 0.38684380054473877, "info_normalized_performance_final": 0.4147321283817291, "info_performance_mean": 0.38684380054473877, "info_performance_final": 0.4147321283817291, "step": 41500}
{"episode_reward": 773.6875000000003, "episode": 416.0, "batch_reward": 6.717568397521973, "critic_loss": 280.0911865234375, "actor_loss": -1111.900146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.9357389211654663, "alpha_loss": -0.023370355367660522, "alpha_value": 0.4662839799088843, "duration": 1.4365732669830322, "info_normalized_performance_mean": 0.08887583017349243, "info_normalized_performance_final": 0.09673202782869339, "info_performance_mean": 0.08887583017349243, "info_performance_final": 0.09673202782869339, "step": 42000}
{"episode_reward": 177.75163398692771, "episode": 421.0, "batch_reward": 6.990505218505859, "critic_loss": 211.7827606201172, "actor_loss": -1100.20263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1177834272384644, "alpha_loss": 0.20860621333122253, "alpha_value": 0.4697457959364256, "duration": 1.4036815166473389, "info_normalized_performance_mean": 0.35380101203918457, "info_normalized_performance_final": 0.42091837525367737, "info_performance_mean": 0.35380101203918457, "info_performance_final": 0.42091837525367737, "step": 42500}
{"episode_reward": 707.602040816327, "episode": 426.0, "batch_reward": 7.377137660980225, "critic_loss": 416.39453125, "actor_loss": -1105.49658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1935832500457764, "alpha_loss": -0.06343746185302734, "alpha_value": 0.4756744562475016, "duration": 1.489330768585205, "info_normalized_performance_mean": 0.38553565740585327, "info_normalized_performance_final": 0.45695969462394714, "info_performance_mean": 0.38553565740585327, "info_performance_final": 0.45695969462394714, "step": 43000}
{"episode_reward": 771.0714285714296, "episode": 431.0, "batch_reward": 6.3984785079956055, "critic_loss": 340.33734130859375, "actor_loss": -1092.7274169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3690288066864014, "alpha_loss": 0.05254644155502319, "alpha_value": 0.4811506879747549, "duration": 1.574493169784546, "info_normalized_performance_mean": 0.5605332851409912, "info_normalized_performance_final": 0.6166666746139526, "info_performance_mean": 0.5605332851409912, "info_performance_final": 0.6166666746139526, "step": 43500}
{"episode_reward": 1121.0666666666673, "episode": 436.0, "batch_reward": 6.286675453186035, "critic_loss": 300.53924560546875, "actor_loss": -1116.3062744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.1271480321884155, "alpha_loss": -0.0618891641497612, "alpha_value": 0.4841025220200965, "duration": 1.4857378005981445, "info_normalized_performance_mean": 0.30566757917404175, "info_normalized_performance_final": 0.3735795319080353, "info_performance_mean": 0.30566757917404175, "info_performance_final": 0.3735795319080353, "step": 44000}
{"episode_reward": 611.3352272727277, "episode": 441.0, "batch_reward": 6.739978790283203, "critic_loss": 553.0916137695312, "actor_loss": -1103.3984375, "actor_target_entropy": -3.0, "actor_entropy": 1.6145480871200562, "alpha_loss": -0.0630941390991211, "alpha_value": 0.4825273492666838, "duration": 1.570824146270752, "info_normalized_performance_mean": 0.34806740283966064, "info_normalized_performance_final": 0.4173789322376251, "info_performance_mean": 0.34806740283966064, "info_performance_final": 0.4173789322376251, "step": 44500}
{"episode_reward": 696.1348528015183, "episode": 446.0, "batch_reward": 6.584037780761719, "critic_loss": 267.694580078125, "actor_loss": -1132.412841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.2870409488677979, "alpha_loss": -0.05220239609479904, "alpha_value": 0.48117522050080724, "duration": 1.395850419998169, "info_normalized_performance_mean": 0.3923931419849396, "info_normalized_performance_final": 0.420634925365448, "info_performance_mean": 0.3923931419849396, "info_performance_final": 0.420634925365448, "step": 45000}
{"episode_reward": 784.7863247863258, "episode": 451.0, "batch_reward": 6.821995735168457, "critic_loss": 182.7544708251953, "actor_loss": -1100.140869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.5124921798706055, "alpha_loss": 0.3761688470840454, "alpha_value": 0.4747664022504496, "duration": 1.688091516494751, "info_normalized_performance_mean": 0.27847716212272644, "info_normalized_performance_final": 0.31283068656921387, "info_performance_mean": 0.27847716212272644, "info_performance_final": 0.31283068656921387, "step": 45500}
{"episode_reward": 556.9543650793653, "episode": 456.0, "batch_reward": 5.613818168640137, "critic_loss": 152.6958770751953, "actor_loss": -1040.638427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.5933001041412354, "alpha_loss": 0.2633933424949646, "alpha_value": 0.4651575952518315, "duration": 1.4533095359802246, "info_normalized_performance_mean": 0.5837946534156799, "info_normalized_performance_final": 0.640625, "info_performance_mean": 0.5837946534156799, "info_performance_final": 0.640625, "step": 46000}
{"episode_reward": 1167.5892857142858, "episode": 461.0, "batch_reward": 7.1232733726501465, "critic_loss": 726.8578491210938, "actor_loss": -1114.4068603515625, "actor_target_entropy": -3.0, "actor_entropy": 1.5089471340179443, "alpha_loss": -0.0038526803255081177, "alpha_value": 0.45817036753082563, "duration": 1.5135071277618408, "info_normalized_performance_mean": 0.1847255378961563, "info_normalized_performance_final": 0.21470588445663452, "info_performance_mean": 0.1847255378961563, "info_performance_final": 0.21470588445663452, "step": 46500}
{"episode_reward": 369.450980392157, "episode": 466.0, "batch_reward": 6.480040073394775, "critic_loss": 152.51498413085938, "actor_loss": -1076.644775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.458261489868164, "alpha_loss": 0.2931766211986542, "alpha_value": 0.45205484065478674, "duration": 1.5731143951416016, "info_normalized_performance_mean": 0.35252606868743896, "info_normalized_performance_final": 0.3888888955116272, "info_performance_mean": 0.35252606868743896, "info_performance_final": 0.3888888955116272, "step": 47000}
{"episode_reward": 705.0520833333343, "episode": 471.0, "batch_reward": 5.895902633666992, "critic_loss": 290.1954345703125, "actor_loss": -1087.1541748046875, "actor_target_entropy": -3.0, "actor_entropy": 1.4376333951950073, "alpha_loss": 0.2136489599943161, "alpha_value": 0.4504115896480378, "duration": 1.5754730701446533, "info_normalized_performance_mean": 0.6195489764213562, "info_normalized_performance_final": 0.6656862497329712, "info_performance_mean": 0.6195489764213562, "info_performance_final": 0.6656862497329712, "step": 47500}
{"episode_reward": 1239.0980392156832, "episode": 476.0, "batch_reward": 6.643834114074707, "critic_loss": 377.38592529296875, "actor_loss": -1119.89501953125, "actor_target_entropy": -3.0, "actor_entropy": 1.355275273323059, "alpha_loss": -0.0038325637578964233, "alpha_value": 0.45068958784114443, "duration": 1.4468581676483154, "info_normalized_performance_mean": 0.08242513984441757, "info_normalized_performance_final": 0.0885416641831398, "info_performance_mean": 0.08242513984441757, "info_performance_final": 0.0885416641831398, "step": 48000}
{"episode_reward": 164.8502604166667, "episode": 481.0, "batch_reward": 7.343847274780273, "critic_loss": 520.2281494140625, "actor_loss": -1171.0115966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3402643203735352, "alpha_loss": 0.04607558250427246, "alpha_value": 0.447822460116278, "duration": 1.47908616065979, "info_normalized_performance_mean": 0.41830727458000183, "info_normalized_performance_final": 0.4435763955116272, "info_performance_mean": 0.41830727458000183, "info_performance_final": 0.4435763955116272, "step": 48500}
{"episode_reward": 836.6145833333348, "episode": 486.0, "batch_reward": 7.13850736618042, "critic_loss": 312.3147888183594, "actor_loss": -1161.4168701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2718907594680786, "alpha_loss": 0.18481218814849854, "alpha_value": 0.44524837162273506, "duration": 1.5947010517120361, "info_normalized_performance_mean": 0.4757640063762665, "info_normalized_performance_final": 0.5090277791023254, "info_performance_mean": 0.4757640063762665, "info_performance_final": 0.5090277791023254, "step": 49000}
{"episode_reward": 951.5277777777768, "episode": 491.0, "batch_reward": 7.106131553649902, "critic_loss": 307.7691650390625, "actor_loss": -1164.209716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1154929399490356, "alpha_loss": -0.13730892539024353, "alpha_value": 0.44227494065171313, "duration": 1.4218947887420654, "info_normalized_performance_mean": 0.3420031666755676, "info_normalized_performance_final": 0.3947649598121643, "info_performance_mean": 0.3420031666755676, "info_performance_final": 0.3947649598121643, "step": 49500}
{"episode_reward": 684.0064102564107, "episode": 496.0, "batch_reward": 7.082727432250977, "critic_loss": 578.04736328125, "actor_loss": -1145.9632568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.0437750816345215, "alpha_loss": -0.02975398674607277, "alpha_value": 0.43766914422819225, "step": 50000}
{"duration": 18.56046485900879, "info_normalized_performance_mean": 0.07687143236398697, "info_normalized_performance_final": 0.09285714477300644, "info_performance_mean": 0.07687143236398697, "info_performance_final": 0.09285714477300644, "step": 50000}
{"episode_reward": 153.7428571428573, "episode": 501.0, "batch_reward": 7.383642196655273, "critic_loss": 1091.4951171875, "actor_loss": -1193.073486328125, "actor_target_entropy": -3.0, "actor_entropy": 1.190199613571167, "alpha_loss": -0.06998451054096222, "alpha_value": 0.43530337621753695, "duration": 1.512882947921753, "info_normalized_performance_mean": 0.4266287088394165, "info_normalized_performance_final": 0.4595761299133301, "info_performance_mean": 0.4266287088394165, "info_performance_final": 0.4595761299133301, "step": 50500}
{"episode_reward": 853.2574568288838, "episode": 506.0, "batch_reward": 6.572163105010986, "critic_loss": 620.8577270507812, "actor_loss": -1121.606201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.175573706626892, "alpha_loss": -0.2351876199245453, "alpha_value": 0.43255600308047415, "duration": 1.5728111267089844, "info_normalized_performance_mean": 0.4411698281764984, "info_normalized_performance_final": 0.5438253283500671, "info_performance_mean": 0.4411698281764984, "info_performance_final": 0.5438253283500671, "step": 51000}
{"episode_reward": 882.3395242750071, "episode": 511.0, "batch_reward": 6.1140899658203125, "critic_loss": 369.6755065917969, "actor_loss": -1130.925048828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3922557830810547, "alpha_loss": 0.15071314573287964, "alpha_value": 0.4332304039268795, "duration": 1.5433058738708496, "info_normalized_performance_mean": 0.2754652798175812, "info_normalized_performance_final": 0.2958333194255829, "info_performance_mean": 0.2754652798175812, "info_performance_final": 0.2958333194255829, "step": 51500}
{"episode_reward": 550.930555555556, "episode": 516.0, "batch_reward": 6.832489013671875, "critic_loss": 268.1405334472656, "actor_loss": -1184.771728515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9764536619186401, "alpha_loss": 0.2862228751182556, "alpha_value": 0.4345040549793603, "duration": 1.4390254020690918, "info_normalized_performance_mean": 0.27511993050575256, "info_normalized_performance_final": 0.31186869740486145, "info_performance_mean": 0.27511993050575256, "info_performance_final": 0.31186869740486145, "step": 52000}
{"episode_reward": 550.239898989899, "episode": 521.0, "batch_reward": 6.593823432922363, "critic_loss": 626.25146484375, "actor_loss": -1184.8865966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.149223804473877, "alpha_loss": -0.035382308065891266, "alpha_value": 0.43355174497297533, "duration": 1.474863052368164, "info_normalized_performance_mean": 0.30119311809539795, "info_normalized_performance_final": 0.3920722007751465, "info_performance_mean": 0.30119311809539795, "info_performance_final": 0.3920722007751465, "step": 52500}
{"episode_reward": 602.3861852433281, "episode": 526.0, "batch_reward": 5.901721000671387, "critic_loss": 499.0185546875, "actor_loss": -1146.2178955078125, "actor_target_entropy": -3.0, "actor_entropy": 1.1091233491897583, "alpha_loss": -0.08691585063934326, "alpha_value": 0.43488970509193203, "duration": 1.4640562534332275, "info_normalized_performance_mean": 0.2603296935558319, "info_normalized_performance_final": 0.32692307233810425, "info_performance_mean": 0.2603296935558319, "info_performance_final": 0.32692307233810425, "step": 53000}
{"episode_reward": 520.6593406593405, "episode": 531.0, "batch_reward": 7.002671241760254, "critic_loss": 364.2835998535156, "actor_loss": -1160.9078369140625, "actor_target_entropy": -3.0, "actor_entropy": 1.0729352235794067, "alpha_loss": 0.07599812000989914, "alpha_value": 0.4340327797000806, "duration": 1.594573736190796, "info_normalized_performance_mean": 0.5013453960418701, "info_normalized_performance_final": 0.5418182015419006, "info_performance_mean": 0.5013453960418701, "info_performance_final": 0.5418182015419006, "step": 53500}
{"episode_reward": 1002.6909090909103, "episode": 536.0, "batch_reward": 6.905125141143799, "critic_loss": 198.5432891845703, "actor_loss": -1210.5621337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0308477878570557, "alpha_loss": 0.13384808599948883, "alpha_value": 0.43286080998005694, "duration": 1.602863073348999, "info_normalized_performance_mean": 0.2957482635974884, "info_normalized_performance_final": 0.3920068144798279, "info_performance_mean": 0.2957482635974884, "info_performance_final": 0.3920068144798279, "step": 54000}
{"episode_reward": 591.4965986394557, "episode": 541.0, "batch_reward": 6.675504684448242, "critic_loss": 183.34722900390625, "actor_loss": -1223.6083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.7539006471633911, "alpha_loss": 0.12887278199195862, "alpha_value": 0.43367694031724435, "duration": 1.4252309799194336, "info_normalized_performance_mean": 0.23674453794956207, "info_normalized_performance_final": 0.30128204822540283, "info_performance_mean": 0.23674453794956207, "info_performance_final": 0.30128204822540283, "step": 54500}
{"episode_reward": 473.4890109890118, "episode": 546.0, "batch_reward": 6.301270961761475, "critic_loss": 1315.6116943359375, "actor_loss": -1186.25244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8637704849243164, "alpha_loss": 0.11215139925479889, "alpha_value": 0.4319842413346214, "duration": 1.7012274265289307, "info_normalized_performance_mean": 0.4111061990261078, "info_normalized_performance_final": 0.5494378209114075, "info_performance_mean": 0.4111061990261078, "info_performance_final": 0.5494378209114075, "step": 55000}
{"episode_reward": 822.2123015873028, "episode": 551.0, "batch_reward": 7.2106122970581055, "critic_loss": 393.059326171875, "actor_loss": -1226.978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1365455389022827, "alpha_loss": 0.10315608978271484, "alpha_value": 0.431340074606445, "duration": 1.5522661209106445, "info_normalized_performance_mean": 0.36228400468826294, "info_normalized_performance_final": 0.41177982091903687, "info_performance_mean": 0.36228400468826294, "info_performance_final": 0.41177982091903687, "step": 55500}
{"episode_reward": 724.5679012345679, "episode": 556.0, "batch_reward": 7.729377746582031, "critic_loss": 984.5889892578125, "actor_loss": -1273.2152099609375, "actor_target_entropy": -3.0, "actor_entropy": 0.8350684642791748, "alpha_loss": 0.009815379977226257, "alpha_value": 0.4348282172528821, "duration": 1.6205615997314453, "info_normalized_performance_mean": 0.38126975297927856, "info_normalized_performance_final": 0.45502644777297974, "info_performance_mean": 0.38126975297927856, "info_performance_final": 0.45502644777297974, "step": 56000}
{"episode_reward": 762.5396825396832, "episode": 561.0, "batch_reward": 5.672997951507568, "critic_loss": 167.5321044921875, "actor_loss": -1166.7275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0452111959457397, "alpha_loss": -0.007095322012901306, "alpha_value": 0.4352141784989332, "duration": 1.6670591831207275, "info_normalized_performance_mean": 0.21819591522216797, "info_normalized_performance_final": 0.2621527910232544, "info_performance_mean": 0.21819591522216797, "info_performance_final": 0.2621527910232544, "step": 56500}
{"episode_reward": 436.3917824074067, "episode": 566.0, "batch_reward": 6.4977312088012695, "critic_loss": 424.9761962890625, "actor_loss": -1154.96728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0722452402114868, "alpha_loss": 0.0069188885390758514, "alpha_value": 0.4354398547126112, "duration": 1.413083553314209, "info_normalized_performance_mean": 0.26849567890167236, "info_normalized_performance_final": 0.29004329442977905, "info_performance_mean": 0.26849567890167236, "info_performance_final": 0.29004329442977905, "step": 57000}
{"episode_reward": 536.9913419913414, "episode": 571.0, "batch_reward": 7.362700462341309, "critic_loss": 590.9166259765625, "actor_loss": -1225.66552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.4947500228881836, "alpha_loss": -0.02166178449988365, "alpha_value": 0.43468996929438647, "duration": 1.5301353931427002, "info_normalized_performance_mean": 0.2513468265533447, "info_normalized_performance_final": 0.2946127951145172, "info_performance_mean": 0.2513468265533447, "info_performance_final": 0.2946127951145172, "step": 57500}
{"episode_reward": 502.69360269360254, "episode": 576.0, "batch_reward": 7.129580974578857, "critic_loss": 456.4747314453125, "actor_loss": -1214.116943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.784686267375946, "alpha_loss": 0.14093346893787384, "alpha_value": 0.43729857956874185, "duration": 1.4580662250518799, "info_normalized_performance_mean": 0.4906887114048004, "info_normalized_performance_final": 0.5382652878761292, "info_performance_mean": 0.4906887114048004, "info_performance_final": 0.5382652878761292, "step": 58000}
{"episode_reward": 981.3775510204104, "episode": 581.0, "batch_reward": 6.71810245513916, "critic_loss": 652.1671142578125, "actor_loss": -1172.9990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.0722293853759766, "alpha_loss": -0.017467573285102844, "alpha_value": 0.43886418324304655, "duration": 1.4908182621002197, "info_normalized_performance_mean": 0.22679996490478516, "info_normalized_performance_final": 0.38285714387893677, "info_performance_mean": 0.22679996490478516, "info_performance_final": 0.38285714387893677, "step": 58500}
{"episode_reward": 453.5999999999999, "episode": 586.0, "batch_reward": 6.3552398681640625, "critic_loss": 408.4300537109375, "actor_loss": -1172.482177734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1809413433074951, "alpha_loss": 0.10525567829608917, "alpha_value": 0.44104274117367076, "duration": 1.508988380432129, "info_normalized_performance_mean": 0.7526785135269165, "info_normalized_performance_final": 0.8234127163887024, "info_performance_mean": 0.7526785135269165, "info_performance_final": 0.8234127163887024, "step": 59000}
{"episode_reward": 1505.3571428571433, "episode": 591.0, "batch_reward": 7.47935676574707, "critic_loss": 350.57562255859375, "actor_loss": -1265.3040771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.6731609106063843, "alpha_loss": 0.16733549535274506, "alpha_value": 0.44334783510122255, "duration": 1.4361748695373535, "info_normalized_performance_mean": 0.2860203981399536, "info_normalized_performance_final": 0.30725622177124023, "info_performance_mean": 0.2860203981399536, "info_performance_final": 0.30725622177124023, "step": 59500}
{"episode_reward": 572.0408163265312, "episode": 596.0, "batch_reward": 6.784822463989258, "critic_loss": 504.4833679199219, "actor_loss": -1256.0308837890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2174227237701416, "alpha_loss": 0.1830608993768692, "alpha_value": 0.44558958339313715, "step": 60000}
{"duration": 19.553977012634277, "info_normalized_performance_mean": 0.39141714572906494, "info_normalized_performance_final": 0.43027210235595703, "info_performance_mean": 0.39141714572906494, "info_performance_final": 0.43027210235595703, "step": 60000}
{"episode_reward": 782.8344671201801, "episode": 601.0, "batch_reward": 6.415935516357422, "critic_loss": 322.58544921875, "actor_loss": -1222.05224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.0816670656204224, "alpha_loss": -0.029224608093500137, "alpha_value": 0.4480875716159982, "duration": 1.4437742233276367, "info_normalized_performance_mean": 0.31017857789993286, "info_normalized_performance_final": 0.46071428060531616, "info_performance_mean": 0.31017857789993286, "info_performance_final": 0.46071428060531616, "step": 60500}
{"episode_reward": 620.3571428571425, "episode": 606.0, "batch_reward": 7.615930557250977, "critic_loss": 1665.02587890625, "actor_loss": -1232.72998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.0194389820098877, "alpha_loss": 0.25646212697029114, "alpha_value": 0.4501701343247512, "duration": 1.4979839324951172, "info_normalized_performance_mean": 0.42792201042175293, "info_normalized_performance_final": 0.5113636255264282, "info_performance_mean": 0.42792201042175293, "info_performance_final": 0.5113636255264282, "step": 61000}
{"episode_reward": 855.8441558441572, "episode": 611.0, "batch_reward": 7.347212791442871, "critic_loss": 1140.1064453125, "actor_loss": -1248.970947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0458776950836182, "alpha_loss": 0.05561240389943123, "alpha_value": 0.4501262368012294, "duration": 1.5250253677368164, "info_normalized_performance_mean": 0.2915108799934387, "info_normalized_performance_final": 0.38351255655288696, "info_performance_mean": 0.2915108799934387, "info_performance_final": 0.38351255655288696, "step": 61500}
{"episode_reward": 583.0217810862968, "episode": 616.0, "batch_reward": 7.187763690948486, "critic_loss": 2216.5400390625, "actor_loss": -1240.7188720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9846264123916626, "alpha_loss": 0.05250614136457443, "alpha_value": 0.45633424605306366, "duration": 1.4872612953186035, "info_normalized_performance_mean": 0.36547309160232544, "info_normalized_performance_final": 0.4865451455116272, "info_performance_mean": 0.36547309160232544, "info_performance_final": 0.4865451455116272, "step": 62000}
{"episode_reward": 730.9461805555568, "episode": 621.0, "batch_reward": 6.686093807220459, "critic_loss": 454.22705078125, "actor_loss": -1239.5263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3234734535217285, "alpha_loss": 0.10549679398536682, "alpha_value": 0.46161714042718255, "duration": 1.4463975429534912, "info_normalized_performance_mean": 0.35785117745399475, "info_normalized_performance_final": 0.4375, "info_performance_mean": 0.35785117745399475, "info_performance_final": 0.4375, "step": 62500}
{"episode_reward": 715.7023809523805, "episode": 626.0, "batch_reward": 6.817368030548096, "critic_loss": 348.68914794921875, "actor_loss": -1227.181884765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9591262936592102, "alpha_loss": -0.158362478017807, "alpha_value": 0.46585432642388, "duration": 1.4978148937225342, "info_normalized_performance_mean": 0.24890302121639252, "info_normalized_performance_final": 0.30102041363716125, "info_performance_mean": 0.24890302121639252, "info_performance_final": 0.30102041363716125, "step": 63000}
{"episode_reward": 497.8061224489793, "episode": 631.0, "batch_reward": 6.7288289070129395, "critic_loss": 277.0997314453125, "actor_loss": -1255.32763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.01759672164917, "alpha_loss": 0.0730079710483551, "alpha_value": 0.4668889246932459, "duration": 1.633362054824829, "info_normalized_performance_mean": 0.5248610973358154, "info_normalized_performance_final": 0.5748456716537476, "info_performance_mean": 0.5248610973358154, "info_performance_final": 0.5748456716537476, "step": 63500}
{"episode_reward": 1049.722222222222, "episode": 636.0, "batch_reward": 7.208241939544678, "critic_loss": 345.76141357421875, "actor_loss": -1230.1954345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0942432880401611, "alpha_loss": 0.05495771765708923, "alpha_value": 0.4688038963450553, "duration": 1.7669761180877686, "info_normalized_performance_mean": 0.32929790019989014, "info_normalized_performance_final": 0.6398046612739563, "info_performance_mean": 0.32929790019989014, "info_performance_final": 0.6398046612739563, "step": 64000}
{"episode_reward": 658.5958485958487, "episode": 641.0, "batch_reward": 6.707086563110352, "critic_loss": 1214.1552734375, "actor_loss": -1246.3255615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.0157827138900757, "alpha_loss": 0.2663123905658722, "alpha_value": 0.468623839040523, "duration": 1.4640281200408936, "info_normalized_performance_mean": 0.4351785182952881, "info_normalized_performance_final": 0.5059523582458496, "info_performance_mean": 0.4351785182952881, "info_performance_final": 0.5059523582458496, "step": 64500}
{"episode_reward": 870.3571428571414, "episode": 646.0, "batch_reward": 7.41727352142334, "critic_loss": 167.0042724609375, "actor_loss": -1277.925537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.0781731605529785, "alpha_loss": -0.023378392681479454, "alpha_value": 0.4665463958632918, "duration": 1.6091556549072266, "info_normalized_performance_mean": 0.8321449160575867, "info_normalized_performance_final": 0.9085972905158997, "info_performance_mean": 0.8321449160575867, "info_performance_final": 0.9085972905158997, "step": 65000}
{"episode_reward": 1664.2895927601844, "episode": 651.0, "batch_reward": 7.276495933532715, "critic_loss": 469.17730712890625, "actor_loss": -1226.613525390625, "actor_target_entropy": -3.0, "actor_entropy": 1.3780295848846436, "alpha_loss": 0.025819744914770126, "alpha_value": 0.46472387955664096, "duration": 1.5672507286071777, "info_normalized_performance_mean": 0.18946032226085663, "info_normalized_performance_final": 0.3523809611797333, "info_performance_mean": 0.18946032226085663, "info_performance_final": 0.3523809611797333, "step": 65500}
{"episode_reward": 378.92063492063465, "episode": 656.0, "batch_reward": 6.944300651550293, "critic_loss": 364.29986572265625, "actor_loss": -1285.9112548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8311767578125, "alpha_loss": -0.017605524510145187, "alpha_value": 0.46273902598446964, "duration": 1.4785869121551514, "info_normalized_performance_mean": 0.29298561811447144, "info_normalized_performance_final": 0.3354838788509369, "info_performance_mean": 0.29298561811447144, "info_performance_final": 0.3354838788509369, "step": 66000}
{"episode_reward": 585.9713261648743, "episode": 661.0, "batch_reward": 6.840468883514404, "critic_loss": 414.98931884765625, "actor_loss": -1245.3170166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.3494274616241455, "alpha_loss": -0.05454794317483902, "alpha_value": 0.4609111118188016, "duration": 1.6021413803100586, "info_normalized_performance_mean": 0.7812497615814209, "info_normalized_performance_final": 0.856249988079071, "info_performance_mean": 0.7812497615814209, "info_performance_final": 0.856249988079071, "step": 66500}
{"episode_reward": 1562.5, "episode": 666.0, "batch_reward": 6.334331512451172, "critic_loss": 864.3948974609375, "actor_loss": -1243.28515625, "actor_target_entropy": -3.0, "actor_entropy": 1.629660725593567, "alpha_loss": 0.18590611219406128, "alpha_value": 0.46190099041351723, "duration": 1.717832326889038, "info_normalized_performance_mean": 0.2757478654384613, "info_normalized_performance_final": 0.32451921701431274, "info_performance_mean": 0.2757478654384613, "info_performance_final": 0.32451921701431274, "step": 67000}
{"episode_reward": 551.4957264957276, "episode": 671.0, "batch_reward": 7.462688446044922, "critic_loss": 540.9437255859375, "actor_loss": -1271.482666015625, "actor_target_entropy": -3.0, "actor_entropy": 1.3238122463226318, "alpha_loss": -0.2585228383541107, "alpha_value": 0.4646419967575249, "duration": 1.5940964221954346, "info_normalized_performance_mean": 0.5549206733703613, "info_normalized_performance_final": 0.6021825671195984, "info_performance_mean": 0.5549206733703613, "info_performance_final": 0.6021825671195984, "step": 67500}
{"episode_reward": 1109.841269841272, "episode": 676.0, "batch_reward": 7.769713401794434, "critic_loss": 243.52420043945312, "actor_loss": -1267.114013671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2718820571899414, "alpha_loss": -0.055479392409324646, "alpha_value": 0.46468669474985524, "duration": 1.4610462188720703, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 68000}
{"episode_reward": 0.0, "episode": 681.0, "batch_reward": 6.227916717529297, "critic_loss": 315.417724609375, "actor_loss": -1244.022705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.3208128213882446, "alpha_loss": -0.08056584000587463, "alpha_value": 0.4582487345467833, "duration": 1.447746753692627, "info_normalized_performance_mean": 0.6721684336662292, "info_normalized_performance_final": 0.7397959232330322, "info_performance_mean": 0.6721684336662292, "info_performance_final": 0.7397959232330322, "step": 68500}
{"episode_reward": 1344.3367346938787, "episode": 686.0, "batch_reward": 7.424520492553711, "critic_loss": 187.48594665527344, "actor_loss": -1260.60693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.5662260055541992, "alpha_loss": -0.20991742610931396, "alpha_value": 0.4566526106026271, "duration": 1.6166584491729736, "info_normalized_performance_mean": 0.526334822177887, "info_normalized_performance_final": 0.579365074634552, "info_performance_mean": 0.526334822177887, "info_performance_final": 0.579365074634552, "step": 69000}
{"episode_reward": 1052.6695526695519, "episode": 691.0, "batch_reward": 6.401484489440918, "critic_loss": 495.9807434082031, "actor_loss": -1266.07373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.0448516607284546, "alpha_loss": 0.05990105867385864, "alpha_value": 0.46106478361601055, "duration": 1.5310742855072021, "info_normalized_performance_mean": 0.5442350506782532, "info_normalized_performance_final": 0.6012369990348816, "info_performance_mean": 0.5442350506782532, "info_performance_final": 0.6012369990348816, "step": 69500}
{"episode_reward": 1088.470052083334, "episode": 696.0, "batch_reward": 7.5206170082092285, "critic_loss": 339.0267028808594, "actor_loss": -1299.42041015625, "actor_target_entropy": -3.0, "actor_entropy": 1.2997870445251465, "alpha_loss": 0.06546355783939362, "alpha_value": 0.4642733717901557, "step": 70000}
{"duration": 18.323498725891113, "info_normalized_performance_mean": 0.5473254919052124, "info_normalized_performance_final": 0.60317462682724, "info_performance_mean": 0.5473254919052124, "info_performance_final": 0.60317462682724, "step": 70000}
{"episode_reward": 1094.6507936507926, "episode": 701.0, "batch_reward": 7.425533294677734, "critic_loss": 304.9749755859375, "actor_loss": -1286.990966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.6112735271453857, "alpha_loss": -0.235975980758667, "alpha_value": 0.46900118878775604, "duration": 1.4682281017303467, "info_normalized_performance_mean": 0.38966378569602966, "info_normalized_performance_final": 0.4252100884914398, "info_performance_mean": 0.38966378569602966, "info_performance_final": 0.4252100884914398, "step": 70500}
{"episode_reward": 779.3277310924378, "episode": 706.0, "batch_reward": 7.119874954223633, "critic_loss": 185.93743896484375, "actor_loss": -1320.99169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.5034186840057373, "alpha_loss": -0.19942620396614075, "alpha_value": 0.4730330859236496, "duration": 1.4670732021331787, "info_normalized_performance_mean": 0.5097389817237854, "info_normalized_performance_final": 0.6057692170143127, "info_performance_mean": 0.5097389817237854, "info_performance_final": 0.6057692170143127, "step": 71000}
{"episode_reward": 1019.4780219780235, "episode": 711.0, "batch_reward": 7.261804580688477, "critic_loss": 5102.244140625, "actor_loss": -1273.8260498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3685615062713623, "alpha_loss": 0.2667448818683624, "alpha_value": 0.47637872204744813, "duration": 1.3893117904663086, "info_normalized_performance_mean": 0.3401770293712616, "info_normalized_performance_final": 0.3742368817329407, "info_performance_mean": 0.3401770293712616, "info_performance_final": 0.3742368817329407, "step": 71500}
{"episode_reward": 680.35409035409, "episode": 716.0, "batch_reward": 6.193164825439453, "critic_loss": 816.6981201171875, "actor_loss": -1253.3438720703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1052736043930054, "alpha_loss": -0.06279899924993515, "alpha_value": 0.48519837839352997, "duration": 1.5937926769256592, "info_normalized_performance_mean": 0.5726606845855713, "info_normalized_performance_final": 0.6687783002853394, "info_performance_mean": 0.5726606845855713, "info_performance_final": 0.6687783002853394, "step": 72000}
{"episode_reward": 1145.3212669683267, "episode": 721.0, "batch_reward": 7.741942405700684, "critic_loss": 1381.9736328125, "actor_loss": -1337.625, "actor_target_entropy": -3.0, "actor_entropy": 1.437096357345581, "alpha_loss": 0.14071626961231232, "alpha_value": 0.4838656365206387, "duration": 1.6136422157287598, "info_normalized_performance_mean": 0.5836384296417236, "info_normalized_performance_final": 0.6398809552192688, "info_performance_mean": 0.5836384296417236, "info_performance_final": 0.6398809552192688, "step": 72500}
{"episode_reward": 1167.2767857142849, "episode": 726.0, "batch_reward": 6.343170166015625, "critic_loss": 900.727783203125, "actor_loss": -1275.9219970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.4853935241699219, "alpha_loss": -0.060811106115579605, "alpha_value": 0.47912327980685915, "duration": 1.406670093536377, "info_normalized_performance_mean": 0.06728123873472214, "info_normalized_performance_final": 0.07500000298023224, "info_performance_mean": 0.06728123873472214, "info_performance_final": 0.07500000298023224, "step": 73000}
{"episode_reward": 134.5625, "episode": 731.0, "batch_reward": 7.565890312194824, "critic_loss": 632.4520263671875, "actor_loss": -1302.359130859375, "actor_target_entropy": -3.0, "actor_entropy": 1.3268630504608154, "alpha_loss": 0.10042712092399597, "alpha_value": 0.4774094830677678, "duration": 1.598583459854126, "info_normalized_performance_mean": 0.18941493332386017, "info_normalized_performance_final": 0.23379729688167572, "info_performance_mean": 0.18941493332386017, "info_performance_final": 0.23379729688167572, "step": 73500}
{"episode_reward": 378.82992605480666, "episode": 736.0, "batch_reward": 7.561707496643066, "critic_loss": 476.989990234375, "actor_loss": -1308.03369140625, "actor_target_entropy": -3.0, "actor_entropy": 1.8676798343658447, "alpha_loss": -0.14528700709342957, "alpha_value": 0.4762297698378572, "duration": 1.4797842502593994, "info_normalized_performance_mean": 0.25534847378730774, "info_normalized_performance_final": 0.28156113624572754, "info_performance_mean": 0.25534847378730774, "info_performance_final": 0.28156113624572754, "step": 74000}
{"episode_reward": 510.696933492633, "episode": 741.0, "batch_reward": 7.267830848693848, "critic_loss": 559.2111206054688, "actor_loss": -1338.831787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.4483962059020996, "alpha_loss": 0.1296469271183014, "alpha_value": 0.4785918383200398, "duration": 1.5728600025177002, "info_normalized_performance_mean": 0.28568753600120544, "info_normalized_performance_final": 0.3252083361148834, "info_performance_mean": 0.28568753600120544, "info_performance_final": 0.3252083361148834, "step": 74500}
{"episode_reward": 571.3750000000005, "episode": 746.0, "batch_reward": 7.52943754196167, "critic_loss": 1443.201904296875, "actor_loss": -1331.3671875, "actor_target_entropy": -3.0, "actor_entropy": 1.37992525100708, "alpha_loss": 0.23199018836021423, "alpha_value": 0.47854128042846183, "duration": 1.508368968963623, "info_normalized_performance_mean": 0.06614086776971817, "info_normalized_performance_final": 0.0982142835855484, "info_performance_mean": 0.06614086776971817, "info_performance_final": 0.0982142835855484, "step": 75000}
{"episode_reward": 132.28174603174614, "episode": 751.0, "batch_reward": 7.4456377029418945, "critic_loss": 671.6832275390625, "actor_loss": -1313.64111328125, "actor_target_entropy": -3.0, "actor_entropy": 1.4396255016326904, "alpha_loss": 0.07856081426143646, "alpha_value": 0.48141080417826315, "duration": 1.5402300357818604, "info_normalized_performance_mean": 0.44288188219070435, "info_normalized_performance_final": 0.49537035822868347, "info_performance_mean": 0.44288188219070435, "info_performance_final": 0.49537035822868347, "step": 75500}
{"episode_reward": 885.7638888888878, "episode": 756.0, "batch_reward": 7.436266899108887, "critic_loss": 395.9796142578125, "actor_loss": -1330.2591552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.66941237449646, "alpha_loss": -0.1880299150943756, "alpha_value": 0.4849721431525999, "duration": 1.656508445739746, "info_normalized_performance_mean": 0.8388819098472595, "info_normalized_performance_final": 0.9090277552604675, "info_performance_mean": 0.8388819098472595, "info_performance_final": 0.9090277552604675, "step": 76000}
{"episode_reward": 1677.7638888888919, "episode": 761.0, "batch_reward": 6.558670520782471, "critic_loss": 346.628662109375, "actor_loss": -1316.3538818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.7336792945861816, "alpha_loss": -0.403622031211853, "alpha_value": 0.4875721216417079, "duration": 1.5757966041564941, "info_normalized_performance_mean": 0.3112967014312744, "info_normalized_performance_final": 0.37626373767852783, "info_performance_mean": 0.3112967014312744, "info_performance_final": 0.37626373767852783, "step": 76500}
{"episode_reward": 622.5934065934053, "episode": 766.0, "batch_reward": 7.605578422546387, "critic_loss": 887.372802734375, "actor_loss": -1333.7447509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.6387966871261597, "alpha_loss": 0.06956738233566284, "alpha_value": 0.4851983549081548, "duration": 1.4951765537261963, "info_normalized_performance_mean": 0.29624995589256287, "info_normalized_performance_final": 0.3611111044883728, "info_performance_mean": 0.29624995589256287, "info_performance_final": 0.3611111044883728, "step": 77000}
{"episode_reward": 592.4999999999994, "episode": 771.0, "batch_reward": 7.527179718017578, "critic_loss": 765.1837158203125, "actor_loss": -1363.7752685546875, "actor_target_entropy": -3.0, "actor_entropy": 1.7075324058532715, "alpha_loss": 0.07316004484891891, "alpha_value": 0.48782191065986097, "duration": 1.5824153423309326, "info_normalized_performance_mean": 0.4174405038356781, "info_normalized_performance_final": 0.4532313048839569, "info_performance_mean": 0.4174405038356781, "info_performance_final": 0.4532313048839569, "step": 77500}
{"episode_reward": 834.8809523809513, "episode": 776.0, "batch_reward": 6.679882049560547, "critic_loss": 6404.3876953125, "actor_loss": -1292.06396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4690015316009521, "alpha_loss": 0.08675754070281982, "alpha_value": 0.490099904437713, "duration": 1.5035598278045654, "info_normalized_performance_mean": 0.5209619998931885, "info_normalized_performance_final": 0.5892857313156128, "info_performance_mean": 0.5209619998931885, "info_performance_final": 0.5892857313156128, "step": 78000}
{"episode_reward": 1041.923701298703, "episode": 781.0, "batch_reward": 7.086094379425049, "critic_loss": 918.19677734375, "actor_loss": -1306.709228515625, "actor_target_entropy": -3.0, "actor_entropy": 1.59571373462677, "alpha_loss": 0.000563308596611023, "alpha_value": 0.49051829599430147, "duration": 1.7126240730285645, "info_normalized_performance_mean": 0.27338215708732605, "info_normalized_performance_final": 0.44810745120048523, "info_performance_mean": 0.27338215708732605, "info_performance_final": 0.44810745120048523, "step": 78500}
{"episode_reward": 546.7643467643463, "episode": 786.0, "batch_reward": 6.960613250732422, "critic_loss": 661.2489013671875, "actor_loss": -1354.4595947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.589259147644043, "alpha_loss": -0.23919209837913513, "alpha_value": 0.4922823266914723, "duration": 1.6110756397247314, "info_normalized_performance_mean": 0.7484607696533203, "info_normalized_performance_final": 0.863725483417511, "info_performance_mean": 0.7484607696533203, "info_performance_final": 0.863725483417511, "step": 79000}
{"episode_reward": 1496.9215686274495, "episode": 791.0, "batch_reward": 7.265852928161621, "critic_loss": 959.3093872070312, "actor_loss": -1343.9619140625, "actor_target_entropy": -3.0, "actor_entropy": 1.7069345712661743, "alpha_loss": -0.3174326717853546, "alpha_value": 0.4955830363870631, "duration": 1.592203140258789, "info_normalized_performance_mean": 0.1995411366224289, "info_normalized_performance_final": 0.26489779353141785, "info_performance_mean": 0.1995411366224289, "info_performance_final": 0.26489779353141785, "step": 79500}
{"episode_reward": 399.08220965637264, "episode": 796.0, "batch_reward": 7.564336776733398, "critic_loss": 1581.9166259765625, "actor_loss": -1361.49951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.277886152267456, "alpha_loss": 0.05416351556777954, "alpha_value": 0.5033821882884607, "step": 80000}
{"duration": 18.506776571273804, "info_normalized_performance_mean": 0.2780914902687073, "info_normalized_performance_final": 0.3124183118343353, "info_performance_mean": 0.2780914902687073, "info_performance_final": 0.3124183118343353, "step": 80000}
{"episode_reward": 556.1830065359482, "episode": 801.0, "batch_reward": 6.894894599914551, "critic_loss": 796.0745849609375, "actor_loss": -1329.136474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.6822233200073242, "alpha_loss": 0.0061208270490169525, "alpha_value": 0.500798753155529, "duration": 1.4673545360565186, "info_normalized_performance_mean": 0.42638489603996277, "info_normalized_performance_final": 0.4975142180919647, "info_performance_mean": 0.42638489603996277, "info_performance_final": 0.4975142180919647, "step": 80500}
{"episode_reward": 852.7698863636368, "episode": 806.0, "batch_reward": 7.9550886154174805, "critic_loss": 508.03826904296875, "actor_loss": -1370.345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6965340375900269, "alpha_loss": 0.10550414770841599, "alpha_value": 0.5014429201705565, "duration": 1.5507333278656006, "info_normalized_performance_mean": 0.8613796830177307, "info_normalized_performance_final": 0.9625668525695801, "info_performance_mean": 0.8613796830177307, "info_performance_final": 0.9625668525695801, "step": 81000}
{"episode_reward": 1722.7593582887698, "episode": 811.0, "batch_reward": 7.723896503448486, "critic_loss": 1249.631103515625, "actor_loss": -1389.554443359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6398117542266846, "alpha_loss": -0.12756338715553284, "alpha_value": 0.5100509238639186, "duration": 1.6133291721343994, "info_normalized_performance_mean": 0.7684787511825562, "info_normalized_performance_final": 0.8492063283920288, "info_performance_mean": 0.7684787511825562, "info_performance_final": 0.8492063283920288, "step": 81500}
{"episode_reward": 1536.9576719576721, "episode": 816.0, "batch_reward": 7.464569568634033, "critic_loss": 713.7699584960938, "actor_loss": -1358.1005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.9219398498535156, "alpha_loss": 0.24240483343601227, "alpha_value": 0.5131337489741031, "duration": 1.4017682075500488, "info_normalized_performance_mean": 0.32184895873069763, "info_normalized_performance_final": 0.3567708432674408, "info_performance_mean": 0.32184895873069763, "info_performance_final": 0.3567708432674408, "step": 82000}
{"episode_reward": 643.6979166666665, "episode": 821.0, "batch_reward": 8.056610107421875, "critic_loss": 364.69000244140625, "actor_loss": -1370.64697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.909576654434204, "alpha_loss": -0.10214179009199142, "alpha_value": 0.5075849111231965, "duration": 1.4587352275848389, "info_normalized_performance_mean": 0.46771660447120667, "info_normalized_performance_final": 0.5166666507720947, "info_performance_mean": 0.46771660447120667, "info_performance_final": 0.5166666507720947, "step": 82500}
{"episode_reward": 935.4333333333345, "episode": 826.0, "batch_reward": 7.931363105773926, "critic_loss": 893.246337890625, "actor_loss": -1398.197998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5592896938323975, "alpha_loss": 0.12539291381835938, "alpha_value": 0.5074491417182739, "duration": 1.4949393272399902, "info_normalized_performance_mean": 0.5884480476379395, "info_normalized_performance_final": 0.6449829936027527, "info_performance_mean": 0.5884480476379395, "info_performance_final": 0.6449829936027527, "step": 83000}
{"episode_reward": 1176.8962585034, "episode": 831.0, "batch_reward": 7.293553352355957, "critic_loss": 822.5057983398438, "actor_loss": -1384.0792236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.7542271614074707, "alpha_loss": 0.05474115535616875, "alpha_value": 0.5087442738909392, "duration": 1.4452500343322754, "info_normalized_performance_mean": 0.24961493909358978, "info_normalized_performance_final": 0.2705882489681244, "info_performance_mean": 0.24961493909358978, "info_performance_final": 0.2705882489681244, "step": 83500}
{"episode_reward": 499.22994652406504, "episode": 836.0, "batch_reward": 7.610407829284668, "critic_loss": 338.21112060546875, "actor_loss": -1353.419189453125, "actor_target_entropy": -3.0, "actor_entropy": 1.8949044942855835, "alpha_loss": 0.14491015672683716, "alpha_value": 0.508424082272683, "duration": 1.443378210067749, "info_normalized_performance_mean": 0.28756698966026306, "info_normalized_performance_final": 0.3191964328289032, "info_performance_mean": 0.28756698966026306, "info_performance_final": 0.3191964328289032, "step": 84000}
{"episode_reward": 575.133928571428, "episode": 841.0, "batch_reward": 7.193824768066406, "critic_loss": 3366.825439453125, "actor_loss": -1391.62255859375, "actor_target_entropy": -3.0, "actor_entropy": 1.9006714820861816, "alpha_loss": -0.08875732123851776, "alpha_value": 0.5021739343543474, "duration": 1.5598983764648438, "info_normalized_performance_mean": 0.36950522661209106, "info_normalized_performance_final": 0.4071180522441864, "info_performance_mean": 0.36950522661209106, "info_performance_final": 0.4071180522441864, "step": 84500}
{"episode_reward": 739.0104166666653, "episode": 846.0, "batch_reward": 7.577198028564453, "critic_loss": 247.6291046142578, "actor_loss": -1372.169677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.7131361961364746, "alpha_loss": -0.1384236216545105, "alpha_value": 0.5001029919733373, "duration": 1.3883452415466309, "info_normalized_performance_mean": 0.3757812976837158, "info_normalized_performance_final": 0.41874998807907104, "info_performance_mean": 0.3757812976837158, "info_performance_final": 0.41874998807907104, "step": 85000}
{"episode_reward": 751.5625, "episode": 851.0, "batch_reward": 7.812067985534668, "critic_loss": 466.58636474609375, "actor_loss": -1361.5565185546875, "actor_target_entropy": -3.0, "actor_entropy": 1.758838176727295, "alpha_loss": 0.1744820773601532, "alpha_value": 0.4985295125963534, "duration": 1.581132173538208, "info_normalized_performance_mean": 0.37113097310066223, "info_normalized_performance_final": 0.4294217824935913, "info_performance_mean": 0.37113097310066223, "info_performance_final": 0.4294217824935913, "step": 85500}
{"episode_reward": 742.2619047619038, "episode": 856.0, "batch_reward": 7.800450325012207, "critic_loss": 549.617919921875, "actor_loss": -1372.0997314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.9693042039871216, "alpha_loss": -0.09813946485519409, "alpha_value": 0.49581003558904096, "duration": 1.4895625114440918, "info_normalized_performance_mean": 0.45733964443206787, "info_normalized_performance_final": 0.5206043720245361, "info_performance_mean": 0.45733964443206787, "info_performance_final": 0.5206043720245361, "step": 86000}
{"episode_reward": 914.6794871794891, "episode": 861.0, "batch_reward": 6.919685363769531, "critic_loss": 570.0120849609375, "actor_loss": -1340.2568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6789848804473877, "alpha_loss": 0.23118609189987183, "alpha_value": 0.49249770432573237, "duration": 1.6023635864257812, "info_normalized_performance_mean": 0.8111273050308228, "info_normalized_performance_final": 0.889090895652771, "info_performance_mean": 0.8111273050308228, "info_performance_final": 0.889090895652771, "step": 86500}
{"episode_reward": 1622.2545454545434, "episode": 866.0, "batch_reward": 7.928735256195068, "critic_loss": 691.320556640625, "actor_loss": -1367.1083984375, "actor_target_entropy": -3.0, "actor_entropy": 1.7497944831848145, "alpha_loss": 0.24149715900421143, "alpha_value": 0.48410873850555475, "duration": 1.4976584911346436, "info_normalized_performance_mean": 0.40814414620399475, "info_normalized_performance_final": 0.4798884987831116, "info_performance_mean": 0.40814414620399475, "info_performance_final": 0.4798884987831116, "step": 87000}
{"episode_reward": 816.2883313420947, "episode": 871.0, "batch_reward": 6.764495849609375, "critic_loss": 886.055419921875, "actor_loss": -1364.0614013671875, "actor_target_entropy": -3.0, "actor_entropy": 1.8749139308929443, "alpha_loss": -0.2679233253002167, "alpha_value": 0.4833709383400266, "duration": 1.4409894943237305, "info_normalized_performance_mean": 0.19755683839321136, "info_normalized_performance_final": 0.22230114042758942, "info_performance_mean": 0.19755683839321136, "info_performance_final": 0.22230114042758942, "step": 87500}
{"episode_reward": 395.11363636363666, "episode": 876.0, "batch_reward": 7.235985279083252, "critic_loss": 305.32757568359375, "actor_loss": -1367.76611328125, "actor_target_entropy": -3.0, "actor_entropy": 2.051708936691284, "alpha_loss": -0.10029224306344986, "alpha_value": 0.48536738812019753, "duration": 1.4480276107788086, "info_normalized_performance_mean": 0.008703705854713917, "info_normalized_performance_final": 0.009259259328246117, "info_performance_mean": 0.008703705854713917, "info_performance_final": 0.009259259328246117, "step": 88000}
{"episode_reward": 17.407407407407415, "episode": 881.0, "batch_reward": 7.657078742980957, "critic_loss": 656.3355102539062, "actor_loss": -1377.985595703125, "actor_target_entropy": -3.0, "actor_entropy": 1.8485357761383057, "alpha_loss": 0.21576008200645447, "alpha_value": 0.48260389214473254, "duration": 1.6335961818695068, "info_normalized_performance_mean": 0.700707197189331, "info_normalized_performance_final": 0.7633477449417114, "info_performance_mean": 0.700707197189331, "info_performance_final": 0.7633477449417114, "step": 88500}
{"episode_reward": 1401.4141414141395, "episode": 886.0, "batch_reward": 6.780054092407227, "critic_loss": 457.8740234375, "actor_loss": -1364.202880859375, "actor_target_entropy": -3.0, "actor_entropy": 1.5403950214385986, "alpha_loss": 0.20734462141990662, "alpha_value": 0.4767783406484335, "duration": 1.497828483581543, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 89000}
{"episode_reward": 0.0, "episode": 891.0, "batch_reward": 7.138463497161865, "critic_loss": 880.346435546875, "actor_loss": -1368.694580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4335867166519165, "alpha_loss": 0.05017530918121338, "alpha_value": 0.47082915021480815, "duration": 1.4104266166687012, "info_normalized_performance_mean": 0.20731252431869507, "info_normalized_performance_final": 0.2562499940395355, "info_performance_mean": 0.20731252431869507, "info_performance_final": 0.2562499940395355, "step": 89500}
{"episode_reward": 414.625, "episode": 896.0, "batch_reward": 7.133199691772461, "critic_loss": 697.2314453125, "actor_loss": -1359.7623291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5084362030029297, "alpha_loss": 0.029951315373182297, "alpha_value": 0.4656072840761353, "step": 90000}
{"duration": 18.90218162536621, "info_normalized_performance_mean": 0.42753300070762634, "info_normalized_performance_final": 0.48677247762680054, "info_performance_mean": 0.42753300070762634, "info_performance_final": 0.48677247762680054, "step": 90000}
{"episode_reward": 855.0661375661364, "episode": 901.0, "batch_reward": 6.910871982574463, "critic_loss": 713.6152954101562, "actor_loss": -1360.373779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.6240270137786865, "alpha_loss": 0.02974306046962738, "alpha_value": 0.4657262817291947, "duration": 1.4885706901550293, "info_normalized_performance_mean": 0.2546078860759735, "info_normalized_performance_final": 0.33725491166114807, "info_performance_mean": 0.2546078860759735, "info_performance_final": 0.33725491166114807, "step": 90500}
{"episode_reward": 509.2156862745101, "episode": 906.0, "batch_reward": 7.42069149017334, "critic_loss": 3657.324951171875, "actor_loss": -1383.8138427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.6786020994186401, "alpha_loss": -0.07043208926916122, "alpha_value": 0.4649689160609866, "duration": 1.55843186378479, "info_normalized_performance_mean": 0.8038049340248108, "info_normalized_performance_final": 0.8956043720245361, "info_performance_mean": 0.8038049340248108, "info_performance_final": 0.8956043720245361, "step": 91000}
{"episode_reward": 1607.6098901098885, "episode": 911.0, "batch_reward": 6.671055316925049, "critic_loss": 802.8744506835938, "actor_loss": -1331.142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7866332530975342, "alpha_loss": 0.14031186699867249, "alpha_value": 0.47729183159279137, "duration": 1.6089141368865967, "info_normalized_performance_mean": 0.5944603085517883, "info_normalized_performance_final": 0.6476190686225891, "info_performance_mean": 0.5944603085517883, "info_performance_final": 0.6476190686225891, "step": 91500}
{"episode_reward": 1188.9206349206356, "episode": 916.0, "batch_reward": 7.691020488739014, "critic_loss": 1587.476318359375, "actor_loss": -1387.5, "actor_target_entropy": -3.0, "actor_entropy": 1.7027621269226074, "alpha_loss": 0.017971158027648926, "alpha_value": 0.4774767041849921, "duration": 1.5111770629882812, "info_normalized_performance_mean": 0.3453821837902069, "info_normalized_performance_final": 0.40337133407592773, "info_performance_mean": 0.3453821837902069, "info_performance_final": 0.40337133407592773, "step": 92000}
{"episode_reward": 690.7644824311479, "episode": 921.0, "batch_reward": 7.393959045410156, "critic_loss": 1202.1328125, "actor_loss": -1402.220947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6807115077972412, "alpha_loss": 0.013838708400726318, "alpha_value": 0.4788976071963502, "duration": 1.4931671619415283, "info_normalized_performance_mean": 0.6082499623298645, "info_normalized_performance_final": 0.6910714507102966, "info_performance_mean": 0.6082499623298645, "info_performance_final": 0.6910714507102966, "step": 92500}
{"episode_reward": 1216.5000000000005, "episode": 926.0, "batch_reward": 7.212612152099609, "critic_loss": 359.81396484375, "actor_loss": -1355.80517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7767302989959717, "alpha_loss": 0.28157514333724976, "alpha_value": 0.48061718070430853, "duration": 1.56028413772583, "info_normalized_performance_mean": 0.347278892993927, "info_normalized_performance_final": 0.4625850319862366, "info_performance_mean": 0.347278892993927, "info_performance_final": 0.4625850319862366, "step": 93000}
{"episode_reward": 694.5578231292507, "episode": 931.0, "batch_reward": 8.252574920654297, "critic_loss": 2315.433837890625, "actor_loss": -1419.0426025390625, "actor_target_entropy": -3.0, "actor_entropy": 1.7270197868347168, "alpha_loss": -0.039746712893247604, "alpha_value": 0.4797109714185154, "duration": 1.7680513858795166, "info_normalized_performance_mean": 0.48644232749938965, "info_normalized_performance_final": 0.5810630321502686, "info_performance_mean": 0.48644232749938965, "info_performance_final": 0.5810630321502686, "step": 93500}
{"episode_reward": 972.8846153846175, "episode": 936.0, "batch_reward": 7.145208358764648, "critic_loss": 1252.4073486328125, "actor_loss": -1377.182373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.8036155700683594, "alpha_loss": -0.23562845587730408, "alpha_value": 0.4833642932378381, "duration": 1.5757274627685547, "info_normalized_performance_mean": 0.7446275353431702, "info_normalized_performance_final": 0.8235294222831726, "info_performance_mean": 0.7446275353431702, "info_performance_final": 0.8235294222831726, "step": 94000}
{"episode_reward": 1489.2549019607861, "episode": 941.0, "batch_reward": 7.811304092407227, "critic_loss": 792.9118041992188, "actor_loss": -1411.1015625, "actor_target_entropy": -3.0, "actor_entropy": 1.9815598726272583, "alpha_loss": -0.04782485216856003, "alpha_value": 0.48080060461080937, "duration": 1.4753892421722412, "info_normalized_performance_mean": 0.2995312511920929, "info_normalized_performance_final": 0.3338068127632141, "info_performance_mean": 0.2995312511920929, "info_performance_final": 0.3338068127632141, "step": 94500}
{"episode_reward": 599.0625000000001, "episode": 946.0, "batch_reward": 6.404257774353027, "critic_loss": 534.5594482421875, "actor_loss": -1365.1268310546875, "actor_target_entropy": -3.0, "actor_entropy": 1.908056616783142, "alpha_loss": 0.19833238422870636, "alpha_value": 0.47861904997241284, "duration": 1.600217580795288, "info_normalized_performance_mean": 0.6283500790596008, "info_normalized_performance_final": 0.706250011920929, "info_performance_mean": 0.6283500790596008, "info_performance_final": 0.706250011920929, "step": 95000}
{"episode_reward": 1256.7, "episode": 951.0, "batch_reward": 7.1823320388793945, "critic_loss": 775.830810546875, "actor_loss": -1395.91796875, "actor_target_entropy": -3.0, "actor_entropy": 1.673438310623169, "alpha_loss": -0.0264880508184433, "alpha_value": 0.4783796712061775, "duration": 1.5879228115081787, "info_normalized_performance_mean": 0.673809289932251, "info_normalized_performance_final": 0.7469135522842407, "info_performance_mean": 0.673809289932251, "info_performance_final": 0.7469135522842407, "step": 95500}
{"episode_reward": 1347.6190476190475, "episode": 956.0, "batch_reward": 7.204833507537842, "critic_loss": 986.0343627929688, "actor_loss": -1393.1099853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.8080077171325684, "alpha_loss": 0.23583629727363586, "alpha_value": 0.47793930059142775, "duration": 1.5478568077087402, "info_normalized_performance_mean": 0.6508238315582275, "info_normalized_performance_final": 0.7357954382896423, "info_performance_mean": 0.6508238315582275, "info_performance_final": 0.7357954382896423, "step": 96000}
{"episode_reward": 1301.647727272727, "episode": 961.0, "batch_reward": 7.449641704559326, "critic_loss": 393.5753173828125, "actor_loss": -1397.331787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.7731332778930664, "alpha_loss": -0.11785595118999481, "alpha_value": 0.47981888545444784, "duration": 1.5985448360443115, "info_normalized_performance_mean": 0.7077465057373047, "info_normalized_performance_final": 0.7746606469154358, "info_performance_mean": 0.7077465057373047, "info_performance_final": 0.7746606469154358, "step": 96500}
{"episode_reward": 1415.4932126696829, "episode": 966.0, "batch_reward": 7.545682907104492, "critic_loss": 988.876953125, "actor_loss": -1415.617919921875, "actor_target_entropy": -3.0, "actor_entropy": 1.9277980327606201, "alpha_loss": -0.3977257013320923, "alpha_value": 0.48397130596035465, "duration": 1.573171615600586, "info_normalized_performance_mean": 0.3941918909549713, "info_normalized_performance_final": 0.5173160433769226, "info_performance_mean": 0.3941918909549713, "info_performance_final": 0.5173160433769226, "step": 97000}
{"episode_reward": 788.3838383838381, "episode": 971.0, "batch_reward": 7.331526756286621, "critic_loss": 820.68017578125, "actor_loss": -1412.75146484375, "actor_target_entropy": -3.0, "actor_entropy": 2.0800418853759766, "alpha_loss": -0.1797378659248352, "alpha_value": 0.4871085028193817, "duration": 1.5756056308746338, "info_normalized_performance_mean": 0.32257145643234253, "info_normalized_performance_final": 0.4877921938896179, "info_performance_mean": 0.32257145643234253, "info_performance_final": 0.4877921938896179, "step": 97500}
{"episode_reward": 645.1428571428565, "episode": 976.0, "batch_reward": 7.945788383483887, "critic_loss": 1881.6875, "actor_loss": -1456.076904296875, "actor_target_entropy": -3.0, "actor_entropy": 1.7455956935882568, "alpha_loss": 0.38758257031440735, "alpha_value": 0.4852413429111775, "duration": 1.515413522720337, "info_normalized_performance_mean": 0.8575487732887268, "info_normalized_performance_final": 0.9415584206581116, "info_performance_mean": 0.8575487732887268, "info_performance_final": 0.9415584206581116, "step": 98000}
{"episode_reward": 1715.097402597399, "episode": 981.0, "batch_reward": 7.843753337860107, "critic_loss": 307.50726318359375, "actor_loss": -1414.73828125, "actor_target_entropy": -3.0, "actor_entropy": 1.9867945909500122, "alpha_loss": 0.16570547223091125, "alpha_value": 0.48113320573543467, "duration": 1.603762149810791, "info_normalized_performance_mean": 0.5897617936134338, "info_normalized_performance_final": 0.6473214030265808, "info_performance_mean": 0.5897617936134338, "info_performance_final": 0.6473214030265808, "step": 98500}
{"episode_reward": 1179.5238095238099, "episode": 986.0, "batch_reward": 7.5067548751831055, "critic_loss": 1346.640380859375, "actor_loss": -1436.2950439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.9755290746688843, "alpha_loss": -0.17066650092601776, "alpha_value": 0.48254054518864187, "duration": 1.490011215209961, "info_normalized_performance_mean": 0.39432618021965027, "info_normalized_performance_final": 0.4345703125, "info_performance_mean": 0.39432618021965027, "info_performance_final": 0.4345703125, "step": 99000}
{"episode_reward": 788.65234375, "episode": 991.0, "batch_reward": 6.589195251464844, "critic_loss": 1082.8966064453125, "actor_loss": -1345.139892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.903053641319275, "alpha_loss": -0.19144704937934875, "alpha_value": 0.4792901853415162, "duration": 1.5388312339782715, "info_normalized_performance_mean": 0.717032790184021, "info_normalized_performance_final": 0.813579261302948, "info_performance_mean": 0.717032790184021, "info_performance_final": 0.813579261302948, "step": 99500}
{"episode_reward": 1434.0659340659363, "episode": 996.0, "batch_reward": 8.640657424926758, "critic_loss": 468.20123291015625, "actor_loss": -1456.5697021484375, "actor_target_entropy": -3.0, "actor_entropy": 1.912501573562622, "alpha_loss": 0.09908340871334076, "alpha_value": 0.4767186277478266, "step": 100000}
{"duration": 18.802035808563232, "info_normalized_performance_mean": 0.5667261481285095, "info_normalized_performance_final": 0.6923365592956543, "info_performance_mean": 0.5667261481285095, "info_performance_final": 0.6923365592956543, "step": 100000}
{"episode_reward": 1133.452291510143, "episode": 1001.0, "batch_reward": 7.617349147796631, "critic_loss": 657.517578125, "actor_loss": -1422.3701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.8029708862304688, "alpha_loss": 0.055113960057497025, "alpha_value": 0.4760850640817694, "duration": 1.449949026107788, "info_normalized_performance_mean": 0.2976807951927185, "info_normalized_performance_final": 0.3236331641674042, "info_performance_mean": 0.2976807951927185, "info_performance_final": 0.3236331641674042, "step": 100500}
{"episode_reward": 595.3615520282194, "episode": 1006.0, "batch_reward": 7.7369704246521, "critic_loss": 2588.998046875, "actor_loss": -1414.2369384765625, "actor_target_entropy": -3.0, "actor_entropy": 2.008244276046753, "alpha_loss": 0.1782810240983963, "alpha_value": 0.47421241826585186, "duration": 1.5706439018249512, "info_normalized_performance_mean": 0.5924435257911682, "info_normalized_performance_final": 0.64796382188797, "info_performance_mean": 0.5924435257911682, "info_performance_final": 0.64796382188797, "step": 101000}
{"episode_reward": 1184.8868778280537, "episode": 1011.0, "batch_reward": 7.352652549743652, "critic_loss": 872.2362060546875, "actor_loss": -1388.03271484375, "actor_target_entropy": -3.0, "actor_entropy": 1.8083720207214355, "alpha_loss": -0.10046639293432236, "alpha_value": 0.46789214286404235, "duration": 1.472412347793579, "info_normalized_performance_mean": 0.30514758825302124, "info_normalized_performance_final": 0.3450520932674408, "info_performance_mean": 0.30514758825302124, "info_performance_final": 0.3450520932674408, "step": 101500}
{"episode_reward": 610.2951388888879, "episode": 1016.0, "batch_reward": 7.427016735076904, "critic_loss": 685.75732421875, "actor_loss": -1421.2294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.7858833074569702, "alpha_loss": 0.30767714977264404, "alpha_value": 0.4671761227615961, "duration": 1.404726266860962, "info_normalized_performance_mean": 0.3941785395145416, "info_normalized_performance_final": 0.5321428775787354, "info_performance_mean": 0.3941785395145416, "info_performance_final": 0.5321428775787354, "step": 102000}
{"episode_reward": 788.3571428571425, "episode": 1021.0, "batch_reward": 8.637674331665039, "critic_loss": 1081.9332275390625, "actor_loss": -1493.104736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.950101375579834, "alpha_loss": -0.04711591452360153, "alpha_value": 0.46447317965551577, "duration": 1.6547706127166748, "info_normalized_performance_mean": 0.45420733094215393, "info_normalized_performance_final": 0.5172802209854126, "info_performance_mean": 0.45420733094215393, "info_performance_final": 0.5172802209854126, "step": 102500}
{"episode_reward": 908.4147257700969, "episode": 1026.0, "batch_reward": 6.614549160003662, "critic_loss": 3336.079833984375, "actor_loss": -1379.310546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4661922454833984, "alpha_loss": 0.10496301203966141, "alpha_value": 0.4633899338736621, "duration": 1.4513537883758545, "info_normalized_performance_mean": 0.22673438489437103, "info_normalized_performance_final": 0.2515625059604645, "info_performance_mean": 0.22673438489437103, "info_performance_final": 0.2515625059604645, "step": 103000}
{"episode_reward": 453.46875, "episode": 1031.0, "batch_reward": 7.378936767578125, "critic_loss": 1166.290283203125, "actor_loss": -1416.888916015625, "actor_target_entropy": -3.0, "actor_entropy": 1.6650807857513428, "alpha_loss": 0.0453723669052124, "alpha_value": 0.4621506027374689, "duration": 1.458219289779663, "info_normalized_performance_mean": 0.18576472997665405, "info_normalized_performance_final": 0.20336134731769562, "info_performance_mean": 0.18576472997665405, "info_performance_final": 0.20336134731769562, "step": 103500}
{"episode_reward": 371.52941176470506, "episode": 1036.0, "batch_reward": 7.5428667068481445, "critic_loss": 306.95147705078125, "actor_loss": -1423.44140625, "actor_target_entropy": -3.0, "actor_entropy": 1.8165754079818726, "alpha_loss": 0.20422255992889404, "alpha_value": 0.4595288289943261, "duration": 1.4925870895385742, "info_normalized_performance_mean": 0.5410760641098022, "info_normalized_performance_final": 0.6593406796455383, "info_performance_mean": 0.5410760641098022, "info_performance_final": 0.6593406796455383, "step": 104000}
{"episode_reward": 1082.1520146520152, "episode": 1041.0, "batch_reward": 8.26832103729248, "critic_loss": 1778.91748046875, "actor_loss": -1447.4287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.7375527620315552, "alpha_loss": 0.36630287766456604, "alpha_value": 0.4535992955110746, "duration": 1.5923659801483154, "info_normalized_performance_mean": 0.6626487970352173, "info_normalized_performance_final": 0.7152777910232544, "info_performance_mean": 0.6626487970352173, "info_performance_final": 0.7152777910232544, "step": 104500}
{"episode_reward": 1325.2976190476206, "episode": 1046.0, "batch_reward": 7.385824203491211, "critic_loss": 488.53106689453125, "actor_loss": -1408.7779541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.7449719905853271, "alpha_loss": -0.0220029279589653, "alpha_value": 0.4536542717699564, "duration": 1.6016731262207031, "info_normalized_performance_mean": 0.824483335018158, "info_normalized_performance_final": 0.9125000238418579, "info_performance_mean": 0.824483335018158, "info_performance_final": 0.9125000238418579, "step": 105000}
{"episode_reward": 1648.9666666666667, "episode": 1051.0, "batch_reward": 8.467656135559082, "critic_loss": 5016.2548828125, "actor_loss": -1459.041259765625, "actor_target_entropy": -3.0, "actor_entropy": 2.0957956314086914, "alpha_loss": 0.02539198100566864, "alpha_value": 0.45119960578170326, "duration": 1.3322887420654297, "info_normalized_performance_mean": 0.00022321428696159273, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.00022321428696159273, "info_performance_final": 0.0, "step": 105500}
{"episode_reward": 0.44642857142857145, "episode": 1056.0, "batch_reward": 7.056001663208008, "critic_loss": 336.7095031738281, "actor_loss": -1380.4122314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.752828598022461, "alpha_loss": -0.017615970224142075, "alpha_value": 0.44823106946175967, "duration": 1.736100435256958, "info_normalized_performance_mean": 0.4589582085609436, "info_normalized_performance_final": 0.5324074029922485, "info_performance_mean": 0.4589582085609436, "info_performance_final": 0.5324074029922485, "step": 106000}
{"episode_reward": 917.916666666667, "episode": 1061.0, "batch_reward": 8.039724349975586, "critic_loss": 515.03369140625, "actor_loss": -1456.01513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.7393081188201904, "alpha_loss": 0.08635224401950836, "alpha_value": 0.44520105183456354, "duration": 1.5938606262207031, "info_normalized_performance_mean": 0.5464428663253784, "info_normalized_performance_final": 0.5941358208656311, "info_performance_mean": 0.5464428663253784, "info_performance_final": 0.5941358208656311, "step": 106500}
{"episode_reward": 1092.8858024691344, "episode": 1066.0, "batch_reward": 7.5865020751953125, "critic_loss": 681.06787109375, "actor_loss": -1411.1070556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.8913735151290894, "alpha_loss": 0.17908351123332977, "alpha_value": 0.44185003598695516, "duration": 1.4769582748413086, "info_normalized_performance_mean": 0.5294826626777649, "info_normalized_performance_final": 0.5778388381004333, "info_performance_mean": 0.5294826626777649, "info_performance_final": 0.5778388381004333, "step": 107000}
{"episode_reward": 1058.9652014651997, "episode": 1071.0, "batch_reward": 8.13153076171875, "critic_loss": 730.8351440429688, "actor_loss": -1458.43603515625, "actor_target_entropy": -3.0, "actor_entropy": 1.9866197109222412, "alpha_loss": 0.04233521968126297, "alpha_value": 0.4396718825417119, "duration": 1.5306529998779297, "info_normalized_performance_mean": 0.526371419429779, "info_normalized_performance_final": 0.5885714292526245, "info_performance_mean": 0.526371419429779, "info_performance_final": 0.5885714292526245, "step": 107500}
{"episode_reward": 1052.7428571428584, "episode": 1076.0, "batch_reward": 8.203584671020508, "critic_loss": 242.18362426757812, "actor_loss": -1486.2353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.9041682481765747, "alpha_loss": -0.06669629365205765, "alpha_value": 0.43890315711542616, "duration": 1.409773349761963, "info_normalized_performance_mean": 0.20529751479625702, "info_normalized_performance_final": 0.2383512556552887, "info_performance_mean": 0.20529751479625702, "info_performance_final": 0.2383512556552887, "step": 108000}
{"episode_reward": 410.5949820788535, "episode": 1081.0, "batch_reward": 8.54525375366211, "critic_loss": 692.7802734375, "actor_loss": -1431.28662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.7110841274261475, "alpha_loss": 0.1558423787355423, "alpha_value": 0.4383924780293918, "duration": 1.599562168121338, "info_normalized_performance_mean": 0.8225176334381104, "info_normalized_performance_final": 0.9011764526367188, "info_performance_mean": 0.8225176334381104, "info_performance_final": 0.9011764526367188, "step": 108500}
{"episode_reward": 1645.0352941176454, "episode": 1086.0, "batch_reward": 8.067170143127441, "critic_loss": 501.54541015625, "actor_loss": -1457.9534912109375, "actor_target_entropy": -3.0, "actor_entropy": 1.9136828184127808, "alpha_loss": 0.109034463763237, "alpha_value": 0.44187274004746635, "duration": 1.4307944774627686, "info_normalized_performance_mean": 0.22450996935367584, "info_normalized_performance_final": 0.24325284361839294, "info_performance_mean": 0.22450996935367584, "info_performance_final": 0.24325284361839294, "step": 109000}
{"episode_reward": 449.019886363636, "episode": 1091.0, "batch_reward": 7.446467876434326, "critic_loss": 1060.8055419921875, "actor_loss": -1389.13037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.6237661838531494, "alpha_loss": 0.054231494665145874, "alpha_value": 0.4449601292844609, "duration": 1.4918489456176758, "info_normalized_performance_mean": 0.2314453274011612, "info_normalized_performance_final": 0.2757161557674408, "info_performance_mean": 0.2314453274011612, "info_performance_final": 0.2757161557674408, "step": 109500}
{"episode_reward": 462.8906250000005, "episode": 1096.0, "batch_reward": 8.099222183227539, "critic_loss": 522.0992431640625, "actor_loss": -1459.688232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.5956804752349854, "alpha_loss": -0.015857815742492676, "alpha_value": 0.44186978407198074, "step": 110000}
{"duration": 18.780503511428833, "info_normalized_performance_mean": 0.38645827770233154, "info_normalized_performance_final": 0.4508744776248932, "info_performance_mean": 0.38645827770233154, "info_performance_final": 0.4508744776248932, "step": 110000}
{"episode_reward": 772.9166666666654, "episode": 1101.0, "batch_reward": 8.084112167358398, "critic_loss": 270.30462646484375, "actor_loss": -1453.312744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.738987922668457, "alpha_loss": 0.24250106513500214, "alpha_value": 0.44139455504064146, "duration": 1.435986042022705, "info_normalized_performance_mean": 0.33551692962646484, "info_normalized_performance_final": 0.3677884638309479, "info_performance_mean": 0.33551692962646484, "info_performance_final": 0.3677884638309479, "step": 110500}
{"episode_reward": 671.0336538461547, "episode": 1106.0, "batch_reward": 7.814375877380371, "critic_loss": 430.82391357421875, "actor_loss": -1437.802001953125, "actor_target_entropy": -3.0, "actor_entropy": 1.557152509689331, "alpha_loss": 0.30081167817115784, "alpha_value": 0.44012290049026076, "duration": 1.537442922592163, "info_normalized_performance_mean": 0.5288780927658081, "info_normalized_performance_final": 0.6913978457450867, "info_performance_mean": 0.5288780927658081, "info_performance_final": 0.6913978457450867, "step": 111000}
{"episode_reward": 1057.756272401435, "episode": 1111.0, "batch_reward": 7.605738639831543, "critic_loss": 290.0732421875, "actor_loss": -1431.923583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.8260921239852905, "alpha_loss": -0.04003610461950302, "alpha_value": 0.4339716904026413, "duration": 1.4918527603149414, "info_normalized_performance_mean": 0.7260892987251282, "info_normalized_performance_final": 0.8017857074737549, "info_performance_mean": 0.7260892987251282, "info_performance_final": 0.8017857074737549, "step": 111500}
{"episode_reward": 1452.178571428571, "episode": 1116.0, "batch_reward": 8.37348461151123, "critic_loss": 583.1549072265625, "actor_loss": -1493.3472900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.7031751871109009, "alpha_loss": 0.11163879930973053, "alpha_value": 0.4332194613152871, "duration": 1.614438772201538, "info_normalized_performance_mean": 0.5823485851287842, "info_normalized_performance_final": 0.6708754301071167, "info_performance_mean": 0.5823485851287842, "info_performance_final": 0.6708754301071167, "step": 112000}
{"episode_reward": 1164.6969696969693, "episode": 1121.0, "batch_reward": 7.904646873474121, "critic_loss": 1168.125, "actor_loss": -1459.61376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.5879970788955688, "alpha_loss": 0.054938413202762604, "alpha_value": 0.43193821156216866, "duration": 1.6283187866210938, "info_normalized_performance_mean": 0.8096998333930969, "info_normalized_performance_final": 0.9008333086967468, "info_performance_mean": 0.8096998333930969, "info_performance_final": 0.9008333086967468, "step": 112500}
{"episode_reward": 1619.399999999999, "episode": 1126.0, "batch_reward": 8.225518226623535, "critic_loss": 458.8829040527344, "actor_loss": -1472.08984375, "actor_target_entropy": -3.0, "actor_entropy": 1.731381893157959, "alpha_loss": 0.13352061808109283, "alpha_value": 0.4319136481706747, "duration": 1.5853159427642822, "info_normalized_performance_mean": 0.23605747520923615, "info_normalized_performance_final": 0.326070636510849, "info_performance_mean": 0.23605747520923615, "info_performance_final": 0.326070636510849, "step": 113000}
{"episode_reward": 472.1149511645373, "episode": 1131.0, "batch_reward": 8.128046989440918, "critic_loss": 457.7134094238281, "actor_loss": -1451.8590087890625, "actor_target_entropy": -3.0, "actor_entropy": 1.7099189758300781, "alpha_loss": -0.08678781986236572, "alpha_value": 0.43501710530378646, "duration": 1.5613715648651123, "info_normalized_performance_mean": 0.07700908184051514, "info_normalized_performance_final": 0.0854545459151268, "info_performance_mean": 0.07700908184051514, "info_performance_final": 0.0854545459151268, "step": 113500}
{"episode_reward": 154.01818181818177, "episode": 1136.0, "batch_reward": 8.53661823272705, "critic_loss": 856.95263671875, "actor_loss": -1492.884033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.9188369512557983, "alpha_loss": 0.062449704855680466, "alpha_value": 0.4397478559356156, "duration": 1.519960880279541, "info_normalized_performance_mean": 0.36126509308815, "info_normalized_performance_final": 0.41977164149284363, "info_performance_mean": 0.36126509308815, "info_performance_final": 0.41977164149284363, "step": 114000}
{"episode_reward": 722.5300480769237, "episode": 1141.0, "batch_reward": 7.574777126312256, "critic_loss": 1022.8757934570312, "actor_loss": -1428.860595703125, "actor_target_entropy": -3.0, "actor_entropy": 2.000861644744873, "alpha_loss": -0.1684970259666443, "alpha_value": 0.44518758817766113, "duration": 1.5733716487884521, "info_normalized_performance_mean": 0.5530528426170349, "info_normalized_performance_final": 0.6310096383094788, "info_performance_mean": 0.5530528426170349, "info_performance_final": 0.6310096383094788, "step": 114500}
{"episode_reward": 1106.1057692307681, "episode": 1146.0, "batch_reward": 8.129319190979004, "critic_loss": 746.3739013671875, "actor_loss": -1472.685791015625, "actor_target_entropy": -3.0, "actor_entropy": 1.9834352731704712, "alpha_loss": -0.0012831762433052063, "alpha_value": 0.44967977427070005, "duration": 1.5814995765686035, "info_normalized_performance_mean": 0.6160494089126587, "info_normalized_performance_final": 0.686948835849762, "info_performance_mean": 0.6160494089126587, "info_performance_final": 0.686948835849762, "step": 115000}
{"episode_reward": 1232.0987654320984, "episode": 1151.0, "batch_reward": 7.997879981994629, "critic_loss": 987.557373046875, "actor_loss": -1463.860595703125, "actor_target_entropy": -3.0, "actor_entropy": 1.8516510725021362, "alpha_loss": -0.026763172820210457, "alpha_value": 0.4540223821278845, "duration": 1.4976844787597656, "info_normalized_performance_mean": 0.486855149269104, "info_normalized_performance_final": 0.65625, "info_performance_mean": 0.486855149269104, "info_performance_final": 0.65625, "step": 115500}
{"episode_reward": 973.7103174603175, "episode": 1156.0, "batch_reward": 8.296656608581543, "critic_loss": 819.242919921875, "actor_loss": -1487.1207275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.6939125061035156, "alpha_loss": 0.10804703831672668, "alpha_value": 0.45088665441131465, "duration": 1.5303409099578857, "info_normalized_performance_mean": 0.2809629440307617, "info_normalized_performance_final": 0.3777777850627899, "info_performance_mean": 0.2809629440307617, "info_performance_final": 0.3777777850627899, "step": 116000}
{"episode_reward": 561.9259259259258, "episode": 1161.0, "batch_reward": 8.690860748291016, "critic_loss": 895.3930053710938, "actor_loss": -1488.0775146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.7524645328521729, "alpha_loss": 0.09921418130397797, "alpha_value": 0.4498674624796489, "duration": 1.456437349319458, "info_normalized_performance_mean": 0.2787656784057617, "info_normalized_performance_final": 0.30937498807907104, "info_performance_mean": 0.2787656784057617, "info_performance_final": 0.30937498807907104, "step": 116500}
{"episode_reward": 557.53125, "episode": 1166.0, "batch_reward": 6.920431137084961, "critic_loss": 335.18084716796875, "actor_loss": -1385.5928955078125, "actor_target_entropy": -3.0, "actor_entropy": 1.9822719097137451, "alpha_loss": -0.07271455228328705, "alpha_value": 0.44601995282810264, "duration": 1.6141867637634277, "info_normalized_performance_mean": 0.8168331980705261, "info_normalized_performance_final": 0.9049999713897705, "info_performance_mean": 0.8168331980705261, "info_performance_final": 0.9049999713897705, "step": 117000}
{"episode_reward": 1633.6666666666645, "episode": 1171.0, "batch_reward": 8.05192756652832, "critic_loss": 322.5722351074219, "actor_loss": -1491.619140625, "actor_target_entropy": -3.0, "actor_entropy": 1.720386028289795, "alpha_loss": -0.009068667888641357, "alpha_value": 0.4430916709296971, "duration": 1.4766454696655273, "info_normalized_performance_mean": 0.7186328172683716, "info_normalized_performance_final": 0.80078125, "info_performance_mean": 0.7186328172683716, "info_performance_final": 0.80078125, "step": 117500}
{"episode_reward": 1437.265625, "episode": 1176.0, "batch_reward": 8.430717468261719, "critic_loss": 647.76025390625, "actor_loss": -1495.593017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.8657987117767334, "alpha_loss": 0.06606688350439072, "alpha_value": 0.43794897215417045, "duration": 1.5108702182769775, "info_normalized_performance_mean": 0.4185620844364166, "info_normalized_performance_final": 0.501960813999176, "info_performance_mean": 0.4185620844364166, "info_performance_final": 0.501960813999176, "step": 118000}
{"episode_reward": 837.1241830065352, "episode": 1181.0, "batch_reward": 7.951136589050293, "critic_loss": 893.9779052734375, "actor_loss": -1459.263427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.6555761098861694, "alpha_loss": -0.031923480331897736, "alpha_value": 0.4348053960992273, "duration": 1.4746809005737305, "info_normalized_performance_mean": 0.6655677556991577, "info_normalized_performance_final": 0.7429792284965515, "info_performance_mean": 0.6655677556991577, "info_performance_final": 0.7429792284965515, "step": 118500}
{"episode_reward": 1331.135531135531, "episode": 1186.0, "batch_reward": 7.4519243240356445, "critic_loss": 938.0537109375, "actor_loss": -1416.30322265625, "actor_target_entropy": -3.0, "actor_entropy": 1.7994468212127686, "alpha_loss": 0.06099186837673187, "alpha_value": 0.42977579963589035, "duration": 1.571171760559082, "info_normalized_performance_mean": 0.3969174921512604, "info_normalized_performance_final": 0.4752500057220459, "info_performance_mean": 0.3969174921512604, "info_performance_final": 0.4752500057220459, "step": 119000}
{"episode_reward": 793.8349999999998, "episode": 1191.0, "batch_reward": 8.02914810180664, "critic_loss": 850.1895141601562, "actor_loss": -1469.564208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.4059990644454956, "alpha_loss": 0.29847365617752075, "alpha_value": 0.4220694374352777, "duration": 1.434432029724121, "info_normalized_performance_mean": 0.0053125000558793545, "info_normalized_performance_final": 0.0982142835855484, "info_performance_mean": 0.0053125000558793545, "info_performance_final": 0.0982142835855484, "step": 119500}
{"episode_reward": 10.625, "episode": 1196.0, "batch_reward": 7.6616058349609375, "critic_loss": 499.7127380371094, "actor_loss": -1448.26416015625, "actor_target_entropy": -3.0, "actor_entropy": 1.9560179710388184, "alpha_loss": -0.00762079656124115, "alpha_value": 0.4210400042435331, "step": 120000}
{"duration": 18.38657522201538, "info_normalized_performance_mean": 0.3274739384651184, "info_normalized_performance_final": 0.3862847089767456, "info_performance_mean": 0.3274739384651184, "info_performance_final": 0.3862847089767456, "step": 120000}
{"episode_reward": 654.9479166666674, "episode": 1201.0, "batch_reward": 8.502864837646484, "critic_loss": 982.0904541015625, "actor_loss": -1453.0977783203125, "actor_target_entropy": -3.0, "actor_entropy": 2.0914859771728516, "alpha_loss": 0.11714869737625122, "alpha_value": 0.41996961020538864, "duration": 1.4368095397949219, "info_normalized_performance_mean": 0.3699800372123718, "info_normalized_performance_final": 0.47200000286102295, "info_performance_mean": 0.3699800372123718, "info_performance_final": 0.47200000286102295, "step": 120500}
{"episode_reward": 739.9600000000014, "episode": 1206.0, "batch_reward": 7.913715362548828, "critic_loss": 537.3096923828125, "actor_loss": -1452.061767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.8399444818496704, "alpha_loss": -0.015669964253902435, "alpha_value": 0.42038481781565595, "duration": 1.5190627574920654, "info_normalized_performance_mean": 0.3499351143836975, "info_normalized_performance_final": 0.3942857086658478, "info_performance_mean": 0.3499351143836975, "info_performance_final": 0.3942857086658478, "step": 121000}
{"episode_reward": 699.8701298701295, "episode": 1211.0, "batch_reward": 7.452905654907227, "critic_loss": 1259.8458251953125, "actor_loss": -1427.3345947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6357688903808594, "alpha_loss": 0.1394684612751007, "alpha_value": 0.4173673012780975, "duration": 1.5830180644989014, "info_normalized_performance_mean": 0.42378243803977966, "info_normalized_performance_final": 0.4950000047683716, "info_performance_mean": 0.42378243803977966, "info_performance_final": 0.4950000047683716, "step": 121500}
{"episode_reward": 847.5649999999988, "episode": 1216.0, "batch_reward": 7.943869113922119, "critic_loss": 1124.709228515625, "actor_loss": -1445.21533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4593755006790161, "alpha_loss": 0.013745537027716637, "alpha_value": 0.4131776010408809, "duration": 1.5759053230285645, "info_normalized_performance_mean": 0.8304351568222046, "info_normalized_performance_final": 0.9247058629989624, "info_performance_mean": 0.8304351568222046, "info_performance_final": 0.9247058629989624, "step": 122000}
{"episode_reward": 1660.8705882352945, "episode": 1221.0, "batch_reward": 7.936248302459717, "critic_loss": 645.9527587890625, "actor_loss": -1437.2020263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.919930338859558, "alpha_loss": 0.16529059410095215, "alpha_value": 0.4116004395469951, "duration": 1.622410535812378, "info_normalized_performance_mean": 0.48041456937789917, "info_normalized_performance_final": 0.5620833039283752, "info_performance_mean": 0.48041456937789917, "info_performance_final": 0.5620833039283752, "step": 122500}
{"episode_reward": 960.8291666666671, "episode": 1226.0, "batch_reward": 7.946066856384277, "critic_loss": 1953.27294921875, "actor_loss": -1426.314208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.5701568126678467, "alpha_loss": -0.08810816705226898, "alpha_value": 0.40664425387276465, "duration": 1.6257693767547607, "info_normalized_performance_mean": 0.7513996958732605, "info_normalized_performance_final": 0.8340548276901245, "info_performance_mean": 0.7513996958732605, "info_performance_final": 0.8340548276901245, "step": 123000}
{"episode_reward": 1502.7994227994257, "episode": 1231.0, "batch_reward": 7.658744812011719, "critic_loss": 1785.0262451171875, "actor_loss": -1415.526123046875, "actor_target_entropy": -3.0, "actor_entropy": 1.9166654348373413, "alpha_loss": -0.1477053314447403, "alpha_value": 0.40282436869614585, "duration": 1.5891222953796387, "info_normalized_performance_mean": 0.6932891607284546, "info_normalized_performance_final": 0.7795414328575134, "info_performance_mean": 0.6932891607284546, "info_performance_final": 0.7795414328575134, "step": 123500}
{"episode_reward": 1386.5784832451484, "episode": 1236.0, "batch_reward": 8.28569221496582, "critic_loss": 2362.745849609375, "actor_loss": -1475.5902099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.821277141571045, "alpha_loss": -0.12398681044578552, "alpha_value": 0.3982467749023681, "duration": 1.5538570880889893, "info_normalized_performance_mean": 0.7057144045829773, "info_normalized_performance_final": 0.7802197933197021, "info_performance_mean": 0.7057144045829773, "info_performance_final": 0.7802197933197021, "step": 124000}
{"episode_reward": 1411.428571428572, "episode": 1241.0, "batch_reward": 8.327140808105469, "critic_loss": 341.35540771484375, "actor_loss": -1482.77197265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6596508026123047, "alpha_loss": 0.016817541792988777, "alpha_value": 0.39760378603506, "duration": 1.6212520599365234, "info_normalized_performance_mean": 0.5781547427177429, "info_normalized_performance_final": 0.6882440447807312, "info_performance_mean": 0.5781547427177429, "info_performance_final": 0.6882440447807312, "step": 124500}
{"episode_reward": 1156.3095238095243, "episode": 1246.0, "batch_reward": 7.658238887786865, "critic_loss": 724.8416137695312, "actor_loss": -1380.52392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.657366394996643, "alpha_loss": 0.04646677523851395, "alpha_value": 0.39798959724942573, "duration": 1.5119481086730957, "info_normalized_performance_mean": 0.4535617530345917, "info_normalized_performance_final": 0.5326704382896423, "info_performance_mean": 0.4535617530345917, "info_performance_final": 0.5326704382896423, "step": 125000}
{"episode_reward": 907.1235795454551, "episode": 1251.0, "batch_reward": 8.45649528503418, "critic_loss": 1428.96875, "actor_loss": -1481.038330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.7246191501617432, "alpha_loss": -0.24222332239151, "alpha_value": 0.4001540455104885, "duration": 1.5287814140319824, "info_normalized_performance_mean": 0.6545625329017639, "info_normalized_performance_final": 0.7300000190734863, "info_performance_mean": 0.6545625329017639, "info_performance_final": 0.7300000190734863, "step": 125500}
{"episode_reward": 1309.1249999999993, "episode": 1256.0, "batch_reward": 8.919282913208008, "critic_loss": 2913.43115234375, "actor_loss": -1506.38916015625, "actor_target_entropy": -3.0, "actor_entropy": 1.6436810493469238, "alpha_loss": 0.09036019444465637, "alpha_value": 0.3958484560470536, "duration": 1.517449140548706, "info_normalized_performance_mean": 0.5563823580741882, "info_normalized_performance_final": 0.6264705657958984, "info_performance_mean": 0.5563823580741882, "info_performance_final": 0.6264705657958984, "step": 126000}
{"episode_reward": 1112.764705882351, "episode": 1261.0, "batch_reward": 8.440742492675781, "critic_loss": 758.3170166015625, "actor_loss": -1461.997802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.6328136920928955, "alpha_loss": -0.2188759297132492, "alpha_value": 0.39697418745397783, "duration": 1.4607341289520264, "info_normalized_performance_mean": 0.5334820747375488, "info_normalized_performance_final": 0.5940476059913635, "info_performance_mean": 0.5334820747375488, "info_performance_final": 0.5940476059913635, "step": 126500}
{"episode_reward": 1066.9642857142871, "episode": 1266.0, "batch_reward": 7.604297637939453, "critic_loss": 1093.486083984375, "actor_loss": -1398.244384765625, "actor_target_entropy": -3.0, "actor_entropy": 1.4971957206726074, "alpha_loss": -0.1938410997390747, "alpha_value": 0.39997137488807916, "duration": 1.5687720775604248, "info_normalized_performance_mean": 0.7270923852920532, "info_normalized_performance_final": 0.8621848821640015, "info_performance_mean": 0.7270923852920532, "info_performance_final": 0.8621848821640015, "step": 127000}
{"episode_reward": 1454.1848739495817, "episode": 1271.0, "batch_reward": 8.824317932128906, "critic_loss": 822.41259765625, "actor_loss": -1451.288330078125, "actor_target_entropy": -3.0, "actor_entropy": 2.018333911895752, "alpha_loss": 0.10664262622594833, "alpha_value": 0.3978388007966266, "duration": 1.4588403701782227, "info_normalized_performance_mean": 0.4127231538295746, "info_normalized_performance_final": 0.4751984179019928, "info_performance_mean": 0.4127231538295746, "info_performance_final": 0.4751984179019928, "step": 127500}
{"episode_reward": 825.4464285714266, "episode": 1276.0, "batch_reward": 8.061838150024414, "critic_loss": 565.4530029296875, "actor_loss": -1404.0980224609375, "actor_target_entropy": -3.0, "actor_entropy": 2.086540699005127, "alpha_loss": -0.24242830276489258, "alpha_value": 0.3977203703491663, "duration": 1.4146983623504639, "info_normalized_performance_mean": 0.3566741645336151, "info_normalized_performance_final": 0.3995535671710968, "info_performance_mean": 0.3566741645336151, "info_performance_final": 0.3995535671710968, "step": 128000}
{"episode_reward": 713.348214285715, "episode": 1281.0, "batch_reward": 8.192161560058594, "critic_loss": 1268.906982421875, "actor_loss": -1470.21875, "actor_target_entropy": -3.0, "actor_entropy": 1.3374719619750977, "alpha_loss": 3.329664468765259e-05, "alpha_value": 0.4021376910863669, "duration": 1.4071660041809082, "info_normalized_performance_mean": 1.7361111531499773e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 1.7361111531499773e-05, "info_performance_final": 0.0, "step": 128500}
{"episode_reward": 0.034722222222222224, "episode": 1286.0, "batch_reward": 8.269458770751953, "critic_loss": 514.0608520507812, "actor_loss": -1454.00341796875, "actor_target_entropy": -3.0, "actor_entropy": 1.7591066360473633, "alpha_loss": 0.04046310484409332, "alpha_value": 0.40224583986463913, "duration": 1.428992509841919, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 129000}
{"episode_reward": 0.0, "episode": 1291.0, "batch_reward": 8.463068008422852, "critic_loss": 1120.44384765625, "actor_loss": -1442.8917236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.8497445583343506, "alpha_loss": 0.08153829723596573, "alpha_value": 0.40265855323351274, "duration": 1.5506103038787842, "info_normalized_performance_mean": 0.44352424144744873, "info_normalized_performance_final": 0.5109427571296692, "info_performance_mean": 0.44352424144744873, "info_performance_final": 0.5109427571296692, "step": 129500}
{"episode_reward": 887.0482603815927, "episode": 1296.0, "batch_reward": 7.461449146270752, "critic_loss": 270.96221923828125, "actor_loss": -1392.12451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5815439224243164, "alpha_loss": 0.1742256134748459, "alpha_value": 0.4005958603851258, "step": 130000}
{"duration": 18.46361255645752, "info_normalized_performance_mean": 0.3122176229953766, "info_normalized_performance_final": 0.3917011022567749, "info_performance_mean": 0.3122176229953766, "info_performance_final": 0.3917011022567749, "step": 130000}
{"episode_reward": 624.4352617079884, "episode": 1301.0, "batch_reward": 8.618181228637695, "critic_loss": 635.2408447265625, "actor_loss": -1454.0869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.7935185432434082, "alpha_loss": 0.11114385724067688, "alpha_value": 0.39692858024838795, "duration": 1.6132757663726807, "info_normalized_performance_mean": 0.6717233061790466, "info_normalized_performance_final": 0.7369614243507385, "info_performance_mean": 0.6717233061790466, "info_performance_final": 0.7369614243507385, "step": 130500}
{"episode_reward": 1343.44671201814, "episode": 1306.0, "batch_reward": 7.793125152587891, "critic_loss": 594.863525390625, "actor_loss": -1377.1513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.6323777437210083, "alpha_loss": -0.031073443591594696, "alpha_value": 0.39545449938994826, "duration": 1.4869673252105713, "info_normalized_performance_mean": 0.39053404331207275, "info_normalized_performance_final": 0.4831541180610657, "info_performance_mean": 0.39053404331207275, "info_performance_final": 0.4831541180610657, "step": 131000}
{"episode_reward": 781.0681003584231, "episode": 1311.0, "batch_reward": 8.208041191101074, "critic_loss": 545.562255859375, "actor_loss": -1398.78125, "actor_target_entropy": -3.0, "actor_entropy": 2.0603065490722656, "alpha_loss": 0.0878177359700203, "alpha_value": 0.39109444756644746, "duration": 1.439755916595459, "info_normalized_performance_mean": 0.5502321720123291, "info_normalized_performance_final": 0.6107142567634583, "info_performance_mean": 0.5502321720123291, "info_performance_final": 0.6107142567634583, "step": 131500}
{"episode_reward": 1100.4642857142844, "episode": 1316.0, "batch_reward": 8.91209888458252, "critic_loss": 318.46722412109375, "actor_loss": -1444.33203125, "actor_target_entropy": -3.0, "actor_entropy": 2.103726863861084, "alpha_loss": -0.14179840683937073, "alpha_value": 0.3899263965936179, "duration": 1.467313528060913, "info_normalized_performance_mean": 0.5455159544944763, "info_normalized_performance_final": 0.6051587462425232, "info_performance_mean": 0.5455159544944763, "info_performance_final": 0.6051587462425232, "step": 132000}
{"episode_reward": 1091.0317460317451, "episode": 1321.0, "batch_reward": 9.742500305175781, "critic_loss": 1694.728271484375, "actor_loss": -1509.9632568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.9443271160125732, "alpha_loss": -0.09756065905094147, "alpha_value": 0.3865527170636006, "duration": 1.4875118732452393, "info_normalized_performance_mean": 0.2628351151943207, "info_normalized_performance_final": 0.3491039574146271, "info_performance_mean": 0.2628351151943207, "info_performance_final": 0.3491039574146271, "step": 132500}
{"episode_reward": 525.6702508960574, "episode": 1326.0, "batch_reward": 7.808295249938965, "critic_loss": 346.31317138671875, "actor_loss": -1366.9893798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.5831389427185059, "alpha_loss": 0.08402545005083084, "alpha_value": 0.3850586723538109, "duration": 1.3473081588745117, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 133000}
{"episode_reward": 0.0, "episode": 1331.0, "batch_reward": 8.213094711303711, "critic_loss": 991.8331909179688, "actor_loss": -1428.2364501953125, "actor_target_entropy": -3.0, "actor_entropy": 1.5749132633209229, "alpha_loss": -0.10041965544223785, "alpha_value": 0.3822970404262365, "duration": 1.447868824005127, "info_normalized_performance_mean": 0.6734820604324341, "info_normalized_performance_final": 0.7745535969734192, "info_performance_mean": 0.6734820604324341, "info_performance_final": 0.7745535969734192, "step": 133500}
{"episode_reward": 1346.9642857142844, "episode": 1336.0, "batch_reward": 8.582443237304688, "critic_loss": 650.955322265625, "actor_loss": -1429.931396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4951738119125366, "alpha_loss": 0.0585264191031456, "alpha_value": 0.3794858401513944, "duration": 1.527000904083252, "info_normalized_performance_mean": 0.4243199825286865, "info_normalized_performance_final": 0.49004119634628296, "info_performance_mean": 0.4243199825286865, "info_performance_final": 0.49004119634628296, "step": 134000}
{"episode_reward": 848.6401098901079, "episode": 1341.0, "batch_reward": 8.521032333374023, "critic_loss": 706.4371948242188, "actor_loss": -1435.320068359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6803441047668457, "alpha_loss": 0.18484073877334595, "alpha_value": 0.375503225166283, "duration": 1.4585232734680176, "info_normalized_performance_mean": 0.3647705018520355, "info_normalized_performance_final": 0.42138671875, "info_performance_mean": 0.3647705018520355, "info_performance_final": 0.42138671875, "step": 134500}
{"episode_reward": 729.541015625, "episode": 1346.0, "batch_reward": 7.934896469116211, "critic_loss": 1098.98583984375, "actor_loss": -1368.593017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7807894945144653, "alpha_loss": -0.0037080422043800354, "alpha_value": 0.3723775722296199, "duration": 1.407512903213501, "info_normalized_performance_mean": 0.1538676619529724, "info_normalized_performance_final": 0.17058824002742767, "info_performance_mean": 0.1538676619529724, "info_performance_final": 0.17058824002742767, "step": 135000}
{"episode_reward": 307.7352941176472, "episode": 1351.0, "batch_reward": 7.969277381896973, "critic_loss": 1084.8609619140625, "actor_loss": -1396.67578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2699692249298096, "alpha_loss": 0.1745227575302124, "alpha_value": 0.36981374736095934, "duration": 1.5948913097381592, "info_normalized_performance_mean": 0.4109799563884735, "info_normalized_performance_final": 0.45679011940956116, "info_performance_mean": 0.4109799563884735, "info_performance_final": 0.45679011940956116, "step": 135500}
{"episode_reward": 821.9598765432102, "episode": 1356.0, "batch_reward": 7.351230621337891, "critic_loss": 1353.1611328125, "actor_loss": -1344.13427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3711521625518799, "alpha_loss": 0.18266387283802032, "alpha_value": 0.36510567625194973, "duration": 1.4765667915344238, "info_normalized_performance_mean": 0.03662499785423279, "info_normalized_performance_final": 0.04027777910232544, "info_performance_mean": 0.03662499785423279, "info_performance_final": 0.04027777910232544, "step": 136000}
{"episode_reward": 73.2500000000001, "episode": 1361.0, "batch_reward": 8.370340347290039, "critic_loss": 881.6848754882812, "actor_loss": -1401.701416015625, "actor_target_entropy": -3.0, "actor_entropy": 1.6057465076446533, "alpha_loss": -0.019786901772022247, "alpha_value": 0.36591110318078396, "duration": 1.494943618774414, "info_normalized_performance_mean": 0.6145156025886536, "info_normalized_performance_final": 0.684374988079071, "info_performance_mean": 0.6145156025886536, "info_performance_final": 0.684374988079071, "step": 136500}
{"episode_reward": 1229.03125, "episode": 1366.0, "batch_reward": 8.149749755859375, "critic_loss": 1670.245849609375, "actor_loss": -1418.729248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.6214998960494995, "alpha_loss": 0.037301935255527496, "alpha_value": 0.36502462159464993, "duration": 1.5677473545074463, "info_normalized_performance_mean": 0.37722697854042053, "info_normalized_performance_final": 0.43708452582359314, "info_performance_mean": 0.37722697854042053, "info_performance_final": 0.43708452582359314, "step": 137000}
{"episode_reward": 754.4539411206072, "episode": 1371.0, "batch_reward": 8.7979736328125, "critic_loss": 1262.2667236328125, "actor_loss": -1441.88720703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6306781768798828, "alpha_loss": 0.013448728248476982, "alpha_value": 0.36638376717910626, "duration": 1.7599561214447021, "info_normalized_performance_mean": 0.5613095164299011, "info_normalized_performance_final": 0.766330897808075, "info_performance_mean": 0.5613095164299011, "info_performance_final": 0.766330897808075, "step": 137500}
{"episode_reward": 1122.6190476190484, "episode": 1376.0, "batch_reward": 9.133599281311035, "critic_loss": 426.1556396484375, "actor_loss": -1424.10302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.949087142944336, "alpha_loss": 0.20325613021850586, "alpha_value": 0.3713917222274484, "duration": 1.4740817546844482, "info_normalized_performance_mean": 0.4030419886112213, "info_normalized_performance_final": 0.47265625, "info_performance_mean": 0.4030419886112213, "info_performance_final": 0.47265625, "step": 138000}
{"episode_reward": 806.083984375, "episode": 1381.0, "batch_reward": 7.405773162841797, "critic_loss": 678.2127685546875, "actor_loss": -1341.7359619140625, "actor_target_entropy": -3.0, "actor_entropy": 1.3236756324768066, "alpha_loss": 0.06022052466869354, "alpha_value": 0.3684217573352195, "duration": 1.6645476818084717, "info_normalized_performance_mean": 0.4810647964477539, "info_normalized_performance_final": 0.613095223903656, "info_performance_mean": 0.4810647964477539, "info_performance_final": 0.613095223903656, "step": 138500}
{"episode_reward": 962.1296296296316, "episode": 1386.0, "batch_reward": 8.062845230102539, "critic_loss": 1413.004150390625, "actor_loss": -1363.4150390625, "actor_target_entropy": -3.0, "actor_entropy": 1.599252462387085, "alpha_loss": -0.224395290017128, "alpha_value": 0.36754319412167546, "duration": 1.4515771865844727, "info_normalized_performance_mean": 0.3335459232330322, "info_normalized_performance_final": 0.4368622303009033, "info_performance_mean": 0.3335459232330322, "info_performance_final": 0.4368622303009033, "step": 139000}
{"episode_reward": 667.0918367346927, "episode": 1391.0, "batch_reward": 8.1615571975708, "critic_loss": 1151.9122314453125, "actor_loss": -1403.0423583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3299064636230469, "alpha_loss": -0.013030249625444412, "alpha_value": 0.36578002544081334, "duration": 1.5858943462371826, "info_normalized_performance_mean": 0.7208877801895142, "info_normalized_performance_final": 0.7882353067398071, "info_performance_mean": 0.7208877801895142, "info_performance_final": 0.7882353067398071, "step": 139500}
{"episode_reward": 1441.7754010695178, "episode": 1396.0, "batch_reward": 8.830880165100098, "critic_loss": 795.1993408203125, "actor_loss": -1452.591552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.6215507984161377, "alpha_loss": -0.172447070479393, "alpha_value": 0.36388652611219313, "step": 140000}
{"duration": 19.055267810821533, "info_normalized_performance_mean": 0.5934682488441467, "info_normalized_performance_final": 0.670634925365448, "info_performance_mean": 0.5934682488441467, "info_performance_final": 0.670634925365448, "step": 140000}
{"episode_reward": 1186.936507936508, "episode": 1401.0, "batch_reward": 7.734862804412842, "critic_loss": 2384.611328125, "actor_loss": -1409.073486328125, "actor_target_entropy": -3.0, "actor_entropy": 1.6774194240570068, "alpha_loss": -0.022007334977388382, "alpha_value": 0.35931176303361195, "duration": 1.653337001800537, "info_normalized_performance_mean": 0.25050216913223267, "info_normalized_performance_final": 0.28617215156555176, "info_performance_mean": 0.25050216913223267, "info_performance_final": 0.28617215156555176, "step": 140500}
{"episode_reward": 501.00427350427293, "episode": 1406.0, "batch_reward": 8.415416717529297, "critic_loss": 1681.0390625, "actor_loss": -1396.128173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.5773743391036987, "alpha_loss": 0.29139959812164307, "alpha_value": 0.35826070741315474, "duration": 1.583137035369873, "info_normalized_performance_mean": 0.3806638717651367, "info_normalized_performance_final": 0.42424243688583374, "info_performance_mean": 0.3806638717651367, "info_performance_final": 0.42424243688583374, "step": 141000}
{"episode_reward": 761.3275613275623, "episode": 1411.0, "batch_reward": 8.300225257873535, "critic_loss": 2168.90869140625, "actor_loss": -1390.708740234375, "actor_target_entropy": -3.0, "actor_entropy": 1.7214627265930176, "alpha_loss": -0.20961257815361023, "alpha_value": 0.35474592745837813, "duration": 1.5879895687103271, "info_normalized_performance_mean": 0.6161805987358093, "info_normalized_performance_final": 0.6753472089767456, "info_performance_mean": 0.6161805987358093, "info_performance_final": 0.6753472089767456, "step": 141500}
{"episode_reward": 1232.3611111111104, "episode": 1416.0, "batch_reward": 8.213748931884766, "critic_loss": 470.07440185546875, "actor_loss": -1397.32421875, "actor_target_entropy": -3.0, "actor_entropy": 1.245964765548706, "alpha_loss": 0.2295907884836197, "alpha_value": 0.3532167483876694, "duration": 1.4878954887390137, "info_normalized_performance_mean": 0.45554688572883606, "info_normalized_performance_final": 0.515625, "info_performance_mean": 0.45554688572883606, "info_performance_final": 0.515625, "step": 142000}
{"episode_reward": 911.09375, "episode": 1421.0, "batch_reward": 8.850797653198242, "critic_loss": 929.1365966796875, "actor_loss": -1436.0911865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.6620774269104004, "alpha_loss": 0.1523311883211136, "alpha_value": 0.350684532691373, "duration": 1.4887044429779053, "info_normalized_performance_mean": 0.45834702253341675, "info_normalized_performance_final": 0.5700549483299255, "info_performance_mean": 0.45834702253341675, "info_performance_final": 0.5700549483299255, "step": 142500}
{"episode_reward": 916.6941391941375, "episode": 1426.0, "batch_reward": 7.984003067016602, "critic_loss": 721.3075561523438, "actor_loss": -1390.347412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3900823593139648, "alpha_loss": -0.18244928121566772, "alpha_value": 0.34815447106394076, "duration": 1.5724775791168213, "info_normalized_performance_mean": 0.6844331622123718, "info_normalized_performance_final": 0.7630385756492615, "info_performance_mean": 0.6844331622123718, "info_performance_final": 0.7630385756492615, "step": 143000}
{"episode_reward": 1368.8662131519268, "episode": 1431.0, "batch_reward": 8.865842819213867, "critic_loss": 1110.665771484375, "actor_loss": -1429.59375, "actor_target_entropy": -3.0, "actor_entropy": 1.412759780883789, "alpha_loss": 0.19057247042655945, "alpha_value": 0.3459088667862422, "duration": 1.5993564128875732, "info_normalized_performance_mean": 0.7808274626731873, "info_normalized_performance_final": 0.8718820810317993, "info_performance_mean": 0.7808274626731873, "info_performance_final": 0.8718820810317993, "step": 143500}
{"episode_reward": 1561.6553287981835, "episode": 1436.0, "batch_reward": 8.313307762145996, "critic_loss": 450.5933837890625, "actor_loss": -1427.06005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.7359850406646729, "alpha_loss": 0.09962549805641174, "alpha_value": 0.3473583994339947, "duration": 1.4835460186004639, "info_normalized_performance_mean": 0.4227243661880493, "info_normalized_performance_final": 0.4734693765640259, "info_performance_mean": 0.4227243661880493, "info_performance_final": 0.4734693765640259, "step": 144000}
{"episode_reward": 845.448979591837, "episode": 1441.0, "batch_reward": 8.612205505371094, "critic_loss": 1762.0125732421875, "actor_loss": -1405.8623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.538832664489746, "alpha_loss": -0.04261969402432442, "alpha_value": 0.34840686238581425, "duration": 1.4733359813690186, "info_normalized_performance_mean": 0.1644875407218933, "info_normalized_performance_final": 0.18000000715255737, "info_performance_mean": 0.1644875407218933, "info_performance_final": 0.18000000715255737, "step": 144500}
{"episode_reward": 328.9750000000002, "episode": 1446.0, "batch_reward": 9.048500061035156, "critic_loss": 373.71575927734375, "actor_loss": -1424.471923828125, "actor_target_entropy": -3.0, "actor_entropy": 1.5794694423675537, "alpha_loss": 0.010277226567268372, "alpha_value": 0.3489459321502286, "duration": 1.4488999843597412, "info_normalized_performance_mean": 0.7311480045318604, "info_normalized_performance_final": 0.8035714030265808, "info_performance_mean": 0.7311480045318604, "info_performance_final": 0.8035714030265808, "step": 145000}
{"episode_reward": 1462.295918367349, "episode": 1451.0, "batch_reward": 8.446233749389648, "critic_loss": 342.59637451171875, "actor_loss": -1405.1055908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.677983045578003, "alpha_loss": -0.3306899666786194, "alpha_value": 0.35151473900839597, "duration": 1.4533681869506836, "info_normalized_performance_mean": 0.4244323968887329, "info_normalized_performance_final": 0.46301019191741943, "info_performance_mean": 0.4244323968887329, "info_performance_final": 0.46301019191741943, "step": 145500}
{"episode_reward": 848.8647959183672, "episode": 1456.0, "batch_reward": 8.925769805908203, "critic_loss": 851.2666015625, "actor_loss": -1432.327880859375, "actor_target_entropy": -3.0, "actor_entropy": 1.5897225141525269, "alpha_loss": 0.18128374218940735, "alpha_value": 0.3485869634820487, "duration": 1.4684085845947266, "info_normalized_performance_mean": 0.14160512387752533, "info_normalized_performance_final": 0.15482954680919647, "info_performance_mean": 0.14160512387752533, "info_performance_final": 0.15482954680919647, "step": 146000}
{"episode_reward": 283.2102272727273, "episode": 1461.0, "batch_reward": 8.008742332458496, "critic_loss": 425.2688293457031, "actor_loss": -1395.2247314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.4170887470245361, "alpha_loss": -0.10432117432355881, "alpha_value": 0.34547351305175816, "duration": 1.605121374130249, "info_normalized_performance_mean": 0.6119548082351685, "info_normalized_performance_final": 0.6687783002853394, "info_performance_mean": 0.6119548082351685, "info_performance_final": 0.6687783002853394, "step": 146500}
{"episode_reward": 1223.909502262445, "episode": 1466.0, "batch_reward": 8.432928085327148, "critic_loss": 929.31884765625, "actor_loss": -1399.46728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.524674654006958, "alpha_loss": -0.09582196921110153, "alpha_value": 0.3448661068432515, "duration": 1.5030303001403809, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 147000}
{"episode_reward": 0.0, "episode": 1471.0, "batch_reward": 8.01840591430664, "critic_loss": 976.9317016601562, "actor_loss": -1385.932861328125, "actor_target_entropy": -3.0, "actor_entropy": 1.447383999824524, "alpha_loss": -0.11425134539604187, "alpha_value": 0.3446700678714225, "duration": 1.7760443687438965, "info_normalized_performance_mean": 0.5885887145996094, "info_normalized_performance_final": 0.6768912672996521, "info_performance_mean": 0.5885887145996094, "info_performance_final": 0.6768912672996521, "step": 147500}
{"episode_reward": 1177.1773680864587, "episode": 1476.0, "batch_reward": 7.979491233825684, "critic_loss": 415.062744140625, "actor_loss": -1372.72705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4682844877243042, "alpha_loss": 0.05090642347931862, "alpha_value": 0.34618884798457755, "duration": 1.6745715141296387, "info_normalized_performance_mean": 0.23889809846878052, "info_normalized_performance_final": 0.2710055112838745, "info_performance_mean": 0.23889809846878052, "info_performance_final": 0.2710055112838745, "step": 148000}
{"episode_reward": 477.7961432506881, "episode": 1481.0, "batch_reward": 8.533523559570312, "critic_loss": 579.3740234375, "actor_loss": -1356.5035400390625, "actor_target_entropy": -3.0, "actor_entropy": 1.4858416318893433, "alpha_loss": 0.04327695816755295, "alpha_value": 0.3409409400942194, "duration": 1.5571210384368896, "info_normalized_performance_mean": 0.765618085861206, "info_normalized_performance_final": 0.8502747416496277, "info_performance_mean": 0.765618085861206, "info_performance_final": 0.8502747416496277, "step": 148500}
{"episode_reward": 1531.2362637362621, "episode": 1486.0, "batch_reward": 9.291269302368164, "critic_loss": 545.6387939453125, "actor_loss": -1448.725341796875, "actor_target_entropy": -3.0, "actor_entropy": 1.6287190914154053, "alpha_loss": -0.1703331470489502, "alpha_value": 0.33928197669505933, "duration": 1.5589745044708252, "info_normalized_performance_mean": 0.8272547721862793, "info_normalized_performance_final": 0.9071895480155945, "info_performance_mean": 0.8272547721862793, "info_performance_final": 0.9071895480155945, "step": 149000}
{"episode_reward": 1654.50980392157, "episode": 1491.0, "batch_reward": 8.629762649536133, "critic_loss": 620.5753173828125, "actor_loss": -1394.912841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5505579710006714, "alpha_loss": -0.0014475015923380852, "alpha_value": 0.3407137713869999, "duration": 1.4760754108428955, "info_normalized_performance_mean": 0.49232056736946106, "info_normalized_performance_final": 0.5387731194496155, "info_performance_mean": 0.49232056736946106, "info_performance_final": 0.5387731194496155, "step": 149500}
{"episode_reward": 984.6412037037018, "episode": 1496.0, "batch_reward": 8.297033309936523, "critic_loss": 577.4493408203125, "actor_loss": -1380.8037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.527477502822876, "alpha_loss": -0.1359613537788391, "alpha_value": 0.34308729033341395, "step": 150000}
{"duration": 18.746140718460083, "info_normalized_performance_mean": 0.8485293388366699, "info_normalized_performance_final": 0.9784313440322876, "info_performance_mean": 0.8485293388366699, "info_performance_final": 0.9784313440322876, "step": 150000}
{"episode_reward": 1697.058823529411, "episode": 1501.0, "batch_reward": 8.723125457763672, "critic_loss": 411.94561767578125, "actor_loss": -1414.542724609375, "actor_target_entropy": -3.0, "actor_entropy": 1.5383597612380981, "alpha_loss": 0.08486095815896988, "alpha_value": 0.34340196211072904, "duration": 1.421691656112671, "info_normalized_performance_mean": 0.3619534373283386, "info_normalized_performance_final": 0.40043291449546814, "info_performance_mean": 0.3619534373283386, "info_performance_final": 0.40043291449546814, "step": 150500}
{"episode_reward": 723.9069264069269, "episode": 1506.0, "batch_reward": 8.154093742370605, "critic_loss": 603.2608642578125, "actor_loss": -1391.43408203125, "actor_target_entropy": -3.0, "actor_entropy": 1.3968415260314941, "alpha_loss": -0.2991694211959839, "alpha_value": 0.3434504549033479, "duration": 1.6182920932769775, "info_normalized_performance_mean": 0.3249461352825165, "info_normalized_performance_final": 0.39254385232925415, "info_performance_mean": 0.3249461352825165, "info_performance_final": 0.39254385232925415, "step": 151000}
{"episode_reward": 649.8923444976083, "episode": 1511.0, "batch_reward": 8.95411491394043, "critic_loss": 444.4483642578125, "actor_loss": -1385.33984375, "actor_target_entropy": -3.0, "actor_entropy": 1.528883934020996, "alpha_loss": 0.12146981060504913, "alpha_value": 0.3434306353135051, "duration": 1.6278924942016602, "info_normalized_performance_mean": 0.39838680624961853, "info_normalized_performance_final": 0.538021981716156, "info_performance_mean": 0.39838680624961853, "info_performance_final": 0.538021981716156, "step": 151500}
{"episode_reward": 796.7736263736272, "episode": 1516.0, "batch_reward": 9.536855697631836, "critic_loss": 1291.3262939453125, "actor_loss": -1455.333251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.3799564838409424, "alpha_loss": -0.1951126605272293, "alpha_value": 0.341579200956407, "duration": 1.6253981590270996, "info_normalized_performance_mean": 0.5801516175270081, "info_normalized_performance_final": 0.639971137046814, "info_performance_mean": 0.5801516175270081, "info_performance_final": 0.639971137046814, "step": 152000}
{"episode_reward": 1160.3030303030303, "episode": 1521.0, "batch_reward": 8.807559967041016, "critic_loss": 351.4422607421875, "actor_loss": -1411.3685302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.8179256916046143, "alpha_loss": -0.06302700936794281, "alpha_value": 0.34361794167365695, "duration": 1.594285488128662, "info_normalized_performance_mean": 0.47547629475593567, "info_normalized_performance_final": 0.5299823880195618, "info_performance_mean": 0.47547629475593567, "info_performance_final": 0.5299823880195618, "step": 152500}
{"episode_reward": 950.9523809523803, "episode": 1526.0, "batch_reward": 8.464839935302734, "critic_loss": 1272.6065673828125, "actor_loss": -1353.587646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3645856380462646, "alpha_loss": 0.02558714523911476, "alpha_value": 0.34283265627500625, "duration": 1.4858989715576172, "info_normalized_performance_mean": 0.2047647088766098, "info_normalized_performance_final": 0.2245098054409027, "info_performance_mean": 0.2047647088766098, "info_performance_final": 0.2245098054409027, "step": 153000}
{"episode_reward": 409.52941176470637, "episode": 1531.0, "batch_reward": 8.379878997802734, "critic_loss": 331.8416748046875, "actor_loss": -1353.2930908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.6105659008026123, "alpha_loss": 0.24498793482780457, "alpha_value": 0.33571343617406213, "duration": 1.4520978927612305, "info_normalized_performance_mean": 0.6436953544616699, "info_normalized_performance_final": 0.7088293433189392, "info_performance_mean": 0.6436953544616699, "info_performance_final": 0.7088293433189392, "step": 153500}
{"episode_reward": 1287.390873015873, "episode": 1536.0, "batch_reward": 8.553611755371094, "critic_loss": 632.6983642578125, "actor_loss": -1379.105224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3149940967559814, "alpha_loss": 0.08318963646888733, "alpha_value": 0.32872864482641395, "duration": 1.3789350986480713, "info_normalized_performance_mean": 0.2654688060283661, "info_normalized_performance_final": 0.3102678656578064, "info_performance_mean": 0.2654688060283661, "info_performance_final": 0.3102678656578064, "step": 154000}
{"episode_reward": 530.9375000000008, "episode": 1541.0, "batch_reward": 8.664525985717773, "critic_loss": 646.63671875, "actor_loss": -1391.4111328125, "actor_target_entropy": -3.0, "actor_entropy": 1.5765423774719238, "alpha_loss": 0.07557621598243713, "alpha_value": 0.32141242843339907, "duration": 1.51926589012146, "info_normalized_performance_mean": 0.20042060315608978, "info_normalized_performance_final": 0.21984127163887024, "info_performance_mean": 0.20042060315608978, "info_performance_final": 0.21984127163887024, "step": 154500}
{"episode_reward": 400.8412698412704, "episode": 1546.0, "batch_reward": 8.871821403503418, "critic_loss": 741.733154296875, "actor_loss": -1389.8375244140625, "actor_target_entropy": -3.0, "actor_entropy": 1.187131643295288, "alpha_loss": 0.05058891326189041, "alpha_value": 0.3181856657044219, "duration": 1.4832496643066406, "info_normalized_performance_mean": 0.3302604556083679, "info_normalized_performance_final": 0.369047611951828, "info_performance_mean": 0.3302604556083679, "info_performance_final": 0.369047611951828, "step": 155000}
{"episode_reward": 660.5208333333347, "episode": 1551.0, "batch_reward": 8.649312973022461, "critic_loss": 412.2518615722656, "actor_loss": -1386.0924072265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3574862480163574, "alpha_loss": 0.007881825789809227, "alpha_value": 0.31536337478772664, "duration": 1.640972375869751, "info_normalized_performance_mean": 0.4514351189136505, "info_normalized_performance_final": 0.5734127163887024, "info_performance_mean": 0.4514351189136505, "info_performance_final": 0.5734127163887024, "step": 155500}
{"episode_reward": 902.8703703703688, "episode": 1556.0, "batch_reward": 8.71651840209961, "critic_loss": 445.8205871582031, "actor_loss": -1377.7843017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2804815769195557, "alpha_loss": 0.24250446259975433, "alpha_value": 0.31401031882356595, "duration": 1.63679838180542, "info_normalized_performance_mean": 0.6120057106018066, "info_normalized_performance_final": 0.6897546648979187, "info_performance_mean": 0.6120057106018066, "info_performance_final": 0.6897546648979187, "step": 156000}
{"episode_reward": 1224.0115440115435, "episode": 1561.0, "batch_reward": 9.292301177978516, "critic_loss": 545.3990478515625, "actor_loss": -1408.62890625, "actor_target_entropy": -3.0, "actor_entropy": 1.4073352813720703, "alpha_loss": -0.04501587152481079, "alpha_value": 0.30924846002378215, "duration": 1.4853100776672363, "info_normalized_performance_mean": 0.5529540777206421, "info_normalized_performance_final": 0.61669921875, "info_performance_mean": 0.5529540777206421, "info_performance_final": 0.61669921875, "step": 156500}
{"episode_reward": 1105.908203125, "episode": 1566.0, "batch_reward": 8.741191864013672, "critic_loss": 882.21435546875, "actor_loss": -1390.390869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.106717586517334, "alpha_loss": -0.07761378586292267, "alpha_value": 0.30673270384612045, "duration": 1.4438679218292236, "info_normalized_performance_mean": 0.10015685111284256, "info_normalized_performance_final": 0.1111111119389534, "info_performance_mean": 0.10015685111284256, "info_performance_final": 0.1111111119389534, "step": 157000}
{"episode_reward": 200.31372549019645, "episode": 1571.0, "batch_reward": 8.875838279724121, "critic_loss": 1251.579833984375, "actor_loss": -1403.40087890625, "actor_target_entropy": -3.0, "actor_entropy": 1.594388484954834, "alpha_loss": 0.01335742324590683, "alpha_value": 0.3028024418162944, "duration": 1.4926555156707764, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 157500}
{"episode_reward": 0.0, "episode": 1576.0, "batch_reward": 8.265571594238281, "critic_loss": 655.533203125, "actor_loss": -1341.969970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.188887119293213, "alpha_loss": 0.03217757120728493, "alpha_value": 0.30103163612949396, "duration": 1.620943307876587, "info_normalized_performance_mean": 0.6512203812599182, "info_normalized_performance_final": 0.7142857313156128, "info_performance_mean": 0.6512203812599182, "info_performance_final": 0.7142857313156128, "step": 158000}
{"episode_reward": 1302.4404761904766, "episode": 1581.0, "batch_reward": 8.592170715332031, "critic_loss": 1765.3541259765625, "actor_loss": -1317.899658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.3688796758651733, "alpha_loss": 0.09511303156614304, "alpha_value": 0.30025835486791397, "duration": 1.5001673698425293, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 158500}
{"episode_reward": 0.0, "episode": 1586.0, "batch_reward": 8.402064323425293, "critic_loss": 2888.605224609375, "actor_loss": -1355.3443603515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1564505100250244, "alpha_loss": 0.0755244642496109, "alpha_value": 0.29796644627575214, "duration": 1.3948159217834473, "info_normalized_performance_mean": 0.6482440829277039, "info_normalized_performance_final": 0.711309552192688, "info_performance_mean": 0.6482440829277039, "info_performance_final": 0.711309552192688, "step": 159000}
{"episode_reward": 1296.4880952380934, "episode": 1591.0, "batch_reward": 9.525169372558594, "critic_loss": 828.6192016601562, "actor_loss": -1387.9853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.3113309144973755, "alpha_loss": 0.15168754756450653, "alpha_value": 0.2962717041713037, "duration": 1.5037260055541992, "info_normalized_performance_mean": 0.4009864032268524, "info_normalized_performance_final": 0.44104307889938354, "info_performance_mean": 0.4009864032268524, "info_performance_final": 0.44104307889938354, "step": 159500}
{"episode_reward": 801.9727891156473, "episode": 1596.0, "batch_reward": 8.19087028503418, "critic_loss": 1416.934326171875, "actor_loss": -1360.916748046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8858115673065186, "alpha_loss": -0.1177867203950882, "alpha_value": 0.2943294237610724, "step": 160000}
{"duration": 18.75225853919983, "info_normalized_performance_mean": 0.37752479314804077, "info_normalized_performance_final": 0.46209055185317993, "info_performance_mean": 0.37752479314804077, "info_performance_final": 0.46209055185317993, "step": 160000}
{"episode_reward": 755.0496871549508, "episode": 1601.0, "batch_reward": 8.431446075439453, "critic_loss": 1953.05126953125, "actor_loss": -1333.999267578125, "actor_target_entropy": -3.0, "actor_entropy": 1.304764747619629, "alpha_loss": 0.046700216829776764, "alpha_value": 0.2944759470391567, "duration": 1.4891245365142822, "info_normalized_performance_mean": 0.1822395771741867, "info_normalized_performance_final": 0.265625, "info_performance_mean": 0.1822395771741867, "info_performance_final": 0.265625, "step": 160500}
{"episode_reward": 364.47916666666663, "episode": 1606.0, "batch_reward": 8.700976371765137, "critic_loss": 496.98974609375, "actor_loss": -1375.989501953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1961462497711182, "alpha_loss": -0.032906945794820786, "alpha_value": 0.29239131249813793, "duration": 1.430302381515503, "info_normalized_performance_mean": 0.21189452707767487, "info_normalized_performance_final": 0.2421875, "info_performance_mean": 0.21189452707767487, "info_performance_final": 0.2421875, "step": 161000}
{"episode_reward": 423.7890625, "episode": 1611.0, "batch_reward": 9.011919021606445, "critic_loss": 989.9533081054688, "actor_loss": -1383.4599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2749241590499878, "alpha_loss": -0.1317281275987625, "alpha_value": 0.29389469776097044, "duration": 1.474109411239624, "info_normalized_performance_mean": 0.3289843797683716, "info_normalized_performance_final": 0.3802083432674408, "info_performance_mean": 0.3289843797683716, "info_performance_final": 0.3802083432674408, "step": 161500}
{"episode_reward": 657.9687499999995, "episode": 1616.0, "batch_reward": 8.36357307434082, "critic_loss": 863.5205688476562, "actor_loss": -1340.1168212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0549944639205933, "alpha_loss": -0.08698521554470062, "alpha_value": 0.2944818124699498, "duration": 1.4745161533355713, "info_normalized_performance_mean": 0.569774329662323, "info_normalized_performance_final": 0.6475694179534912, "info_performance_mean": 0.569774329662323, "info_performance_final": 0.6475694179534912, "step": 162000}
{"episode_reward": 1139.548611111113, "episode": 1621.0, "batch_reward": 9.542718887329102, "critic_loss": 1142.9599609375, "actor_loss": -1396.779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.133434534072876, "alpha_loss": 0.11742164194583893, "alpha_value": 0.2909539550804883, "duration": 1.7183837890625, "info_normalized_performance_mean": 0.3160744905471802, "info_normalized_performance_final": 0.38721001148223877, "info_performance_mean": 0.3160744905471802, "info_performance_final": 0.38721001148223877, "step": 162500}
{"episode_reward": 632.1489621489626, "episode": 1626.0, "batch_reward": 8.749608993530273, "critic_loss": 287.0702209472656, "actor_loss": -1363.68701171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7680451273918152, "alpha_loss": 0.061237089335918427, "alpha_value": 0.28966980050679536, "duration": 1.4699091911315918, "info_normalized_performance_mean": 0.37075287103652954, "info_normalized_performance_final": 0.4082352817058563, "info_performance_mean": 0.37075287103652954, "info_performance_final": 0.4082352817058563, "step": 163000}
{"episode_reward": 741.5058823529407, "episode": 1631.0, "batch_reward": 8.661956787109375, "critic_loss": 422.6180419921875, "actor_loss": -1370.397705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0532199144363403, "alpha_loss": -0.048595577478408813, "alpha_value": 0.2898811605764798, "duration": 1.410639762878418, "info_normalized_performance_mean": 0.028142360970377922, "info_normalized_performance_final": 0.03125, "info_performance_mean": 0.028142360970377922, "info_performance_final": 0.03125, "step": 163500}
{"episode_reward": 56.28472222222222, "episode": 1636.0, "batch_reward": 8.700471878051758, "critic_loss": 951.1702880859375, "actor_loss": -1332.37158203125, "actor_target_entropy": -3.0, "actor_entropy": 0.9812889099121094, "alpha_loss": 0.07489833235740662, "alpha_value": 0.285786609410127, "duration": 1.465670108795166, "info_normalized_performance_mean": 0.7708927989006042, "info_normalized_performance_final": 0.8720238208770752, "info_performance_mean": 0.7708927989006042, "info_performance_final": 0.8720238208770752, "step": 164000}
{"episode_reward": 1541.785714285713, "episode": 1641.0, "batch_reward": 9.390052795410156, "critic_loss": 753.1175537109375, "actor_loss": -1378.255126953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9617341756820679, "alpha_loss": 0.03890334069728851, "alpha_value": 0.2843190943027553, "duration": 1.5292840003967285, "info_normalized_performance_mean": 0.5877410769462585, "info_normalized_performance_final": 0.765625, "info_performance_mean": 0.5877410769462585, "info_performance_final": 0.765625, "step": 164500}
{"episode_reward": 1175.4821428571427, "episode": 1646.0, "batch_reward": 7.978760719299316, "critic_loss": 860.4693603515625, "actor_loss": -1371.709716796875, "actor_target_entropy": -3.0, "actor_entropy": 0.9146265983581543, "alpha_loss": -0.028224941343069077, "alpha_value": 0.28314805676538457, "duration": 1.48930025100708, "info_normalized_performance_mean": 0.29610389471054077, "info_normalized_performance_final": 0.44155845046043396, "info_performance_mean": 0.29610389471054077, "info_performance_final": 0.44155845046043396, "step": 165000}
{"episode_reward": 592.2077922077926, "episode": 1651.0, "batch_reward": 9.433048248291016, "critic_loss": 421.2711486816406, "actor_loss": -1357.8865966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0696762800216675, "alpha_loss": 0.1925288289785385, "alpha_value": 0.2838421460209284, "duration": 1.5416679382324219, "info_normalized_performance_mean": 0.7522143721580505, "info_normalized_performance_final": 0.8357142806053162, "info_performance_mean": 0.7522143721580505, "info_performance_final": 0.8357142806053162, "step": 165500}
{"episode_reward": 1504.428571428572, "episode": 1656.0, "batch_reward": 9.261144638061523, "critic_loss": 685.5372314453125, "actor_loss": -1355.4857177734375, "actor_target_entropy": -3.0, "actor_entropy": 1.080015778541565, "alpha_loss": 0.010254926048219204, "alpha_value": 0.2817936510643257, "duration": 1.5744283199310303, "info_normalized_performance_mean": 0.4334052801132202, "info_normalized_performance_final": 0.5111688375473022, "info_performance_mean": 0.4334052801132202, "info_performance_final": 0.5111688375473022, "step": 166000}
{"episode_reward": 866.8103896103914, "episode": 1661.0, "batch_reward": 9.21330738067627, "critic_loss": 542.0704345703125, "actor_loss": -1399.432373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1869699954986572, "alpha_loss": -0.16095896065235138, "alpha_value": 0.281686196124943, "duration": 1.4495220184326172, "info_normalized_performance_mean": 0.4958730638027191, "info_normalized_performance_final": 0.5446428656578064, "info_performance_mean": 0.4958730638027191, "info_performance_final": 0.5446428656578064, "step": 166500}
{"episode_reward": 991.7460317460308, "episode": 1666.0, "batch_reward": 8.628881454467773, "critic_loss": 952.9757690429688, "actor_loss": -1357.2509765625, "actor_target_entropy": -3.0, "actor_entropy": 0.7510212659835815, "alpha_loss": 0.01671013981103897, "alpha_value": 0.28290797412974317, "duration": 1.6429061889648438, "info_normalized_performance_mean": 0.6068284511566162, "info_normalized_performance_final": 0.7502381205558777, "info_performance_mean": 0.6068284511566162, "info_performance_final": 0.7502381205558777, "step": 167000}
{"episode_reward": 1213.6571428571433, "episode": 1671.0, "batch_reward": 8.937793731689453, "critic_loss": 1219.80517578125, "actor_loss": -1378.824951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.0127363204956055, "alpha_loss": -0.07960988581180573, "alpha_value": 0.2857432156904292, "duration": 1.4810259342193604, "info_normalized_performance_mean": 0.828697919845581, "info_normalized_performance_final": 0.9140625, "info_performance_mean": 0.828697919845581, "info_performance_final": 0.9140625, "step": 167500}
{"episode_reward": 1657.3958333333333, "episode": 1676.0, "batch_reward": 9.26375961303711, "critic_loss": 762.4334716796875, "actor_loss": -1320.414794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.5243858098983765, "alpha_loss": 0.00043839961290359497, "alpha_value": 0.2869764529751877, "duration": 1.4741311073303223, "info_normalized_performance_mean": 0.5224218964576721, "info_normalized_performance_final": 0.5716145634651184, "info_performance_mean": 0.5224218964576721, "info_performance_final": 0.5716145634651184, "step": 168000}
{"episode_reward": 1044.8437499999989, "episode": 1681.0, "batch_reward": 8.862414360046387, "critic_loss": 698.9347534179688, "actor_loss": -1375.25146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0797542333602905, "alpha_loss": 0.05119774490594864, "alpha_value": 0.28942292029005895, "duration": 1.6107757091522217, "info_normalized_performance_mean": 0.44025126099586487, "info_normalized_performance_final": 0.48478835821151733, "info_performance_mean": 0.44025126099586487, "info_performance_final": 0.48478835821151733, "step": 168500}
{"episode_reward": 880.502645502645, "episode": 1686.0, "batch_reward": 8.977252960205078, "critic_loss": 362.46630859375, "actor_loss": -1348.564697265625, "actor_target_entropy": -3.0, "actor_entropy": 0.9688112735748291, "alpha_loss": -0.09163694083690643, "alpha_value": 0.29398519249718097, "duration": 1.5530543327331543, "info_normalized_performance_mean": 0.8840234279632568, "info_normalized_performance_final": 0.998046875, "info_performance_mean": 0.8840234279632568, "info_performance_final": 0.998046875, "step": 169000}
{"episode_reward": 1768.046875, "episode": 1691.0, "batch_reward": 8.223834991455078, "critic_loss": 494.2569885253906, "actor_loss": -1319.29150390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1507220268249512, "alpha_loss": -0.335976779460907, "alpha_value": 0.2999551421064988, "duration": 1.5185983180999756, "info_normalized_performance_mean": 0.22954510152339935, "info_normalized_performance_final": 0.2633030116558075, "info_performance_mean": 0.22954510152339935, "info_performance_final": 0.2633030116558075, "step": 169500}
{"episode_reward": 459.09015715467325, "episode": 1696.0, "batch_reward": 9.278936386108398, "critic_loss": 1014.545166015625, "actor_loss": -1359.2694091796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1235754489898682, "alpha_loss": 0.10519829392433167, "alpha_value": 0.30847841362511585, "step": 170000}
{"duration": 19.312700510025024, "info_normalized_performance_mean": 0.8269416093826294, "info_normalized_performance_final": 0.9166666865348816, "info_performance_mean": 0.8269416093826294, "info_performance_final": 0.9166666865348816, "step": 170000}
{"episode_reward": 1653.8833333333316, "episode": 1701.0, "batch_reward": 8.93035888671875, "critic_loss": 1499.3189697265625, "actor_loss": -1365.01513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.0827205181121826, "alpha_loss": -0.020456843078136444, "alpha_value": 0.3141740766436703, "duration": 1.4008193016052246, "info_normalized_performance_mean": 0.03815624862909317, "info_normalized_performance_final": 0.04374999925494194, "info_performance_mean": 0.03815624862909317, "info_performance_final": 0.04374999925494194, "step": 170500}
{"episode_reward": 76.3125, "episode": 1706.0, "batch_reward": 8.808062553405762, "critic_loss": 1860.364013671875, "actor_loss": -1331.366455078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0889840126037598, "alpha_loss": -0.28825241327285767, "alpha_value": 0.3191156661133064, "duration": 1.5480759143829346, "info_normalized_performance_mean": 0.35498493909835815, "info_normalized_performance_final": 0.3915264308452606, "info_performance_mean": 0.35498493909835815, "info_performance_final": 0.3915264308452606, "step": 171000}
{"episode_reward": 709.9699519230766, "episode": 1711.0, "batch_reward": 9.848091125488281, "critic_loss": 667.5128173828125, "actor_loss": -1427.04541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.3497982025146484, "alpha_loss": -0.058902159333229065, "alpha_value": 0.32525332025275455, "duration": 1.574315071105957, "info_normalized_performance_mean": 0.49230071902275085, "info_normalized_performance_final": 0.5462962985038757, "info_performance_mean": 0.49230071902275085, "info_performance_final": 0.5462962985038757, "step": 171500}
{"episode_reward": 984.6015712682403, "episode": 1716.0, "batch_reward": 8.072769165039062, "critic_loss": 728.2135620117188, "actor_loss": -1335.2781982421875, "actor_target_entropy": -3.0, "actor_entropy": 1.1926281452178955, "alpha_loss": -0.20461542904376984, "alpha_value": 0.32957195915825405, "duration": 1.7487285137176514, "info_normalized_performance_mean": 0.6054779291152954, "info_normalized_performance_final": 0.735615074634552, "info_performance_mean": 0.6054779291152954, "info_performance_final": 0.735615074634552, "step": 172000}
{"episode_reward": 1210.9556878306882, "episode": 1721.0, "batch_reward": 8.712213516235352, "critic_loss": 449.46624755859375, "actor_loss": -1355.277587890625, "actor_target_entropy": -3.0, "actor_entropy": 1.356135368347168, "alpha_loss": 0.017130009829998016, "alpha_value": 0.3323724056582986, "duration": 1.544922113418579, "info_normalized_performance_mean": 0.33305561542510986, "info_normalized_performance_final": 0.3919753134250641, "info_performance_mean": 0.33305561542510986, "info_performance_final": 0.3919753134250641, "step": 172500}
{"episode_reward": 666.1111111111114, "episode": 1726.0, "batch_reward": 9.491155624389648, "critic_loss": 3638.61181640625, "actor_loss": -1393.8642578125, "actor_target_entropy": -3.0, "actor_entropy": 0.8873074054718018, "alpha_loss": 0.14208842813968658, "alpha_value": 0.3348131160835145, "duration": 1.4756724834442139, "info_normalized_performance_mean": 0.41749513149261475, "info_normalized_performance_final": 0.46044921875, "info_performance_mean": 0.41749513149261475, "info_performance_final": 0.46044921875, "step": 173000}
{"episode_reward": 834.990234375, "episode": 1731.0, "batch_reward": 9.039946556091309, "critic_loss": 537.160888671875, "actor_loss": -1397.157470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0902682542800903, "alpha_loss": -0.012898437678813934, "alpha_value": 0.3372007839053111, "duration": 1.576488733291626, "info_normalized_performance_mean": 0.5510677099227905, "info_normalized_performance_final": 0.6015625, "info_performance_mean": 0.5510677099227905, "info_performance_final": 0.6015625, "step": 173500}
{"episode_reward": 1102.1354166666665, "episode": 1736.0, "batch_reward": 8.734267234802246, "critic_loss": 1064.7359619140625, "actor_loss": -1398.61279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.1189002990722656, "alpha_loss": -0.18598267436027527, "alpha_value": 0.3399688044849683, "duration": 1.5666651725769043, "info_normalized_performance_mean": 0.6711000800132751, "info_normalized_performance_final": 0.7362499833106995, "info_performance_mean": 0.6711000800132751, "info_performance_final": 0.7362499833106995, "step": 174000}
{"episode_reward": 1342.1999999999991, "episode": 1741.0, "batch_reward": 9.363971710205078, "critic_loss": 252.78271484375, "actor_loss": -1369.8719482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.4096894264221191, "alpha_loss": 0.09387540817260742, "alpha_value": 0.34531539078620854, "duration": 1.4790029525756836, "info_normalized_performance_mean": 0.7300000190734863, "info_normalized_performance_final": 0.8010203838348389, "info_performance_mean": 0.7300000190734863, "info_performance_final": 0.8010203838348389, "step": 174500}
{"episode_reward": 1459.9999999999998, "episode": 1746.0, "batch_reward": 8.809297561645508, "critic_loss": 1524.0728759765625, "actor_loss": -1360.539306640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0447849035263062, "alpha_loss": 0.09759152680635452, "alpha_value": 0.3430808963686297, "duration": 1.4931666851043701, "info_normalized_performance_mean": 0.6264757513999939, "info_normalized_performance_final": 0.6753472089767456, "info_performance_mean": 0.6264757513999939, "info_performance_final": 0.6753472089767456, "step": 175000}
{"episode_reward": 1252.951388888888, "episode": 1751.0, "batch_reward": 9.194764137268066, "critic_loss": 469.4410705566406, "actor_loss": -1417.5455322265625, "actor_target_entropy": -3.0, "actor_entropy": 1.350725769996643, "alpha_loss": 0.009723082184791565, "alpha_value": 0.34044094904593086, "duration": 1.6234431266784668, "info_normalized_performance_mean": 0.6151041388511658, "info_normalized_performance_final": 0.6866319179534912, "info_performance_mean": 0.6151041388511658, "info_performance_final": 0.6866319179534912, "step": 175500}
{"episode_reward": 1230.208333333335, "episode": 1756.0, "batch_reward": 8.201498985290527, "critic_loss": 914.5932006835938, "actor_loss": -1354.5260009765625, "actor_target_entropy": -3.0, "actor_entropy": 1.3574799299240112, "alpha_loss": 0.08251246064901352, "alpha_value": 0.33912400050763647, "duration": 1.6171870231628418, "info_normalized_performance_mean": 0.4597857594490051, "info_normalized_performance_final": 0.5134920477867126, "info_performance_mean": 0.4597857594490051, "info_performance_final": 0.5134920477867126, "step": 176000}
{"episode_reward": 919.5714285714305, "episode": 1761.0, "batch_reward": 8.527997970581055, "critic_loss": 1189.708740234375, "actor_loss": -1391.831787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3053085803985596, "alpha_loss": -0.2286113202571869, "alpha_value": 0.33694282756880667, "duration": 1.6438381671905518, "info_normalized_performance_mean": 0.5500338077545166, "info_normalized_performance_final": 0.7633765935897827, "info_performance_mean": 0.5500338077545166, "info_performance_final": 0.7633765935897827, "step": 176500}
{"episode_reward": 1100.0675324675308, "episode": 1766.0, "batch_reward": 9.499032974243164, "critic_loss": 623.854736328125, "actor_loss": -1428.5469970703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9277341365814209, "alpha_loss": 0.015439793467521667, "alpha_value": 0.33617020331701725, "duration": 1.4785430431365967, "info_normalized_performance_mean": 0.7928327322006226, "info_normalized_performance_final": 0.9096459150314331, "info_performance_mean": 0.7928327322006226, "info_performance_final": 0.9096459150314331, "step": 177000}
{"episode_reward": 1585.665445665444, "episode": 1771.0, "batch_reward": 9.42262077331543, "critic_loss": 979.7254028320312, "actor_loss": -1404.172607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.2537994384765625, "alpha_loss": 0.15358997881412506, "alpha_value": 0.3322997983469852, "duration": 1.4031965732574463, "info_normalized_performance_mean": 0.4446427822113037, "info_normalized_performance_final": 0.4892857074737549, "info_performance_mean": 0.4446427822113037, "info_performance_final": 0.4892857074737549, "step": 177500}
{"episode_reward": 889.2857142857158, "episode": 1776.0, "batch_reward": 8.864236831665039, "critic_loss": 374.7127685546875, "actor_loss": -1343.44970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1662534475326538, "alpha_loss": 0.07808105647563934, "alpha_value": 0.32860671845178396, "duration": 1.5835888385772705, "info_normalized_performance_mean": 0.47449052333831787, "info_normalized_performance_final": 0.5519047379493713, "info_performance_mean": 0.47449052333831787, "info_performance_final": 0.5519047379493713, "step": 178000}
{"episode_reward": 948.9809523809533, "episode": 1781.0, "batch_reward": 9.330615043640137, "critic_loss": 792.5615844726562, "actor_loss": -1436.4970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.109305739402771, "alpha_loss": 0.0019324300810694695, "alpha_value": 0.32815179889971885, "duration": 1.5694513320922852, "info_normalized_performance_mean": 0.7979786396026611, "info_normalized_performance_final": 0.8834224343299866, "info_performance_mean": 0.7979786396026611, "info_performance_final": 0.8834224343299866, "step": 178500}
{"episode_reward": 1595.9572192513383, "episode": 1786.0, "batch_reward": 9.123422622680664, "critic_loss": 3391.285400390625, "actor_loss": -1384.7784423828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9255067110061646, "alpha_loss": -0.04104410484433174, "alpha_value": 0.32395156035926365, "duration": 1.48685622215271, "info_normalized_performance_mean": 0.7221428751945496, "info_normalized_performance_final": 0.796875, "info_performance_mean": 0.7221428751945496, "info_performance_final": 0.796875, "step": 179000}
{"episode_reward": 1444.2857142857142, "episode": 1791.0, "batch_reward": 9.568507194519043, "critic_loss": 1771.40625, "actor_loss": -1402.38232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0633517503738403, "alpha_loss": 0.21498283743858337, "alpha_value": 0.32097513010847883, "duration": 1.4100897312164307, "info_normalized_performance_mean": 0.3045833110809326, "info_normalized_performance_final": 0.3422619104385376, "info_performance_mean": 0.3045833110809326, "info_performance_final": 0.3422619104385376, "step": 179500}
{"episode_reward": 609.1666666666656, "episode": 1796.0, "batch_reward": 10.378660202026367, "critic_loss": 358.8996887207031, "actor_loss": -1440.08056640625, "actor_target_entropy": -3.0, "actor_entropy": 0.9088930487632751, "alpha_loss": 0.20072895288467407, "alpha_value": 0.3175104926744828, "step": 180000}
{"duration": 18.8944034576416, "info_normalized_performance_mean": 0.23088686168193817, "info_normalized_performance_final": 0.2604895234107971, "info_performance_mean": 0.23088686168193817, "info_performance_final": 0.2604895234107971, "step": 180000}
{"episode_reward": 461.7736808645891, "episode": 1801.0, "batch_reward": 7.780112266540527, "critic_loss": 822.60791015625, "actor_loss": -1347.276123046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8559540510177612, "alpha_loss": -0.3305797278881073, "alpha_value": 0.3173114316036921, "duration": 1.5407400131225586, "info_normalized_performance_mean": 0.3847224712371826, "info_normalized_performance_final": 0.44874998927116394, "info_performance_mean": 0.3847224712371826, "info_performance_final": 0.44874998927116394, "step": 180500}
{"episode_reward": 769.4450000000012, "episode": 1806.0, "batch_reward": 9.763774871826172, "critic_loss": 282.2828063964844, "actor_loss": -1417.8076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5161373615264893, "alpha_loss": 0.03556911274790764, "alpha_value": 0.3177339399759902, "duration": 1.5382888317108154, "info_normalized_performance_mean": 0.44361957907676697, "info_normalized_performance_final": 0.5109890103340149, "info_performance_mean": 0.44361957907676697, "info_performance_final": 0.5109890103340149, "step": 181000}
{"episode_reward": 887.2390109890105, "episode": 1811.0, "batch_reward": 9.026694297790527, "critic_loss": 549.49169921875, "actor_loss": -1389.95068359375, "actor_target_entropy": -3.0, "actor_entropy": 1.242790937423706, "alpha_loss": -0.08333159983158112, "alpha_value": 0.3208314364080115, "duration": 1.6378395557403564, "info_normalized_performance_mean": 0.36317306756973267, "info_normalized_performance_final": 0.44788461923599243, "info_performance_mean": 0.36317306756973267, "info_performance_final": 0.44788461923599243, "step": 181500}
{"episode_reward": 726.3461538461555, "episode": 1816.0, "batch_reward": 9.378036499023438, "critic_loss": 1056.932373046875, "actor_loss": -1412.1981201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2463839054107666, "alpha_loss": -0.09783221036195755, "alpha_value": 0.3201981664578402, "duration": 1.502023696899414, "info_normalized_performance_mean": 0.47010308504104614, "info_normalized_performance_final": 0.5262784361839294, "info_performance_mean": 0.47010308504104614, "info_performance_final": 0.5262784361839294, "step": 182000}
{"episode_reward": 940.205965909089, "episode": 1821.0, "batch_reward": 9.333656311035156, "critic_loss": 1553.121826171875, "actor_loss": -1408.691650390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5392122268676758, "alpha_loss": -0.19684866070747375, "alpha_value": 0.3212577417851937, "duration": 1.4335618019104004, "info_normalized_performance_mean": 0.13641157746315002, "info_normalized_performance_final": 0.15362811088562012, "info_performance_mean": 0.13641157746315002, "info_performance_final": 0.15362811088562012, "step": 182500}
{"episode_reward": 272.823129251701, "episode": 1826.0, "batch_reward": 9.463295936584473, "critic_loss": 1547.4482421875, "actor_loss": -1380.1414794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.2712452411651611, "alpha_loss": 0.06720489263534546, "alpha_value": 0.3248142705685074, "duration": 1.4708316326141357, "info_normalized_performance_mean": 0.4684920608997345, "info_normalized_performance_final": 0.5402494072914124, "info_performance_mean": 0.4684920608997345, "info_performance_final": 0.5402494072914124, "step": 183000}
{"episode_reward": 936.9841269841277, "episode": 1831.0, "batch_reward": 8.92325496673584, "critic_loss": 371.9505920410156, "actor_loss": -1369.20361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.2312767505645752, "alpha_loss": -0.022285789251327515, "alpha_value": 0.32655105959390646, "duration": 1.4625482559204102, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 183500}
{"episode_reward": 0.0, "episode": 1836.0, "batch_reward": 9.957857131958008, "critic_loss": 2287.90380859375, "actor_loss": -1400.90380859375, "actor_target_entropy": -3.0, "actor_entropy": 1.252403974533081, "alpha_loss": -0.12797917425632477, "alpha_value": 0.3259860875273711, "duration": 1.6138582229614258, "info_normalized_performance_mean": 0.0478418730199337, "info_normalized_performance_final": 0.06517094373703003, "info_performance_mean": 0.0478418730199337, "info_performance_final": 0.06517094373703003, "step": 184000}
{"episode_reward": 95.6837606837608, "episode": 1841.0, "batch_reward": 9.32159423828125, "critic_loss": 596.7636108398438, "actor_loss": -1372.054443359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3406028747558594, "alpha_loss": -0.061238136142492294, "alpha_value": 0.3237629789036395, "duration": 1.5544941425323486, "info_normalized_performance_mean": 0.20534320175647736, "info_normalized_performance_final": 0.22795455157756805, "info_performance_mean": 0.20534320175647736, "info_performance_final": 0.22795455157756805, "step": 184500}
{"episode_reward": 410.68636363636386, "episode": 1846.0, "batch_reward": 9.22012996673584, "critic_loss": 1358.3687744140625, "actor_loss": -1377.4423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.2473599910736084, "alpha_loss": -0.1294230967760086, "alpha_value": 0.3235370511861509, "duration": 1.5935113430023193, "info_normalized_performance_mean": 0.7952580451965332, "info_normalized_performance_final": 0.885067880153656, "info_performance_mean": 0.7952580451965332, "info_performance_final": 0.885067880153656, "step": 185000}
{"episode_reward": 1590.515837104074, "episode": 1851.0, "batch_reward": 9.597342491149902, "critic_loss": 758.031982421875, "actor_loss": -1399.429931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2713357210159302, "alpha_loss": 0.08627618104219437, "alpha_value": 0.3259334228236821, "duration": 1.537649154663086, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 185500}
{"episode_reward": 0.0, "episode": 1856.0, "batch_reward": 9.156824111938477, "critic_loss": 360.66973876953125, "actor_loss": -1349.2042236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.3167128562927246, "alpha_loss": 0.26106196641921997, "alpha_value": 0.3248100107832195, "duration": 1.5644700527191162, "info_normalized_performance_mean": 0.7956249713897705, "info_normalized_performance_final": 0.875, "info_performance_mean": 0.7956249713897705, "info_performance_final": 0.875, "step": 186000}
{"episode_reward": 1591.25, "episode": 1861.0, "batch_reward": 9.346671104431152, "critic_loss": 564.6747436523438, "actor_loss": -1401.9791259765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8969366550445557, "alpha_loss": -0.005641162395477295, "alpha_value": 0.3179047507372236, "duration": 1.5809977054595947, "info_normalized_performance_mean": 0.8263461589813232, "info_normalized_performance_final": 0.9079670310020447, "info_performance_mean": 0.8263461589813232, "info_performance_final": 0.9079670310020447, "step": 186500}
{"episode_reward": 1652.6923076923051, "episode": 1866.0, "batch_reward": 9.530375480651855, "critic_loss": 910.13671875, "actor_loss": -1375.955078125, "actor_target_entropy": -3.0, "actor_entropy": 0.9673842191696167, "alpha_loss": 0.061108071357011795, "alpha_value": 0.3146424558910447, "duration": 1.4420392513275146, "info_normalized_performance_mean": 0.8539286851882935, "info_normalized_performance_final": 0.9357143044471741, "info_performance_mean": 0.8539286851882935, "info_performance_final": 0.9357143044471741, "step": 187000}
{"episode_reward": 1707.857142857144, "episode": 1871.0, "batch_reward": 9.283796310424805, "critic_loss": 1045.5965576171875, "actor_loss": -1389.8109130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.9470491409301758, "alpha_loss": -0.10374785959720612, "alpha_value": 0.3125698085706454, "duration": 1.4894897937774658, "info_normalized_performance_mean": 0.5290816426277161, "info_normalized_performance_final": 0.5994898080825806, "info_performance_mean": 0.5290816426277161, "info_performance_final": 0.5994898080825806, "step": 187500}
{"episode_reward": 1058.1632653061224, "episode": 1876.0, "batch_reward": 9.163017272949219, "critic_loss": 863.7099609375, "actor_loss": -1386.407470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1540164947509766, "alpha_loss": 0.01733297109603882, "alpha_value": 0.3084540511277085, "duration": 1.4711785316467285, "info_normalized_performance_mean": 0.02155422978103161, "info_normalized_performance_final": 0.02380952425301075, "info_performance_mean": 0.02155422978103161, "info_performance_final": 0.02380952425301075, "step": 188000}
{"episode_reward": 43.108465608465515, "episode": 1881.0, "batch_reward": 9.547359466552734, "critic_loss": 1149.241455078125, "actor_loss": -1400.2158203125, "actor_target_entropy": -3.0, "actor_entropy": 1.2421749830245972, "alpha_loss": -0.04832157492637634, "alpha_value": 0.30994629689033976, "duration": 1.54219388961792, "info_normalized_performance_mean": 0.7272772789001465, "info_normalized_performance_final": 0.826890766620636, "info_performance_mean": 0.7272772789001465, "info_performance_final": 0.826890766620636, "step": 188500}
{"episode_reward": 1454.5546218487393, "episode": 1886.0, "batch_reward": 9.56029224395752, "critic_loss": 1053.252197265625, "actor_loss": -1369.993896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.468806505203247, "alpha_loss": 0.11239159852266312, "alpha_value": 0.3073352464210035, "duration": 1.4932904243469238, "info_normalized_performance_mean": 0.5924603343009949, "info_normalized_performance_final": 0.668154776096344, "info_performance_mean": 0.5924603343009949, "info_performance_final": 0.668154776096344, "step": 189000}
{"episode_reward": 1184.9206349206322, "episode": 1891.0, "batch_reward": 9.21990966796875, "critic_loss": 2848.0966796875, "actor_loss": -1365.8204345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1882634162902832, "alpha_loss": 0.16873788833618164, "alpha_value": 0.30819980225521143, "duration": 1.4334862232208252, "info_normalized_performance_mean": 0.39726492762565613, "info_normalized_performance_final": 0.43589743971824646, "info_performance_mean": 0.39726492762565613, "info_performance_final": 0.43589743971824646, "step": 189500}
{"episode_reward": 794.5299145299155, "episode": 1896.0, "batch_reward": 9.457023620605469, "critic_loss": 728.2623291015625, "actor_loss": -1397.033935546875, "actor_target_entropy": -3.0, "actor_entropy": 0.830230176448822, "alpha_loss": 0.055554408580064774, "alpha_value": 0.30602019677128456, "step": 190000}
{"duration": 19.37730121612549, "info_normalized_performance_mean": 0.704906165599823, "info_normalized_performance_final": 0.7718750238418579, "info_performance_mean": 0.704906165599823, "info_performance_final": 0.7718750238418579, "step": 190000}
{"episode_reward": 1409.8125, "episode": 1901.0, "batch_reward": 9.420843124389648, "critic_loss": 1068.7490234375, "actor_loss": -1363.590087890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2033145427703857, "alpha_loss": -0.11894866079092026, "alpha_value": 0.30588423216602506, "duration": 1.503605604171753, "info_normalized_performance_mean": 0.18238818645477295, "info_normalized_performance_final": 0.20057719945907593, "info_performance_mean": 0.18238818645477295, "info_performance_final": 0.20057719945907593, "step": 190500}
{"episode_reward": 364.7763347763344, "episode": 1906.0, "batch_reward": 8.907095909118652, "critic_loss": 1318.30224609375, "actor_loss": -1379.1217041015625, "actor_target_entropy": -3.0, "actor_entropy": 1.3665497303009033, "alpha_loss": -0.053791593760252, "alpha_value": 0.3071846506070865, "duration": 1.5737874507904053, "info_normalized_performance_mean": 0.4367411136627197, "info_normalized_performance_final": 0.484375, "info_performance_mean": 0.4367411136627197, "info_performance_final": 0.484375, "step": 191000}
{"episode_reward": 873.4821428571429, "episode": 1911.0, "batch_reward": 8.979424476623535, "critic_loss": 747.885009765625, "actor_loss": -1340.19775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.432265043258667, "alpha_loss": 0.03888259083032608, "alpha_value": 0.3119599309244978, "duration": 1.4431920051574707, "info_normalized_performance_mean": 0.6065384149551392, "info_normalized_performance_final": 0.691773533821106, "info_performance_mean": 0.6065384149551392, "info_performance_final": 0.691773533821106, "step": 191500}
{"episode_reward": 1213.0769230769224, "episode": 1916.0, "batch_reward": 9.367722511291504, "critic_loss": 1720.8626708984375, "actor_loss": -1388.41162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.0218967199325562, "alpha_loss": -0.07219048589468002, "alpha_value": 0.309842308837762, "duration": 1.552828311920166, "info_normalized_performance_mean": 0.7076210975646973, "info_normalized_performance_final": 0.7764706015586853, "info_performance_mean": 0.7076210975646973, "info_performance_final": 0.7764706015586853, "step": 192000}
{"episode_reward": 1415.2418300653576, "episode": 1921.0, "batch_reward": 9.009736061096191, "critic_loss": 804.5966796875, "actor_loss": -1332.6483154296875, "actor_target_entropy": -3.0, "actor_entropy": 1.237275242805481, "alpha_loss": 0.11204789578914642, "alpha_value": 0.30786781568545557, "duration": 1.4367218017578125, "info_normalized_performance_mean": 0.6017090678215027, "info_normalized_performance_final": 0.6607142686843872, "info_performance_mean": 0.6017090678215027, "info_performance_final": 0.6607142686843872, "step": 192500}
{"episode_reward": 1203.4183673469379, "episode": 1926.0, "batch_reward": 9.293665885925293, "critic_loss": 523.7523193359375, "actor_loss": -1382.4376220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0018202066421509, "alpha_loss": -0.13771653175354004, "alpha_value": 0.30642021595475744, "duration": 1.5624043941497803, "info_normalized_performance_mean": 0.7742999196052551, "info_normalized_performance_final": 0.8500000238418579, "info_performance_mean": 0.7742999196052551, "info_performance_final": 0.8500000238418579, "step": 193000}
{"episode_reward": 1548.6, "episode": 1931.0, "batch_reward": 9.283624649047852, "critic_loss": 898.4576416015625, "actor_loss": -1346.56201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1147794723510742, "alpha_loss": -0.02943733148276806, "alpha_value": 0.3039175585523532, "duration": 1.4716482162475586, "info_normalized_performance_mean": 0.5130677819252014, "info_normalized_performance_final": 0.6080586314201355, "info_performance_mean": 0.5130677819252014, "info_performance_final": 0.6080586314201355, "step": 193500}
{"episode_reward": 1026.1355311355323, "episode": 1936.0, "batch_reward": 10.085721969604492, "critic_loss": 416.7864074707031, "actor_loss": -1391.741943359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3553218841552734, "alpha_loss": -0.0054061077535152435, "alpha_value": 0.30484880948822946, "duration": 1.5666131973266602, "info_normalized_performance_mean": 0.7573071122169495, "info_normalized_performance_final": 0.8300653696060181, "info_performance_mean": 0.7573071122169495, "info_performance_final": 0.8300653696060181, "step": 194000}
{"episode_reward": 1514.6143790849662, "episode": 1941.0, "batch_reward": 8.768043518066406, "critic_loss": 788.0318603515625, "actor_loss": -1337.856201171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8670073747634888, "alpha_loss": -0.1385781317949295, "alpha_value": 0.3098305606594957, "duration": 1.6383912563323975, "info_normalized_performance_mean": 0.758280336856842, "info_normalized_performance_final": 0.8591269850730896, "info_performance_mean": 0.758280336856842, "info_performance_final": 0.8591269850730896, "step": 194500}
{"episode_reward": 1516.5608465608475, "episode": 1946.0, "batch_reward": 9.134956359863281, "critic_loss": 397.634521484375, "actor_loss": -1349.11865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1504037380218506, "alpha_loss": -0.09368129819631577, "alpha_value": 0.31116604250381746, "duration": 1.4879136085510254, "info_normalized_performance_mean": 0.42134979367256165, "info_normalized_performance_final": 0.4665798544883728, "info_performance_mean": 0.42134979367256165, "info_performance_final": 0.4665798544883728, "step": 195000}
{"episode_reward": 842.6996527777762, "episode": 1951.0, "batch_reward": 9.370582580566406, "critic_loss": 1099.62353515625, "actor_loss": -1372.8477783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1025112867355347, "alpha_loss": 0.06704609096050262, "alpha_value": 0.3126929379346547, "duration": 1.6117117404937744, "info_normalized_performance_mean": 0.6934566497802734, "info_normalized_performance_final": 0.7739197611808777, "info_performance_mean": 0.6934566497802734, "info_performance_final": 0.7739197611808777, "step": 195500}
{"episode_reward": 1386.9135802469136, "episode": 1956.0, "batch_reward": 9.557929039001465, "critic_loss": 2692.697265625, "actor_loss": -1376.9444580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4939357042312622, "alpha_loss": -0.15305843949317932, "alpha_value": 0.3168624522786459, "duration": 1.5439050197601318, "info_normalized_performance_mean": 0.44328776001930237, "info_normalized_performance_final": 0.498046875, "info_performance_mean": 0.44328776001930237, "info_performance_final": 0.498046875, "step": 196000}
{"episode_reward": 886.5755208333333, "episode": 1961.0, "batch_reward": 8.59277629852295, "critic_loss": 259.0622253417969, "actor_loss": -1359.292724609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1022305488586426, "alpha_loss": -0.1173955500125885, "alpha_value": 0.32056154698201134, "duration": 1.6155409812927246, "info_normalized_performance_mean": 0.6055802702903748, "info_normalized_performance_final": 0.6703869104385376, "info_performance_mean": 0.6055802702903748, "info_performance_final": 0.6703869104385376, "step": 196500}
{"episode_reward": 1211.1607142857129, "episode": 1966.0, "batch_reward": 9.00172233581543, "critic_loss": 962.0139770507812, "actor_loss": -1356.5927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9672709107398987, "alpha_loss": 0.00918336771428585, "alpha_value": 0.3212222796342905, "duration": 1.50480318069458, "info_normalized_performance_mean": 0.7734375, "info_normalized_performance_final": 0.83984375, "info_performance_mean": 0.7734375, "info_performance_final": 0.83984375, "step": 197000}
{"episode_reward": 1546.875, "episode": 1971.0, "batch_reward": 9.320005416870117, "critic_loss": 277.2745361328125, "actor_loss": -1352.747802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3206449747085571, "alpha_loss": -0.11466221511363983, "alpha_value": 0.3250962625457566, "duration": 1.586855411529541, "info_normalized_performance_mean": 0.7458000779151917, "info_normalized_performance_final": 0.8190000057220459, "info_performance_mean": 0.7458000779151917, "info_performance_final": 0.8190000057220459, "step": 197500}
{"episode_reward": 1491.6000000000029, "episode": 1976.0, "batch_reward": 9.137833595275879, "critic_loss": 439.0856018066406, "actor_loss": -1359.759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.6990301609039307, "alpha_loss": -0.2790157198905945, "alpha_value": 0.3347880043494959, "duration": 1.5316722393035889, "info_normalized_performance_mean": 0.8034641742706299, "info_normalized_performance_final": 0.8803571462631226, "info_performance_mean": 0.8034641742706299, "info_performance_final": 0.8803571462631226, "step": 198000}
{"episode_reward": 1606.9285714285732, "episode": 1981.0, "batch_reward": 9.638484954833984, "critic_loss": 394.0723876953125, "actor_loss": -1393.680908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.166728138923645, "alpha_loss": 0.003249015659093857, "alpha_value": 0.3421488767437339, "duration": 1.6237998008728027, "info_normalized_performance_mean": 0.2994835376739502, "info_normalized_performance_final": 0.3745304346084595, "info_performance_mean": 0.2994835376739502, "info_performance_final": 0.3745304346084595, "step": 198500}
{"episode_reward": 598.9669421487604, "episode": 1986.0, "batch_reward": 8.80832290649414, "critic_loss": 1201.3695068359375, "actor_loss": -1333.4293212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.307295560836792, "alpha_loss": -0.7073674201965332, "alpha_value": 0.3527711629648488, "duration": 1.5900521278381348, "info_normalized_performance_mean": 0.739858865737915, "info_normalized_performance_final": 0.8152941465377808, "info_performance_mean": 0.739858865737915, "info_performance_final": 0.8152941465377808, "step": 199000}
{"episode_reward": 1479.7176470588206, "episode": 1991.0, "batch_reward": 10.142557144165039, "critic_loss": 590.289306640625, "actor_loss": -1418.9359130859375, "actor_target_entropy": -3.0, "actor_entropy": 1.4349361658096313, "alpha_loss": -0.42665210366249084, "alpha_value": 0.3667671430439691, "duration": 1.489549160003662, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 199500}
{"episode_reward": 0.0, "episode": 1996.0, "batch_reward": 9.00541877746582, "critic_loss": 706.8307495117188, "actor_loss": -1383.199462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.517810583114624, "alpha_loss": -0.44137004017829895, "alpha_value": 0.378121269820915, "step": 200000}
{"duration": 18.99584174156189, "info_normalized_performance_mean": 0.4328300356864929, "info_normalized_performance_final": 0.4909781515598297, "info_performance_mean": 0.4328300356864929, "info_performance_final": 0.4909781515598297, "step": 200000}
{"episode_reward": 865.6600189933541, "episode": 2001.0, "batch_reward": 8.593057632446289, "critic_loss": 1685.78759765625, "actor_loss": -1366.39599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2252358198165894, "alpha_loss": -0.45916786789894104, "alpha_value": 0.3909292042187829, "duration": 1.5953154563903809, "info_normalized_performance_mean": 0.39444994926452637, "info_normalized_performance_final": 0.44227272272109985, "info_performance_mean": 0.39444994926452637, "info_performance_final": 0.44227272272109985, "step": 200500}
{"episode_reward": 788.9000000000016, "episode": 2006.0, "batch_reward": 9.710042953491211, "critic_loss": 2878.9189453125, "actor_loss": -1439.316650390625, "actor_target_entropy": -3.0, "actor_entropy": 1.3191053867340088, "alpha_loss": -0.46390771865844727, "alpha_value": 0.404710785527546, "duration": 1.4606778621673584, "info_normalized_performance_mean": 0.47503745555877686, "info_normalized_performance_final": 0.5235042572021484, "info_performance_mean": 0.47503745555877686, "info_performance_final": 0.5235042572021484, "step": 201000}
{"episode_reward": 950.0747863247851, "episode": 2011.0, "batch_reward": 9.829716682434082, "critic_loss": 474.39154052734375, "actor_loss": -1446.4300537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.5494651794433594, "alpha_loss": -0.5181549191474915, "alpha_value": 0.4212764790892521, "duration": 1.6742546558380127, "info_normalized_performance_mean": 0.4127235412597656, "info_normalized_performance_final": 0.5268678665161133, "info_performance_mean": 0.4127235412597656, "info_performance_final": 0.5268678665161133, "step": 201500}
{"episode_reward": 825.4471843945522, "episode": 2016.0, "batch_reward": 9.156737327575684, "critic_loss": 2440.903076171875, "actor_loss": -1454.27685546875, "actor_target_entropy": -3.0, "actor_entropy": 1.3167672157287598, "alpha_loss": -0.8130210638046265, "alpha_value": 0.4327091491696141, "duration": 1.4938347339630127, "info_normalized_performance_mean": 0.5787796974182129, "info_normalized_performance_final": 0.670634925365448, "info_performance_mean": 0.5787796974182129, "info_performance_final": 0.670634925365448, "step": 202000}
{"episode_reward": 1157.5595238095239, "episode": 2021.0, "batch_reward": 9.052824020385742, "critic_loss": 3385.0703125, "actor_loss": -1462.9334716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.4365402460098267, "alpha_loss": -0.9868006110191345, "alpha_value": 0.4462002621977724, "duration": 1.466216802597046, "info_normalized_performance_mean": 0.4815872311592102, "info_normalized_performance_final": 0.5317460298538208, "info_performance_mean": 0.4815872311592102, "info_performance_final": 0.5317460298538208, "step": 202500}
{"episode_reward": 963.1746031746025, "episode": 2026.0, "batch_reward": 9.133288383483887, "critic_loss": 882.5650634765625, "actor_loss": -1480.21142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.49271821975708, "alpha_loss": -0.7929219007492065, "alpha_value": 0.45972561018428754, "duration": 1.5715899467468262, "info_normalized_performance_mean": 0.4443421959877014, "info_normalized_performance_final": 0.5614973306655884, "info_performance_mean": 0.4443421959877014, "info_performance_final": 0.5614973306655884, "step": 203000}
{"episode_reward": 888.6844919786107, "episode": 2031.0, "batch_reward": 9.62806510925293, "critic_loss": 1874.311767578125, "actor_loss": -1540.436767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.4795894622802734, "alpha_loss": -0.89093416929245, "alpha_value": 0.47087117080668583, "duration": 1.567793369293213, "info_normalized_performance_mean": 0.1908281445503235, "info_normalized_performance_final": 0.21291865408420563, "info_performance_mean": 0.1908281445503235, "info_performance_final": 0.21291865408420563, "step": 203500}
{"episode_reward": 381.65623849834395, "episode": 2036.0, "batch_reward": 9.404596328735352, "critic_loss": 2247.98681640625, "actor_loss": -1547.1142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.4229799509048462, "alpha_loss": -0.5171800851821899, "alpha_value": 0.48241678573566427, "duration": 1.4936606884002686, "info_normalized_performance_mean": 0.9111605882644653, "info_normalized_performance_final": 0.9970238208770752, "info_performance_mean": 0.9111605882644653, "info_performance_final": 0.9970238208770752, "step": 204000}
{"episode_reward": 1822.321428571426, "episode": 2041.0, "batch_reward": 8.652314186096191, "critic_loss": 1859.207763671875, "actor_loss": -1504.778076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5215048789978027, "alpha_loss": -0.36067435145378113, "alpha_value": 0.4929877461097004, "duration": 1.4115033149719238, "info_normalized_performance_mean": 0.0015625000232830644, "info_normalized_performance_final": 0.004464285913854837, "info_performance_mean": 0.0015625000232830644, "info_performance_final": 0.004464285913854837, "step": 204500}
{"episode_reward": 3.1250000000000004, "episode": 2046.0, "batch_reward": 9.705070495605469, "critic_loss": 1052.551025390625, "actor_loss": -1570.88330078125, "actor_target_entropy": -3.0, "actor_entropy": 2.0105538368225098, "alpha_loss": -0.7772800326347351, "alpha_value": 0.5019668938051117, "duration": 1.4628283977508545, "info_normalized_performance_mean": 0.3236386179924011, "info_normalized_performance_final": 0.7387057542800903, "info_performance_mean": 0.3236386179924011, "info_performance_final": 0.7387057542800903, "step": 205000}
{"episode_reward": 647.277167277167, "episode": 2051.0, "batch_reward": 9.008630752563477, "critic_loss": 731.6805419921875, "actor_loss": -1534.855224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.7628895044326782, "alpha_loss": -0.4030989408493042, "alpha_value": 0.5107974866605689, "duration": 1.4619722366333008, "info_normalized_performance_mean": 0.4531179666519165, "info_normalized_performance_final": 0.4977324306964874, "info_performance_mean": 0.4531179666519165, "info_performance_final": 0.4977324306964874, "step": 205500}
{"episode_reward": 906.2358276643998, "episode": 2056.0, "batch_reward": 9.182214736938477, "critic_loss": 1798.760986328125, "actor_loss": -1576.267578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7320101261138916, "alpha_loss": -0.34174832701683044, "alpha_value": 0.5173408155903797, "duration": 1.5626602172851562, "info_normalized_performance_mean": 0.7159345746040344, "info_normalized_performance_final": 0.7816993594169617, "info_performance_mean": 0.7159345746040344, "info_performance_final": 0.7816993594169617, "step": 206000}
{"episode_reward": 1431.8692810457528, "episode": 2061.0, "batch_reward": 9.680041313171387, "critic_loss": 840.4466552734375, "actor_loss": -1604.35693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.4890800714492798, "alpha_loss": 0.11706624180078506, "alpha_value": 0.5229461708827804, "duration": 1.480940341949463, "info_normalized_performance_mean": 0.677539050579071, "info_normalized_performance_final": 0.73046875, "info_performance_mean": 0.677539050579071, "info_performance_final": 0.73046875, "step": 206500}
{"episode_reward": 1355.078125, "episode": 2066.0, "batch_reward": 9.26600456237793, "critic_loss": 551.0177612304688, "actor_loss": -1595.0567626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.7268617153167725, "alpha_loss": -0.24184812605381012, "alpha_value": 0.5250938716406766, "duration": 1.5752995014190674, "info_normalized_performance_mean": 0.4666825532913208, "info_normalized_performance_final": 0.5142857432365417, "info_performance_mean": 0.4666825532913208, "info_performance_final": 0.5142857432365417, "step": 207000}
{"episode_reward": 933.365079365081, "episode": 2071.0, "batch_reward": 9.694777488708496, "critic_loss": 496.15692138671875, "actor_loss": -1613.164306640625, "actor_target_entropy": -3.0, "actor_entropy": 1.9064404964447021, "alpha_loss": -0.23653486371040344, "alpha_value": 0.5319048736459616, "duration": 1.4438626766204834, "info_normalized_performance_mean": 0.4719693660736084, "info_normalized_performance_final": 0.5341836810112, "info_performance_mean": 0.4719693660736084, "info_performance_final": 0.5341836810112, "step": 207500}
{"episode_reward": 943.9387755102031, "episode": 2076.0, "batch_reward": 9.286766052246094, "critic_loss": 653.2180786132812, "actor_loss": -1616.036865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.6257774829864502, "alpha_loss": 0.012699726969003677, "alpha_value": 0.537728650368783, "duration": 1.473438024520874, "info_normalized_performance_mean": 0.3658415973186493, "info_normalized_performance_final": 0.3984375, "info_performance_mean": 0.3658415973186493, "info_performance_final": 0.3984375, "step": 208000}
{"episode_reward": 731.6832386363636, "episode": 2081.0, "batch_reward": 9.834257125854492, "critic_loss": 763.36767578125, "actor_loss": -1622.6163330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.5191333293914795, "alpha_loss": -0.04278886318206787, "alpha_value": 0.5454577465498262, "duration": 1.6353509426116943, "info_normalized_performance_mean": 0.690416693687439, "info_normalized_performance_final": 0.7534722089767456, "info_performance_mean": 0.690416693687439, "info_performance_final": 0.7534722089767456, "step": 208500}
{"episode_reward": 1380.8333333333317, "episode": 2086.0, "batch_reward": 9.866392135620117, "critic_loss": 1205.7652587890625, "actor_loss": -1668.5380859375, "actor_target_entropy": -3.0, "actor_entropy": 1.60797119140625, "alpha_loss": -0.2730451822280884, "alpha_value": 0.5501418391578433, "duration": 1.6189172267913818, "info_normalized_performance_mean": 0.7611961364746094, "info_normalized_performance_final": 0.8666666746139526, "info_performance_mean": 0.7611961364746094, "info_performance_final": 0.8666666746139526, "step": 209000}
{"episode_reward": 1522.3921568627436, "episode": 2091.0, "batch_reward": 10.025691986083984, "critic_loss": 730.1744384765625, "actor_loss": -1653.2645263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.7018462419509888, "alpha_loss": -0.3508676588535309, "alpha_value": 0.5567565993186343, "duration": 1.4527156352996826, "info_normalized_performance_mean": 0.7972187995910645, "info_normalized_performance_final": 0.859375, "info_performance_mean": 0.7972187995910645, "info_performance_final": 0.859375, "step": 209500}
{"episode_reward": 1594.4375, "episode": 2096.0, "batch_reward": 8.907337188720703, "critic_loss": 499.7215270996094, "actor_loss": -1645.8016357421875, "actor_target_entropy": -3.0, "actor_entropy": 1.354856014251709, "alpha_loss": -0.2597121000289917, "alpha_value": 0.5646504219313949, "step": 210000}
{"duration": 18.92551064491272, "info_normalized_performance_mean": 0.7280286550521851, "info_normalized_performance_final": 0.7956730723381042, "info_performance_mean": 0.7280286550521851, "info_performance_final": 0.7956730723381042, "step": 210000}
{"episode_reward": 1456.0576923076899, "episode": 2101.0, "batch_reward": 9.659035682678223, "critic_loss": 672.2584228515625, "actor_loss": -1629.946533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.6560359001159668, "alpha_loss": -0.07426635921001434, "alpha_value": 0.5719340100369743, "duration": 1.6336734294891357, "info_normalized_performance_mean": 0.5581802129745483, "info_normalized_performance_final": 0.6593406796455383, "info_performance_mean": 0.5581802129745483, "info_performance_final": 0.6593406796455383, "step": 210500}
{"episode_reward": 1116.3604395604402, "episode": 2106.0, "batch_reward": 8.749861717224121, "critic_loss": 1077.6241455078125, "actor_loss": -1596.26318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.4897775650024414, "alpha_loss": -0.3760281503200531, "alpha_value": 0.5781361737990806, "duration": 1.4381437301635742, "info_normalized_performance_mean": 0.3964987099170685, "info_normalized_performance_final": 0.4419642984867096, "info_performance_mean": 0.3964987099170685, "info_performance_final": 0.4419642984867096, "step": 211000}
{"episode_reward": 792.9974489795903, "episode": 2111.0, "batch_reward": 9.759194374084473, "critic_loss": 2606.82958984375, "actor_loss": -1641.774169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.7417311668395996, "alpha_loss": -0.28579214215278625, "alpha_value": 0.5829272195291476, "duration": 1.609567403793335, "info_normalized_performance_mean": 0.5816377997398376, "info_normalized_performance_final": 0.6421356201171875, "info_performance_mean": 0.5816377997398376, "info_performance_final": 0.6421356201171875, "step": 211500}
{"episode_reward": 1163.275613275616, "episode": 2116.0, "batch_reward": 9.231819152832031, "critic_loss": 3633.962890625, "actor_loss": -1675.356201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5534271001815796, "alpha_loss": -0.37797462940216064, "alpha_value": 0.5863506349208165, "duration": 1.6226119995117188, "info_normalized_performance_mean": 0.20999999344348907, "info_normalized_performance_final": 0.23569612205028534, "info_performance_mean": 0.20999999344348907, "info_performance_final": 0.23569612205028534, "step": 212000}
{"episode_reward": 419.99999999999955, "episode": 2121.0, "batch_reward": 9.12863826751709, "critic_loss": 751.89453125, "actor_loss": -1652.7003173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.5823147296905518, "alpha_loss": -0.3356591761112213, "alpha_value": 0.5872574961811636, "duration": 1.5261485576629639, "info_normalized_performance_mean": 0.7057142853736877, "info_normalized_performance_final": 0.7723214030265808, "info_performance_mean": 0.7057142853736877, "info_performance_final": 0.7723214030265808, "step": 212500}
{"episode_reward": 1411.4285714285732, "episode": 2126.0, "batch_reward": 9.510151863098145, "critic_loss": 1222.769775390625, "actor_loss": -1672.998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.684875249862671, "alpha_loss": -0.2953261137008667, "alpha_value": 0.5898818881540607, "duration": 1.4232401847839355, "info_normalized_performance_mean": 0.534318208694458, "info_normalized_performance_final": 0.5839646458625793, "info_performance_mean": 0.534318208694458, "info_performance_final": 0.5839646458625793, "step": 213000}
{"episode_reward": 1068.636363636365, "episode": 2131.0, "batch_reward": 9.518024444580078, "critic_loss": 630.1994018554688, "actor_loss": -1669.25, "actor_target_entropy": -3.0, "actor_entropy": 1.7307276725769043, "alpha_loss": 0.013366147875785828, "alpha_value": 0.5880207859254911, "duration": 1.6022148132324219, "info_normalized_performance_mean": 0.4702363610267639, "info_normalized_performance_final": 0.5584415793418884, "info_performance_mean": 0.4702363610267639, "info_performance_final": 0.5584415793418884, "step": 213500}
{"episode_reward": 940.4727272727267, "episode": 2136.0, "batch_reward": 8.725358963012695, "critic_loss": 765.255859375, "actor_loss": -1611.3004150390625, "actor_target_entropy": -3.0, "actor_entropy": 1.7263154983520508, "alpha_loss": -0.09055838733911514, "alpha_value": 0.5891376974647221, "duration": 1.3824920654296875, "info_normalized_performance_mean": 0.3577335476875305, "info_normalized_performance_final": 0.3983585834503174, "info_performance_mean": 0.3577335476875305, "info_performance_final": 0.3983585834503174, "step": 214000}
{"episode_reward": 715.4671717171713, "episode": 2141.0, "batch_reward": 8.951024055480957, "critic_loss": 1011.8162841796875, "actor_loss": -1651.821533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.7271728515625, "alpha_loss": 0.0024749189615249634, "alpha_value": 0.5864036370933594, "duration": 1.5759129524230957, "info_normalized_performance_mean": 0.7223652005195618, "info_normalized_performance_final": 0.7976190447807312, "info_performance_mean": 0.7223652005195618, "info_performance_final": 0.7976190447807312, "step": 214500}
{"episode_reward": 1444.7301587301595, "episode": 2146.0, "batch_reward": 9.763431549072266, "critic_loss": 3604.12060546875, "actor_loss": -1747.5814208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.7830501794815063, "alpha_loss": -0.21544161438941956, "alpha_value": 0.5767848766986404, "duration": 1.6236295700073242, "info_normalized_performance_mean": 0.2578289806842804, "info_normalized_performance_final": 0.29895105957984924, "info_performance_mean": 0.2578289806842804, "info_performance_final": 0.29895105957984924, "step": 215000}
{"episode_reward": 515.6579783852504, "episode": 2151.0, "batch_reward": 9.170580863952637, "critic_loss": 1110.2711181640625, "actor_loss": -1710.8782958984375, "actor_target_entropy": -3.0, "actor_entropy": 1.573581576347351, "alpha_loss": 0.1658589243888855, "alpha_value": 0.5670022197394582, "duration": 1.437366008758545, "info_normalized_performance_mean": 0.35002601146698, "info_normalized_performance_final": 0.4296875, "info_performance_mean": 0.35002601146698, "info_performance_final": 0.4296875, "step": 215500}
{"episode_reward": 700.0520833333334, "episode": 2156.0, "batch_reward": 8.942460060119629, "critic_loss": 673.6881103515625, "actor_loss": -1669.4716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.9410223960876465, "alpha_loss": 0.05284543335437775, "alpha_value": 0.5580068712462121, "duration": 1.5372629165649414, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 216000}
{"episode_reward": 0.0, "episode": 2161.0, "batch_reward": 10.192497253417969, "critic_loss": 624.7708740234375, "actor_loss": -1724.5142822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.8895058631896973, "alpha_loss": -0.04382704943418503, "alpha_value": 0.553214548285405, "duration": 1.6929166316986084, "info_normalized_performance_mean": 0.3651541769504547, "info_normalized_performance_final": 0.45613476634025574, "info_performance_mean": 0.3651541769504547, "info_performance_final": 0.45613476634025574, "step": 216500}
{"episode_reward": 730.3083280356004, "episode": 2166.0, "batch_reward": 9.20052719116211, "critic_loss": 343.8653564453125, "actor_loss": -1677.5224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.8532719612121582, "alpha_loss": 0.2646721303462982, "alpha_value": 0.5472903751525322, "duration": 1.4582860469818115, "info_normalized_performance_mean": 0.07739183306694031, "info_normalized_performance_final": 0.09495192021131516, "info_performance_mean": 0.07739183306694031, "info_performance_final": 0.09495192021131516, "step": 217000}
{"episode_reward": 154.78365384615395, "episode": 2171.0, "batch_reward": 8.398475646972656, "critic_loss": 1027.9434814453125, "actor_loss": -1630.0975341796875, "actor_target_entropy": -3.0, "actor_entropy": 1.7331581115722656, "alpha_loss": 0.0888928472995758, "alpha_value": 0.5365907133490976, "duration": 1.4995412826538086, "info_normalized_performance_mean": 0.44117623567581177, "info_normalized_performance_final": 0.4869791567325592, "info_performance_mean": 0.44117623567581177, "info_performance_final": 0.4869791567325592, "step": 217500}
{"episode_reward": 882.3524305555566, "episode": 2176.0, "batch_reward": 9.475988388061523, "critic_loss": 1324.5001220703125, "actor_loss": -1738.771240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4619749784469604, "alpha_loss": 0.2572247087955475, "alpha_value": 0.5255493409942773, "duration": 1.5163800716400146, "info_normalized_performance_mean": 0.8131025433540344, "info_normalized_performance_final": 0.8995535969734192, "info_performance_mean": 0.8131025433540344, "info_performance_final": 0.8995535969734192, "step": 218000}
{"episode_reward": 1626.2053571428544, "episode": 2181.0, "batch_reward": 9.453492164611816, "critic_loss": 900.8255004882812, "actor_loss": -1689.9923095703125, "actor_target_entropy": -3.0, "actor_entropy": 2.014162540435791, "alpha_loss": 0.1723523885011673, "alpha_value": 0.513599122429398, "duration": 1.4410479068756104, "info_normalized_performance_mean": 0.5457679033279419, "info_normalized_performance_final": 0.6017857193946838, "info_performance_mean": 0.5457679033279419, "info_performance_final": 0.6017857193946838, "step": 218500}
{"episode_reward": 1091.5357142857158, "episode": 2186.0, "batch_reward": 10.871376037597656, "critic_loss": 1810.028076171875, "actor_loss": -1790.146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.5725326538085938, "alpha_loss": 0.4709165394306183, "alpha_value": 0.5026619708897159, "duration": 1.5610253810882568, "info_normalized_performance_mean": 0.3274973928928375, "info_normalized_performance_final": 0.41898149251937866, "info_performance_mean": 0.3274973928928375, "info_performance_final": 0.41898149251937866, "step": 219000}
{"episode_reward": 654.9948559670787, "episode": 2191.0, "batch_reward": 8.693845748901367, "critic_loss": 573.409912109375, "actor_loss": -1676.8123779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.5166609287261963, "alpha_loss": 0.2552056610584259, "alpha_value": 0.49182379049338426, "duration": 1.6374258995056152, "info_normalized_performance_mean": 0.3851945400238037, "info_normalized_performance_final": 0.44232094287872314, "info_performance_mean": 0.3851945400238037, "info_performance_final": 0.44232094287872314, "step": 219500}
{"episode_reward": 770.3891184572996, "episode": 2196.0, "batch_reward": 8.73824405670166, "critic_loss": 1992.280517578125, "actor_loss": -1658.9891357421875, "actor_target_entropy": -3.0, "actor_entropy": 1.6824147701263428, "alpha_loss": 0.018859978765249252, "alpha_value": 0.4855068719210311, "step": 220000}
{"duration": 18.980318307876587, "info_normalized_performance_mean": 0.6539942026138306, "info_normalized_performance_final": 0.7190755009651184, "info_performance_mean": 0.6539942026138306, "info_performance_final": 0.7190755009651184, "step": 220000}
{"episode_reward": 1307.9882812500005, "episode": 2201.0, "batch_reward": 9.85212230682373, "critic_loss": 1019.377197265625, "actor_loss": -1707.7139892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7115678787231445, "alpha_loss": 0.22972345352172852, "alpha_value": 0.47842347398900986, "duration": 1.43709135055542, "info_normalized_performance_mean": 0.593035876750946, "info_normalized_performance_final": 0.6495535969734192, "info_performance_mean": 0.593035876750946, "info_performance_final": 0.6495535969734192, "step": 220500}
{"episode_reward": 1186.0714285714282, "episode": 2206.0, "batch_reward": 9.688323974609375, "critic_loss": 1117.354736328125, "actor_loss": -1699.60009765625, "actor_target_entropy": -3.0, "actor_entropy": 1.725203275680542, "alpha_loss": 0.16039066016674042, "alpha_value": 0.47432260906923496, "duration": 1.4990177154541016, "info_normalized_performance_mean": 0.41011372208595276, "info_normalized_performance_final": 0.4513494372367859, "info_performance_mean": 0.41011372208595276, "info_performance_final": 0.4513494372367859, "step": 221000}
{"episode_reward": 820.2272727272721, "episode": 2211.0, "batch_reward": 9.509916305541992, "critic_loss": 382.9401550292969, "actor_loss": -1696.163330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.627347707748413, "alpha_loss": -0.1371677964925766, "alpha_value": 0.4692617847975159, "duration": 1.4604415893554688, "info_normalized_performance_mean": 0.14102303981781006, "info_normalized_performance_final": 0.161086305975914, "info_performance_mean": 0.14102303981781006, "info_performance_final": 0.161086305975914, "step": 221500}
{"episode_reward": 282.0461309523809, "episode": 2216.0, "batch_reward": 9.544504165649414, "critic_loss": 616.3602905273438, "actor_loss": -1695.6024169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6853525638580322, "alpha_loss": -0.046967118978500366, "alpha_value": 0.46350876581974376, "duration": 1.5106561183929443, "info_normalized_performance_mean": 0.2600386440753937, "info_normalized_performance_final": 0.29335537552833557, "info_performance_mean": 0.2600386440753937, "info_performance_final": 0.29335537552833557, "step": 222000}
{"episode_reward": 520.077198786875, "episode": 2221.0, "batch_reward": 9.493755340576172, "critic_loss": 1524.7069091796875, "actor_loss": -1684.3958740234375, "actor_target_entropy": -3.0, "actor_entropy": 1.750345230102539, "alpha_loss": 0.05923369899392128, "alpha_value": 0.46171653519244565, "duration": 1.6287932395935059, "info_normalized_performance_mean": 0.20189398527145386, "info_normalized_performance_final": 0.25361570715904236, "info_performance_mean": 0.20189398527145386, "info_performance_final": 0.25361570715904236, "step": 222500}
{"episode_reward": 403.787878787879, "episode": 2226.0, "batch_reward": 9.42184066772461, "critic_loss": 522.2411499023438, "actor_loss": -1691.8572998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5900086164474487, "alpha_loss": -0.23112282156944275, "alpha_value": 0.4588272829669259, "duration": 1.5109460353851318, "info_normalized_performance_mean": 0.21983522176742554, "info_normalized_performance_final": 0.2390109896659851, "info_performance_mean": 0.21983522176742554, "info_performance_final": 0.2390109896659851, "step": 223000}
{"episode_reward": 439.6703296703299, "episode": 2231.0, "batch_reward": 9.611623764038086, "critic_loss": 1445.4346923828125, "actor_loss": -1708.771240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1533477306365967, "alpha_loss": 0.08879784494638443, "alpha_value": 0.45679329670476304, "duration": 1.4607508182525635, "info_normalized_performance_mean": 0.3288393020629883, "info_normalized_performance_final": 0.40714284777641296, "info_performance_mean": 0.3288393020629883, "info_performance_final": 0.40714284777641296, "step": 223500}
{"episode_reward": 657.6785714285711, "episode": 2236.0, "batch_reward": 10.066807746887207, "critic_loss": 632.244384765625, "actor_loss": -1710.0543212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.6555863618850708, "alpha_loss": 0.19642281532287598, "alpha_value": 0.45350686194294043, "duration": 1.6219329833984375, "info_normalized_performance_mean": 0.7631083726882935, "info_normalized_performance_final": 0.8374999761581421, "info_performance_mean": 0.7631083726882935, "info_performance_final": 0.8374999761581421, "step": 224000}
{"episode_reward": 1526.2166666666667, "episode": 2241.0, "batch_reward": 9.091358184814453, "critic_loss": 2169.281494140625, "actor_loss": -1616.2734375, "actor_target_entropy": -3.0, "actor_entropy": 1.677396297454834, "alpha_loss": 0.0022491775453090668, "alpha_value": 0.44883791933481554, "duration": 1.4566833972930908, "info_normalized_performance_mean": 0.32383209466934204, "info_normalized_performance_final": 0.375, "info_performance_mean": 0.32383209466934204, "info_performance_final": 0.375, "step": 224500}
{"episode_reward": 647.6641414141409, "episode": 2246.0, "batch_reward": 9.647347450256348, "critic_loss": 994.4492797851562, "actor_loss": -1656.83251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.7373895645141602, "alpha_loss": -0.05262326821684837, "alpha_value": 0.441024298453579, "duration": 1.6925785541534424, "info_normalized_performance_mean": 0.23771342635154724, "info_normalized_performance_final": 0.26423075795173645, "info_performance_mean": 0.23771342635154724, "info_performance_final": 0.26423075795173645, "step": 225000}
{"episode_reward": 475.4269230769234, "episode": 2251.0, "batch_reward": 9.174518585205078, "critic_loss": 442.8402099609375, "actor_loss": -1661.62548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.6798356771469116, "alpha_loss": 0.06770655512809753, "alpha_value": 0.4358148718071675, "duration": 1.595759391784668, "info_normalized_performance_mean": 0.6853386163711548, "info_normalized_performance_final": 0.8324652910232544, "info_performance_mean": 0.6853386163711548, "info_performance_final": 0.8324652910232544, "step": 225500}
{"episode_reward": 1370.6770833333353, "episode": 2256.0, "batch_reward": 10.36204719543457, "critic_loss": 332.0825500488281, "actor_loss": -1678.55224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.7733557224273682, "alpha_loss": 0.2505044639110565, "alpha_value": 0.4292243593531238, "duration": 1.4799420833587646, "info_normalized_performance_mean": 0.2014630287885666, "info_normalized_performance_final": 0.26621049642562866, "info_performance_mean": 0.2014630287885666, "info_performance_final": 0.26621049642562866, "step": 226000}
{"episode_reward": 402.92603453893815, "episode": 2261.0, "batch_reward": 8.724656105041504, "critic_loss": 1678.33740234375, "actor_loss": -1606.007080078125, "actor_target_entropy": -3.0, "actor_entropy": 1.446120023727417, "alpha_loss": 0.02768029272556305, "alpha_value": 0.4223903700727075, "duration": 1.4570565223693848, "info_normalized_performance_mean": 0.41108939051628113, "info_normalized_performance_final": 0.4526909589767456, "info_performance_mean": 0.41108939051628113, "info_performance_final": 0.4526909589767456, "step": 226500}
{"episode_reward": 822.1788194444454, "episode": 2266.0, "batch_reward": 9.240983009338379, "critic_loss": 1035.758056640625, "actor_loss": -1636.989990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.7328767776489258, "alpha_loss": -0.07473410665988922, "alpha_value": 0.4192085814824607, "duration": 1.4476768970489502, "info_normalized_performance_mean": 0.5431597232818604, "info_normalized_performance_final": 0.59375, "info_performance_mean": 0.5431597232818604, "info_performance_final": 0.59375, "step": 227000}
{"episode_reward": 1086.3194444444443, "episode": 2271.0, "batch_reward": 9.481132507324219, "critic_loss": 1167.5277099609375, "actor_loss": -1624.884521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3094574213027954, "alpha_loss": 0.09095528721809387, "alpha_value": 0.41571754133031463, "duration": 1.5103645324707031, "info_normalized_performance_mean": 0.3826855421066284, "info_normalized_performance_final": 0.4228515625, "info_performance_mean": 0.3826855421066284, "info_performance_final": 0.4228515625, "step": 227500}
{"episode_reward": 765.37109375, "episode": 2276.0, "batch_reward": 9.298891067504883, "critic_loss": 1273.2041015625, "actor_loss": -1599.57666015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5486505031585693, "alpha_loss": -0.15532247722148895, "alpha_value": 0.4145139744574452, "duration": 1.5714144706726074, "info_normalized_performance_mean": 0.6739754676818848, "info_normalized_performance_final": 0.7442908883094788, "info_performance_mean": 0.6739754676818848, "info_performance_final": 0.7442908883094788, "step": 228000}
{"episode_reward": 1347.9507211538462, "episode": 2281.0, "batch_reward": 8.85336685180664, "critic_loss": 595.1281127929688, "actor_loss": -1605.166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.4333410263061523, "alpha_loss": -0.04767151549458504, "alpha_value": 0.41354682839320905, "duration": 1.573599100112915, "info_normalized_performance_mean": 0.6399599313735962, "info_normalized_performance_final": 0.7152500152587891, "info_performance_mean": 0.6399599313735962, "info_performance_final": 0.7152500152587891, "step": 228500}
{"episode_reward": 1279.9199999999994, "episode": 2286.0, "batch_reward": 9.055802345275879, "critic_loss": 2388.170166015625, "actor_loss": -1636.2958984375, "actor_target_entropy": -3.0, "actor_entropy": 1.54798424243927, "alpha_loss": -0.10356266796588898, "alpha_value": 0.41389631664159005, "duration": 1.5057425498962402, "info_normalized_performance_mean": 0.38408923149108887, "info_normalized_performance_final": 0.5076572299003601, "info_performance_mean": 0.38408923149108887, "info_performance_final": 0.5076572299003601, "step": 229000}
{"episode_reward": 768.1785597914644, "episode": 2291.0, "batch_reward": 9.639808654785156, "critic_loss": 621.3170166015625, "actor_loss": -1644.8544921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4894622564315796, "alpha_loss": 0.05991252511739731, "alpha_value": 0.4155204183464365, "duration": 1.4101576805114746, "info_normalized_performance_mean": 0.3800446391105652, "info_normalized_performance_final": 0.46875, "info_performance_mean": 0.3800446391105652, "info_performance_final": 0.46875, "step": 229500}
{"episode_reward": 760.0892857142858, "episode": 2296.0, "batch_reward": 9.32489013671875, "critic_loss": 1073.595947265625, "actor_loss": -1591.7076416015625, "actor_target_entropy": -3.0, "actor_entropy": 1.4098942279815674, "alpha_loss": -0.03528920188546181, "alpha_value": 0.415963512644822, "step": 230000}
{"duration": 18.883838653564453, "info_normalized_performance_mean": 0.6856377124786377, "info_normalized_performance_final": 0.75, "info_performance_mean": 0.6856377124786377, "info_performance_final": 0.75, "step": 230000}
{"episode_reward": 1371.2755102040817, "episode": 2301.0, "batch_reward": 9.093671798706055, "critic_loss": 453.354736328125, "actor_loss": -1596.100341796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5721272230148315, "alpha_loss": -0.20702485740184784, "alpha_value": 0.4149404149991499, "duration": 1.5860142707824707, "info_normalized_performance_mean": 0.589633047580719, "info_normalized_performance_final": 0.6517857313156128, "info_performance_mean": 0.589633047580719, "info_performance_final": 0.6517857313156128, "step": 230500}
{"episode_reward": 1179.265873015874, "episode": 2306.0, "batch_reward": 9.576749801635742, "critic_loss": 1123.2281494140625, "actor_loss": -1620.0830078125, "actor_target_entropy": -3.0, "actor_entropy": 1.5597267150878906, "alpha_loss": 0.03519536927342415, "alpha_value": 0.41494051973248847, "duration": 1.4376237392425537, "info_normalized_performance_mean": 0.7822185754776001, "info_normalized_performance_final": 0.856249988079071, "info_performance_mean": 0.7822185754776001, "info_performance_final": 0.856249988079071, "step": 231000}
{"episode_reward": 1564.4375, "episode": 2311.0, "batch_reward": 10.30461597442627, "critic_loss": 3987.3974609375, "actor_loss": -1655.48388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3607590198516846, "alpha_loss": 0.215043306350708, "alpha_value": 0.4108339017682709, "duration": 1.6963093280792236, "info_normalized_performance_mean": 0.5712679028511047, "info_normalized_performance_final": 0.7647528052330017, "info_performance_mean": 0.5712679028511047, "info_performance_final": 0.7647528052330017, "step": 231500}
{"episode_reward": 1142.5358851674644, "episode": 2316.0, "batch_reward": 9.406704902648926, "critic_loss": 715.7531127929688, "actor_loss": -1586.44482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.4843354225158691, "alpha_loss": -0.05177207291126251, "alpha_value": 0.4093704055545104, "duration": 1.48417067527771, "info_normalized_performance_mean": 0.6456784605979919, "info_normalized_performance_final": 0.7053571343421936, "info_performance_mean": 0.6456784605979919, "info_performance_final": 0.7053571343421936, "step": 232000}
{"episode_reward": 1291.3571428571443, "episode": 2321.0, "batch_reward": 10.253433227539062, "critic_loss": 427.5329895019531, "actor_loss": -1623.89599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.4349207878112793, "alpha_loss": 0.37532711029052734, "alpha_value": 0.4062456937183068, "duration": 1.6721282005310059, "info_normalized_performance_mean": 0.4007655084133148, "info_normalized_performance_final": 0.5374800562858582, "info_performance_mean": 0.4007655084133148, "info_performance_final": 0.5374800562858582, "step": 232500}
{"episode_reward": 801.5311004784687, "episode": 2326.0, "batch_reward": 9.487569808959961, "critic_loss": 481.618408203125, "actor_loss": -1594.3460693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2693713903427124, "alpha_loss": -0.08942580223083496, "alpha_value": 0.4060802739349479, "duration": 1.480637550354004, "info_normalized_performance_mean": 0.19008484482765198, "info_normalized_performance_final": 0.21090534329414368, "info_performance_mean": 0.19008484482765198, "info_performance_final": 0.21090534329414368, "step": 233000}
{"episode_reward": 380.16975308642014, "episode": 2331.0, "batch_reward": 8.794017791748047, "critic_loss": 2586.6884765625, "actor_loss": -1523.874755859375, "actor_target_entropy": -3.0, "actor_entropy": 1.271072268486023, "alpha_loss": -0.11718166619539261, "alpha_value": 0.40167384378095766, "duration": 1.5717709064483643, "info_normalized_performance_mean": 0.8516029119491577, "info_normalized_performance_final": 0.9352940917015076, "info_performance_mean": 0.8516029119491577, "info_performance_final": 0.9352940917015076, "step": 233500}
{"episode_reward": 1703.2058823529435, "episode": 2336.0, "batch_reward": 8.697420120239258, "critic_loss": 1254.7686767578125, "actor_loss": -1541.64208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.6203336715698242, "alpha_loss": -0.09063267707824707, "alpha_value": 0.4005042466132752, "duration": 1.4775562286376953, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 234000}
{"episode_reward": 0.0, "episode": 2341.0, "batch_reward": 8.862728118896484, "critic_loss": 590.1923828125, "actor_loss": -1541.0673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3876701593399048, "alpha_loss": -0.12387283146381378, "alpha_value": 0.39667330698378706, "duration": 1.5982317924499512, "info_normalized_performance_mean": 0.7320747375488281, "info_normalized_performance_final": 0.8010694980621338, "info_performance_mean": 0.7320747375488281, "info_performance_final": 0.8010694980621338, "step": 234500}
{"episode_reward": 1464.1497326203196, "episode": 2346.0, "batch_reward": 9.230450630187988, "critic_loss": 793.3333129882812, "actor_loss": -1563.00341796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3925347328186035, "alpha_loss": 0.05180463567376137, "alpha_value": 0.39491073516468994, "duration": 1.6323597431182861, "info_normalized_performance_mean": 0.5097920894622803, "info_normalized_performance_final": 0.6581818461418152, "info_performance_mean": 0.5097920894622803, "info_performance_final": 0.6581818461418152, "step": 235000}
{"episode_reward": 1019.584415584416, "episode": 2351.0, "batch_reward": 9.748411178588867, "critic_loss": 566.4341430664062, "actor_loss": -1592.7601318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.8454498052597046, "alpha_loss": -0.06213247776031494, "alpha_value": 0.3909389751675108, "duration": 1.5406787395477295, "info_normalized_performance_mean": 0.7820785045623779, "info_normalized_performance_final": 0.8568627238273621, "info_performance_mean": 0.7820785045623779, "info_performance_final": 0.8568627238273621, "step": 235500}
{"episode_reward": 1564.1568627451009, "episode": 2356.0, "batch_reward": 9.615379333496094, "critic_loss": 776.8718872070312, "actor_loss": -1599.1658935546875, "actor_target_entropy": -3.0, "actor_entropy": 1.460343837738037, "alpha_loss": 0.13276490569114685, "alpha_value": 0.3900028270685867, "duration": 1.5069565773010254, "info_normalized_performance_mean": 0.5177833437919617, "info_normalized_performance_final": 0.574999988079071, "info_performance_mean": 0.5177833437919617, "info_performance_final": 0.574999988079071, "step": 236000}
{"episode_reward": 1035.5666666666666, "episode": 2361.0, "batch_reward": 9.74113655090332, "critic_loss": 538.1866455078125, "actor_loss": -1558.233154296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3032290935516357, "alpha_loss": 0.13239534199237823, "alpha_value": 0.3902532948678165, "duration": 1.5635619163513184, "info_normalized_performance_mean": 0.7490665912628174, "info_normalized_performance_final": 0.8166666626930237, "info_performance_mean": 0.7490665912628174, "info_performance_final": 0.8166666626930237, "step": 236500}
{"episode_reward": 1498.133333333332, "episode": 2366.0, "batch_reward": 10.702492713928223, "critic_loss": 532.36474609375, "actor_loss": -1592.496826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2961208820343018, "alpha_loss": 0.22087976336479187, "alpha_value": 0.38944476520282767, "duration": 1.5102314949035645, "info_normalized_performance_mean": 0.44952392578125, "info_normalized_performance_final": 0.4977324306964874, "info_performance_mean": 0.44952392578125, "info_performance_final": 0.4977324306964874, "step": 237000}
{"episode_reward": 899.0476190476196, "episode": 2371.0, "batch_reward": 9.223336219787598, "critic_loss": 485.8317565917969, "actor_loss": -1526.829345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3154008388519287, "alpha_loss": 0.20207154750823975, "alpha_value": 0.3890486388781888, "duration": 1.4618747234344482, "info_normalized_performance_mean": 0.321656197309494, "info_normalized_performance_final": 0.3485086262226105, "info_performance_mean": 0.321656197309494, "info_performance_final": 0.3485086262226105, "step": 237500}
{"episode_reward": 643.3124018838304, "episode": 2376.0, "batch_reward": 9.981385231018066, "critic_loss": 2992.70361328125, "actor_loss": -1527.6715087890625, "actor_target_entropy": -3.0, "actor_entropy": 1.7292046546936035, "alpha_loss": 0.2680647373199463, "alpha_value": 0.3831711697504004, "duration": 1.5371513366699219, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 238000}
{"episode_reward": 0.0, "episode": 2381.0, "batch_reward": 8.894289016723633, "critic_loss": 598.0858764648438, "actor_loss": -1574.504638671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3100740909576416, "alpha_loss": -0.04563436657190323, "alpha_value": 0.38069632599695397, "duration": 1.4484248161315918, "info_normalized_performance_mean": 0.22323749959468842, "info_normalized_performance_final": 0.24397031962871552, "info_performance_mean": 0.22323749959468842, "info_performance_final": 0.24397031962871552, "step": 238500}
{"episode_reward": 446.47495361781023, "episode": 2386.0, "batch_reward": 10.615957260131836, "critic_loss": 415.3926086425781, "actor_loss": -1576.05029296875, "actor_target_entropy": -3.0, "actor_entropy": 1.6169507503509521, "alpha_loss": 0.19101977348327637, "alpha_value": 0.3769954619240916, "duration": 1.5820472240447998, "info_normalized_performance_mean": 0.10211904346942902, "info_normalized_performance_final": 0.11349206417798996, "info_performance_mean": 0.10211904346942902, "info_performance_final": 0.11349206417798996, "step": 239000}
{"episode_reward": 204.23809523809499, "episode": 2391.0, "batch_reward": 9.577615737915039, "critic_loss": 762.7161865234375, "actor_loss": -1533.3035888671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3837456703186035, "alpha_loss": 0.2793915271759033, "alpha_value": 0.3739144914903252, "duration": 1.4729905128479004, "info_normalized_performance_mean": 0.28296515345573425, "info_normalized_performance_final": 0.34636688232421875, "info_performance_mean": 0.28296515345573425, "info_performance_final": 0.34636688232421875, "step": 239500}
{"episode_reward": 565.9302704464003, "episode": 2396.0, "batch_reward": 9.788896560668945, "critic_loss": 981.5462646484375, "actor_loss": -1507.829345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3970890045166016, "alpha_loss": -0.10565271973609924, "alpha_value": 0.37523561069152417, "step": 240000}
{"duration": 18.75237274169922, "info_normalized_performance_mean": 0.4771230220794678, "info_normalized_performance_final": 0.523809552192688, "info_performance_mean": 0.4771230220794678, "info_performance_final": 0.523809552192688, "step": 240000}
{"episode_reward": 954.2460317460321, "episode": 2401.0, "batch_reward": 9.16522216796875, "critic_loss": 524.7802124023438, "actor_loss": -1564.8924560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.354288101196289, "alpha_loss": 0.022417403757572174, "alpha_value": 0.3717743403280568, "duration": 1.7196786403656006, "info_normalized_performance_mean": 0.32012560963630676, "info_normalized_performance_final": 0.3629298806190491, "info_performance_mean": 0.32012560963630676, "info_performance_final": 0.3629298806190491, "step": 240500}
{"episode_reward": 640.251322751322, "episode": 2406.0, "batch_reward": 8.805414199829102, "critic_loss": 436.37322998046875, "actor_loss": -1496.7269287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.5290371179580688, "alpha_loss": -0.010867644101381302, "alpha_value": 0.36550068792397267, "duration": 1.5054740905761719, "info_normalized_performance_mean": 0.5459896326065063, "info_normalized_performance_final": 0.60546875, "info_performance_mean": 0.5459896326065063, "info_performance_final": 0.60546875, "step": 241000}
{"episode_reward": 1091.9791666666665, "episode": 2411.0, "batch_reward": 9.003166198730469, "critic_loss": 1473.26171875, "actor_loss": -1492.4820556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.3234449625015259, "alpha_loss": 0.1814029961824417, "alpha_value": 0.36131508352860764, "duration": 1.5238313674926758, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 241500}
{"episode_reward": 0.0, "episode": 2416.0, "batch_reward": 9.986551284790039, "critic_loss": 596.1094970703125, "actor_loss": -1535.42822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3481025695800781, "alpha_loss": 0.143524169921875, "alpha_value": 0.35680700271475857, "duration": 1.6493451595306396, "info_normalized_performance_mean": 0.026886524632573128, "info_normalized_performance_final": 0.07088366150856018, "info_performance_mean": 0.026886524632573128, "info_performance_final": 0.07088366150856018, "step": 242000}
{"episode_reward": 53.77304513668147, "episode": 2421.0, "batch_reward": 8.732999801635742, "critic_loss": 886.0435791015625, "actor_loss": -1486.8701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3872759342193604, "alpha_loss": 0.04767395555973053, "alpha_value": 0.3520331908300954, "duration": 1.4711811542510986, "info_normalized_performance_mean": 0.37016791105270386, "info_normalized_performance_final": 0.40546876192092896, "info_performance_mean": 0.37016791105270386, "info_performance_final": 0.40546876192092896, "step": 242500}
{"episode_reward": 740.3359375, "episode": 2426.0, "batch_reward": 9.279460906982422, "critic_loss": 1147.9698486328125, "actor_loss": -1512.9378662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2550145387649536, "alpha_loss": -0.03718940168619156, "alpha_value": 0.34517441083822453, "duration": 1.5842163562774658, "info_normalized_performance_mean": 0.35346001386642456, "info_normalized_performance_final": 0.44624999165534973, "info_performance_mean": 0.35346001386642456, "info_performance_final": 0.44624999165534973, "step": 243000}
{"episode_reward": 706.9199999999994, "episode": 2431.0, "batch_reward": 8.44205379486084, "critic_loss": 1183.441162109375, "actor_loss": -1414.977294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.405749797821045, "alpha_loss": 0.05136461555957794, "alpha_value": 0.34129439473569345, "duration": 1.5993878841400146, "info_normalized_performance_mean": 0.6907222270965576, "info_normalized_performance_final": 0.7555555701255798, "info_performance_mean": 0.6907222270965576, "info_performance_final": 0.7555555701255798, "step": 243500}
{"episode_reward": 1381.4444444444428, "episode": 2436.0, "batch_reward": 9.219560623168945, "critic_loss": 391.7903137207031, "actor_loss": -1474.192138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.5896482467651367, "alpha_loss": 0.040747907012701035, "alpha_value": 0.3384110642791826, "duration": 1.5354642868041992, "info_normalized_performance_mean": 0.2775000333786011, "info_normalized_performance_final": 0.3063492178916931, "info_performance_mean": 0.2775000333786011, "info_performance_final": 0.3063492178916931, "step": 244000}
{"episode_reward": 555.0000000000009, "episode": 2441.0, "batch_reward": 9.414562225341797, "critic_loss": 982.1138305664062, "actor_loss": -1493.483642578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2776775360107422, "alpha_loss": 0.16423898935317993, "alpha_value": 0.33709236314067587, "duration": 1.4541587829589844, "info_normalized_performance_mean": 0.5846309661865234, "info_normalized_performance_final": 0.648809552192688, "info_performance_mean": 0.5846309661865234, "info_performance_final": 0.648809552192688, "step": 244500}
{"episode_reward": 1169.261904761904, "episode": 2446.0, "batch_reward": 9.432028770446777, "critic_loss": 355.2056884765625, "actor_loss": -1456.8197021484375, "actor_target_entropy": -3.0, "actor_entropy": 1.5322580337524414, "alpha_loss": -0.10850649327039719, "alpha_value": 0.33573186825062373, "duration": 1.5323936939239502, "info_normalized_performance_mean": 0.42546871304512024, "info_normalized_performance_final": 0.4779829680919647, "info_performance_mean": 0.42546871304512024, "info_performance_final": 0.4779829680919647, "step": 245000}
{"episode_reward": 850.9375000000002, "episode": 2451.0, "batch_reward": 9.31886100769043, "critic_loss": 2142.716064453125, "actor_loss": -1501.3009033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.5998597145080566, "alpha_loss": -0.014475144445896149, "alpha_value": 0.33512729579510253, "duration": 1.5027039051055908, "info_normalized_performance_mean": 0.2073376476764679, "info_normalized_performance_final": 0.23160172998905182, "info_performance_mean": 0.2073376476764679, "info_performance_final": 0.23160172998905182, "step": 245500}
{"episode_reward": 414.6753246753244, "episode": 2456.0, "batch_reward": 9.624652862548828, "critic_loss": 529.9276733398438, "actor_loss": -1465.4501953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9772495031356812, "alpha_loss": 0.17825299501419067, "alpha_value": 0.3360044320445141, "duration": 1.8055167198181152, "info_normalized_performance_mean": 0.1901467740535736, "info_normalized_performance_final": 0.3195266127586365, "info_performance_mean": 0.1901467740535736, "info_performance_final": 0.3195266127586365, "step": 246000}
{"episode_reward": 380.29358215748755, "episode": 2461.0, "batch_reward": 8.839632034301758, "critic_loss": 309.90142822265625, "actor_loss": -1456.208251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.4013464450836182, "alpha_loss": 0.06385862827301025, "alpha_value": 0.3320135212795868, "duration": 1.5073778629302979, "info_normalized_performance_mean": 0.08585023880004883, "info_normalized_performance_final": 0.09625668078660965, "info_performance_mean": 0.08585023880004883, "info_performance_final": 0.09625668078660965, "step": 246500}
{"episode_reward": 171.7005347593584, "episode": 2466.0, "batch_reward": 10.015073776245117, "critic_loss": 1135.878662109375, "actor_loss": -1481.806884765625, "actor_target_entropy": -3.0, "actor_entropy": 1.6505993604660034, "alpha_loss": 0.22549594938755035, "alpha_value": 0.3256644672842983, "duration": 1.4711687564849854, "info_normalized_performance_mean": 0.5391630530357361, "info_normalized_performance_final": 0.5931919813156128, "info_performance_mean": 0.5391630530357361, "info_performance_final": 0.5931919813156128, "step": 247000}
{"episode_reward": 1078.3258928571445, "episode": 2471.0, "batch_reward": 9.839582443237305, "critic_loss": 793.7139282226562, "actor_loss": -1510.668212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2485849857330322, "alpha_loss": 0.0224636048078537, "alpha_value": 0.32171004078010224, "duration": 1.4779493808746338, "info_normalized_performance_mean": 0.4658547341823578, "info_normalized_performance_final": 0.5089285969734192, "info_performance_mean": 0.4658547341823578, "info_performance_final": 0.5089285969734192, "step": 247500}
{"episode_reward": 931.7091836734703, "episode": 2476.0, "batch_reward": 8.934041976928711, "critic_loss": 451.0832214355469, "actor_loss": -1445.5972900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.592798113822937, "alpha_loss": -0.06453628838062286, "alpha_value": 0.3198582334241983, "duration": 1.583775520324707, "info_normalized_performance_mean": 0.35176876187324524, "info_normalized_performance_final": 0.4651360511779785, "info_performance_mean": 0.35176876187324524, "info_performance_final": 0.4651360511779785, "step": 248000}
{"episode_reward": 703.5374149659872, "episode": 2481.0, "batch_reward": 9.229979515075684, "critic_loss": 479.2147216796875, "actor_loss": -1461.35546875, "actor_target_entropy": -3.0, "actor_entropy": 1.5285758972167969, "alpha_loss": 0.007863745093345642, "alpha_value": 0.32002784641457216, "duration": 1.467085838317871, "info_normalized_performance_mean": 0.325585275888443, "info_normalized_performance_final": 0.3586309552192688, "info_performance_mean": 0.325585275888443, "info_performance_final": 0.3586309552192688, "step": 248500}
{"episode_reward": 651.1706349206343, "episode": 2486.0, "batch_reward": 9.696704864501953, "critic_loss": 386.8048400878906, "actor_loss": -1435.226806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.3867857456207275, "alpha_loss": 0.09353861212730408, "alpha_value": 0.3199222403321601, "duration": 1.436368703842163, "info_normalized_performance_mean": 0.2574675679206848, "info_normalized_performance_final": 0.2792207896709442, "info_performance_mean": 0.2574675679206848, "info_performance_final": 0.2792207896709442, "step": 249000}
{"episode_reward": 514.9350649350647, "episode": 2491.0, "batch_reward": 9.065852165222168, "critic_loss": 663.208251953125, "actor_loss": -1449.897216796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1562583446502686, "alpha_loss": 0.21711203455924988, "alpha_value": 0.3177756625879723, "duration": 1.6104564666748047, "info_normalized_performance_mean": 0.802361249923706, "info_normalized_performance_final": 0.8908730149269104, "info_performance_mean": 0.802361249923706, "info_performance_final": 0.8908730149269104, "step": 249500}
{"episode_reward": 1604.7222222222229, "episode": 2496.0, "batch_reward": 8.797807693481445, "critic_loss": 268.10626220703125, "actor_loss": -1394.11474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.37899649143219, "alpha_loss": 0.11343944817781448, "alpha_value": 0.31545258234617946, "step": 250000}
{"duration": 18.494240760803223, "info_normalized_performance_mean": 0.4621111750602722, "info_normalized_performance_final": 0.5530465841293335, "info_performance_mean": 0.4621111750602722, "info_performance_final": 0.5530465841293335, "step": 250000}
{"episode_reward": 924.2222222222213, "episode": 2501.0, "batch_reward": 9.124105453491211, "critic_loss": 918.8565673828125, "actor_loss": -1421.562744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.5705249309539795, "alpha_loss": -0.11255775392055511, "alpha_value": 0.3137163989183832, "duration": 1.5358450412750244, "info_normalized_performance_mean": 0.10336662083864212, "info_normalized_performance_final": 0.11733217537403107, "info_performance_mean": 0.10336662083864212, "info_performance_final": 0.11733217537403107, "step": 250500}
{"episode_reward": 206.73321759259215, "episode": 2506.0, "batch_reward": 8.877981185913086, "critic_loss": 1389.3720703125, "actor_loss": -1453.025146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.112097144126892, "alpha_loss": -0.28205034136772156, "alpha_value": 0.3118213478350456, "duration": 1.3979382514953613, "info_normalized_performance_mean": 0.294183611869812, "info_normalized_performance_final": 0.3183673322200775, "info_performance_mean": 0.294183611869812, "info_performance_final": 0.3183673322200775, "step": 251000}
{"episode_reward": 588.3673469387749, "episode": 2511.0, "batch_reward": 9.550146102905273, "critic_loss": 453.9576110839844, "actor_loss": -1448.747314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.3154520988464355, "alpha_loss": -0.017382608726620674, "alpha_value": 0.3155716004270422, "duration": 1.4723429679870605, "info_normalized_performance_mean": 0.8580058217048645, "info_normalized_performance_final": 0.9345238208770752, "info_performance_mean": 0.8580058217048645, "info_performance_final": 0.9345238208770752, "step": 251500}
{"episode_reward": 1716.0119047619023, "episode": 2516.0, "batch_reward": 9.715217590332031, "critic_loss": 750.83544921875, "actor_loss": -1456.2620849609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2231347560882568, "alpha_loss": 0.005720611661672592, "alpha_value": 0.3156017760603837, "duration": 1.5098040103912354, "info_normalized_performance_mean": 0.8650221824645996, "info_normalized_performance_final": 0.9419642686843872, "info_performance_mean": 0.8650221824645996, "info_performance_final": 0.9419642686843872, "step": 252000}
{"episode_reward": 1730.0446428571443, "episode": 2521.0, "batch_reward": 9.33424186706543, "critic_loss": 1722.729736328125, "actor_loss": -1445.2401123046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3293495178222656, "alpha_loss": 0.04191509634256363, "alpha_value": 0.3169174052698939, "duration": 1.6882140636444092, "info_normalized_performance_mean": 0.4664593040943146, "info_normalized_performance_final": 0.6107839345932007, "info_performance_mean": 0.4664593040943146, "info_performance_final": 0.6107839345932007, "step": 252500}
{"episode_reward": 932.918660287082, "episode": 2526.0, "batch_reward": 9.546324729919434, "critic_loss": 560.4437866210938, "actor_loss": -1446.352783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.213814377784729, "alpha_loss": -0.04438645765185356, "alpha_value": 0.3161100686396017, "duration": 1.4454827308654785, "info_normalized_performance_mean": 0.30355316400527954, "info_normalized_performance_final": 0.3365384638309479, "info_performance_mean": 0.30355316400527954, "info_performance_final": 0.3365384638309479, "step": 253000}
{"episode_reward": 607.1062271062276, "episode": 2531.0, "batch_reward": 9.785284042358398, "critic_loss": 666.1121826171875, "actor_loss": -1462.0767822265625, "actor_target_entropy": -3.0, "actor_entropy": 0.7577843070030212, "alpha_loss": 0.051681261509656906, "alpha_value": 0.31355256744946114, "duration": 1.4636523723602295, "info_normalized_performance_mean": 0.47134822607040405, "info_normalized_performance_final": 0.518750011920929, "info_performance_mean": 0.47134822607040405, "info_performance_final": 0.518750011920929, "step": 253500}
{"episode_reward": 942.6964285714286, "episode": 2536.0, "batch_reward": 8.64396858215332, "critic_loss": 2122.03271484375, "actor_loss": -1379.305908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.214693307876587, "alpha_loss": -0.11661936342716217, "alpha_value": 0.3120550880402166, "duration": 1.4396708011627197, "info_normalized_performance_mean": 0.5574242472648621, "info_normalized_performance_final": 0.6010100841522217, "info_performance_mean": 0.5574242472648621, "info_performance_final": 0.6010100841522217, "step": 254000}
{"episode_reward": 1114.8484848484877, "episode": 2541.0, "batch_reward": 8.84634017944336, "critic_loss": 444.98577880859375, "actor_loss": -1421.4013671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1614642143249512, "alpha_loss": -0.004943178966641426, "alpha_value": 0.31293805079219655, "duration": 1.4340708255767822, "info_normalized_performance_mean": 0.35092535614967346, "info_normalized_performance_final": 0.38311687111854553, "info_performance_mean": 0.35092535614967346, "info_performance_final": 0.38311687111854553, "step": 254500}
{"episode_reward": 701.8506493506504, "episode": 2546.0, "batch_reward": 9.385969161987305, "critic_loss": 1088.6568603515625, "actor_loss": -1416.35498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.2524864673614502, "alpha_loss": -0.022456763312220573, "alpha_value": 0.3146065346499168, "duration": 1.6211025714874268, "info_normalized_performance_mean": 0.7562942504882812, "info_normalized_performance_final": 0.8752940893173218, "info_performance_mean": 0.7562942504882812, "info_performance_final": 0.8752940893173218, "step": 255000}
{"episode_reward": 1512.5882352941164, "episode": 2551.0, "batch_reward": 8.577942848205566, "critic_loss": 331.37762451171875, "actor_loss": -1337.059814453125, "actor_target_entropy": -3.0, "actor_entropy": 1.4715088605880737, "alpha_loss": -0.0961071327328682, "alpha_value": 0.31568467690117, "duration": 1.4802367687225342, "info_normalized_performance_mean": 0.6394765377044678, "info_normalized_performance_final": 0.6976495981216431, "info_performance_mean": 0.6394765377044678, "info_performance_final": 0.6976495981216431, "step": 255500}
{"episode_reward": 1278.9529914529915, "episode": 2556.0, "batch_reward": 9.231021881103516, "critic_loss": 416.6929931640625, "actor_loss": -1398.199462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0211021900177002, "alpha_loss": 0.09958836436271667, "alpha_value": 0.3155050677875814, "duration": 1.607980489730835, "info_normalized_performance_mean": 0.6274603009223938, "info_normalized_performance_final": 0.6855158805847168, "info_performance_mean": 0.6274603009223938, "info_performance_final": 0.6855158805847168, "step": 256000}
{"episode_reward": 1254.9206349206338, "episode": 2561.0, "batch_reward": 8.897343635559082, "critic_loss": 333.7406311035156, "actor_loss": -1399.365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2597707509994507, "alpha_loss": 0.04145475849509239, "alpha_value": 0.3139690365102249, "duration": 1.5145132541656494, "info_normalized_performance_mean": 0.5247802734375, "info_normalized_performance_final": 0.58544921875, "info_performance_mean": 0.5247802734375, "info_performance_final": 0.58544921875, "step": 256500}
{"episode_reward": 1049.560546875, "episode": 2566.0, "batch_reward": 8.907787322998047, "critic_loss": 381.2373962402344, "actor_loss": -1444.6802978515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8956131935119629, "alpha_loss": 0.02871144376695156, "alpha_value": 0.31187706097098683, "duration": 1.610320806503296, "info_normalized_performance_mean": 0.520880937576294, "info_normalized_performance_final": 0.5761904716491699, "info_performance_mean": 0.520880937576294, "info_performance_final": 0.5761904716491699, "step": 257000}
{"episode_reward": 1041.7619047619046, "episode": 2571.0, "batch_reward": 9.172927856445312, "critic_loss": 633.0332641601562, "actor_loss": -1425.6866455078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2568695545196533, "alpha_loss": -0.026028184220194817, "alpha_value": 0.31223587538295433, "duration": 1.4641485214233398, "info_normalized_performance_mean": 0.5127609372138977, "info_normalized_performance_final": 0.5975274443626404, "info_performance_mean": 0.5127609372138977, "info_performance_final": 0.5975274443626404, "step": 257500}
{"episode_reward": 1025.5219780219793, "episode": 2576.0, "batch_reward": 9.104925155639648, "critic_loss": 1085.0257568359375, "actor_loss": -1378.843505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1585471630096436, "alpha_loss": -0.20817720890045166, "alpha_value": 0.31549351968201367, "duration": 1.6152048110961914, "info_normalized_performance_mean": 0.2112261801958084, "info_normalized_performance_final": 0.2666666805744171, "info_performance_mean": 0.2112261801958084, "info_performance_final": 0.2666666805744171, "step": 258000}
{"episode_reward": 422.4523809523804, "episode": 2581.0, "batch_reward": 10.384082794189453, "critic_loss": 413.6180419921875, "actor_loss": -1452.2481689453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9191930890083313, "alpha_loss": 0.13321247696876526, "alpha_value": 0.31683231258535227, "duration": 1.768871784210205, "info_normalized_performance_mean": 0.5879472494125366, "info_normalized_performance_final": 0.773809552192688, "info_performance_mean": 0.5879472494125366, "info_performance_final": 0.773809552192688, "step": 258500}
{"episode_reward": 1175.8943833943822, "episode": 2586.0, "batch_reward": 9.470367431640625, "critic_loss": 1275.6632080078125, "actor_loss": -1372.9072265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3237011432647705, "alpha_loss": -0.03390241414308548, "alpha_value": 0.3173999814311481, "duration": 1.5599913597106934, "info_normalized_performance_mean": 0.6535887122154236, "info_normalized_performance_final": 0.7709478139877319, "info_performance_mean": 0.6535887122154236, "info_performance_final": 0.7709478139877319, "step": 259000}
{"episode_reward": 1307.1771978021998, "episode": 2591.0, "batch_reward": 9.23453426361084, "critic_loss": 486.673583984375, "actor_loss": -1383.910400390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1845524311065674, "alpha_loss": -0.04905664920806885, "alpha_value": 0.3202315975592216, "duration": 1.556232213973999, "info_normalized_performance_mean": 0.43271878361701965, "info_normalized_performance_final": 0.4783950746059418, "info_performance_mean": 0.43271878361701965, "info_performance_final": 0.4783950746059418, "step": 259500}
{"episode_reward": 865.4377104377103, "episode": 2596.0, "batch_reward": 8.688804626464844, "critic_loss": 674.5877075195312, "actor_loss": -1384.150146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1901092529296875, "alpha_loss": -0.3453724980354309, "alpha_value": 0.3251824337864101, "step": 260000}
{"duration": 18.466176509857178, "info_normalized_performance_mean": 0.24079860746860504, "info_normalized_performance_final": 0.2604166567325592, "info_performance_mean": 0.24079860746860504, "info_performance_final": 0.2604166567325592, "step": 260000}
{"episode_reward": 481.5972222222216, "episode": 2601.0, "batch_reward": 8.85737419128418, "critic_loss": 1911.9951171875, "actor_loss": -1389.304931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.3429045677185059, "alpha_loss": -0.04920969903469086, "alpha_value": 0.327931776551149, "duration": 1.4738948345184326, "info_normalized_performance_mean": 0.5516250729560852, "info_normalized_performance_final": 0.6071428656578064, "info_performance_mean": 0.5516250729560852, "info_performance_final": 0.6071428656578064, "step": 260500}
{"episode_reward": 1103.2499999999989, "episode": 2606.0, "batch_reward": 9.688629150390625, "critic_loss": 340.85418701171875, "actor_loss": -1427.5506591796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1354267597198486, "alpha_loss": 0.09076190739870071, "alpha_value": 0.3285776296003751, "duration": 1.6088578701019287, "info_normalized_performance_mean": 0.30616432428359985, "info_normalized_performance_final": 0.3885566294193268, "info_performance_mean": 0.30616432428359985, "info_performance_final": 0.3885566294193268, "step": 261000}
{"episode_reward": 612.328548644338, "episode": 2611.0, "batch_reward": 9.31500244140625, "critic_loss": 967.491455078125, "actor_loss": -1397.121826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.186401128768921, "alpha_loss": 0.1681310087442398, "alpha_value": 0.3314478715439203, "duration": 1.602184534072876, "info_normalized_performance_mean": 0.8107916116714478, "info_normalized_performance_final": 0.8816666603088379, "info_performance_mean": 0.8107916116714478, "info_performance_final": 0.8816666603088379, "step": 261500}
{"episode_reward": 1621.5833333333367, "episode": 2616.0, "batch_reward": 9.940473556518555, "critic_loss": 638.8900146484375, "actor_loss": -1415.268798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.875133752822876, "alpha_loss": 0.23386871814727783, "alpha_value": 0.332991287671238, "duration": 1.4283230304718018, "info_normalized_performance_mean": 0.4051561653614044, "info_normalized_performance_final": 0.4437499940395355, "info_performance_mean": 0.4051561653614044, "info_performance_final": 0.4437499940395355, "step": 262000}
{"episode_reward": 810.3125, "episode": 2621.0, "batch_reward": 9.478778839111328, "critic_loss": 982.7945556640625, "actor_loss": -1396.42138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2780383825302124, "alpha_loss": -0.08859949558973312, "alpha_value": 0.33352904023708013, "duration": 1.4645392894744873, "info_normalized_performance_mean": 0.3062254786491394, "info_normalized_performance_final": 0.3323529362678528, "info_performance_mean": 0.3062254786491394, "info_performance_final": 0.3323529362678528, "step": 262500}
{"episode_reward": 612.4509803921559, "episode": 2626.0, "batch_reward": 9.48214340209961, "critic_loss": 2907.542236328125, "actor_loss": -1430.400390625, "actor_target_entropy": -3.0, "actor_entropy": 1.512343168258667, "alpha_loss": -0.07855074107646942, "alpha_value": 0.33746978776076514, "duration": 1.536301851272583, "info_normalized_performance_mean": 0.7605195045471191, "info_normalized_performance_final": 0.8668830990791321, "info_performance_mean": 0.7605195045471191, "info_performance_final": 0.8668830990791321, "step": 263000}
{"episode_reward": 1521.038961038961, "episode": 2631.0, "batch_reward": 10.121261596679688, "critic_loss": 826.7839965820312, "actor_loss": -1409.23681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.219866156578064, "alpha_loss": -0.2075454741716385, "alpha_value": 0.34176216517594105, "duration": 1.4898457527160645, "info_normalized_performance_mean": 0.49369508028030396, "info_normalized_performance_final": 0.5746337175369263, "info_performance_mean": 0.49369508028030396, "info_performance_final": 0.5746337175369263, "step": 263500}
{"episode_reward": 987.3901098901094, "episode": 2636.0, "batch_reward": 9.78900146484375, "critic_loss": 174.13531494140625, "actor_loss": -1406.599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.6255478858947754, "alpha_loss": -0.03931310400366783, "alpha_value": 0.3455556793204175, "duration": 1.6424534320831299, "info_normalized_performance_mean": 0.7757947444915771, "info_normalized_performance_final": 0.8680555820465088, "info_performance_mean": 0.7757947444915771, "info_performance_final": 0.8680555820465088, "step": 264000}
{"episode_reward": 1551.589506172838, "episode": 2641.0, "batch_reward": 9.634125709533691, "critic_loss": 799.7430419921875, "actor_loss": -1400.9302978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.193649172782898, "alpha_loss": -0.25765228271484375, "alpha_value": 0.34954353303598645, "duration": 1.5051062107086182, "info_normalized_performance_mean": 0.3819500803947449, "info_normalized_performance_final": 0.4212740361690521, "info_performance_mean": 0.3819500803947449, "info_performance_final": 0.4212740361690521, "step": 264500}
{"episode_reward": 763.9002403846132, "episode": 2646.0, "batch_reward": 10.622354507446289, "critic_loss": 167.9315948486328, "actor_loss": -1458.34521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.505265474319458, "alpha_loss": -0.06389161944389343, "alpha_value": 0.35608387520737694, "duration": 1.562364101409912, "info_normalized_performance_mean": 0.6387215852737427, "info_normalized_performance_final": 0.7457386255264282, "info_performance_mean": 0.6387215852737427, "info_performance_final": 0.7457386255264282, "step": 265000}
{"episode_reward": 1277.4431818181815, "episode": 2651.0, "batch_reward": 9.508996963500977, "critic_loss": 703.9207763671875, "actor_loss": -1397.889404296875, "actor_target_entropy": -3.0, "actor_entropy": 1.2569849491119385, "alpha_loss": -0.14315064251422882, "alpha_value": 0.3573151290199895, "duration": 1.5716519355773926, "info_normalized_performance_mean": 0.5884285569190979, "info_normalized_performance_final": 0.6657142639160156, "info_performance_mean": 0.5884285569190979, "info_performance_final": 0.6657142639160156, "step": 265500}
{"episode_reward": 1176.8571428571427, "episode": 2656.0, "batch_reward": 9.272632598876953, "critic_loss": 613.199462890625, "actor_loss": -1402.985107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3593478202819824, "alpha_loss": 0.09802418947219849, "alpha_value": 0.35769823133846534, "duration": 1.6437320709228516, "info_normalized_performance_mean": 0.615350604057312, "info_normalized_performance_final": 0.679894208908081, "info_performance_mean": 0.615350604057312, "info_performance_final": 0.679894208908081, "step": 266000}
{"episode_reward": 1230.7010582010591, "episode": 2661.0, "batch_reward": 9.699735641479492, "critic_loss": 372.62127685546875, "actor_loss": -1455.7938232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.454101800918579, "alpha_loss": -0.2764478027820587, "alpha_value": 0.35827539709760514, "duration": 1.5633766651153564, "info_normalized_performance_mean": 0.7333174347877502, "info_normalized_performance_final": 0.8185096383094788, "info_performance_mean": 0.7333174347877502, "info_performance_final": 0.8185096383094788, "step": 266500}
{"episode_reward": 1466.6346153846162, "episode": 2666.0, "batch_reward": 9.882671356201172, "critic_loss": 326.3875732421875, "actor_loss": -1458.378173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.2374690771102905, "alpha_loss": -0.1768970936536789, "alpha_value": 0.36208910361715957, "duration": 1.4927804470062256, "info_normalized_performance_mean": 0.40487074851989746, "info_normalized_performance_final": 0.44651442766189575, "info_performance_mean": 0.40487074851989746, "info_performance_final": 0.44651442766189575, "step": 267000}
{"episode_reward": 809.7415865384609, "episode": 2671.0, "batch_reward": 9.140883445739746, "critic_loss": 527.9434204101562, "actor_loss": -1384.9833984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3654842376708984, "alpha_loss": -0.08926878869533539, "alpha_value": 0.3648156927511537, "duration": 1.6578271389007568, "info_normalized_performance_mean": 0.36386188864707947, "info_normalized_performance_final": 0.4056473970413208, "info_performance_mean": 0.36386188864707947, "info_performance_final": 0.4056473970413208, "step": 267500}
{"episode_reward": 727.7238292011012, "episode": 2676.0, "batch_reward": 9.61445426940918, "critic_loss": 251.58596801757812, "actor_loss": -1395.5230712890625, "actor_target_entropy": -3.0, "actor_entropy": 1.316612720489502, "alpha_loss": 0.16912122070789337, "alpha_value": 0.3670156449777875, "duration": 1.520721673965454, "info_normalized_performance_mean": 0.3935929834842682, "info_normalized_performance_final": 0.4285714328289032, "info_performance_mean": 0.3935929834842682, "info_performance_final": 0.4285714328289032, "step": 268000}
{"episode_reward": 787.1861471861464, "episode": 2681.0, "batch_reward": 8.060249328613281, "critic_loss": 503.70330810546875, "actor_loss": -1344.873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3596700429916382, "alpha_loss": -0.18030494451522827, "alpha_value": 0.36909402814023823, "duration": 1.5755579471588135, "info_normalized_performance_mean": 0.8119251728057861, "info_normalized_performance_final": 0.9165775179862976, "info_performance_mean": 0.8119251728057861, "info_performance_final": 0.9165775179862976, "step": 268500}
{"episode_reward": 1623.8502673796777, "episode": 2686.0, "batch_reward": 8.625293731689453, "critic_loss": 824.9111328125, "actor_loss": -1376.9302978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0458505153656006, "alpha_loss": -0.11161637306213379, "alpha_value": 0.37433311054895385, "duration": 1.4042983055114746, "info_normalized_performance_mean": 0.22215276956558228, "info_normalized_performance_final": 0.2408854216337204, "info_performance_mean": 0.22215276956558228, "info_performance_final": 0.2408854216337204, "step": 269000}
{"episode_reward": 444.30555555555503, "episode": 2691.0, "batch_reward": 9.209575653076172, "critic_loss": 354.466796875, "actor_loss": -1379.9892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2786531448364258, "alpha_loss": -0.005148326978087425, "alpha_value": 0.3759389821987511, "duration": 1.7308871746063232, "info_normalized_performance_mean": 0.30946579575538635, "info_normalized_performance_final": 0.3683226406574249, "info_performance_mean": 0.30946579575538635, "info_performance_final": 0.3683226406574249, "step": 269500}
{"episode_reward": 618.9316239316242, "episode": 2696.0, "batch_reward": 9.381684303283691, "critic_loss": 356.307861328125, "actor_loss": -1376.52490234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4843109846115112, "alpha_loss": 0.118947833776474, "alpha_value": 0.37364483513185587, "step": 270000}
{"duration": 18.274996757507324, "info_normalized_performance_mean": 0.7686977982521057, "info_normalized_performance_final": 0.8658854365348816, "info_performance_mean": 0.7686977982521057, "info_performance_final": 0.8658854365348816, "step": 270000}
{"episode_reward": 1537.395833333332, "episode": 2701.0, "batch_reward": 9.345430374145508, "critic_loss": 343.28515625, "actor_loss": -1389.5360107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3384461402893066, "alpha_loss": -0.028027549386024475, "alpha_value": 0.3769204193476744, "duration": 1.4875881671905518, "info_normalized_performance_mean": 0.13342013955116272, "info_normalized_performance_final": 0.1440972238779068, "info_performance_mean": 0.13342013955116272, "info_performance_final": 0.1440972238779068, "step": 270500}
{"episode_reward": 266.84027777777834, "episode": 2706.0, "batch_reward": 9.796892166137695, "critic_loss": 232.1582489013672, "actor_loss": -1406.450439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.4237830638885498, "alpha_loss": -0.1012355387210846, "alpha_value": 0.38100907708144255, "duration": 1.6513183116912842, "info_normalized_performance_mean": 0.8130487203598022, "info_normalized_performance_final": 0.9222221970558167, "info_performance_mean": 0.8130487203598022, "info_performance_final": 0.9222221970558167, "step": 271000}
{"episode_reward": 1626.0972222222192, "episode": 2711.0, "batch_reward": 9.508170127868652, "critic_loss": 176.15518188476562, "actor_loss": -1408.672607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.1821391582489014, "alpha_loss": 0.07475847750902176, "alpha_value": 0.3833479275242223, "duration": 1.4848120212554932, "info_normalized_performance_mean": 0.7690160870552063, "info_normalized_performance_final": 0.8582175970077515, "info_performance_mean": 0.7690160870552063, "info_performance_final": 0.8582175970077515, "step": 271500}
{"episode_reward": 1538.0324074074106, "episode": 2716.0, "batch_reward": 8.62519645690918, "critic_loss": 815.0775146484375, "actor_loss": -1382.609619140625, "actor_target_entropy": -3.0, "actor_entropy": 1.201225996017456, "alpha_loss": -0.1794934868812561, "alpha_value": 0.38479963339794193, "duration": 1.6110115051269531, "info_normalized_performance_mean": 0.8358394503593445, "info_normalized_performance_final": 0.966844916343689, "info_performance_mean": 0.8358394503593445, "info_performance_final": 0.966844916343689, "step": 272000}
{"episode_reward": 1671.6791443850248, "episode": 2721.0, "batch_reward": 8.842016220092773, "critic_loss": 953.4324951171875, "actor_loss": -1391.162353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1787574291229248, "alpha_loss": 0.1509941816329956, "alpha_value": 0.38635349388998047, "duration": 1.631892204284668, "info_normalized_performance_mean": 0.3032204508781433, "info_normalized_performance_final": 0.3739418387413025, "info_performance_mean": 0.3032204508781433, "info_performance_final": 0.3739418387413025, "step": 272500}
{"episode_reward": 606.4409274935593, "episode": 2726.0, "batch_reward": 9.742980003356934, "critic_loss": 440.9331970214844, "actor_loss": -1399.913330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.3889048099517822, "alpha_loss": -0.0849854126572609, "alpha_value": 0.3859022109919562, "duration": 1.4825530052185059, "info_normalized_performance_mean": 0.7480612993240356, "info_normalized_performance_final": 0.8112244606018066, "info_performance_mean": 0.7480612993240356, "info_performance_final": 0.8112244606018066, "step": 273000}
{"episode_reward": 1496.1224489795889, "episode": 2731.0, "batch_reward": 9.078741073608398, "critic_loss": 996.6556396484375, "actor_loss": -1382.2938232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.2304270267486572, "alpha_loss": 0.08193092793226242, "alpha_value": 0.3854779535035174, "duration": 1.6209332942962646, "info_normalized_performance_mean": 0.4902452826499939, "info_normalized_performance_final": 0.5909090638160706, "info_performance_mean": 0.4902452826499939, "info_performance_final": 0.5909090638160706, "step": 273500}
{"episode_reward": 980.4906204906221, "episode": 2736.0, "batch_reward": 8.711162567138672, "critic_loss": 337.5838623046875, "actor_loss": -1389.976318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.513994812965393, "alpha_loss": -0.06089955195784569, "alpha_value": 0.3829246686498366, "duration": 1.6029601097106934, "info_normalized_performance_mean": 0.5361734628677368, "info_normalized_performance_final": 0.5926870703697205, "info_performance_mean": 0.5361734628677368, "info_performance_final": 0.5926870703697205, "step": 274000}
{"episode_reward": 1072.3469387755108, "episode": 2741.0, "batch_reward": 9.448057174682617, "critic_loss": 1570.5535888671875, "actor_loss": -1404.8355712890625, "actor_target_entropy": -3.0, "actor_entropy": 1.4729584455490112, "alpha_loss": 0.06483924388885498, "alpha_value": 0.3816439098192518, "duration": 1.466038703918457, "info_normalized_performance_mean": 0.7960119843482971, "info_normalized_performance_final": 0.8660714030265808, "info_performance_mean": 0.7960119843482971, "info_performance_final": 0.8660714030265808, "step": 274500}
{"episode_reward": 1592.0238095238121, "episode": 2746.0, "batch_reward": 10.129877090454102, "critic_loss": 431.0606689453125, "actor_loss": -1455.880615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.458260178565979, "alpha_loss": 0.11536234617233276, "alpha_value": 0.38217806287975103, "duration": 1.3652870655059814, "info_normalized_performance_mean": 0.5571429133415222, "info_normalized_performance_final": 0.6035714149475098, "info_performance_mean": 0.5571429133415222, "info_performance_final": 0.6035714149475098, "step": 275000}
{"episode_reward": 1114.2857142857142, "episode": 2751.0, "batch_reward": 8.914997100830078, "critic_loss": 1638.348876953125, "actor_loss": -1397.358154296875, "actor_target_entropy": -3.0, "actor_entropy": 1.6502394676208496, "alpha_loss": -0.14407813549041748, "alpha_value": 0.3783623998557629, "duration": 1.4553265571594238, "info_normalized_performance_mean": 0.4674956798553467, "info_normalized_performance_final": 0.5125868320465088, "info_performance_mean": 0.4674956798553467, "info_performance_final": 0.5125868320465088, "step": 275500}
{"episode_reward": 934.9913194444429, "episode": 2756.0, "batch_reward": 10.18825912475586, "critic_loss": 298.25628662109375, "actor_loss": -1427.393798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3924344778060913, "alpha_loss": 0.06997837126255035, "alpha_value": 0.3760523483350548, "duration": 1.5529799461364746, "info_normalized_performance_mean": 0.805117666721344, "info_normalized_performance_final": 0.9205882549285889, "info_performance_mean": 0.805117666721344, "info_performance_final": 0.9205882549285889, "step": 276000}
{"episode_reward": 1610.235294117649, "episode": 2761.0, "batch_reward": 9.27458381652832, "critic_loss": 340.7317199707031, "actor_loss": -1450.7418212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.4989644289016724, "alpha_loss": -0.11289021372795105, "alpha_value": 0.37397402994645723, "duration": 1.4943554401397705, "info_normalized_performance_mean": 0.35797688364982605, "info_normalized_performance_final": 0.3934687376022339, "info_performance_mean": 0.35797688364982605, "info_performance_final": 0.3934687376022339, "step": 276500}
{"episode_reward": 715.9538032656305, "episode": 2766.0, "batch_reward": 8.830375671386719, "critic_loss": 900.5804443359375, "actor_loss": -1408.1024169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.023858904838562, "alpha_loss": 0.1082099974155426, "alpha_value": 0.36939108699362877, "duration": 1.458266258239746, "info_normalized_performance_mean": 0.47307288646698, "info_normalized_performance_final": 0.5208333134651184, "info_performance_mean": 0.47307288646698, "info_performance_final": 0.5208333134651184, "step": 277000}
{"episode_reward": 946.1458333333321, "episode": 2771.0, "batch_reward": 9.317426681518555, "critic_loss": 487.18060302734375, "actor_loss": -1405.043212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2371704578399658, "alpha_loss": -0.01746508851647377, "alpha_value": 0.3663097814887105, "duration": 1.5303170680999756, "info_normalized_performance_mean": 0.6372928619384766, "info_normalized_performance_final": 0.7035156488418579, "info_performance_mean": 0.6372928619384766, "info_performance_final": 0.7035156488418579, "step": 277500}
{"episode_reward": 1274.5859375, "episode": 2776.0, "batch_reward": 8.988410949707031, "critic_loss": 799.4978637695312, "actor_loss": -1420.5938720703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2056611776351929, "alpha_loss": -0.059775009751319885, "alpha_value": 0.3657022687292593, "duration": 1.4390592575073242, "info_normalized_performance_mean": 0.18588237464427948, "info_normalized_performance_final": 0.20147058367729187, "info_performance_mean": 0.18588237464427948, "info_performance_final": 0.20147058367729187, "step": 278000}
{"episode_reward": 371.76470588235225, "episode": 2781.0, "batch_reward": 9.413309097290039, "critic_loss": 872.933349609375, "actor_loss": -1419.3223876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.348724603652954, "alpha_loss": 0.03934890776872635, "alpha_value": 0.3619956007601021, "duration": 1.5951569080352783, "info_normalized_performance_mean": 0.42870956659317017, "info_normalized_performance_final": 0.4928571283817291, "info_performance_mean": 0.42870956659317017, "info_performance_final": 0.4928571283817291, "step": 278500}
{"episode_reward": 857.4190476190481, "episode": 2786.0, "batch_reward": 9.974166870117188, "critic_loss": 209.83322143554688, "actor_loss": -1445.4932861328125, "actor_target_entropy": -3.0, "actor_entropy": 1.3625833988189697, "alpha_loss": 0.0905887708067894, "alpha_value": 0.35840014271169335, "duration": 1.5383100509643555, "info_normalized_performance_mean": 0.38055339455604553, "info_normalized_performance_final": 0.4775390625, "info_performance_mean": 0.38055339455604553, "info_performance_final": 0.4775390625, "step": 279000}
{"episode_reward": 761.1067708333343, "episode": 2791.0, "batch_reward": 9.530887603759766, "critic_loss": 765.54345703125, "actor_loss": -1441.7698974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.140021800994873, "alpha_loss": -0.028632812201976776, "alpha_value": 0.35479087412414195, "duration": 1.609431266784668, "info_normalized_performance_mean": 0.8087239265441895, "info_normalized_performance_final": 0.9296875, "info_performance_mean": 0.8087239265441895, "info_performance_final": 0.9296875, "step": 279500}
{"episode_reward": 1617.447916666666, "episode": 2796.0, "batch_reward": 10.400663375854492, "critic_loss": 311.7427978515625, "actor_loss": -1431.5452880859375, "actor_target_entropy": -3.0, "actor_entropy": 1.2501060962677002, "alpha_loss": 0.13429558277130127, "alpha_value": 0.3511167874188247, "step": 280000}
{"duration": 18.133986234664917, "info_normalized_performance_mean": 0.5408580303192139, "info_normalized_performance_final": 0.5997217297554016, "info_performance_mean": 0.5408580303192139, "info_performance_final": 0.5997217297554016, "step": 280000}
{"episode_reward": 1081.7161410018562, "episode": 2801.0, "batch_reward": 9.468992233276367, "critic_loss": 373.30267333984375, "actor_loss": -1391.68701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1475027799606323, "alpha_loss": 0.023605801165103912, "alpha_value": 0.3487882069312817, "duration": 1.567781686782837, "info_normalized_performance_mean": 0.8270719647407532, "info_normalized_performance_final": 0.9320261478424072, "info_performance_mean": 0.8270719647407532, "info_performance_final": 0.9320261478424072, "step": 280500}
{"episode_reward": 1654.14379084967, "episode": 2806.0, "batch_reward": 9.939189910888672, "critic_loss": 508.1014404296875, "actor_loss": -1445.0404052734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9035425186157227, "alpha_loss": 0.032218173146247864, "alpha_value": 0.3489284563300166, "duration": 1.5268476009368896, "info_normalized_performance_mean": 0.6086858510971069, "info_normalized_performance_final": 0.8008241653442383, "info_performance_mean": 0.6086858510971069, "info_performance_final": 0.8008241653442383, "step": 281000}
{"episode_reward": 1217.3717948717942, "episode": 2811.0, "batch_reward": 10.137656211853027, "critic_loss": 943.4644165039062, "actor_loss": -1460.544677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.2305488586425781, "alpha_loss": 0.07167617976665497, "alpha_value": 0.3485593030220815, "duration": 1.4447262287139893, "info_normalized_performance_mean": 0.5011480450630188, "info_normalized_performance_final": 0.5542091727256775, "info_performance_mean": 0.5011480450630188, "info_performance_final": 0.5542091727256775, "step": 281500}
{"episode_reward": 1002.2959183673476, "episode": 2816.0, "batch_reward": 8.556621551513672, "critic_loss": 895.3529052734375, "actor_loss": -1364.531005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.3090096712112427, "alpha_loss": -0.13223353028297424, "alpha_value": 0.35020407797633246, "duration": 1.6025118827819824, "info_normalized_performance_mean": 0.39761117100715637, "info_normalized_performance_final": 0.43263888359069824, "info_performance_mean": 0.39761117100715637, "info_performance_final": 0.43263888359069824, "step": 282000}
{"episode_reward": 795.2222222222235, "episode": 2821.0, "batch_reward": 9.462217330932617, "critic_loss": 449.80230712890625, "actor_loss": -1445.534912109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1825499534606934, "alpha_loss": -0.02180083654820919, "alpha_value": 0.3508737708864719, "duration": 1.4957902431488037, "info_normalized_performance_mean": 0.1407967060804367, "info_normalized_performance_final": 0.1675824224948883, "info_performance_mean": 0.1407967060804367, "info_performance_final": 0.1675824224948883, "step": 282500}
{"episode_reward": 281.59340659340654, "episode": 2826.0, "batch_reward": 8.842521667480469, "critic_loss": 621.980224609375, "actor_loss": -1364.1361083984375, "actor_target_entropy": -3.0, "actor_entropy": 1.45306396484375, "alpha_loss": -0.08110503852367401, "alpha_value": 0.3533491739488811, "duration": 1.5154094696044922, "info_normalized_performance_mean": 0.054265860468149185, "info_normalized_performance_final": 0.0615079365670681, "info_performance_mean": 0.054265860468149185, "info_performance_final": 0.0615079365670681, "step": 283000}
{"episode_reward": 108.53174603174614, "episode": 2831.0, "batch_reward": 10.033106803894043, "critic_loss": 934.0742797851562, "actor_loss": -1463.676513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2313992977142334, "alpha_loss": -0.1106627881526947, "alpha_value": 0.35915824656098644, "duration": 1.6070315837860107, "info_normalized_performance_mean": 0.8035909533500671, "info_normalized_performance_final": 0.9118182063102722, "info_performance_mean": 0.8035909533500671, "info_performance_final": 0.9118182063102722, "step": 283500}
{"episode_reward": 1607.1818181818192, "episode": 2836.0, "batch_reward": 9.692051887512207, "critic_loss": 732.2857666015625, "actor_loss": -1465.1585693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3615739345550537, "alpha_loss": -0.008157115429639816, "alpha_value": 0.36418905092114906, "duration": 1.4910659790039062, "info_normalized_performance_mean": 0.4500626027584076, "info_normalized_performance_final": 0.5035156011581421, "info_performance_mean": 0.4500626027584076, "info_performance_final": 0.5035156011581421, "step": 284000}
{"episode_reward": 900.125, "episode": 2841.0, "batch_reward": 9.664149284362793, "critic_loss": 870.334716796875, "actor_loss": -1411.498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1892417669296265, "alpha_loss": -0.010749312117695808, "alpha_value": 0.3660866932715381, "duration": 1.6041312217712402, "info_normalized_performance_mean": 0.5467560291290283, "info_normalized_performance_final": 0.6071428656578064, "info_performance_mean": 0.5467560291290283, "info_performance_final": 0.6071428656578064, "step": 284500}
{"episode_reward": 1093.5119047619037, "episode": 2846.0, "batch_reward": 9.973993301391602, "critic_loss": 641.4696655273438, "actor_loss": -1478.919677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3114936351776123, "alpha_loss": 0.012170679867267609, "alpha_value": 0.3697000506677579, "duration": 1.609029769897461, "info_normalized_performance_mean": 0.5513708591461182, "info_normalized_performance_final": 0.6360596418380737, "info_performance_mean": 0.5513708591461182, "info_performance_final": 0.6360596418380737, "step": 285000}
{"episode_reward": 1102.7417695473268, "episode": 2851.0, "batch_reward": 9.953453063964844, "critic_loss": 1824.7540283203125, "actor_loss": -1405.067138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.14566969871521, "alpha_loss": 0.0693841427564621, "alpha_value": 0.37274148985391403, "duration": 1.7203483581542969, "info_normalized_performance_mean": 0.412393182516098, "info_normalized_performance_final": 0.4923687279224396, "info_performance_mean": 0.412393182516098, "info_performance_final": 0.4923687279224396, "step": 285500}
{"episode_reward": 824.7863247863233, "episode": 2856.0, "batch_reward": 10.117203712463379, "critic_loss": 833.9196166992188, "actor_loss": -1437.855224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3315091133117676, "alpha_loss": -0.08162694424390793, "alpha_value": 0.3724912596636504, "duration": 1.6203556060791016, "info_normalized_performance_mean": 0.3672659993171692, "info_normalized_performance_final": 0.5277777910232544, "info_performance_mean": 0.3672659993171692, "info_performance_final": 0.5277777910232544, "step": 286000}
{"episode_reward": 734.5318930041147, "episode": 2861.0, "batch_reward": 9.451562881469727, "critic_loss": 445.9400634765625, "actor_loss": -1397.1533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.5543146133422852, "alpha_loss": -0.09245795756578445, "alpha_value": 0.37749903450245254, "duration": 1.5943524837493896, "info_normalized_performance_mean": 0.700247049331665, "info_normalized_performance_final": 0.8227513432502747, "info_performance_mean": 0.700247049331665, "info_performance_final": 0.8227513432502747, "step": 286500}
{"episode_reward": 1400.4938271604929, "episode": 2866.0, "batch_reward": 8.339401245117188, "critic_loss": 1326.38232421875, "actor_loss": -1398.171630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.5279539823532104, "alpha_loss": -0.20889586210250854, "alpha_value": 0.3820591432836445, "duration": 1.6175882816314697, "info_normalized_performance_mean": 0.726329505443573, "info_normalized_performance_final": 0.89682537317276, "info_performance_mean": 0.726329505443573, "info_performance_final": 0.89682537317276, "step": 287000}
{"episode_reward": 1452.6587301587315, "episode": 2871.0, "batch_reward": 9.88736629486084, "critic_loss": 884.0078125, "actor_loss": -1447.67919921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6142218112945557, "alpha_loss": -0.0402352400124073, "alpha_value": 0.3822667570716207, "duration": 1.6347742080688477, "info_normalized_performance_mean": 0.3982797861099243, "info_normalized_performance_final": 0.4351311922073364, "info_performance_mean": 0.3982797861099243, "info_performance_final": 0.4351311922073364, "step": 287500}
{"episode_reward": 796.5597667638474, "episode": 2876.0, "batch_reward": 9.417546272277832, "critic_loss": 1248.025390625, "actor_loss": -1437.9964599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.08510422706604, "alpha_loss": -0.05723007768392563, "alpha_value": 0.38374256826347536, "duration": 1.4709904193878174, "info_normalized_performance_mean": 0.43814292550086975, "info_normalized_performance_final": 0.48265305161476135, "info_performance_mean": 0.43814292550086975, "info_performance_final": 0.48265305161476135, "step": 288000}
{"episode_reward": 876.2857142857134, "episode": 2881.0, "batch_reward": 9.799874305725098, "critic_loss": 787.3780517578125, "actor_loss": -1454.536865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4453938007354736, "alpha_loss": -0.1869649887084961, "alpha_value": 0.38753829750449315, "duration": 1.4767851829528809, "info_normalized_performance_mean": 0.3284706175327301, "info_normalized_performance_final": 0.35630252957344055, "info_performance_mean": 0.3284706175327301, "info_performance_final": 0.35630252957344055, "step": 288500}
{"episode_reward": 656.9411764705881, "episode": 2886.0, "batch_reward": 8.972650527954102, "critic_loss": 586.52294921875, "actor_loss": -1396.0567626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.2740176916122437, "alpha_loss": -0.07797643542289734, "alpha_value": 0.3906523926520976, "duration": 1.5765814781188965, "info_normalized_performance_mean": 0.8603362441062927, "info_normalized_performance_final": 0.9536363482475281, "info_performance_mean": 0.8603362441062927, "info_performance_final": 0.9536363482475281, "step": 289000}
{"episode_reward": 1720.672727272726, "episode": 2891.0, "batch_reward": 9.824005126953125, "critic_loss": 435.089111328125, "actor_loss": -1438.48046875, "actor_target_entropy": -3.0, "actor_entropy": 1.433365821838379, "alpha_loss": -0.14517931640148163, "alpha_value": 0.39494745927629427, "duration": 1.5990042686462402, "info_normalized_performance_mean": 0.5810999274253845, "info_normalized_performance_final": 0.6291666626930237, "info_performance_mean": 0.5810999274253845, "info_performance_final": 0.6291666626930237, "step": 289500}
{"episode_reward": 1162.2000000000005, "episode": 2896.0, "batch_reward": 9.652336120605469, "critic_loss": 1142.35888671875, "actor_loss": -1459.38818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.1781659126281738, "alpha_loss": 0.012512452900409698, "alpha_value": 0.39872880482759443, "step": 290000}
{"duration": 18.479438066482544, "info_normalized_performance_mean": 0.42032310366630554, "info_normalized_performance_final": 0.45691609382629395, "info_performance_mean": 0.42032310366630554, "info_performance_final": 0.45691609382629395, "step": 290000}
{"episode_reward": 840.6462585034009, "episode": 2901.0, "batch_reward": 8.813365936279297, "critic_loss": 539.0540771484375, "actor_loss": -1389.90478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.672071933746338, "alpha_loss": -0.17725063860416412, "alpha_value": 0.4003964065783552, "duration": 1.468108892440796, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 290500}
{"episode_reward": 0.0, "episode": 2906.0, "batch_reward": 8.712127685546875, "critic_loss": 1799.1556396484375, "actor_loss": -1388.806396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4865479469299316, "alpha_loss": -0.20165053009986877, "alpha_value": 0.4075519816365284, "duration": 1.4313633441925049, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 291000}
{"episode_reward": 0.0, "episode": 2911.0, "batch_reward": 8.757301330566406, "critic_loss": 1665.197998046875, "actor_loss": -1388.0274658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.6131062507629395, "alpha_loss": -0.3937016725540161, "alpha_value": 0.41805616162651504, "duration": 1.523543357849121, "info_normalized_performance_mean": 0.8091962933540344, "info_normalized_performance_final": 0.8892857432365417, "info_performance_mean": 0.8091962933540344, "info_performance_final": 0.8892857432365417, "step": 291500}
{"episode_reward": 1618.3928571428562, "episode": 2916.0, "batch_reward": 9.939897537231445, "critic_loss": 485.552490234375, "actor_loss": -1429.211181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.4911344051361084, "alpha_loss": -0.07221382111310959, "alpha_value": 0.4289699282075123, "duration": 1.5776939392089844, "info_normalized_performance_mean": 0.6849037408828735, "info_normalized_performance_final": 0.739182710647583, "info_performance_mean": 0.6849037408828735, "info_performance_final": 0.739182710647583, "step": 292000}
{"episode_reward": 1369.8076923076906, "episode": 2921.0, "batch_reward": 9.028871536254883, "critic_loss": 760.9804077148438, "actor_loss": -1463.7886962890625, "actor_target_entropy": -3.0, "actor_entropy": 1.5573811531066895, "alpha_loss": -0.20965531468391418, "alpha_value": 0.44044294363241254, "duration": 1.447784185409546, "info_normalized_performance_mean": 0.423104465007782, "info_normalized_performance_final": 0.47664836049079895, "info_performance_mean": 0.423104465007782, "info_performance_final": 0.47664836049079895, "step": 292500}
{"episode_reward": 846.2087912087898, "episode": 2926.0, "batch_reward": 9.218244552612305, "critic_loss": 497.68896484375, "actor_loss": -1471.057373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.4309284687042236, "alpha_loss": -0.4837888777256012, "alpha_value": 0.4524065935856257, "duration": 1.4169752597808838, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 293000}
{"episode_reward": 0.0, "episode": 2931.0, "batch_reward": 9.119501113891602, "critic_loss": 853.9869384765625, "actor_loss": -1438.68408203125, "actor_target_entropy": -3.0, "actor_entropy": 1.474208116531372, "alpha_loss": -0.40687689185142517, "alpha_value": 0.4650528507776014, "duration": 1.4400103092193604, "info_normalized_performance_mean": 0.5816190242767334, "info_normalized_performance_final": 0.6392857432365417, "info_performance_mean": 0.5816190242767334, "info_performance_final": 0.6392857432365417, "step": 293500}
{"episode_reward": 1163.2380952380963, "episode": 2936.0, "batch_reward": 9.00511360168457, "critic_loss": 425.465576171875, "actor_loss": -1398.463134765625, "actor_target_entropy": -3.0, "actor_entropy": 1.5654441118240356, "alpha_loss": -0.03009355068206787, "alpha_value": 0.47712164874984525, "duration": 1.4559440612792969, "info_normalized_performance_mean": 0.5119505524635315, "info_normalized_performance_final": 0.5590659379959106, "info_performance_mean": 0.5119505524635315, "info_performance_final": 0.5590659379959106, "step": 294000}
{"episode_reward": 1023.9010989010974, "episode": 2941.0, "batch_reward": 10.397058486938477, "critic_loss": 700.7473754882812, "actor_loss": -1553.08056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.6740977764129639, "alpha_loss": -0.05155026540160179, "alpha_value": 0.48422921297918464, "duration": 1.6141889095306396, "info_normalized_performance_mean": 0.4397464692592621, "info_normalized_performance_final": 0.49455296993255615, "info_performance_mean": 0.4397464692592621, "info_performance_final": 0.49455296993255615, "step": 294500}
{"episode_reward": 879.4928625093925, "episode": 2946.0, "batch_reward": 8.391854286193848, "critic_loss": 304.96533203125, "actor_loss": -1453.87548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.5433285236358643, "alpha_loss": -0.24318775534629822, "alpha_value": 0.494958114490805, "duration": 1.464721441268921, "info_normalized_performance_mean": 0.33077317476272583, "info_normalized_performance_final": 0.3630252182483673, "info_performance_mean": 0.33077317476272583, "info_performance_final": 0.3630252182483673, "step": 295000}
{"episode_reward": 661.5462184873946, "episode": 2951.0, "batch_reward": 9.202974319458008, "critic_loss": 412.54144287109375, "actor_loss": -1454.076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.650457739830017, "alpha_loss": -0.3418106436729431, "alpha_value": 0.50486574911143, "duration": 1.5920436382293701, "info_normalized_performance_mean": 0.47486111521720886, "info_normalized_performance_final": 0.5763888955116272, "info_performance_mean": 0.47486111521720886, "info_performance_final": 0.5763888955116272, "step": 295500}
{"episode_reward": 949.7222222222243, "episode": 2956.0, "batch_reward": 9.2407865524292, "critic_loss": 421.96331787109375, "actor_loss": -1510.6156005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.4781241416931152, "alpha_loss": -0.2118159681558609, "alpha_value": 0.5154289798714797, "duration": 1.5577006340026855, "info_normalized_performance_mean": 0.36953866481781006, "info_normalized_performance_final": 0.40840908885002136, "info_performance_mean": 0.36953866481781006, "info_performance_final": 0.40840908885002136, "step": 296000}
{"episode_reward": 739.0772727272721, "episode": 2961.0, "batch_reward": 9.286758422851562, "critic_loss": 1416.830810546875, "actor_loss": -1551.7509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.427228331565857, "alpha_loss": -0.12756164371967316, "alpha_value": 0.5252706735761513, "duration": 1.547382116317749, "info_normalized_performance_mean": 0.738823652267456, "info_normalized_performance_final": 0.8098039031028748, "info_performance_mean": 0.738823652267456, "info_performance_final": 0.8098039031028748, "step": 296500}
{"episode_reward": 1477.647058823532, "episode": 2966.0, "batch_reward": 9.05758285522461, "critic_loss": 823.9998779296875, "actor_loss": -1533.99658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4848251342773438, "alpha_loss": -0.33327218890190125, "alpha_value": 0.5348212345074372, "duration": 1.6394619941711426, "info_normalized_performance_mean": 0.8033486008644104, "info_normalized_performance_final": 0.8765432238578796, "info_performance_mean": 0.8033486008644104, "info_performance_final": 0.8765432238578796, "step": 297000}
{"episode_reward": 1606.6975308641995, "episode": 2971.0, "batch_reward": 10.184816360473633, "critic_loss": 501.9859924316406, "actor_loss": -1614.4169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6391465663909912, "alpha_loss": -0.11708751320838928, "alpha_value": 0.5422642776146915, "duration": 1.467085361480713, "info_normalized_performance_mean": 0.5213046073913574, "info_normalized_performance_final": 0.5758928656578064, "info_performance_mean": 0.5213046073913574, "info_performance_final": 0.5758928656578064, "step": 297500}
{"episode_reward": 1042.609126984126, "episode": 2976.0, "batch_reward": 9.405929565429688, "critic_loss": 4136.28125, "actor_loss": -1588.634521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4572796821594238, "alpha_loss": -0.3591762185096741, "alpha_value": 0.5484721874086461, "duration": 1.638415813446045, "info_normalized_performance_mean": 0.5795303583145142, "info_normalized_performance_final": 0.6554232835769653, "info_performance_mean": 0.5795303583145142, "info_performance_final": 0.6554232835769653, "step": 298000}
{"episode_reward": 1159.0608465608475, "episode": 2981.0, "batch_reward": 10.062309265136719, "critic_loss": 439.257080078125, "actor_loss": -1571.3687744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.6459375619888306, "alpha_loss": -0.18901866674423218, "alpha_value": 0.5579708483197237, "duration": 1.7591583728790283, "info_normalized_performance_mean": 0.32188892364501953, "info_normalized_performance_final": 0.36959490180015564, "info_performance_mean": 0.32188892364501953, "info_performance_final": 0.36959490180015564, "step": 298500}
{"episode_reward": 643.7778789258086, "episode": 2986.0, "batch_reward": 8.914119720458984, "critic_loss": 569.064453125, "actor_loss": -1543.411376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.68501615524292, "alpha_loss": -0.23152227699756622, "alpha_value": 0.5630040736072813, "duration": 1.5623705387115479, "info_normalized_performance_mean": 0.35319215059280396, "info_normalized_performance_final": 0.4023376703262329, "info_performance_mean": 0.35319215059280396, "info_performance_final": 0.4023376703262329, "step": 299000}
{"episode_reward": 706.3844155844167, "episode": 2991.0, "batch_reward": 9.155878067016602, "critic_loss": 863.5703125, "actor_loss": -1528.034912109375, "actor_target_entropy": -3.0, "actor_entropy": 1.323361873626709, "alpha_loss": -0.2732771039009094, "alpha_value": 0.5738544458213796, "duration": 1.4552929401397705, "info_normalized_performance_mean": 0.4219897389411926, "info_normalized_performance_final": 0.4585459232330322, "info_performance_mean": 0.4219897389411926, "info_performance_final": 0.4585459232330322, "step": 299500}
{"episode_reward": 843.979591836736, "episode": 2996.0, "batch_reward": 9.329416275024414, "critic_loss": 711.2440185546875, "actor_loss": -1577.407470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3971240520477295, "alpha_loss": -0.04340020939707756, "alpha_value": 0.5862734881002397, "step": 300000}
{"duration": 18.418922901153564, "info_normalized_performance_mean": 0.3358724117279053, "info_normalized_performance_final": 0.3689236044883728, "info_performance_mean": 0.3358724117279053, "info_performance_final": 0.3689236044883728, "step": 300000}
{"episode_reward": 671.744791666666, "episode": 3001.0, "batch_reward": 9.372705459594727, "critic_loss": 922.4395751953125, "actor_loss": -1648.81982421875, "actor_target_entropy": -3.0, "actor_entropy": 1.4809250831604004, "alpha_loss": -0.1853591799736023, "alpha_value": 0.5966477855956067, "duration": 1.6492536067962646, "info_normalized_performance_mean": 0.3229450583457947, "info_normalized_performance_final": 0.3595041334629059, "info_performance_mean": 0.3229450583457947, "info_performance_final": 0.3595041334629059, "step": 300500}
{"episode_reward": 645.8900190718367, "episode": 3006.0, "batch_reward": 10.043853759765625, "critic_loss": 661.606689453125, "actor_loss": -1656.734130859375, "actor_target_entropy": -3.0, "actor_entropy": 1.348067045211792, "alpha_loss": -0.0006918013095855713, "alpha_value": 0.605727516235886, "duration": 1.4512782096862793, "info_normalized_performance_mean": 0.4764682352542877, "info_normalized_performance_final": 0.5181406140327454, "info_performance_mean": 0.4764682352542877, "info_performance_final": 0.5181406140327454, "step": 301000}
{"episode_reward": 952.9365079365086, "episode": 3011.0, "batch_reward": 8.952072143554688, "critic_loss": 711.8888549804688, "actor_loss": -1602.852294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4472941160202026, "alpha_loss": -0.5220592021942139, "alpha_value": 0.6100713193321502, "duration": 1.4553911685943604, "info_normalized_performance_mean": 0.4093593657016754, "info_normalized_performance_final": 0.44614511728286743, "info_performance_mean": 0.4093593657016754, "info_performance_final": 0.44614511728286743, "step": 301500}
{"episode_reward": 818.718820861679, "episode": 3016.0, "batch_reward": 9.617729187011719, "critic_loss": 1043.1058349609375, "actor_loss": -1681.4449462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.6292693614959717, "alpha_loss": -0.200809046626091, "alpha_value": 0.6147349643218577, "duration": 1.4848806858062744, "info_normalized_performance_mean": 0.5174701809883118, "info_normalized_performance_final": 0.5694444179534912, "info_performance_mean": 0.5174701809883118, "info_performance_final": 0.5694444179534912, "step": 302000}
{"episode_reward": 1034.9404761904777, "episode": 3021.0, "batch_reward": 9.482040405273438, "critic_loss": 256.29315185546875, "actor_loss": -1664.483642578125, "actor_target_entropy": -3.0, "actor_entropy": 1.4104642868041992, "alpha_loss": -0.13410821557044983, "alpha_value": 0.6148203925717298, "duration": 1.5769546031951904, "info_normalized_performance_mean": 0.8845054507255554, "info_normalized_performance_final": 0.973901093006134, "info_performance_mean": 0.8845054507255554, "info_performance_final": 0.973901093006134, "step": 302500}
{"episode_reward": 1769.0109890109918, "episode": 3026.0, "batch_reward": 9.60586166381836, "critic_loss": 1032.314208984375, "actor_loss": -1672.1229248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.692011833190918, "alpha_loss": -0.21119357645511627, "alpha_value": 0.6150131148783017, "duration": 1.568589687347412, "info_normalized_performance_mean": 0.8795684576034546, "info_normalized_performance_final": 0.9940476417541504, "info_performance_mean": 0.8795684576034546, "info_performance_final": 0.9940476417541504, "step": 303000}
{"episode_reward": 1759.1369047619025, "episode": 3031.0, "batch_reward": 10.415277481079102, "critic_loss": 391.376220703125, "actor_loss": -1719.83203125, "actor_target_entropy": -3.0, "actor_entropy": 1.546128511428833, "alpha_loss": -0.2127787470817566, "alpha_value": 0.6177347414345491, "duration": 1.4684243202209473, "info_normalized_performance_mean": 0.35824599862098694, "info_normalized_performance_final": 0.40748661756515503, "info_performance_mean": 0.35824599862098694, "info_performance_final": 0.40748661756515503, "step": 303500}
{"episode_reward": 716.4919786096245, "episode": 3036.0, "batch_reward": 9.522136688232422, "critic_loss": 485.31475830078125, "actor_loss": -1701.6932373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.7676310539245605, "alpha_loss": -0.00777863897383213, "alpha_value": 0.6231980938960187, "duration": 1.5930380821228027, "info_normalized_performance_mean": 0.5258809328079224, "info_normalized_performance_final": 0.5801587104797363, "info_performance_mean": 0.5258809328079224, "info_performance_final": 0.5801587104797363, "step": 304000}
{"episode_reward": 1051.7619047619035, "episode": 3041.0, "batch_reward": 9.201478958129883, "critic_loss": 1858.8807373046875, "actor_loss": -1649.2347412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3003711700439453, "alpha_loss": 0.2635529935359955, "alpha_value": 0.6253911594306472, "duration": 1.651958703994751, "info_normalized_performance_mean": 0.8393794298171997, "info_normalized_performance_final": 0.9430014491081238, "info_performance_mean": 0.8393794298171997, "info_performance_final": 0.9430014491081238, "step": 304500}
{"episode_reward": 1678.7590187590204, "episode": 3046.0, "batch_reward": 9.403593063354492, "critic_loss": 370.36065673828125, "actor_loss": -1696.1669921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6060938835144043, "alpha_loss": -0.08044538646936417, "alpha_value": 0.6267010963161929, "duration": 1.4427015781402588, "info_normalized_performance_mean": 0.6146427392959595, "info_normalized_performance_final": 0.6639610528945923, "info_performance_mean": 0.6146427392959595, "info_performance_final": 0.6639610528945923, "step": 305000}
{"episode_reward": 1229.285714285714, "episode": 3051.0, "batch_reward": 9.260724067687988, "critic_loss": 538.9747314453125, "actor_loss": -1679.490478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.5763715505599976, "alpha_loss": -0.13435329496860504, "alpha_value": 0.6281433738304896, "duration": 1.5299830436706543, "info_normalized_performance_mean": 0.6958438754081726, "info_normalized_performance_final": 0.7747252583503723, "info_performance_mean": 0.6958438754081726, "info_performance_final": 0.7747252583503723, "step": 305500}
{"episode_reward": 1391.6875981161706, "episode": 3056.0, "batch_reward": 9.209003448486328, "critic_loss": 898.170166015625, "actor_loss": -1736.5703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6825401782989502, "alpha_loss": 0.06292077898979187, "alpha_value": 0.627739530377374, "duration": 1.6902430057525635, "info_normalized_performance_mean": 0.4281180202960968, "info_normalized_performance_final": 0.5005165338516235, "info_performance_mean": 0.4281180202960968, "info_performance_final": 0.5005165338516235, "step": 306000}
{"episode_reward": 856.2362258953165, "episode": 3061.0, "batch_reward": 9.14639949798584, "critic_loss": 716.7652587890625, "actor_loss": -1680.518310546875, "actor_target_entropy": -3.0, "actor_entropy": 1.3519219160079956, "alpha_loss": 0.13568194210529327, "alpha_value": 0.6258595683523963, "duration": 1.521249771118164, "info_normalized_performance_mean": 0.39208006858825684, "info_normalized_performance_final": 0.43359375, "info_performance_mean": 0.39208006858825684, "info_performance_final": 0.43359375, "step": 306500}
{"episode_reward": 784.16015625, "episode": 3066.0, "batch_reward": 9.671808242797852, "critic_loss": 521.5877685546875, "actor_loss": -1739.987548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.740947961807251, "alpha_loss": 0.15743571519851685, "alpha_value": 0.6274188323127582, "duration": 1.5884945392608643, "info_normalized_performance_mean": 0.7148998975753784, "info_normalized_performance_final": 0.7969231009483337, "info_performance_mean": 0.7148998975753784, "info_performance_final": 0.7969231009483337, "step": 307000}
{"episode_reward": 1429.799999999999, "episode": 3071.0, "batch_reward": 9.344328880310059, "critic_loss": 720.813232421875, "actor_loss": -1715.630615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.6307865381240845, "alpha_loss": -0.04017813131213188, "alpha_value": 0.6258957576399186, "duration": 1.5275547504425049, "info_normalized_performance_mean": 0.4592141807079315, "info_normalized_performance_final": 0.5260545611381531, "info_performance_mean": 0.4592141807079315, "info_performance_final": 0.5260545611381531, "step": 307500}
{"episode_reward": 918.4284532671637, "episode": 3076.0, "batch_reward": 9.683436393737793, "critic_loss": 608.789794921875, "actor_loss": -1804.7713623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3995271921157837, "alpha_loss": 0.3118114471435547, "alpha_value": 0.6277568065982224, "duration": 1.4915869235992432, "info_normalized_performance_mean": 0.46405228972435, "info_normalized_performance_final": 0.5109890103340149, "info_performance_mean": 0.46405228972435, "info_performance_final": 0.5109890103340149, "step": 308000}
{"episode_reward": 928.1043956043944, "episode": 3081.0, "batch_reward": 9.26354694366455, "critic_loss": 842.723388671875, "actor_loss": -1694.198974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.6527049541473389, "alpha_loss": 0.150741308927536, "alpha_value": 0.6237871597826062, "duration": 1.56711745262146, "info_normalized_performance_mean": 0.4105750024318695, "info_normalized_performance_final": 0.4569999873638153, "info_performance_mean": 0.4105750024318695, "info_performance_final": 0.4569999873638153, "step": 308500}
{"episode_reward": 821.1499999999991, "episode": 3086.0, "batch_reward": 8.93014144897461, "critic_loss": 343.00250244140625, "actor_loss": -1758.316650390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5693434476852417, "alpha_loss": -0.47216206789016724, "alpha_value": 0.6206344810171913, "duration": 1.455425500869751, "info_normalized_performance_mean": 0.5834107398986816, "info_normalized_performance_final": 0.6821428537368774, "info_performance_mean": 0.5834107398986816, "info_performance_final": 0.6821428537368774, "step": 309000}
{"episode_reward": 1166.8214285714278, "episode": 3091.0, "batch_reward": 10.315649032592773, "critic_loss": 962.7770385742188, "actor_loss": -1787.683349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.7524831295013428, "alpha_loss": 0.23669582605361938, "alpha_value": 0.6230003142080901, "duration": 1.4292709827423096, "info_normalized_performance_mean": 0.6744063496589661, "info_normalized_performance_final": 0.7437499761581421, "info_performance_mean": 0.6744063496589661, "info_performance_final": 0.7437499761581421, "step": 309500}
{"episode_reward": 1348.8125, "episode": 3096.0, "batch_reward": 9.358907699584961, "critic_loss": 2671.4052734375, "actor_loss": -1755.589111328125, "actor_target_entropy": -3.0, "actor_entropy": 1.4581280946731567, "alpha_loss": -0.005506172776222229, "alpha_value": 0.6199050794191485, "step": 310000}
{"duration": 18.892115354537964, "info_normalized_performance_mean": 0.7925545573234558, "info_normalized_performance_final": 0.8781818151473999, "info_performance_mean": 0.7925545573234558, "info_performance_final": 0.8781818151473999, "step": 310000}
{"episode_reward": 1585.1090909090874, "episode": 3101.0, "batch_reward": 9.294344902038574, "critic_loss": 758.49951171875, "actor_loss": -1768.436279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3887542486190796, "alpha_loss": -0.15810999274253845, "alpha_value": 0.616233235173425, "duration": 1.5107309818267822, "info_normalized_performance_mean": 0.4692831337451935, "info_normalized_performance_final": 0.5344086289405823, "info_performance_mean": 0.4692831337451935, "info_performance_final": 0.5344086289405823, "step": 310500}
{"episode_reward": 938.5663082437297, "episode": 3106.0, "batch_reward": 9.461976051330566, "critic_loss": 678.516357421875, "actor_loss": -1738.0340576171875, "actor_target_entropy": -3.0, "actor_entropy": 1.7422325611114502, "alpha_loss": 0.16385024785995483, "alpha_value": 0.6155194244307961, "duration": 1.4739885330200195, "info_normalized_performance_mean": 0.5527398586273193, "info_normalized_performance_final": 0.6112244725227356, "info_performance_mean": 0.5527398586273193, "info_performance_final": 0.6112244725227356, "step": 311000}
{"episode_reward": 1105.4795918367324, "episode": 3111.0, "batch_reward": 9.9723482131958, "critic_loss": 657.4156494140625, "actor_loss": -1818.068359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6159205436706543, "alpha_loss": 0.028773240745067596, "alpha_value": 0.6138980375012477, "duration": 1.4627220630645752, "info_normalized_performance_mean": 0.4347165822982788, "info_normalized_performance_final": 0.47278910875320435, "info_performance_mean": 0.4347165822982788, "info_performance_final": 0.47278910875320435, "step": 311500}
{"episode_reward": 869.4331065759644, "episode": 3116.0, "batch_reward": 9.760580062866211, "critic_loss": 263.16998291015625, "actor_loss": -1759.822021484375, "actor_target_entropy": -3.0, "actor_entropy": 1.8585364818572998, "alpha_loss": 0.01825278252363205, "alpha_value": 0.6130279704193788, "duration": 1.573890209197998, "info_normalized_performance_mean": 0.7591111660003662, "info_normalized_performance_final": 0.8470588326454163, "info_performance_mean": 0.7591111660003662, "info_performance_final": 0.8470588326454163, "step": 312000}
{"episode_reward": 1518.2222222222254, "episode": 3121.0, "batch_reward": 9.150527000427246, "critic_loss": 434.97052001953125, "actor_loss": -1760.05859375, "actor_target_entropy": -3.0, "actor_entropy": 1.8888417482376099, "alpha_loss": -0.09960177540779114, "alpha_value": 0.6152973772031347, "duration": 1.5537269115447998, "info_normalized_performance_mean": 0.3800167143344879, "info_normalized_performance_final": 0.4256885051727295, "info_performance_mean": 0.3800167143344879, "info_performance_final": 0.4256885051727295, "step": 312500}
{"episode_reward": 760.0332383665709, "episode": 3126.0, "batch_reward": 10.459571838378906, "critic_loss": 5137.48291015625, "actor_loss": -1881.9993896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.6097731590270996, "alpha_loss": -0.281838983297348, "alpha_value": 0.6148647032012178, "duration": 1.5195293426513672, "info_normalized_performance_mean": 0.4968891441822052, "info_normalized_performance_final": 0.5426136255264282, "info_performance_mean": 0.4968891441822052, "info_performance_final": 0.5426136255264282, "step": 313000}
{"episode_reward": 993.7784090909104, "episode": 3131.0, "batch_reward": 9.362634658813477, "critic_loss": 585.7529907226562, "actor_loss": -1801.571044921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6931633949279785, "alpha_loss": -0.050749119371175766, "alpha_value": 0.6137387257942262, "duration": 1.4488143920898438, "info_normalized_performance_mean": 0.39696988463401794, "info_normalized_performance_final": 0.4369419515132904, "info_performance_mean": 0.39696988463401794, "info_performance_final": 0.4369419515132904, "step": 313500}
{"episode_reward": 793.9397321428585, "episode": 3136.0, "batch_reward": 9.665105819702148, "critic_loss": 1178.6947021484375, "actor_loss": -1835.820556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.7329514026641846, "alpha_loss": -0.16269411146640778, "alpha_value": 0.6045293618673431, "duration": 1.5074501037597656, "info_normalized_performance_mean": 0.1248677670955658, "info_normalized_performance_final": 0.13341346383094788, "info_performance_mean": 0.1248677670955658, "info_performance_final": 0.13341346383094788, "step": 314000}
{"episode_reward": 249.73557692307665, "episode": 3141.0, "batch_reward": 9.20387077331543, "critic_loss": 558.7427978515625, "actor_loss": -1794.90478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.388434886932373, "alpha_loss": -0.006305348128080368, "alpha_value": 0.596527826853702, "duration": 1.5125606060028076, "info_normalized_performance_mean": 0.7010564208030701, "info_normalized_performance_final": 0.7633928656578064, "info_performance_mean": 0.7010564208030701, "info_performance_final": 0.7633928656578064, "step": 314500}
{"episode_reward": 1402.1130952380938, "episode": 3146.0, "batch_reward": 9.541069030761719, "critic_loss": 612.7200317382812, "actor_loss": -1850.5704345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6526683568954468, "alpha_loss": -0.020984958857297897, "alpha_value": 0.5900215040008662, "duration": 1.5201318264007568, "info_normalized_performance_mean": 0.525204062461853, "info_normalized_performance_final": 0.595083475112915, "info_performance_mean": 0.525204062461853, "info_performance_final": 0.595083475112915, "step": 315000}
{"episode_reward": 1050.4081632653076, "episode": 3151.0, "batch_reward": 9.521484375, "critic_loss": 836.0274658203125, "actor_loss": -1831.66748046875, "actor_target_entropy": -3.0, "actor_entropy": 1.6552478075027466, "alpha_loss": -0.1822090446949005, "alpha_value": 0.5876808667729664, "duration": 1.4943079948425293, "info_normalized_performance_mean": 0.39235249161720276, "info_normalized_performance_final": 0.4372759759426117, "info_performance_mean": 0.39235249161720276, "info_performance_final": 0.4372759759426117, "step": 315500}
{"episode_reward": 784.7051156728571, "episode": 3156.0, "batch_reward": 9.388481140136719, "critic_loss": 860.3096923828125, "actor_loss": -1818.6571044921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4202601909637451, "alpha_loss": -0.3265456557273865, "alpha_value": 0.5865539128590089, "duration": 1.4453344345092773, "info_normalized_performance_mean": 0.41010990738868713, "info_normalized_performance_final": 0.45009157061576843, "info_performance_mean": 0.41010990738868713, "info_performance_final": 0.45009157061576843, "step": 316000}
{"episode_reward": 820.2197802197786, "episode": 3161.0, "batch_reward": 9.759444236755371, "critic_loss": 602.844482421875, "actor_loss": -1833.4183349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.8506500720977783, "alpha_loss": -0.01438351720571518, "alpha_value": 0.5871055299435096, "duration": 1.4558489322662354, "info_normalized_performance_mean": 0.23501627147197723, "info_normalized_performance_final": 0.25811687111854553, "info_performance_mean": 0.23501627147197723, "info_performance_final": 0.25811687111854553, "step": 316500}
{"episode_reward": 470.0324675324685, "episode": 3166.0, "batch_reward": 10.136601448059082, "critic_loss": 1574.104248046875, "actor_loss": -1841.781982421875, "actor_target_entropy": -3.0, "actor_entropy": 1.8223521709442139, "alpha_loss": -0.28521621227264404, "alpha_value": 0.5859349679194682, "duration": 1.523418664932251, "info_normalized_performance_mean": 0.4476202428340912, "info_normalized_performance_final": 0.4955357015132904, "info_performance_mean": 0.4476202428340912, "info_performance_final": 0.4955357015132904, "step": 317000}
{"episode_reward": 895.2403846153862, "episode": 3171.0, "batch_reward": 8.650701522827148, "critic_loss": 720.90966796875, "actor_loss": -1783.099853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.394073486328125, "alpha_loss": 0.15341567993164062, "alpha_value": 0.5872551422013957, "duration": 1.4957215785980225, "info_normalized_performance_mean": 0.4431421160697937, "info_normalized_performance_final": 0.5020604133605957, "info_performance_mean": 0.4431421160697937, "info_performance_final": 0.5020604133605957, "step": 317500}
{"episode_reward": 886.28434065934, "episode": 3176.0, "batch_reward": 9.789739608764648, "critic_loss": 520.683837890625, "actor_loss": -1827.45166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.647559642791748, "alpha_loss": 0.09129148721694946, "alpha_value": 0.5848665033897735, "duration": 1.5724010467529297, "info_normalized_performance_mean": 0.8444851636886597, "info_normalized_performance_final": 0.9632353186607361, "info_performance_mean": 0.8444851636886597, "info_performance_final": 0.9632353186607361, "step": 318000}
{"episode_reward": 1688.9705882352932, "episode": 3181.0, "batch_reward": 9.952290534973145, "critic_loss": 486.6541748046875, "actor_loss": -1839.92041015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5661081075668335, "alpha_loss": 0.060059040784835815, "alpha_value": 0.5747931766900308, "duration": 1.5347387790679932, "info_normalized_performance_mean": 0.5514594912528992, "info_normalized_performance_final": 0.6061126589775085, "info_performance_mean": 0.5514594912528992, "info_performance_final": 0.6061126589775085, "step": 318500}
{"episode_reward": 1102.9189560439577, "episode": 3186.0, "batch_reward": 10.317481994628906, "critic_loss": 513.2169189453125, "actor_loss": -1886.4853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.4600954055786133, "alpha_loss": -0.04083564877510071, "alpha_value": 0.5678779434591819, "duration": 1.7032394409179688, "info_normalized_performance_mean": 0.24516181647777557, "info_normalized_performance_final": 0.2944139242172241, "info_performance_mean": 0.24516181647777557, "info_performance_final": 0.2944139242172241, "step": 319000}
{"episode_reward": 490.32356532356533, "episode": 3191.0, "batch_reward": 9.351920127868652, "critic_loss": 785.5503540039062, "actor_loss": -1838.19091796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3141077756881714, "alpha_loss": 0.09663980454206467, "alpha_value": 0.563725851479723, "duration": 1.5263056755065918, "info_normalized_performance_mean": 0.8423884510993958, "info_normalized_performance_final": 0.9285714030265808, "info_performance_mean": 0.8423884510993958, "info_performance_final": 0.9285714030265808, "step": 319500}
{"episode_reward": 1684.7767857142887, "episode": 3196.0, "batch_reward": 9.420217514038086, "critic_loss": 3602.78173828125, "actor_loss": -1860.5234375, "actor_target_entropy": -3.0, "actor_entropy": 1.663040280342102, "alpha_loss": 0.10997705161571503, "alpha_value": 0.5541227363296379, "step": 320000}
{"duration": 18.547163724899292, "info_normalized_performance_mean": 0.4384693205356598, "info_normalized_performance_final": 0.4761904776096344, "info_performance_mean": 0.4384693205356598, "info_performance_final": 0.4761904776096344, "step": 320000}
{"episode_reward": 876.9387755102036, "episode": 3201.0, "batch_reward": 9.604353904724121, "critic_loss": 559.7975463867188, "actor_loss": -1831.389404296875, "actor_target_entropy": -3.0, "actor_entropy": 1.4889315366744995, "alpha_loss": 0.10257110744714737, "alpha_value": 0.5412090080233486, "duration": 1.5713801383972168, "info_normalized_performance_mean": 0.23845237493515015, "info_normalized_performance_final": 0.26812660694122314, "info_performance_mean": 0.23845237493515015, "info_performance_final": 0.26812660694122314, "step": 320500}
{"episode_reward": 476.9046742730962, "episode": 3206.0, "batch_reward": 10.043510437011719, "critic_loss": 548.2071533203125, "actor_loss": -1867.59228515625, "actor_target_entropy": -3.0, "actor_entropy": 1.3625874519348145, "alpha_loss": 0.05860833078622818, "alpha_value": 0.5341018019012547, "duration": 1.454270839691162, "info_normalized_performance_mean": 0.35448411107063293, "info_normalized_performance_final": 0.3898809552192688, "info_performance_mean": 0.35448411107063293, "info_performance_final": 0.3898809552192688, "step": 321000}
{"episode_reward": 708.9682539682533, "episode": 3211.0, "batch_reward": 9.922722816467285, "critic_loss": 2305.84521484375, "actor_loss": -1808.319580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.3551347255706787, "alpha_loss": 0.15717127919197083, "alpha_value": 0.5282690814604246, "duration": 1.555110216140747, "info_normalized_performance_mean": 0.515576183795929, "info_normalized_performance_final": 0.572265625, "info_performance_mean": 0.515576183795929, "info_performance_final": 0.572265625, "step": 321500}
{"episode_reward": 1031.15234375, "episode": 3216.0, "batch_reward": 9.696237564086914, "critic_loss": 558.4150390625, "actor_loss": -1845.95166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1427702903747559, "alpha_loss": 0.04712250083684921, "alpha_value": 0.5236420377657288, "duration": 1.4907152652740479, "info_normalized_performance_mean": 0.5482058525085449, "info_normalized_performance_final": 0.6117647290229797, "info_performance_mean": 0.5482058525085449, "info_performance_final": 0.6117647290229797, "step": 322000}
{"episode_reward": 1096.4117647058831, "episode": 3221.0, "batch_reward": 9.058710098266602, "critic_loss": 642.630615234375, "actor_loss": -1793.266845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.5221285820007324, "alpha_loss": -0.20636379718780518, "alpha_value": 0.5178895188496081, "duration": 1.5667705535888672, "info_normalized_performance_mean": 0.8650649189949036, "info_normalized_performance_final": 0.9691558480262756, "info_performance_mean": 0.8650649189949036, "info_performance_final": 0.9691558480262756, "step": 322500}
{"episode_reward": 1730.1298701298667, "episode": 3226.0, "batch_reward": 9.152009963989258, "critic_loss": 641.5264892578125, "actor_loss": -1828.46630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.6064647436141968, "alpha_loss": 0.05167880654335022, "alpha_value": 0.5106874186668414, "duration": 1.4077942371368408, "info_normalized_performance_mean": 0.8937053084373474, "info_normalized_performance_final": 0.96875, "info_performance_mean": 0.8937053084373474, "info_performance_final": 0.96875, "step": 323000}
{"episode_reward": 1787.4107142857144, "episode": 3231.0, "batch_reward": 8.993728637695312, "critic_loss": 923.1337890625, "actor_loss": -1809.1839599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.5024985074996948, "alpha_loss": -0.05535966157913208, "alpha_value": 0.5048580990351783, "duration": 1.5162043571472168, "info_normalized_performance_mean": 0.5343853235244751, "info_normalized_performance_final": 0.5968406796455383, "info_performance_mean": 0.5343853235244751, "info_performance_final": 0.5968406796455383, "step": 323500}
{"episode_reward": 1068.770604395605, "episode": 3236.0, "batch_reward": 9.840774536132812, "critic_loss": 459.75408935546875, "actor_loss": -1864.256591796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5523496866226196, "alpha_loss": 0.10015163570642471, "alpha_value": 0.49826492492409696, "duration": 1.476621150970459, "info_normalized_performance_mean": 0.8416319489479065, "info_normalized_performance_final": 0.9421296119689941, "info_performance_mean": 0.8416319489479065, "info_performance_final": 0.9421296119689941, "step": 324000}
{"episode_reward": 1683.26388888889, "episode": 3241.0, "batch_reward": 9.669510841369629, "critic_loss": 4909.72900390625, "actor_loss": -1791.7548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3047267198562622, "alpha_loss": 0.1363944262266159, "alpha_value": 0.49486612316366985, "duration": 1.4053454399108887, "info_normalized_performance_mean": 0.3269345760345459, "info_normalized_performance_final": 0.3571428656578064, "info_performance_mean": 0.3269345760345459, "info_performance_final": 0.3571428656578064, "step": 324500}
{"episode_reward": 653.8690476190478, "episode": 3246.0, "batch_reward": 10.222784042358398, "critic_loss": 237.34242248535156, "actor_loss": -1849.6229248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.7429391145706177, "alpha_loss": 0.1469946652650833, "alpha_value": 0.49441645721363264, "duration": 1.6835217475891113, "info_normalized_performance_mean": 0.366424024105072, "info_normalized_performance_final": 0.41830897331237793, "info_performance_mean": 0.366424024105072, "info_performance_final": 0.41830897331237793, "step": 325000}
{"episode_reward": 732.8480610298776, "episode": 3251.0, "batch_reward": 9.412161827087402, "critic_loss": 527.9427490234375, "actor_loss": -1818.1700439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.6907374858856201, "alpha_loss": 0.41913849115371704, "alpha_value": 0.48650824931713266, "duration": 1.523061990737915, "info_normalized_performance_mean": 0.6731074452400208, "info_normalized_performance_final": 0.7482638955116272, "info_performance_mean": 0.6731074452400208, "info_performance_final": 0.7482638955116272, "step": 325500}
{"episode_reward": 1346.2152777777803, "episode": 3256.0, "batch_reward": 8.771784782409668, "critic_loss": 577.3023071289062, "actor_loss": -1807.309326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.181549310684204, "alpha_loss": -0.08616098761558533, "alpha_value": 0.4802502448652519, "duration": 1.6229732036590576, "info_normalized_performance_mean": 0.31060898303985596, "info_normalized_performance_final": 0.36646369099617004, "info_performance_mean": 0.31060898303985596, "info_performance_final": 0.36646369099617004, "step": 326000}
{"episode_reward": 621.2179208351464, "episode": 3261.0, "batch_reward": 9.65989875793457, "critic_loss": 478.6747131347656, "actor_loss": -1824.9637451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2498843669891357, "alpha_loss": 0.3172146677970886, "alpha_value": 0.47281016199476267, "duration": 1.436065435409546, "info_normalized_performance_mean": 0.7053214311599731, "info_normalized_performance_final": 0.7571428418159485, "info_performance_mean": 0.7053214311599731, "info_performance_final": 0.7571428418159485, "step": 326500}
{"episode_reward": 1410.6428571428555, "episode": 3266.0, "batch_reward": 9.451066017150879, "critic_loss": 415.974853515625, "actor_loss": -1778.6614990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.661442756652832, "alpha_loss": 0.18229106068611145, "alpha_value": 0.46901278653897827, "duration": 1.4663150310516357, "info_normalized_performance_mean": 0.4259326159954071, "info_normalized_performance_final": 0.4775390625, "info_performance_mean": 0.4259326159954071, "info_performance_final": 0.4775390625, "step": 327000}
{"episode_reward": 851.865234375, "episode": 3271.0, "batch_reward": 9.376989364624023, "critic_loss": 585.46923828125, "actor_loss": -1789.816162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.6967718601226807, "alpha_loss": 0.17731547355651855, "alpha_value": 0.4666022761404894, "duration": 1.6714131832122803, "info_normalized_performance_mean": 0.30235040187835693, "info_normalized_performance_final": 0.34661170840263367, "info_performance_mean": 0.30235040187835693, "info_performance_final": 0.34661170840263367, "step": 327500}
{"episode_reward": 604.7008547008548, "episode": 3276.0, "batch_reward": 9.757972717285156, "critic_loss": 1093.67626953125, "actor_loss": -1796.867919921875, "actor_target_entropy": -3.0, "actor_entropy": 1.2271108627319336, "alpha_loss": -0.10380540788173676, "alpha_value": 0.46560575312200786, "duration": 1.4812688827514648, "info_normalized_performance_mean": 0.31907713413238525, "info_normalized_performance_final": 0.35107421875, "info_performance_mean": 0.31907713413238525, "info_performance_final": 0.35107421875, "step": 328000}
{"episode_reward": 638.154296875, "episode": 3281.0, "batch_reward": 9.675758361816406, "critic_loss": 1019.462158203125, "actor_loss": -1800.1358642578125, "actor_target_entropy": -3.0, "actor_entropy": 1.0983995199203491, "alpha_loss": -0.09570179879665375, "alpha_value": 0.47436987897961813, "duration": 1.596144199371338, "info_normalized_performance_mean": 0.5352381467819214, "info_normalized_performance_final": 0.5896825194358826, "info_performance_mean": 0.5352381467819214, "info_performance_final": 0.5896825194358826, "step": 328500}
{"episode_reward": 1070.4761904761924, "episode": 3286.0, "batch_reward": 9.507413864135742, "critic_loss": 651.7230224609375, "actor_loss": -1825.8118896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.5295257568359375, "alpha_loss": -0.6981716156005859, "alpha_value": 0.49084057592692093, "duration": 1.5920779705047607, "info_normalized_performance_mean": 0.5173289179801941, "info_normalized_performance_final": 0.5617559552192688, "info_performance_mean": 0.5173289179801941, "info_performance_final": 0.5617559552192688, "step": 329000}
{"episode_reward": 1034.6577380952374, "episode": 3291.0, "batch_reward": 10.252490997314453, "critic_loss": 669.0465087890625, "actor_loss": -1876.0797119140625, "actor_target_entropy": -3.0, "actor_entropy": 1.5544862747192383, "alpha_loss": -0.6105014085769653, "alpha_value": 0.5090515630711466, "duration": 1.6296827793121338, "info_normalized_performance_mean": 0.14814049005508423, "info_normalized_performance_final": 0.19312745332717896, "info_performance_mean": 0.14814049005508423, "info_performance_final": 0.19312745332717896, "step": 329500}
{"episode_reward": 296.2809917355372, "episode": 3296.0, "batch_reward": 9.436826705932617, "critic_loss": 679.8402099609375, "actor_loss": -1842.302978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.35686457157135, "alpha_loss": -0.44558510184288025, "alpha_value": 0.5253087498463227, "step": 330000}
{"duration": 18.374675989151, "info_normalized_performance_mean": 0.2541246712207794, "info_normalized_performance_final": 0.28311687707901, "info_performance_mean": 0.2541246712207794, "info_performance_final": 0.28311687707901, "step": 330000}
{"episode_reward": 508.249350649351, "episode": 3301.0, "batch_reward": 9.247764587402344, "critic_loss": 1480.4149169921875, "actor_loss": -1868.192138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.8653676509857178, "alpha_loss": -0.41277414560317993, "alpha_value": 0.5413700195957898, "duration": 1.4516608715057373, "info_normalized_performance_mean": 0.5387783050537109, "info_normalized_performance_final": 0.5752840638160706, "info_performance_mean": 0.5387783050537109, "info_performance_final": 0.5752840638160706, "step": 330500}
{"episode_reward": 1077.55681818182, "episode": 3306.0, "batch_reward": 10.142998695373535, "critic_loss": 909.9693603515625, "actor_loss": -1929.3076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.7830262184143066, "alpha_loss": -0.3162271976470947, "alpha_value": 0.5565492028892151, "duration": 1.5399296283721924, "info_normalized_performance_mean": 0.34299418330192566, "info_normalized_performance_final": 0.36940836906433105, "info_performance_mean": 0.34299418330192566, "info_performance_final": 0.36940836906433105, "step": 331000}
{"episode_reward": 685.9884559884566, "episode": 3311.0, "batch_reward": 9.588447570800781, "critic_loss": 1148.9915771484375, "actor_loss": -1934.6246337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.7290730476379395, "alpha_loss": -0.3686935603618622, "alpha_value": 0.5740736444593006, "duration": 1.5948255062103271, "info_normalized_performance_mean": 0.7846328020095825, "info_normalized_performance_final": 0.8521825671195984, "info_performance_mean": 0.7846328020095825, "info_performance_final": 0.8521825671195984, "step": 331500}
{"episode_reward": 1569.2658730158757, "episode": 3316.0, "batch_reward": 9.527328491210938, "critic_loss": 2259.0849609375, "actor_loss": -1993.19921875, "actor_target_entropy": -3.0, "actor_entropy": 1.7275059223175049, "alpha_loss": -0.9722467660903931, "alpha_value": 0.5914765782628694, "duration": 1.5422799587249756, "info_normalized_performance_mean": 0.23289866745471954, "info_normalized_performance_final": 0.25792208313941956, "info_performance_mean": 0.23289866745471954, "info_performance_final": 0.25792208313941956, "step": 332000}
{"episode_reward": 465.7974025974022, "episode": 3321.0, "batch_reward": 10.04536247253418, "critic_loss": 708.515625, "actor_loss": -2008.138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.605506420135498, "alpha_loss": -0.18402551114559174, "alpha_value": 0.6103369822014895, "duration": 1.579343318939209, "info_normalized_performance_mean": 0.5283035039901733, "info_normalized_performance_final": 0.5694444179534912, "info_performance_mean": 0.5283035039901733, "info_performance_final": 0.5694444179534912, "step": 332500}
{"episode_reward": 1056.6071428571445, "episode": 3326.0, "batch_reward": 9.39651107788086, "critic_loss": 576.4835815429688, "actor_loss": -2038.968017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7569022178649902, "alpha_loss": -0.7012323141098022, "alpha_value": 0.6267479532178629, "duration": 1.685896635055542, "info_normalized_performance_mean": 0.19006946682929993, "info_normalized_performance_final": 0.2083333283662796, "info_performance_mean": 0.19006946682929993, "info_performance_final": 0.2083333283662796, "step": 333000}
{"episode_reward": 380.1388888888892, "episode": 3331.0, "batch_reward": 9.447153091430664, "critic_loss": 3485.48828125, "actor_loss": -2021.8231201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.732445478439331, "alpha_loss": -0.17641380429267883, "alpha_value": 0.6398373129465852, "duration": 1.4705910682678223, "info_normalized_performance_mean": 0.2688801884651184, "info_normalized_performance_final": 0.2886284589767456, "info_performance_mean": 0.2688801884651184, "info_performance_final": 0.2886284589767456, "step": 333500}
{"episode_reward": 537.7604166666675, "episode": 3336.0, "batch_reward": 9.731010437011719, "critic_loss": 1297.351318359375, "actor_loss": -2023.57080078125, "actor_target_entropy": -3.0, "actor_entropy": 1.6224805116653442, "alpha_loss": -0.43333327770233154, "alpha_value": 0.64751152249532, "duration": 1.4227335453033447, "info_normalized_performance_mean": 0.4969792068004608, "info_normalized_performance_final": 0.5338541865348816, "info_performance_mean": 0.4969792068004608, "info_performance_final": 0.5338541865348816, "step": 334000}
{"episode_reward": 993.9583333333347, "episode": 3341.0, "batch_reward": 9.48361587524414, "critic_loss": 3820.626220703125, "actor_loss": -1995.508056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.4742308855056763, "alpha_loss": -0.011471718549728394, "alpha_value": 0.6505442016523683, "duration": 1.5109460353851318, "info_normalized_performance_mean": 0.335666298866272, "info_normalized_performance_final": 0.3677884638309479, "info_performance_mean": 0.335666298866272, "info_performance_final": 0.3677884638309479, "step": 334500}
{"episode_reward": 671.3324175824184, "episode": 3346.0, "batch_reward": 10.130784034729004, "critic_loss": 617.166015625, "actor_loss": -2065.0693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6567680835723877, "alpha_loss": 0.09716153889894485, "alpha_value": 0.6541277676957652, "duration": 1.4354403018951416, "info_normalized_performance_mean": 0.3531292974948883, "info_normalized_performance_final": 0.38321995735168457, "info_performance_mean": 0.3531292974948883, "info_performance_final": 0.38321995735168457, "step": 335000}
{"episode_reward": 706.2585034013601, "episode": 3351.0, "batch_reward": 9.054525375366211, "critic_loss": 882.09423828125, "actor_loss": -2024.36279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.414689064025879, "alpha_loss": -0.10848809778690338, "alpha_value": 0.6536834270287992, "duration": 1.70170259475708, "info_normalized_performance_mean": 0.20171207189559937, "info_normalized_performance_final": 0.2215544879436493, "info_performance_mean": 0.20171207189559937, "info_performance_final": 0.2215544879436493, "step": 335500}
{"episode_reward": 403.42414529914475, "episode": 3356.0, "batch_reward": 9.158712387084961, "critic_loss": 970.7021484375, "actor_loss": -2001.0911865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.7999374866485596, "alpha_loss": 0.2589908540248871, "alpha_value": 0.6480250905924462, "duration": 1.4690711498260498, "info_normalized_performance_mean": 0.29864007234573364, "info_normalized_performance_final": 0.3282966911792755, "info_performance_mean": 0.29864007234573364, "info_performance_final": 0.3282966911792755, "step": 336000}
{"episode_reward": 597.2802197802196, "episode": 3361.0, "batch_reward": 9.463345527648926, "critic_loss": 1436.166015625, "actor_loss": -2040.4412841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.6536896228790283, "alpha_loss": 0.3171416223049164, "alpha_value": 0.6390346779055784, "duration": 1.506765604019165, "info_normalized_performance_mean": 0.13332858681678772, "info_normalized_performance_final": 0.14506173133850098, "info_performance_mean": 0.13332858681678772, "info_performance_final": 0.14506173133850098, "step": 336500}
{"episode_reward": 266.6571699905037, "episode": 3366.0, "batch_reward": 10.281669616699219, "critic_loss": 858.2332763671875, "actor_loss": -2019.722412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2648391723632812, "alpha_loss": 0.4164620637893677, "alpha_value": 0.6273080522624433, "duration": 1.6558032035827637, "info_normalized_performance_mean": 0.3933095932006836, "info_normalized_performance_final": 0.4351923167705536, "info_performance_mean": 0.3933095932006836, "info_performance_final": 0.4351923167705536, "step": 337000}
{"episode_reward": 786.6192307692301, "episode": 3371.0, "batch_reward": 8.848142623901367, "critic_loss": 1072.1854248046875, "actor_loss": -2035.559326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5829620361328125, "alpha_loss": 0.014743704348802567, "alpha_value": 0.6157233821163977, "duration": 1.80808687210083, "info_normalized_performance_mean": 0.21303483843803406, "info_normalized_performance_final": 0.23839326202869415, "info_performance_mean": 0.21303483843803406, "info_performance_final": 0.23839326202869415, "step": 337500}
{"episode_reward": 426.0696404187534, "episode": 3376.0, "batch_reward": 9.572287559509277, "critic_loss": 1106.840087890625, "actor_loss": -2027.0679931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.3878180980682373, "alpha_loss": 0.28750982880592346, "alpha_value": 0.6067264352429453, "duration": 1.51198410987854, "info_normalized_performance_mean": 0.2603883445262909, "info_normalized_performance_final": 0.2847222089767456, "info_performance_mean": 0.2603883445262909, "info_performance_final": 0.2847222089767456, "step": 338000}
{"episode_reward": 520.7767489711943, "episode": 3381.0, "batch_reward": 9.642498016357422, "critic_loss": 562.3223876953125, "actor_loss": -1974.4390869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.472717046737671, "alpha_loss": 0.2799361050128937, "alpha_value": 0.5961964590040184, "duration": 1.8189167976379395, "info_normalized_performance_mean": 0.3192262649536133, "info_normalized_performance_final": 0.38404643535614014, "info_performance_mean": 0.3192262649536133, "info_performance_final": 0.38404643535614014, "step": 338500}
{"episode_reward": 638.4524351388266, "episode": 3386.0, "batch_reward": 9.321157455444336, "critic_loss": 743.8316040039062, "actor_loss": -1949.794189453125, "actor_target_entropy": -3.0, "actor_entropy": 1.7252904176712036, "alpha_loss": 0.3356485962867737, "alpha_value": 0.5887474114981196, "duration": 1.431307077407837, "info_normalized_performance_mean": 0.30780044198036194, "info_normalized_performance_final": 0.34297052025794983, "info_performance_mean": 0.30780044198036194, "info_performance_final": 0.34297052025794983, "step": 339000}
{"episode_reward": 615.6009070294781, "episode": 3391.0, "batch_reward": 9.28586196899414, "critic_loss": 746.201416015625, "actor_loss": -1969.0670166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5172412395477295, "alpha_loss": -0.20989249646663666, "alpha_value": 0.582070804718251, "duration": 1.583040475845337, "info_normalized_performance_mean": 0.3698340654373169, "info_normalized_performance_final": 0.4054833948612213, "info_performance_mean": 0.3698340654373169, "info_performance_final": 0.4054833948612213, "step": 339500}
{"episode_reward": 739.6681096681089, "episode": 3396.0, "batch_reward": 9.169855117797852, "critic_loss": 792.4783935546875, "actor_loss": -2035.9853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1515226364135742, "alpha_loss": -0.06680291146039963, "alpha_value": 0.5765526679689801, "step": 340000}
{"duration": 18.46143889427185, "info_normalized_performance_mean": 0.20510753989219666, "info_normalized_performance_final": 0.22474999725818634, "info_performance_mean": 0.20510753989219666, "info_performance_final": 0.22474999725818634, "step": 340000}
{"episode_reward": 410.2150000000003, "episode": 3401.0, "batch_reward": 9.517644882202148, "critic_loss": 497.5097351074219, "actor_loss": -1977.861572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.66275155544281, "alpha_loss": 0.16229958832263947, "alpha_value": 0.5691375191455539, "duration": 1.4139370918273926, "info_normalized_performance_mean": 0.15415063500404358, "info_normalized_performance_final": 0.16613247990608215, "info_performance_mean": 0.15415063500404358, "info_performance_final": 0.16613247990608215, "step": 340500}
{"episode_reward": 308.3012820512821, "episode": 3406.0, "batch_reward": 8.530440330505371, "critic_loss": 634.4627685546875, "actor_loss": -1935.6484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4292817115783691, "alpha_loss": 0.050766926258802414, "alpha_value": 0.5627847166927235, "duration": 1.4617564678192139, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 341000}
{"episode_reward": 0.0, "episode": 3411.0, "batch_reward": 9.681839942932129, "critic_loss": 942.5370483398438, "actor_loss": -1949.697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2434087991714478, "alpha_loss": 0.22860446572303772, "alpha_value": 0.5553874875835879, "duration": 1.7265870571136475, "info_normalized_performance_mean": 0.21130859851837158, "info_normalized_performance_final": 0.23384159803390503, "info_performance_mean": 0.21130859851837158, "info_performance_final": 0.23384159803390503, "step": 341500}
{"episode_reward": 422.61720527992645, "episode": 3416.0, "batch_reward": 9.658015251159668, "critic_loss": 552.3829345703125, "actor_loss": -1978.4495849609375, "actor_target_entropy": -3.0, "actor_entropy": 1.473559021949768, "alpha_loss": 0.11801999062299728, "alpha_value": 0.5506635800994191, "duration": 1.597001552581787, "info_normalized_performance_mean": 0.7458724975585938, "info_normalized_performance_final": 0.822549045085907, "info_performance_mean": 0.7458724975585938, "info_performance_final": 0.822549045085907, "step": 342000}
{"episode_reward": 1491.745098039218, "episode": 3421.0, "batch_reward": 10.0097074508667, "critic_loss": 977.30419921875, "actor_loss": -1967.5546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4728803634643555, "alpha_loss": 0.3120458722114563, "alpha_value": 0.5410230438685227, "duration": 1.4825000762939453, "info_normalized_performance_mean": 0.0008235294371843338, "info_normalized_performance_final": 0.0009049773798324168, "info_performance_mean": 0.0008235294371843338, "info_performance_final": 0.0009049773798324168, "step": 342500}
{"episode_reward": 1.6470588235294106, "episode": 3426.0, "batch_reward": 9.757320404052734, "critic_loss": 802.6959228515625, "actor_loss": -2004.7041015625, "actor_target_entropy": -3.0, "actor_entropy": 1.2001338005065918, "alpha_loss": -0.2007826268672943, "alpha_value": 0.5358685963278905, "duration": 1.4747440814971924, "info_normalized_performance_mean": 0.35027235746383667, "info_normalized_performance_final": 0.38928571343421936, "info_performance_mean": 0.35027235746383667, "info_performance_final": 0.38928571343421936, "step": 343000}
{"episode_reward": 700.5446428571437, "episode": 3431.0, "batch_reward": 9.458414077758789, "critic_loss": 571.3717041015625, "actor_loss": -2000.1658935546875, "actor_target_entropy": -3.0, "actor_entropy": 1.298763394355774, "alpha_loss": -0.10155971348285675, "alpha_value": 0.5300224839253505, "duration": 1.5406858921051025, "info_normalized_performance_mean": 0.46869999170303345, "info_normalized_performance_final": 0.5429999828338623, "info_performance_mean": 0.46869999170303345, "info_performance_final": 0.5429999828338623, "step": 343500}
{"episode_reward": 937.400000000001, "episode": 3436.0, "batch_reward": 8.478689193725586, "critic_loss": 577.3980712890625, "actor_loss": -1899.5433349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3380061388015747, "alpha_loss": -0.21670056879520416, "alpha_value": 0.527257497719579, "duration": 1.4958312511444092, "info_normalized_performance_mean": 0.28495192527770996, "info_normalized_performance_final": 0.31640625, "info_performance_mean": 0.28495192527770996, "info_performance_final": 0.31640625, "step": 344000}
{"episode_reward": 569.9038461538462, "episode": 3441.0, "batch_reward": 9.687557220458984, "critic_loss": 1121.9114990234375, "actor_loss": -1914.6885986328125, "actor_target_entropy": -3.0, "actor_entropy": 1.5637075901031494, "alpha_loss": -0.10639777779579163, "alpha_value": 0.5250564361329765, "duration": 1.4782276153564453, "info_normalized_performance_mean": 0.09771162271499634, "info_normalized_performance_final": 0.10978835821151733, "info_performance_mean": 0.09771162271499634, "info_performance_final": 0.10978835821151733, "step": 344500}
{"episode_reward": 195.42328042328003, "episode": 3446.0, "batch_reward": 9.881818771362305, "critic_loss": 1531.4473876953125, "actor_loss": -1925.0067138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.4885730743408203, "alpha_loss": 0.5689021348953247, "alpha_value": 0.5260856758498325, "duration": 1.479849100112915, "info_normalized_performance_mean": 0.516946017742157, "info_normalized_performance_final": 0.609375, "info_performance_mean": 0.516946017742157, "info_performance_final": 0.609375, "step": 345000}
{"episode_reward": 1033.8920454545455, "episode": 3451.0, "batch_reward": 10.072324752807617, "critic_loss": 732.27783203125, "actor_loss": -1956.3935546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4619619846343994, "alpha_loss": -0.0020611658692359924, "alpha_value": 0.52641186504822, "duration": 1.396186113357544, "info_normalized_performance_mean": 0.05485919862985611, "info_normalized_performance_final": 0.061469778418540955, "info_performance_mean": 0.05485919862985611, "info_performance_final": 0.061469778418540955, "step": 345500}
{"episode_reward": 109.7184065934067, "episode": 3456.0, "batch_reward": 9.111072540283203, "critic_loss": 2345.1943359375, "actor_loss": -1888.3812255859375, "actor_target_entropy": -3.0, "actor_entropy": 1.3784093856811523, "alpha_loss": -0.13252714276313782, "alpha_value": 0.5300746185474424, "duration": 1.4692981243133545, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 346000}
{"episode_reward": 0.0, "episode": 3461.0, "batch_reward": 9.522852897644043, "critic_loss": 1141.9124755859375, "actor_loss": -1909.9560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.3916916847229004, "alpha_loss": 0.28259557485580444, "alpha_value": 0.5323060895290266, "duration": 1.491332769393921, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 346500}
{"episode_reward": 0.0, "episode": 3466.0, "batch_reward": 9.08360481262207, "critic_loss": 818.035400390625, "actor_loss": -1917.8521728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.5175058841705322, "alpha_loss": 0.09512466192245483, "alpha_value": 0.5311641150840406, "duration": 1.480811595916748, "info_normalized_performance_mean": 5.000000328436727e-06, "info_normalized_performance_final": 0.0, "info_performance_mean": 5.000000328436727e-06, "info_performance_final": 0.0, "step": 347000}
{"episode_reward": 0.01, "episode": 3471.0, "batch_reward": 9.046224594116211, "critic_loss": 680.547119140625, "actor_loss": -1898.40087890625, "actor_target_entropy": -3.0, "actor_entropy": 1.215550184249878, "alpha_loss": 0.227406308054924, "alpha_value": 0.5314027253209141, "duration": 1.4631493091583252, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 347500}
{"episode_reward": 0.0, "episode": 3476.0, "batch_reward": 9.042450904846191, "critic_loss": 684.8602294921875, "actor_loss": -1897.4970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.4322452545166016, "alpha_loss": 0.0874878317117691, "alpha_value": 0.534818264954547, "duration": 1.5023553371429443, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 348000}
{"episode_reward": 0.0, "episode": 3481.0, "batch_reward": 8.38690185546875, "critic_loss": 1034.533203125, "actor_loss": -1859.732421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3142404556274414, "alpha_loss": 0.07091647386550903, "alpha_value": 0.5361913299608649, "duration": 1.537764310836792, "info_normalized_performance_mean": 0.17818179726600647, "info_normalized_performance_final": 0.2288770079612732, "info_performance_mean": 0.17818179726600647, "info_performance_final": 0.2288770079612732, "step": 348500}
{"episode_reward": 356.3636363636357, "episode": 3486.0, "batch_reward": 9.705493927001953, "critic_loss": 430.169189453125, "actor_loss": -1905.9774169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.5637805461883545, "alpha_loss": 0.04637690633535385, "alpha_value": 0.5343365184018072, "duration": 1.4779338836669922, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 349000}
{"episode_reward": 0.0, "episode": 3491.0, "batch_reward": 9.629499435424805, "critic_loss": 546.9739990234375, "actor_loss": -1853.0458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.125380277633667, "alpha_loss": 0.03449691832065582, "alpha_value": 0.5351542419000194, "duration": 1.43416428565979, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 349500}
{"episode_reward": 0.0, "episode": 3496.0, "batch_reward": 9.644451141357422, "critic_loss": 437.6269226074219, "actor_loss": -1872.9315185546875, "actor_target_entropy": -3.0, "actor_entropy": 1.520312786102295, "alpha_loss": 0.2388921082019806, "alpha_value": 0.536416552740951, "step": 350000}
{"duration": 17.96468758583069, "info_normalized_performance_mean": 0.1742578148841858, "info_normalized_performance_final": 0.205078125, "info_performance_mean": 0.1742578148841858, "info_performance_final": 0.205078125, "step": 350000}
{"episode_reward": 348.515625, "episode": 3501.0, "batch_reward": 9.112899780273438, "critic_loss": 227.15365600585938, "actor_loss": -1849.803466796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3036398887634277, "alpha_loss": -0.2621910572052002, "alpha_value": 0.5363711480405678, "duration": 1.4076874256134033, "info_normalized_performance_mean": 0.0025608770083636045, "info_normalized_performance_final": 0.0028409091755747795, "info_performance_mean": 0.0025608770083636045, "info_performance_final": 0.0028409091755747795, "step": 350500}
{"episode_reward": 5.12175324675324, "episode": 3506.0, "batch_reward": 9.28879451751709, "critic_loss": 372.98638916015625, "actor_loss": -1894.68115234375, "actor_target_entropy": -3.0, "actor_entropy": 1.5632801055908203, "alpha_loss": 0.41316086053848267, "alpha_value": 0.5259661931783428, "duration": 1.536238193511963, "info_normalized_performance_mean": 0.0672871470451355, "info_normalized_performance_final": 0.07647907733917236, "info_performance_mean": 0.0672871470451355, "info_performance_final": 0.07647907733917236, "step": 351000}
{"episode_reward": 134.5743145743147, "episode": 3511.0, "batch_reward": 9.007097244262695, "critic_loss": 667.615966796875, "actor_loss": -1829.832275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5126534700393677, "alpha_loss": 0.32443171739578247, "alpha_value": 0.5115720497562635, "duration": 1.4145541191101074, "info_normalized_performance_mean": 0.01875000074505806, "info_normalized_performance_final": 0.02130681835114956, "info_performance_mean": 0.01875000074505806, "info_performance_final": 0.02130681835114956, "step": 351500}
{"episode_reward": 37.50000000000002, "episode": 3516.0, "batch_reward": 8.631388664245605, "critic_loss": 565.9473266601562, "actor_loss": -1780.0401611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.466318964958191, "alpha_loss": 0.2638052999973297, "alpha_value": 0.5020235602583012, "duration": 1.377734661102295, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 352000}
{"episode_reward": 0.0, "episode": 3521.0, "batch_reward": 8.234232902526855, "critic_loss": 260.3454895019531, "actor_loss": -1756.995361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.4754070043563843, "alpha_loss": 0.4075758457183838, "alpha_value": 0.4911962889937426, "duration": 1.3757269382476807, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 352500}
{"episode_reward": 0.0, "episode": 3526.0, "batch_reward": 8.316815376281738, "critic_loss": 262.40447998046875, "actor_loss": -1819.3392333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.5118803977966309, "alpha_loss": -0.01666150987148285, "alpha_value": 0.4811651541461155, "duration": 1.5376100540161133, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 353000}
{"episode_reward": 0.0, "episode": 3531.0, "batch_reward": 8.429058074951172, "critic_loss": 441.19464111328125, "actor_loss": -1805.8369140625, "actor_target_entropy": -3.0, "actor_entropy": 0.9784339666366577, "alpha_loss": -0.16277208924293518, "alpha_value": 0.4694479926800789, "duration": 1.6049818992614746, "info_normalized_performance_mean": 0.574950098991394, "info_normalized_performance_final": 0.6850000023841858, "info_performance_mean": 0.574950098991394, "info_performance_final": 0.6850000023841858, "step": 353500}
{"episode_reward": 1149.9000000000008, "episode": 3536.0, "batch_reward": 9.350663185119629, "critic_loss": 324.0557861328125, "actor_loss": -1808.60107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3361902236938477, "alpha_loss": 0.05400848016142845, "alpha_value": 0.4609070929254386, "duration": 1.4624474048614502, "info_normalized_performance_mean": 0.7279689311981201, "info_normalized_performance_final": 0.7864583134651184, "info_performance_mean": 0.7279689311981201, "info_performance_final": 0.7864583134651184, "step": 354000}
{"episode_reward": 1455.9375000000011, "episode": 3541.0, "batch_reward": 8.759926795959473, "critic_loss": 950.453857421875, "actor_loss": -1793.584716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.2876558303833008, "alpha_loss": 0.13386321067810059, "alpha_value": 0.4525082610679922, "duration": 1.529355764389038, "info_normalized_performance_mean": 0.7191177606582642, "info_normalized_performance_final": 0.7764706015586853, "info_performance_mean": 0.7191177606582642, "info_performance_final": 0.7764706015586853, "step": 354500}
{"episode_reward": 1438.235294117645, "episode": 3546.0, "batch_reward": 9.431888580322266, "critic_loss": 357.7470703125, "actor_loss": -1768.123046875, "actor_target_entropy": -3.0, "actor_entropy": 1.4701191186904907, "alpha_loss": 0.168260395526886, "alpha_value": 0.446595943164455, "duration": 1.4623301029205322, "info_normalized_performance_mean": 0.48854687809944153, "info_normalized_performance_final": 0.526562511920929, "info_performance_mean": 0.48854687809944153, "info_performance_final": 0.526562511920929, "step": 355000}
{"episode_reward": 977.09375, "episode": 3551.0, "batch_reward": 9.852277755737305, "critic_loss": 430.55059814453125, "actor_loss": -1767.380615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.3207533359527588, "alpha_loss": 0.42635804414749146, "alpha_value": 0.4397687062326285, "duration": 1.572227954864502, "info_normalized_performance_mean": 0.7077778577804565, "info_normalized_performance_final": 0.7738562226295471, "info_performance_mean": 0.7077778577804565, "info_performance_final": 0.7738562226295471, "step": 355500}
{"episode_reward": 1415.5555555555525, "episode": 3556.0, "batch_reward": 9.313383102416992, "critic_loss": 1141.55078125, "actor_loss": -1764.6417236328125, "actor_target_entropy": -3.0, "actor_entropy": 0.9892717599868774, "alpha_loss": 0.13247983157634735, "alpha_value": 0.4334319632260968, "duration": 1.492598533630371, "info_normalized_performance_mean": 0.4524463713169098, "info_normalized_performance_final": 0.4910714328289032, "info_performance_mean": 0.4524463713169098, "info_performance_final": 0.4910714328289032, "step": 356000}
{"episode_reward": 904.8928571428562, "episode": 3561.0, "batch_reward": 9.214616775512695, "critic_loss": 1395.3179931640625, "actor_loss": -1751.2421875, "actor_target_entropy": -3.0, "actor_entropy": 1.416674017906189, "alpha_loss": 0.10146023333072662, "alpha_value": 0.42876928386892493, "duration": 1.5820186138153076, "info_normalized_performance_mean": 0.4566425681114197, "info_normalized_performance_final": 0.8796380162239075, "info_performance_mean": 0.4566425681114197, "info_performance_final": 0.8796380162239075, "step": 356500}
{"episode_reward": 913.285067873303, "episode": 3566.0, "batch_reward": 8.496611595153809, "critic_loss": 894.795654296875, "actor_loss": -1756.085693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2798149585723877, "alpha_loss": -0.08179444074630737, "alpha_value": 0.42798899852793937, "duration": 1.5989556312561035, "info_normalized_performance_mean": 0.8004705905914307, "info_normalized_performance_final": 0.8805429935455322, "info_performance_mean": 0.8004705905914307, "info_performance_final": 0.8805429935455322, "step": 357000}
{"episode_reward": 1600.9411764705856, "episode": 3571.0, "batch_reward": 9.181992530822754, "critic_loss": 682.158447265625, "actor_loss": -1713.0579833984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3437364101409912, "alpha_loss": 0.16797661781311035, "alpha_value": 0.42902620987545026, "duration": 1.5256049633026123, "info_normalized_performance_mean": 0.2362019419670105, "info_normalized_performance_final": 0.5925480723381042, "info_performance_mean": 0.2362019419670105, "info_performance_final": 0.5925480723381042, "step": 357500}
{"episode_reward": 472.40384615384636, "episode": 3576.0, "batch_reward": 9.439264297485352, "critic_loss": 678.2154541015625, "actor_loss": -1760.97314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.1246360540390015, "alpha_loss": 0.09694871306419373, "alpha_value": 0.42505087629291993, "duration": 1.4767608642578125, "info_normalized_performance_mean": 0.8881548047065735, "info_normalized_performance_final": 0.9583333134651184, "info_performance_mean": 0.8881548047065735, "info_performance_final": 0.9583333134651184, "step": 358000}
{"episode_reward": 1776.3095238095261, "episode": 3581.0, "batch_reward": 9.192215919494629, "critic_loss": 531.8924560546875, "actor_loss": -1740.78759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.3334481716156006, "alpha_loss": 0.1088835597038269, "alpha_value": 0.4195009254051503, "duration": 1.4789657592773438, "info_normalized_performance_mean": 0.36244046688079834, "info_normalized_performance_final": 0.3978937864303589, "info_performance_mean": 0.36244046688079834, "info_performance_final": 0.3978937864303589, "step": 358500}
{"episode_reward": 724.880952380953, "episode": 3586.0, "batch_reward": 9.566267967224121, "critic_loss": 788.9664916992188, "actor_loss": -1722.9468994140625, "actor_target_entropy": -3.0, "actor_entropy": 1.1306474208831787, "alpha_loss": 0.23371630907058716, "alpha_value": 0.4130574905107097, "duration": 1.5029540061950684, "info_normalized_performance_mean": 0.6352336406707764, "info_normalized_performance_final": 0.682692289352417, "info_performance_mean": 0.6352336406707764, "info_performance_final": 0.682692289352417, "step": 359000}
{"episode_reward": 1270.4670329670346, "episode": 3591.0, "batch_reward": 7.370309352874756, "critic_loss": 1455.992919921875, "actor_loss": -1651.732177734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0854592323303223, "alpha_loss": -0.2186433970928192, "alpha_value": 0.4059541291821934, "duration": 1.4393539428710938, "info_normalized_performance_mean": 0.2837117314338684, "info_normalized_performance_final": 0.3086734712123871, "info_performance_mean": 0.2837117314338684, "info_performance_final": 0.3086734712123871, "step": 359500}
{"episode_reward": 567.4234693877553, "episode": 3596.0, "batch_reward": 8.080262184143066, "critic_loss": 289.37640380859375, "actor_loss": -1642.897705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0606427192687988, "alpha_loss": 0.10422585159540176, "alpha_value": 0.40265872628430394, "step": 360000}
{"duration": 18.372870206832886, "info_normalized_performance_mean": 0.3270758390426636, "info_normalized_performance_final": 0.37812501192092896, "info_performance_mean": 0.3270758390426636, "info_performance_final": 0.37812501192092896, "step": 360000}
{"episode_reward": 654.1517857142849, "episode": 3601.0, "batch_reward": 9.208534240722656, "critic_loss": 1082.5191650390625, "actor_loss": -1687.642333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.1384522914886475, "alpha_loss": 0.05578436702489853, "alpha_value": 0.40156144761492724, "duration": 1.6774792671203613, "info_normalized_performance_mean": 0.3172023594379425, "info_normalized_performance_final": 0.36752137541770935, "info_performance_mean": 0.3172023594379425, "info_performance_final": 0.36752137541770935, "step": 360500}
{"episode_reward": 634.4047619047625, "episode": 3606.0, "batch_reward": 9.317302703857422, "critic_loss": 824.4475708007812, "actor_loss": -1697.2637939453125, "actor_target_entropy": -3.0, "actor_entropy": 1.355095386505127, "alpha_loss": 0.06744995713233948, "alpha_value": 0.39630222881968574, "duration": 1.4999058246612549, "info_normalized_performance_mean": 0.7240585088729858, "info_normalized_performance_final": 0.7824675440788269, "info_performance_mean": 0.7240585088729858, "info_performance_final": 0.7824675440788269, "step": 361000}
{"episode_reward": 1448.116883116883, "episode": 3611.0, "batch_reward": 8.605558395385742, "critic_loss": 354.22381591796875, "actor_loss": -1646.497314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9396616816520691, "alpha_loss": 0.0185110941529274, "alpha_value": 0.39475737834007846, "duration": 1.6209580898284912, "info_normalized_performance_mean": 0.5100763440132141, "info_normalized_performance_final": 0.5611110925674438, "info_performance_mean": 0.5100763440132141, "info_performance_final": 0.5611110925674438, "step": 361500}
{"episode_reward": 1020.1527777777757, "episode": 3616.0, "batch_reward": 8.392313003540039, "critic_loss": 406.08538818359375, "actor_loss": -1669.716552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.2547942399978638, "alpha_loss": -0.33117663860321045, "alpha_value": 0.392486411488763, "duration": 1.5457990169525146, "info_normalized_performance_mean": 0.7883167862892151, "info_normalized_performance_final": 0.8483333587646484, "info_performance_mean": 0.7883167862892151, "info_performance_final": 0.8483333587646484, "step": 362000}
{"episode_reward": 1576.6333333333357, "episode": 3621.0, "batch_reward": 8.474325180053711, "critic_loss": 565.3735961914062, "actor_loss": -1677.71630859375, "actor_target_entropy": -3.0, "actor_entropy": 0.69221431016922, "alpha_loss": 0.0740060955286026, "alpha_value": 0.39190960813775433, "duration": 1.4434621334075928, "info_normalized_performance_mean": 0.5428572297096252, "info_normalized_performance_final": 0.6016865372657776, "info_performance_mean": 0.5428572297096252, "info_performance_final": 0.6016865372657776, "step": 362500}
{"episode_reward": 1085.7142857142844, "episode": 3626.0, "batch_reward": 9.072356224060059, "critic_loss": 385.05596923828125, "actor_loss": -1628.606689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.297487735748291, "alpha_loss": -0.017392072826623917, "alpha_value": 0.39250360164288933, "duration": 1.577561855316162, "info_normalized_performance_mean": 0.8016470074653625, "info_normalized_performance_final": 0.8748663067817688, "info_performance_mean": 0.8016470074653625, "info_performance_final": 0.8748663067817688, "step": 363000}
{"episode_reward": 1603.294117647059, "episode": 3631.0, "batch_reward": 8.880090713500977, "critic_loss": 407.1302185058594, "actor_loss": -1623.327392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1588904857635498, "alpha_loss": -0.12068870663642883, "alpha_value": 0.39733664969443555, "duration": 1.5366463661193848, "info_normalized_performance_mean": 0.33714058995246887, "info_normalized_performance_final": 0.40156251192092896, "info_performance_mean": 0.33714058995246887, "info_performance_final": 0.40156251192092896, "step": 363500}
{"episode_reward": 674.28125, "episode": 3636.0, "batch_reward": 9.75303840637207, "critic_loss": 315.07037353515625, "actor_loss": -1649.7296142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.232611060142517, "alpha_loss": 0.08124709129333496, "alpha_value": 0.40152951002393505, "duration": 1.5749292373657227, "info_normalized_performance_mean": 0.30327165126800537, "info_normalized_performance_final": 0.33784425258636475, "info_performance_mean": 0.30327165126800537, "info_performance_final": 0.33784425258636475, "step": 364000}
{"episode_reward": 606.5432098765435, "episode": 3641.0, "batch_reward": 8.91978931427002, "critic_loss": 618.510009765625, "actor_loss": -1595.5648193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2945523262023926, "alpha_loss": -0.04322834312915802, "alpha_value": 0.40934530578798695, "duration": 1.4226281642913818, "info_normalized_performance_mean": 0.3140774071216583, "info_normalized_performance_final": 0.3407738208770752, "info_performance_mean": 0.3140774071216583, "info_performance_final": 0.3407738208770752, "step": 364500}
{"episode_reward": 628.1547619047619, "episode": 3646.0, "batch_reward": 9.012772560119629, "critic_loss": 446.94097900390625, "actor_loss": -1620.7113037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1099251508712769, "alpha_loss": -0.15495169162750244, "alpha_value": 0.41660457766613695, "duration": 1.6215965747833252, "info_normalized_performance_mean": 0.49130553007125854, "info_normalized_performance_final": 0.53125, "info_performance_mean": 0.49130553007125854, "info_performance_final": 0.53125, "step": 365000}
{"episode_reward": 982.6111111111111, "episode": 3651.0, "batch_reward": 8.12370491027832, "critic_loss": 451.8287353515625, "actor_loss": -1622.85546875, "actor_target_entropy": -3.0, "actor_entropy": 1.104435682296753, "alpha_loss": -0.16716936230659485, "alpha_value": 0.42509220223400407, "duration": 1.5791466236114502, "info_normalized_performance_mean": 0.8358822464942932, "info_normalized_performance_final": 0.9385620951652527, "info_performance_mean": 0.8358822464942932, "info_performance_final": 0.9385620951652527, "step": 365500}
{"episode_reward": 1671.7647058823502, "episode": 3656.0, "batch_reward": 8.149886131286621, "critic_loss": 430.465576171875, "actor_loss": -1598.7835693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3216667175292969, "alpha_loss": -0.4002913236618042, "alpha_value": 0.43332617166101733, "duration": 1.435650110244751, "info_normalized_performance_mean": 0.493779718875885, "info_normalized_performance_final": 0.5440475940704346, "info_performance_mean": 0.493779718875885, "info_performance_final": 0.5440475940704346, "step": 366000}
{"episode_reward": 987.5595238095256, "episode": 3661.0, "batch_reward": 7.953984260559082, "critic_loss": 471.6801452636719, "actor_loss": -1618.562744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.9680978059768677, "alpha_loss": -0.2876513600349426, "alpha_value": 0.4463789800213727, "duration": 1.6107456684112549, "info_normalized_performance_mean": 0.44864585995674133, "info_normalized_performance_final": 0.496279776096344, "info_performance_mean": 0.44864585995674133, "info_performance_final": 0.496279776096344, "step": 366500}
{"episode_reward": 897.2916666666647, "episode": 3666.0, "batch_reward": 7.694832801818848, "critic_loss": 321.7061767578125, "actor_loss": -1571.91845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.4903532266616821, "alpha_loss": -0.08038848638534546, "alpha_value": 0.45781456869608395, "duration": 1.6113722324371338, "info_normalized_performance_mean": 0.20718994736671448, "info_normalized_performance_final": 0.23555392026901245, "info_performance_mean": 0.20718994736671448, "info_performance_final": 0.23555392026901245, "step": 367000}
{"episode_reward": 414.3798306956211, "episode": 3671.0, "batch_reward": 9.494319915771484, "critic_loss": 337.94720458984375, "actor_loss": -1679.8536376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.478268027305603, "alpha_loss": 0.08395913243293762, "alpha_value": 0.46727718943385865, "duration": 1.490391492843628, "info_normalized_performance_mean": 0.4326525628566742, "info_normalized_performance_final": 0.4758184552192688, "info_performance_mean": 0.4326525628566742, "info_performance_final": 0.4758184552192688, "step": 367500}
{"episode_reward": 865.3050595238087, "episode": 3676.0, "batch_reward": 9.417852401733398, "critic_loss": 238.53646850585938, "actor_loss": -1611.97265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3872952461242676, "alpha_loss": 0.14077144861221313, "alpha_value": 0.4732818456907778, "duration": 1.6190924644470215, "info_normalized_performance_mean": 0.6929959058761597, "info_normalized_performance_final": 0.7685185074806213, "info_performance_mean": 0.6929959058761597, "info_performance_final": 0.7685185074806213, "step": 368000}
{"episode_reward": 1385.9920634920634, "episode": 3681.0, "batch_reward": 8.617809295654297, "critic_loss": 385.9233703613281, "actor_loss": -1606.9173583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.366834282875061, "alpha_loss": -0.14505358040332794, "alpha_value": 0.48126915216341043, "duration": 1.4993784427642822, "info_normalized_performance_mean": 0.14091037213802338, "info_normalized_performance_final": 0.15412186086177826, "info_performance_mean": 0.14091037213802338, "info_performance_final": 0.15412186086177826, "step": 368500}
{"episode_reward": 281.82078853046585, "episode": 3686.0, "batch_reward": 8.214179992675781, "critic_loss": 562.9288940429688, "actor_loss": -1629.11474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3607428073883057, "alpha_loss": -0.09001734852790833, "alpha_value": 0.4876434853041244, "duration": 1.4353716373443604, "info_normalized_performance_mean": 0.4116000235080719, "info_normalized_performance_final": 0.4440000057220459, "info_performance_mean": 0.4116000235080719, "info_performance_final": 0.4440000057220459, "step": 369000}
{"episode_reward": 823.1999999999997, "episode": 3691.0, "batch_reward": 9.710196495056152, "critic_loss": 632.309326171875, "actor_loss": -1681.4072265625, "actor_target_entropy": -3.0, "actor_entropy": 1.5438964366912842, "alpha_loss": -0.048549916595220566, "alpha_value": 0.4881391856484192, "duration": 1.550156593322754, "info_normalized_performance_mean": 0.15672051906585693, "info_normalized_performance_final": 0.17261457443237305, "info_performance_mean": 0.15672051906585693, "info_performance_final": 0.17261457443237305, "step": 369500}
{"episode_reward": 313.44102178812875, "episode": 3696.0, "batch_reward": 7.717983245849609, "critic_loss": 289.46392822265625, "actor_loss": -1596.5811767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1853933334350586, "alpha_loss": -0.35924792289733887, "alpha_value": 0.48912728206147055, "step": 370000}
{"duration": 18.498033046722412, "info_normalized_performance_mean": 0.6855155229568481, "info_normalized_performance_final": 0.7406250238418579, "info_performance_mean": 0.6855155229568481, "info_performance_final": 0.7406250238418579, "step": 370000}
{"episode_reward": 1371.03125, "episode": 3701.0, "batch_reward": 8.756255149841309, "critic_loss": 738.4417724609375, "actor_loss": -1608.620361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.6156773567199707, "alpha_loss": 0.27912747859954834, "alpha_value": 0.48788483103424196, "duration": 1.4660894870758057, "info_normalized_performance_mean": 0.49314558506011963, "info_normalized_performance_final": 0.5430402755737305, "info_performance_mean": 0.49314558506011963, "info_performance_final": 0.5430402755737305, "step": 370500}
{"episode_reward": 986.2912087912075, "episode": 3706.0, "batch_reward": 8.44958209991455, "critic_loss": 596.4481201171875, "actor_loss": -1602.8389892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.4658339023590088, "alpha_loss": -0.22627371549606323, "alpha_value": 0.48750739979457636, "duration": 1.3602588176727295, "info_normalized_performance_mean": 0.6741964221000671, "info_normalized_performance_final": 0.7276785969734192, "info_performance_mean": 0.6741964221000671, "info_performance_final": 0.7276785969734192, "step": 371000}
{"episode_reward": 1348.3928571428557, "episode": 3711.0, "batch_reward": 8.663662910461426, "critic_loss": 332.9112548828125, "actor_loss": -1639.10302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.331113338470459, "alpha_loss": -0.12576979398727417, "alpha_value": 0.48588140776400507, "duration": 1.4662652015686035, "info_normalized_performance_mean": 0.6921204924583435, "info_normalized_performance_final": 0.7589285969734192, "info_performance_mean": 0.6921204924583435, "info_performance_final": 0.7589285969734192, "step": 371500}
{"episode_reward": 1384.2410714285697, "episode": 3716.0, "batch_reward": 8.292362213134766, "critic_loss": 979.8684692382812, "actor_loss": -1586.275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.2756085395812988, "alpha_loss": 0.05044236779212952, "alpha_value": 0.4841511179804395, "duration": 1.6098973751068115, "info_normalized_performance_mean": 0.5673611164093018, "info_normalized_performance_final": 0.6316137313842773, "info_performance_mean": 0.5673611164093018, "info_performance_final": 0.6316137313842773, "step": 372000}
{"episode_reward": 1134.722222222222, "episode": 3721.0, "batch_reward": 8.028419494628906, "critic_loss": 283.9635009765625, "actor_loss": -1631.2081298828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3198142051696777, "alpha_loss": -0.12458933889865875, "alpha_value": 0.48418591970620417, "duration": 1.5858628749847412, "info_normalized_performance_mean": 0.749494194984436, "info_normalized_performance_final": 0.8423529267311096, "info_performance_mean": 0.749494194984436, "info_performance_final": 0.8423529267311096, "step": 372500}
{"episode_reward": 1498.9882352941163, "episode": 3726.0, "batch_reward": 8.520362854003906, "critic_loss": 229.26052856445312, "actor_loss": -1607.0645751953125, "actor_target_entropy": -3.0, "actor_entropy": 1.5264229774475098, "alpha_loss": 0.02909044921398163, "alpha_value": 0.4874555475596824, "duration": 1.474684476852417, "info_normalized_performance_mean": 0.7118304371833801, "info_normalized_performance_final": 0.769345223903656, "info_performance_mean": 0.7118304371833801, "info_performance_final": 0.769345223903656, "step": 373000}
{"episode_reward": 1423.6607142857174, "episode": 3731.0, "batch_reward": 8.619606971740723, "critic_loss": 326.5256652832031, "actor_loss": -1606.6279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3279614448547363, "alpha_loss": 0.11694534868001938, "alpha_value": 0.4840246618919247, "duration": 1.619666337966919, "info_normalized_performance_mean": 0.7254790663719177, "info_normalized_performance_final": 0.7951388955116272, "info_performance_mean": 0.7254790663719177, "info_performance_final": 0.7951388955116272, "step": 373500}
{"episode_reward": 1450.9583333333362, "episode": 3736.0, "batch_reward": 8.529173851013184, "critic_loss": 240.9982147216797, "actor_loss": -1583.45947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6056303977966309, "alpha_loss": 0.08610601723194122, "alpha_value": 0.4827304432677837, "duration": 1.4730498790740967, "info_normalized_performance_mean": 0.5188281536102295, "info_normalized_performance_final": 0.587890625, "info_performance_mean": 0.5188281536102295, "info_performance_final": 0.587890625, "step": 374000}
{"episode_reward": 1037.65625, "episode": 3741.0, "batch_reward": 9.48172378540039, "critic_loss": 270.0851745605469, "actor_loss": -1649.3155517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.4808604717254639, "alpha_loss": 0.04461366683244705, "alpha_value": 0.48313692813675013, "duration": 1.4784421920776367, "info_normalized_performance_mean": 0.22593097388744354, "info_normalized_performance_final": 0.244140625, "info_performance_mean": 0.22593097388744354, "info_performance_final": 0.244140625, "step": 374500}
{"episode_reward": 451.86197916666663, "episode": 3746.0, "batch_reward": 8.398533821105957, "critic_loss": 265.85260009765625, "actor_loss": -1612.93603515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1471993923187256, "alpha_loss": -0.2140689343214035, "alpha_value": 0.4841107246686301, "duration": 1.4713068008422852, "info_normalized_performance_mean": 0.5854296684265137, "info_normalized_performance_final": 0.642578125, "info_performance_mean": 0.5854296684265137, "info_performance_final": 0.642578125, "step": 375000}
{"episode_reward": 1170.859375, "episode": 3751.0, "batch_reward": 8.479898452758789, "critic_loss": 234.2591552734375, "actor_loss": -1563.763427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.4243335723876953, "alpha_loss": -0.03529192879796028, "alpha_value": 0.4797308245656997, "duration": 1.5382170677185059, "info_normalized_performance_mean": 0.5723137259483337, "info_normalized_performance_final": 0.6183006763458252, "info_performance_mean": 0.5723137259483337, "info_performance_final": 0.6183006763458252, "step": 375500}
{"episode_reward": 1144.6274509803911, "episode": 3756.0, "batch_reward": 8.020614624023438, "critic_loss": 523.6802978515625, "actor_loss": -1599.441650390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9855544567108154, "alpha_loss": 0.04177916795015335, "alpha_value": 0.47511866523018004, "duration": 1.4926316738128662, "info_normalized_performance_mean": 0.6231563687324524, "info_normalized_performance_final": 0.6812499761581421, "info_performance_mean": 0.6231563687324524, "info_performance_final": 0.6812499761581421, "step": 376000}
{"episode_reward": 1246.3125, "episode": 3761.0, "batch_reward": 8.868578910827637, "critic_loss": 183.11935424804688, "actor_loss": -1592.594970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.438181757926941, "alpha_loss": 0.09576372057199478, "alpha_value": 0.47086008447657773, "duration": 1.6500959396362305, "info_normalized_performance_mean": 0.7103956341743469, "info_normalized_performance_final": 0.793055534362793, "info_performance_mean": 0.7103956341743469, "info_performance_final": 0.793055534362793, "step": 376500}
{"episode_reward": 1420.791666666665, "episode": 3766.0, "batch_reward": 9.179739952087402, "critic_loss": 255.75527954101562, "actor_loss": -1602.2623291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5970056056976318, "alpha_loss": -0.020793240517377853, "alpha_value": 0.46607037388827793, "duration": 1.4505469799041748, "info_normalized_performance_mean": 0.1899956911802292, "info_normalized_performance_final": 0.2044270783662796, "info_performance_mean": 0.1899956911802292, "info_performance_final": 0.2044270783662796, "step": 377000}
{"episode_reward": 379.9913194444448, "episode": 3771.0, "batch_reward": 8.774291038513184, "critic_loss": 582.340087890625, "actor_loss": -1637.6240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4782695770263672, "alpha_loss": -0.07740049064159393, "alpha_value": 0.46336594271774423, "duration": 1.4569523334503174, "info_normalized_performance_mean": 0.6576821804046631, "info_normalized_performance_final": 0.7135416865348816, "info_performance_mean": 0.6576821804046631, "info_performance_final": 0.7135416865348816, "step": 377500}
{"episode_reward": 1315.3645833333328, "episode": 3776.0, "batch_reward": 8.505654335021973, "critic_loss": 305.22882080078125, "actor_loss": -1591.668212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.1886053085327148, "alpha_loss": 0.01445738784968853, "alpha_value": 0.45859507916181486, "duration": 1.548574447631836, "info_normalized_performance_mean": 0.7291015386581421, "info_normalized_performance_final": 0.81640625, "info_performance_mean": 0.7291015386581421, "info_performance_final": 0.81640625, "step": 378000}
{"episode_reward": 1458.203125, "episode": 3781.0, "batch_reward": 9.052967071533203, "critic_loss": 331.46917724609375, "actor_loss": -1619.4154052734375, "actor_target_entropy": -3.0, "actor_entropy": 1.239399790763855, "alpha_loss": 0.17956694960594177, "alpha_value": 0.45452937535141436, "duration": 1.5525760650634766, "info_normalized_performance_mean": 0.1443159431219101, "info_normalized_performance_final": 0.1588636338710785, "info_performance_mean": 0.1443159431219101, "info_performance_final": 0.1588636338710785, "step": 378500}
{"episode_reward": 288.6318181818186, "episode": 3786.0, "batch_reward": 8.597770690917969, "critic_loss": 197.17324829101562, "actor_loss": -1572.851806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.5044331550598145, "alpha_loss": 0.19686460494995117, "alpha_value": 0.4507044077219133, "duration": 1.4458520412445068, "info_normalized_performance_mean": 0.476767897605896, "info_normalized_performance_final": 0.5547618865966797, "info_performance_mean": 0.476767897605896, "info_performance_final": 0.5547618865966797, "step": 379000}
{"episode_reward": 953.535714285713, "episode": 3791.0, "batch_reward": 8.490812301635742, "critic_loss": 192.4653778076172, "actor_loss": -1578.46826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.4254037141799927, "alpha_loss": 0.24373768270015717, "alpha_value": 0.4442102152333275, "duration": 1.6291520595550537, "info_normalized_performance_mean": 0.5734931230545044, "info_normalized_performance_final": 0.6243055462837219, "info_performance_mean": 0.5734931230545044, "info_performance_final": 0.6243055462837219, "step": 379500}
{"episode_reward": 1146.9861111111102, "episode": 3796.0, "batch_reward": 8.45079517364502, "critic_loss": 258.83953857421875, "actor_loss": -1565.179931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.5433911085128784, "alpha_loss": -0.06902047991752625, "alpha_value": 0.43713906811181386, "step": 380000}
{"duration": 18.325352907180786, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 380000}
{"episode_reward": 0.0, "episode": 3801.0, "batch_reward": 8.317239761352539, "critic_loss": 367.8750915527344, "actor_loss": -1553.87109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2554466724395752, "alpha_loss": -0.06257820129394531, "alpha_value": 0.43277701298617527, "duration": 1.6201224327087402, "info_normalized_performance_mean": 0.6678395867347717, "info_normalized_performance_final": 0.7260802388191223, "info_performance_mean": 0.6678395867347717, "info_performance_final": 0.7260802388191223, "step": 380500}
{"episode_reward": 1335.679012345678, "episode": 3806.0, "batch_reward": 8.198369026184082, "critic_loss": 281.4529113769531, "actor_loss": -1555.2420654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9231101870536804, "alpha_loss": -0.017607510089874268, "alpha_value": 0.42974880717919006, "duration": 1.4803462028503418, "info_normalized_performance_mean": 0.0721627026796341, "info_normalized_performance_final": 0.0793650820851326, "info_performance_mean": 0.0721627026796341, "info_performance_final": 0.0793650820851326, "step": 381000}
{"episode_reward": 144.32539682539672, "episode": 3811.0, "batch_reward": 8.819194793701172, "critic_loss": 337.25469970703125, "actor_loss": -1570.9176025390625, "actor_target_entropy": -3.0, "actor_entropy": 1.3429818153381348, "alpha_loss": 0.013953633606433868, "alpha_value": 0.4255471153208828, "duration": 1.4398224353790283, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 381500}
{"episode_reward": 0.0, "episode": 3816.0, "batch_reward": 8.63136100769043, "critic_loss": 287.9623718261719, "actor_loss": -1568.7296142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1842142343521118, "alpha_loss": -0.02690047398209572, "alpha_value": 0.4264403682148785, "duration": 1.4907913208007812, "info_normalized_performance_mean": 0.8576802015304565, "info_normalized_performance_final": 0.95665442943573, "info_performance_mean": 0.8576802015304565, "info_performance_final": 0.95665442943573, "step": 382000}
{"episode_reward": 1715.3601953601992, "episode": 3821.0, "batch_reward": 9.377094268798828, "critic_loss": 217.94427490234375, "actor_loss": -1581.4012451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.356750249862671, "alpha_loss": 0.14391925930976868, "alpha_value": 0.42516537862745546, "duration": 1.490429162979126, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 382500}
{"episode_reward": 0.0, "episode": 3826.0, "batch_reward": 8.687625885009766, "critic_loss": 559.0182495117188, "actor_loss": -1537.609619140625, "actor_target_entropy": -3.0, "actor_entropy": 1.3885905742645264, "alpha_loss": -0.04357646778225899, "alpha_value": 0.419914494727622, "duration": 1.4676728248596191, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 383000}
{"episode_reward": 0.0, "episode": 3831.0, "batch_reward": 9.076934814453125, "critic_loss": 1000.9449462890625, "actor_loss": -1571.068115234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1520655155181885, "alpha_loss": 0.0617201030254364, "alpha_value": 0.4163256300348873, "duration": 1.5369598865509033, "info_normalized_performance_mean": 0.778645932674408, "info_normalized_performance_final": 0.8489583134651184, "info_performance_mean": 0.778645932674408, "info_performance_final": 0.8489583134651184, "step": 383500}
{"episode_reward": 1557.291666666668, "episode": 3836.0, "batch_reward": 8.625823020935059, "critic_loss": 536.78662109375, "actor_loss": -1537.9061279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.4226715564727783, "alpha_loss": 0.2408095896244049, "alpha_value": 0.4101246696538181, "duration": 1.5856788158416748, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 384000}
{"episode_reward": 0.0, "episode": 3841.0, "batch_reward": 8.566254615783691, "critic_loss": 234.82284545898438, "actor_loss": -1510.5733642578125, "actor_target_entropy": -3.0, "actor_entropy": 1.0630457401275635, "alpha_loss": 0.22529014945030212, "alpha_value": 0.4062094876446224, "duration": 1.6206037998199463, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 384500}
{"episode_reward": 0.0, "episode": 3846.0, "batch_reward": 8.229747772216797, "critic_loss": 425.5401306152344, "actor_loss": -1524.58251953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9498149752616882, "alpha_loss": -0.05618288740515709, "alpha_value": 0.3995793632351293, "duration": 1.5733046531677246, "info_normalized_performance_mean": 0.39835062623023987, "info_normalized_performance_final": 0.4366319477558136, "info_performance_mean": 0.39835062623023987, "info_performance_final": 0.4366319477558136, "step": 385000}
{"episode_reward": 796.7013888888903, "episode": 3851.0, "batch_reward": 8.177385330200195, "critic_loss": 834.8953247070312, "actor_loss": -1483.4140625, "actor_target_entropy": -3.0, "actor_entropy": 1.4277828931808472, "alpha_loss": -0.1331224888563156, "alpha_value": 0.3979849775477355, "duration": 1.6219074726104736, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 385500}
{"episode_reward": 0.0, "episode": 3856.0, "batch_reward": 8.65533447265625, "critic_loss": 1257.74365234375, "actor_loss": -1516.7720947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.1604282855987549, "alpha_loss": 0.07673154771327972, "alpha_value": 0.400640704540456, "duration": 1.7077560424804688, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 386000}
{"episode_reward": 0.0, "episode": 3861.0, "batch_reward": 7.642477989196777, "critic_loss": 488.8329162597656, "actor_loss": -1501.839599609375, "actor_target_entropy": -3.0, "actor_entropy": 0.9816982746124268, "alpha_loss": -0.3146247863769531, "alpha_value": 0.4044844899392535, "duration": 1.4294071197509766, "info_normalized_performance_mean": 0.27140629291534424, "info_normalized_performance_final": 0.29374998807907104, "info_performance_mean": 0.27140629291534424, "info_performance_final": 0.29374998807907104, "step": 386500}
{"episode_reward": 542.8125, "episode": 3866.0, "batch_reward": 8.322137832641602, "critic_loss": 615.5022583007812, "actor_loss": -1499.889404296875, "actor_target_entropy": -3.0, "actor_entropy": 1.2237699031829834, "alpha_loss": -0.1129312589764595, "alpha_value": 0.41128881183517685, "duration": 1.553192138671875, "info_normalized_performance_mean": 0.23472709953784943, "info_normalized_performance_final": 0.2593750059604645, "info_performance_mean": 0.23472709953784943, "info_performance_final": 0.2593750059604645, "step": 387000}
{"episode_reward": 469.45416666666665, "episode": 3871.0, "batch_reward": 8.952718734741211, "critic_loss": 222.165771484375, "actor_loss": -1548.769287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.6098978519439697, "alpha_loss": -0.031535498797893524, "alpha_value": 0.4150407412640217, "duration": 1.5764493942260742, "info_normalized_performance_mean": 0.6627745032310486, "info_normalized_performance_final": 0.7833333611488342, "info_performance_mean": 0.6627745032310486, "info_performance_final": 0.7833333611488342, "step": 387500}
{"episode_reward": 1325.5490196078435, "episode": 3876.0, "batch_reward": 8.978645324707031, "critic_loss": 260.0688781738281, "actor_loss": -1495.99169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4033267498016357, "alpha_loss": 0.22197097539901733, "alpha_value": 0.41937738798248475, "duration": 1.4674701690673828, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 388000}
{"episode_reward": 0.0, "episode": 3881.0, "batch_reward": 8.63438606262207, "critic_loss": 284.9090270996094, "actor_loss": -1511.173583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.5438593626022339, "alpha_loss": -0.14193332195281982, "alpha_value": 0.4231444034022537, "duration": 1.5370047092437744, "info_normalized_performance_mean": 0.2634900212287903, "info_normalized_performance_final": 0.2849002778530121, "info_performance_mean": 0.2634900212287903, "info_performance_final": 0.2849002778530121, "step": 388500}
{"episode_reward": 526.9800569800575, "episode": 3886.0, "batch_reward": 8.478994369506836, "critic_loss": 874.7421875, "actor_loss": -1507.86181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.3173460960388184, "alpha_loss": -0.03046788088977337, "alpha_value": 0.42753995242029, "duration": 1.443150520324707, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 389000}
{"episode_reward": 0.0, "episode": 3891.0, "batch_reward": 9.040410995483398, "critic_loss": 428.85504150390625, "actor_loss": -1502.37841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.6308434009552002, "alpha_loss": -0.19313326478004456, "alpha_value": 0.43140979236240284, "duration": 1.627873420715332, "info_normalized_performance_mean": 0.5486795902252197, "info_normalized_performance_final": 0.5966811180114746, "info_performance_mean": 0.5486795902252197, "info_performance_final": 0.5966811180114746, "step": 389500}
{"episode_reward": 1097.3593073593056, "episode": 3896.0, "batch_reward": 7.645435333251953, "critic_loss": 451.37249755859375, "actor_loss": -1444.660400390625, "actor_target_entropy": -3.0, "actor_entropy": 1.147929072380066, "alpha_loss": -0.4435582756996155, "alpha_value": 0.4417470280975952, "step": 390000}
{"duration": 18.484044075012207, "info_normalized_performance_mean": 0.4856477677822113, "info_normalized_performance_final": 0.5732421875, "info_performance_mean": 0.4856477677822113, "info_performance_final": 0.5732421875, "step": 390000}
{"episode_reward": 971.2955729166666, "episode": 3901.0, "batch_reward": 8.052912712097168, "critic_loss": 391.32452392578125, "actor_loss": -1488.70751953125, "actor_target_entropy": -3.0, "actor_entropy": 1.6536122560501099, "alpha_loss": 0.03701053559780121, "alpha_value": 0.4500415531420049, "duration": 1.4804065227508545, "info_normalized_performance_mean": 0.7458592057228088, "info_normalized_performance_final": 0.8151041865348816, "info_performance_mean": 0.7458592057228088, "info_performance_final": 0.8151041865348816, "step": 390500}
{"episode_reward": 1491.7187499999989, "episode": 3906.0, "batch_reward": 8.35202407836914, "critic_loss": 349.6873779296875, "actor_loss": -1470.2252197265625, "actor_target_entropy": -3.0, "actor_entropy": 1.7634999752044678, "alpha_loss": -0.22673992812633514, "alpha_value": 0.4588395758033207, "duration": 1.653160810470581, "info_normalized_performance_mean": 0.7882381677627563, "info_normalized_performance_final": 0.8761904835700989, "info_performance_mean": 0.7882381677627563, "info_performance_final": 0.8761904835700989, "step": 391000}
{"episode_reward": 1576.4761904761936, "episode": 3911.0, "batch_reward": 8.363971710205078, "critic_loss": 416.90521240234375, "actor_loss": -1460.627197265625, "actor_target_entropy": -3.0, "actor_entropy": 1.625666618347168, "alpha_loss": -0.27509504556655884, "alpha_value": 0.4678792766036604, "duration": 1.4037303924560547, "info_normalized_performance_mean": 0.7804284691810608, "info_normalized_performance_final": 0.8535714149475098, "info_performance_mean": 0.7804284691810608, "info_performance_final": 0.8535714149475098, "step": 391500}
{"episode_reward": 1560.8571428571452, "episode": 3916.0, "batch_reward": 9.082843780517578, "critic_loss": 264.60333251953125, "actor_loss": -1538.8466796875, "actor_target_entropy": -3.0, "actor_entropy": 1.8807942867279053, "alpha_loss": -0.34304943680763245, "alpha_value": 0.4775086184762816, "duration": 1.5358033180236816, "info_normalized_performance_mean": 0.2700136601924896, "info_normalized_performance_final": 0.2995454668998718, "info_performance_mean": 0.2700136601924896, "info_performance_final": 0.2995454668998718, "step": 392000}
{"episode_reward": 540.0272727272732, "episode": 3921.0, "batch_reward": 8.465332984924316, "critic_loss": 291.4263916015625, "actor_loss": -1476.3365478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.398315668106079, "alpha_loss": 0.19599318504333496, "alpha_value": 0.4856757781377379, "duration": 1.6131956577301025, "info_normalized_performance_mean": 0.5959954261779785, "info_normalized_performance_final": 0.6921296119689941, "info_performance_mean": 0.5959954261779785, "info_performance_final": 0.6921296119689941, "step": 392500}
{"episode_reward": 1191.9907407407418, "episode": 3926.0, "batch_reward": 6.950666427612305, "critic_loss": 232.53173828125, "actor_loss": -1395.783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.3649543523788452, "alpha_loss": -0.36342525482177734, "alpha_value": 0.49210976602549694, "duration": 1.6290197372436523, "info_normalized_performance_mean": 0.23736804723739624, "info_normalized_performance_final": 0.26525747776031494, "info_performance_mean": 0.23736804723739624, "info_performance_final": 0.26525747776031494, "step": 393000}
{"episode_reward": 474.73617291799076, "episode": 3931.0, "batch_reward": 7.651553153991699, "critic_loss": 338.0466613769531, "actor_loss": -1456.026611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.1871391534805298, "alpha_loss": -0.0554138645529747, "alpha_value": 0.5003385671151602, "duration": 1.6016960144042969, "info_normalized_performance_mean": 0.6750545501708984, "info_normalized_performance_final": 0.7363636493682861, "info_performance_mean": 0.6750545501708984, "info_performance_final": 0.7363636493682861, "step": 393500}
{"episode_reward": 1350.1090909090922, "episode": 3936.0, "batch_reward": 7.181314945220947, "critic_loss": 352.39501953125, "actor_loss": -1399.1170654296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3844739198684692, "alpha_loss": -0.14675281941890717, "alpha_value": 0.5016350165253144, "duration": 1.658503770828247, "info_normalized_performance_mean": 0.6229364275932312, "info_normalized_performance_final": 0.7121211886405945, "info_performance_mean": 0.6229364275932312, "info_performance_final": 0.7121211886405945, "step": 394000}
{"episode_reward": 1245.8730158730161, "episode": 3941.0, "batch_reward": 8.97549057006836, "critic_loss": 1476.85791015625, "actor_loss": -1504.79052734375, "actor_target_entropy": -3.0, "actor_entropy": 1.4318281412124634, "alpha_loss": 0.10818459093570709, "alpha_value": 0.5042485251106559, "duration": 1.6414167881011963, "info_normalized_performance_mean": 0.7279687523841858, "info_normalized_performance_final": 0.8311011791229248, "info_performance_mean": 0.7279687523841858, "info_performance_final": 0.8311011791229248, "step": 394500}
{"episode_reward": 1455.9375000000025, "episode": 3946.0, "batch_reward": 8.1258544921875, "critic_loss": 468.633056640625, "actor_loss": -1449.373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.7067900896072388, "alpha_loss": -0.04613460600376129, "alpha_value": 0.5046661180735236, "duration": 1.551628828048706, "info_normalized_performance_mean": 0.8387641310691833, "info_normalized_performance_final": 0.9446022510528564, "info_performance_mean": 0.8387641310691833, "info_performance_final": 0.9446022510528564, "step": 395000}
{"episode_reward": 1677.528409090912, "episode": 3951.0, "batch_reward": 8.546304702758789, "critic_loss": 432.97283935546875, "actor_loss": -1498.30810546875, "actor_target_entropy": -3.0, "actor_entropy": 1.3056257963180542, "alpha_loss": -0.06614864617586136, "alpha_value": 0.5065423264287793, "duration": 1.5810964107513428, "info_normalized_performance_mean": 0.7046400308609009, "info_normalized_performance_final": 0.7760000228881836, "info_performance_mean": 0.7046400308609009, "info_performance_final": 0.7760000228881836, "step": 395500}
{"episode_reward": 1409.2799999999988, "episode": 3956.0, "batch_reward": 8.833030700683594, "critic_loss": 1331.2415771484375, "actor_loss": -1481.6376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.6223068237304688, "alpha_loss": 0.21210895478725433, "alpha_value": 0.5055419214631609, "duration": 1.5744411945343018, "info_normalized_performance_mean": 0.3338116705417633, "info_normalized_performance_final": 0.3641975224018097, "info_performance_mean": 0.3338116705417633, "info_performance_final": 0.3641975224018097, "step": 396000}
{"episode_reward": 667.6234567901234, "episode": 3961.0, "batch_reward": 8.458802223205566, "critic_loss": 926.7817993164062, "actor_loss": -1466.069091796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3470317125320435, "alpha_loss": 0.045852720737457275, "alpha_value": 0.5035571818482178, "duration": 1.70751953125, "info_normalized_performance_mean": 0.4648982286453247, "info_normalized_performance_final": 0.5182771682739258, "info_performance_mean": 0.4648982286453247, "info_performance_final": 0.5182771682739258, "step": 396500}
{"episode_reward": 929.7965670692955, "episode": 3966.0, "batch_reward": 9.12990951538086, "critic_loss": 730.297119140625, "actor_loss": -1514.8819580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.5278658866882324, "alpha_loss": 0.2004416286945343, "alpha_value": 0.5023981058599071, "duration": 1.6068744659423828, "info_normalized_performance_mean": 0.5109999179840088, "info_normalized_performance_final": 0.5611110925674438, "info_performance_mean": 0.5109999179840088, "info_performance_final": 0.5611110925674438, "step": 397000}
{"episode_reward": 1021.9999999999977, "episode": 3971.0, "batch_reward": 8.106030464172363, "critic_loss": 460.4668884277344, "actor_loss": -1443.5177001953125, "actor_target_entropy": -3.0, "actor_entropy": 1.2746498584747314, "alpha_loss": -0.006742540746927261, "alpha_value": 0.493042718789361, "duration": 1.6123230457305908, "info_normalized_performance_mean": 0.736702561378479, "info_normalized_performance_final": 0.8102453351020813, "info_performance_mean": 0.736702561378479, "info_performance_final": 0.8102453351020813, "step": 397500}
{"episode_reward": 1473.4054834054818, "episode": 3976.0, "batch_reward": 8.497615814208984, "critic_loss": 574.4957275390625, "actor_loss": -1493.360107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.181898593902588, "alpha_loss": 0.008641205728054047, "alpha_value": 0.4843378842217794, "duration": 1.4259388446807861, "info_normalized_performance_mean": 0.19844703376293182, "info_normalized_performance_final": 0.21647058427333832, "info_performance_mean": 0.19844703376293182, "info_performance_final": 0.21647058427333832, "step": 398000}
{"episode_reward": 396.8941176470587, "episode": 3981.0, "batch_reward": 7.924078941345215, "critic_loss": 445.9141845703125, "actor_loss": -1432.220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.4819297790527344, "alpha_loss": -0.10723601281642914, "alpha_value": 0.47875309539642447, "duration": 1.3990528583526611, "info_normalized_performance_mean": 0.47757136821746826, "info_normalized_performance_final": 0.5178571343421936, "info_performance_mean": 0.47757136821746826, "info_performance_final": 0.5178571343421936, "step": 398500}
{"episode_reward": 955.142857142858, "episode": 3986.0, "batch_reward": 7.863292694091797, "critic_loss": 402.28460693359375, "actor_loss": -1397.341552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.601663589477539, "alpha_loss": 0.06444798409938812, "alpha_value": 0.4733288866960597, "duration": 1.564995527267456, "info_normalized_performance_mean": 0.806770920753479, "info_normalized_performance_final": 0.8923611044883728, "info_performance_mean": 0.806770920753479, "info_performance_final": 0.8923611044883728, "step": 399000}
{"episode_reward": 1613.5416666666638, "episode": 3991.0, "batch_reward": 9.055484771728516, "critic_loss": 617.6546630859375, "actor_loss": -1473.9134521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.5655666589736938, "alpha_loss": 0.17880846560001373, "alpha_value": 0.4688391736131871, "duration": 1.4829556941986084, "info_normalized_performance_mean": 0.3881683647632599, "info_normalized_performance_final": 0.4210069477558136, "info_performance_mean": 0.3881683647632599, "info_performance_final": 0.4210069477558136, "step": 399500}
{"episode_reward": 776.336805555557, "episode": 3996.0, "batch_reward": 8.042205810546875, "critic_loss": 581.5924072265625, "actor_loss": -1460.091796875, "actor_target_entropy": -3.0, "actor_entropy": 1.222975254058838, "alpha_loss": -0.1794946789741516, "alpha_value": 0.46455377088872385, "step": 400000}
{"duration": 18.828577756881714, "info_normalized_performance_mean": 0.47076714038848877, "info_normalized_performance_final": 0.5340909361839294, "info_performance_mean": 0.47076714038848877, "info_performance_final": 0.5340909361839294, "step": 400000}
{"episode_reward": 941.5340909090895, "episode": 4001.0, "batch_reward": 8.435522079467773, "critic_loss": 532.867431640625, "actor_loss": -1443.00146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3097991943359375, "alpha_loss": -0.11122855544090271, "alpha_value": 0.46438032522570666, "duration": 1.6121666431427002, "info_normalized_performance_mean": 0.5125148892402649, "info_normalized_performance_final": 0.5572916865348816, "info_performance_mean": 0.5125148892402649, "info_performance_final": 0.5572916865348816, "step": 400500}
{"episode_reward": 1025.0297619047633, "episode": 4006.0, "batch_reward": 8.187591552734375, "critic_loss": 960.610595703125, "actor_loss": -1471.5706787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.129967451095581, "alpha_loss": -0.23691347241401672, "alpha_value": 0.4661823391741508, "duration": 1.5344035625457764, "info_normalized_performance_mean": 0.4155500829219818, "info_normalized_performance_final": 0.4607113301753998, "info_performance_mean": 0.4155500829219818, "info_performance_final": 0.4607113301753998, "step": 401000}
{"episode_reward": 831.1000827129852, "episode": 4011.0, "batch_reward": 7.8584136962890625, "critic_loss": 634.7723388671875, "actor_loss": -1446.37646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4636857509613037, "alpha_loss": -0.33909159898757935, "alpha_value": 0.4689533785926814, "duration": 1.7261953353881836, "info_normalized_performance_mean": 0.19328975677490234, "info_normalized_performance_final": 0.22075557708740234, "info_performance_mean": 0.19328975677490234, "info_performance_final": 0.22075557708740234, "step": 401500}
{"episode_reward": 386.57942649066985, "episode": 4016.0, "batch_reward": 8.761220932006836, "critic_loss": 464.0554504394531, "actor_loss": -1471.398193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.5788562297821045, "alpha_loss": 0.1777605414390564, "alpha_value": 0.47011692323636245, "duration": 1.5061278343200684, "info_normalized_performance_mean": 0.9033506512641907, "info_normalized_performance_final": 0.9878472089767456, "info_performance_mean": 0.9033506512641907, "info_performance_final": 0.9878472089767456, "step": 402000}
{"episode_reward": 1806.7013888888855, "episode": 4021.0, "batch_reward": 8.544355392456055, "critic_loss": 475.66827392578125, "actor_loss": -1469.225341796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5583982467651367, "alpha_loss": -0.18570944666862488, "alpha_value": 0.47351561840070383, "duration": 1.4284722805023193, "info_normalized_performance_mean": 0.3923177421092987, "info_normalized_performance_final": 0.4557291567325592, "info_performance_mean": 0.3923177421092987, "info_performance_final": 0.4557291567325592, "step": 402500}
{"episode_reward": 784.6354166666674, "episode": 4026.0, "batch_reward": 7.624524116516113, "critic_loss": 728.4803466796875, "actor_loss": -1441.198974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.283057451248169, "alpha_loss": -0.3038329482078552, "alpha_value": 0.47904616878186695, "duration": 1.5577678680419922, "info_normalized_performance_mean": 0.882760226726532, "info_normalized_performance_final": 0.9940000176429749, "info_performance_mean": 0.882760226726532, "info_performance_final": 0.9940000176429749, "step": 403000}
{"episode_reward": 1765.520000000004, "episode": 4031.0, "batch_reward": 9.404203414916992, "critic_loss": 2195.23779296875, "actor_loss": -1499.3883056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.184011697769165, "alpha_loss": 0.017732031643390656, "alpha_value": 0.47984367125841954, "duration": 1.4681167602539062, "info_normalized_performance_mean": 0.48419642448425293, "info_normalized_performance_final": 0.5882936716079712, "info_performance_mean": 0.48419642448425293, "info_performance_final": 0.5882936716079712, "step": 403500}
{"episode_reward": 968.3928571428569, "episode": 4036.0, "batch_reward": 9.185691833496094, "critic_loss": 685.53759765625, "actor_loss": -1508.423583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.264542818069458, "alpha_loss": 0.05110304802656174, "alpha_value": 0.4827791337296081, "duration": 1.5910885334014893, "info_normalized_performance_mean": 0.3819318115711212, "info_normalized_performance_final": 0.42431819438934326, "info_performance_mean": 0.3819318115711212, "info_performance_final": 0.42431819438934326, "step": 404000}
{"episode_reward": 763.8636363636373, "episode": 4041.0, "batch_reward": 8.87478256225586, "critic_loss": 976.129638671875, "actor_loss": -1517.0234375, "actor_target_entropy": -3.0, "actor_entropy": 1.413163661956787, "alpha_loss": -0.18765327334403992, "alpha_value": 0.48684672708235943, "duration": 1.537750005722046, "info_normalized_performance_mean": 0.8453124761581421, "info_normalized_performance_final": 0.9375, "info_performance_mean": 0.8453124761581421, "info_performance_final": 0.9375, "step": 404500}
{"episode_reward": 1690.625, "episode": 4046.0, "batch_reward": 8.170425415039062, "critic_loss": 1469.212890625, "actor_loss": -1476.147705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.046871542930603, "alpha_loss": -0.21309882402420044, "alpha_value": 0.49276962808095714, "duration": 1.5190846920013428, "info_normalized_performance_mean": 0.3563251495361328, "info_normalized_performance_final": 0.38161057233810425, "info_performance_mean": 0.3563251495361328, "info_performance_final": 0.38161057233810425, "step": 405000}
{"episode_reward": 712.650240384616, "episode": 4051.0, "batch_reward": 8.488138198852539, "critic_loss": 824.745849609375, "actor_loss": -1443.0692138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3896912336349487, "alpha_loss": -0.006250657141208649, "alpha_value": 0.49472375603921714, "duration": 1.4924321174621582, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 405500}
{"episode_reward": 0.0, "episode": 4056.0, "batch_reward": 9.069201469421387, "critic_loss": 681.28466796875, "actor_loss": -1495.57568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.4060533046722412, "alpha_loss": -0.04964258521795273, "alpha_value": 0.4988616613769524, "duration": 1.545931339263916, "info_normalized_performance_mean": 0.2944064140319824, "info_normalized_performance_final": 0.3433155119419098, "info_performance_mean": 0.2944064140319824, "info_performance_final": 0.3433155119419098, "step": 406000}
{"episode_reward": 588.8128342245991, "episode": 4061.0, "batch_reward": 7.667348384857178, "critic_loss": 1005.5947265625, "actor_loss": -1428.3466796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0519729852676392, "alpha_loss": 0.054040104150772095, "alpha_value": 0.5058343368643191, "duration": 1.5836291313171387, "info_normalized_performance_mean": 0.7242521643638611, "info_normalized_performance_final": 0.7899159789085388, "info_performance_mean": 0.7242521643638611, "info_performance_final": 0.7899159789085388, "step": 406500}
{"episode_reward": 1448.5042016806733, "episode": 4066.0, "batch_reward": 8.364646911621094, "critic_loss": 494.3790283203125, "actor_loss": -1482.28271484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3936434984207153, "alpha_loss": -0.2312270998954773, "alpha_value": 0.5085208218849996, "duration": 1.570941686630249, "info_normalized_performance_mean": 0.13885681331157684, "info_normalized_performance_final": 0.15735653042793274, "info_performance_mean": 0.13885681331157684, "info_performance_final": 0.15735653042793274, "step": 407000}
{"episode_reward": 277.713675213675, "episode": 4071.0, "batch_reward": 9.171005249023438, "critic_loss": 596.4306640625, "actor_loss": -1530.2958984375, "actor_target_entropy": -3.0, "actor_entropy": 1.5347281694412231, "alpha_loss": 0.1321513056755066, "alpha_value": 0.5146679773261893, "duration": 1.5380077362060547, "info_normalized_performance_mean": 0.22853538393974304, "info_normalized_performance_final": 0.2785416543483734, "info_performance_mean": 0.22853538393974304, "info_performance_final": 0.2785416543483734, "step": 407500}
{"episode_reward": 457.0708333333329, "episode": 4076.0, "batch_reward": 9.128791809082031, "critic_loss": 372.33026123046875, "actor_loss": -1543.9385986328125, "actor_target_entropy": -3.0, "actor_entropy": 1.41649329662323, "alpha_loss": -0.04254690557718277, "alpha_value": 0.5198713311154581, "duration": 1.3951213359832764, "info_normalized_performance_mean": 0.15043748915195465, "info_normalized_performance_final": 0.17499999701976776, "info_performance_mean": 0.15043748915195465, "info_performance_final": 0.17499999701976776, "step": 408000}
{"episode_reward": 300.875, "episode": 4081.0, "batch_reward": 7.871916770935059, "critic_loss": 324.13348388671875, "actor_loss": -1430.740234375, "actor_target_entropy": -3.0, "actor_entropy": 1.3926939964294434, "alpha_loss": -0.27018511295318604, "alpha_value": 0.5280337774951034, "duration": 1.6179029941558838, "info_normalized_performance_mean": 0.8360393047332764, "info_normalized_performance_final": 0.9411764740943909, "info_performance_mean": 0.8360393047332764, "info_performance_final": 0.9411764740943909, "step": 408500}
{"episode_reward": 1672.078431372548, "episode": 4086.0, "batch_reward": 8.5208101272583, "critic_loss": 668.5460815429688, "actor_loss": -1483.60791015625, "actor_target_entropy": -3.0, "actor_entropy": 1.4035935401916504, "alpha_loss": -0.08839278668165207, "alpha_value": 0.5384434934047059, "duration": 1.7368342876434326, "info_normalized_performance_mean": 0.38857781887054443, "info_normalized_performance_final": 0.4778311848640442, "info_performance_mean": 0.38857781887054443, "info_performance_final": 0.4778311848640442, "step": 409000}
{"episode_reward": 777.1554487179473, "episode": 4091.0, "batch_reward": 8.674032211303711, "critic_loss": 1498.480712890625, "actor_loss": -1513.1976318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3523749113082886, "alpha_loss": -0.525841236114502, "alpha_value": 0.5458814068754586, "duration": 1.4395909309387207, "info_normalized_performance_mean": 0.496736079454422, "info_normalized_performance_final": 0.5460858345031738, "info_performance_mean": 0.496736079454422, "info_performance_final": 0.5460858345031738, "step": 409500}
{"episode_reward": 993.4722222222231, "episode": 4096.0, "batch_reward": 8.104130744934082, "critic_loss": 482.452880859375, "actor_loss": -1461.259765625, "actor_target_entropy": -3.0, "actor_entropy": 1.6337493658065796, "alpha_loss": 0.13310644030570984, "alpha_value": 0.5543667992904399, "step": 410000}
{"duration": 18.71121835708618, "info_normalized_performance_mean": 0.7402863502502441, "info_normalized_performance_final": 0.7994791865348816, "info_performance_mean": 0.7402863502502441, "info_performance_final": 0.7994791865348816, "step": 410000}
{"episode_reward": 1480.5729166666654, "episode": 4101.0, "batch_reward": 8.200955390930176, "critic_loss": 642.1472778320312, "actor_loss": -1512.5712890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2383506298065186, "alpha_loss": -0.33929741382598877, "alpha_value": 0.5666141578992027, "duration": 1.5543603897094727, "info_normalized_performance_mean": 0.3882996737957001, "info_normalized_performance_final": 0.47867563366889954, "info_performance_mean": 0.3882996737957001, "info_performance_final": 0.47867563366889954, "step": 410500}
{"episode_reward": 776.5993265993255, "episode": 4106.0, "batch_reward": 8.643193244934082, "critic_loss": 1502.43798828125, "actor_loss": -1526.1597900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.3332523107528687, "alpha_loss": -0.5385444164276123, "alpha_value": 0.5792233728126467, "duration": 1.5765471458435059, "info_normalized_performance_mean": 0.6600856781005859, "info_normalized_performance_final": 0.7251337170600891, "info_performance_mean": 0.6600856781005859, "info_performance_final": 0.7251337170600891, "step": 411000}
{"episode_reward": 1320.1711229946523, "episode": 4111.0, "batch_reward": 8.389713287353516, "critic_loss": 587.57958984375, "actor_loss": -1481.003173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3132867813110352, "alpha_loss": -0.2901890277862549, "alpha_value": 0.5948681995304216, "duration": 1.559696912765503, "info_normalized_performance_mean": 0.4412912130355835, "info_normalized_performance_final": 0.49511316418647766, "info_performance_mean": 0.4412912130355835, "info_performance_final": 0.49511316418647766, "step": 411500}
{"episode_reward": 882.5823045267502, "episode": 4116.0, "batch_reward": 8.143035888671875, "critic_loss": 461.0363464355469, "actor_loss": -1469.908447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.5736820697784424, "alpha_loss": -0.28948038816452026, "alpha_value": 0.6071294936606224, "duration": 1.747725009918213, "info_normalized_performance_mean": 0.24905557930469513, "info_normalized_performance_final": 0.2808375060558319, "info_performance_mean": 0.24905557930469513, "info_performance_final": 0.2808375060558319, "step": 412000}
{"episode_reward": 498.1110605370952, "episode": 4121.0, "batch_reward": 7.8060688972473145, "critic_loss": 545.193603515625, "actor_loss": -1533.1766357421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3599897623062134, "alpha_loss": -0.4179319739341736, "alpha_value": 0.6238415361843942, "duration": 1.526876449584961, "info_normalized_performance_mean": 0.7981695532798767, "info_normalized_performance_final": 0.8638392686843872, "info_performance_mean": 0.7981695532798767, "info_performance_final": 0.8638392686843872, "step": 412500}
{"episode_reward": 1596.3392857142867, "episode": 4126.0, "batch_reward": 8.895872116088867, "critic_loss": 297.50494384765625, "actor_loss": -1592.046630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.3152722120285034, "alpha_loss": 0.019607756286859512, "alpha_value": 0.6368025141658904, "duration": 1.5876693725585938, "info_normalized_performance_mean": 0.7403376698493958, "info_normalized_performance_final": 0.800000011920929, "info_performance_mean": 0.7403376698493958, "info_performance_final": 0.800000011920929, "step": 413000}
{"episode_reward": 1480.675, "episode": 4131.0, "batch_reward": 7.5832133293151855, "critic_loss": 324.1831359863281, "actor_loss": -1539.243896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.176020860671997, "alpha_loss": -0.16407355666160583, "alpha_value": 0.6465292379718183, "duration": 1.6026384830474854, "info_normalized_performance_mean": 0.32020846009254456, "info_normalized_performance_final": 0.35593539476394653, "info_performance_mean": 0.32020846009254456, "info_performance_final": 0.35593539476394653, "step": 413500}
{"episode_reward": 640.4169797145001, "episode": 4136.0, "batch_reward": 7.801609516143799, "critic_loss": 2979.51708984375, "actor_loss": -1545.17236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.386108636856079, "alpha_loss": -0.1331494301557541, "alpha_value": 0.6551258972692874, "duration": 1.518141269683838, "info_normalized_performance_mean": 0.26631683111190796, "info_normalized_performance_final": 0.2988682985305786, "info_performance_mean": 0.26631683111190796, "info_performance_final": 0.2988682985305786, "step": 414000}
{"episode_reward": 532.6337448559672, "episode": 4141.0, "batch_reward": 7.469558238983154, "critic_loss": 931.2486572265625, "actor_loss": -1511.925048828125, "actor_target_entropy": -3.0, "actor_entropy": 1.267155647277832, "alpha_loss": -0.4647980332374573, "alpha_value": 0.6634558138497259, "duration": 1.5968677997589111, "info_normalized_performance_mean": 0.32507145404815674, "info_normalized_performance_final": 0.37309524416923523, "info_performance_mean": 0.32507145404815674, "info_performance_final": 0.37309524416923523, "step": 414500}
{"episode_reward": 650.1428571428568, "episode": 4146.0, "batch_reward": 8.696670532226562, "critic_loss": 576.4288330078125, "actor_loss": -1634.7294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4570201635360718, "alpha_loss": -0.20047688484191895, "alpha_value": 0.6629004465146974, "duration": 1.5881586074829102, "info_normalized_performance_mean": 0.811536431312561, "info_normalized_performance_final": 0.890625, "info_performance_mean": 0.811536431312561, "info_performance_final": 0.890625, "step": 415000}
{"episode_reward": 1623.0729166666667, "episode": 4151.0, "batch_reward": 7.7460246086120605, "critic_loss": 937.7108764648438, "actor_loss": -1523.24658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4188224077224731, "alpha_loss": -0.23697848618030548, "alpha_value": 0.6605793468390752, "duration": 1.471217155456543, "info_normalized_performance_mean": 0.4562419056892395, "info_normalized_performance_final": 0.5101460814476013, "info_performance_mean": 0.4562419056892395, "info_performance_final": 0.5101460814476013, "step": 415500}
{"episode_reward": 912.4837662337651, "episode": 4156.0, "batch_reward": 8.985214233398438, "critic_loss": 456.4420166015625, "actor_loss": -1603.062744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.2756212949752808, "alpha_loss": -0.24698790907859802, "alpha_value": 0.6569501681687075, "duration": 1.5188310146331787, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 416000}
{"episode_reward": 0.0, "episode": 4161.0, "batch_reward": 8.323721885681152, "critic_loss": 548.0198974609375, "actor_loss": -1573.03759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.370617151260376, "alpha_loss": -0.015427276492118835, "alpha_value": 0.6546427828607678, "duration": 1.4370298385620117, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 416500}
{"episode_reward": 0.0, "episode": 4166.0, "batch_reward": 7.44979190826416, "critic_loss": 421.592041015625, "actor_loss": -1569.7685546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4399354457855225, "alpha_loss": -0.197172611951828, "alpha_value": 0.6495543379842375, "duration": 1.4825243949890137, "info_normalized_performance_mean": 0.744312047958374, "info_normalized_performance_final": 0.8560606241226196, "info_performance_mean": 0.744312047958374, "info_performance_final": 0.8560606241226196, "step": 417000}
{"episode_reward": 1488.6237373737367, "episode": 4171.0, "batch_reward": 8.080658912658691, "critic_loss": 855.2232055664062, "actor_loss": -1547.464599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.4618279933929443, "alpha_loss": -0.3385622501373291, "alpha_value": 0.6525503836551669, "duration": 1.512848138809204, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 417500}
{"episode_reward": 0.0, "episode": 4176.0, "batch_reward": 8.90609359741211, "critic_loss": 497.11651611328125, "actor_loss": -1572.8916015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5654107332229614, "alpha_loss": 0.19227151572704315, "alpha_value": 0.6483380073155215, "duration": 1.5883936882019043, "info_normalized_performance_mean": 0.6036380529403687, "info_normalized_performance_final": 0.7828054428100586, "info_performance_mean": 0.6036380529403687, "info_performance_final": 0.7828054428100586, "step": 418000}
{"episode_reward": 1207.276018099549, "episode": 4181.0, "batch_reward": 9.193511962890625, "critic_loss": 560.0653076171875, "actor_loss": -1611.388427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.5513731241226196, "alpha_loss": 0.0876639187335968, "alpha_value": 0.6465493926483205, "duration": 1.5320799350738525, "info_normalized_performance_mean": 0.8224015831947327, "info_normalized_performance_final": 0.9184027910232544, "info_performance_mean": 0.8224015831947327, "info_performance_final": 0.9184027910232544, "step": 418500}
{"episode_reward": 1644.8032407407438, "episode": 4186.0, "batch_reward": 8.098777770996094, "critic_loss": 790.21923828125, "actor_loss": -1543.0875244140625, "actor_target_entropy": -3.0, "actor_entropy": 1.8804223537445068, "alpha_loss": -0.1191222295165062, "alpha_value": 0.6421081558988424, "duration": 1.759946346282959, "info_normalized_performance_mean": 0.28934910893440247, "info_normalized_performance_final": 0.35138824582099915, "info_performance_mean": 0.28934910893440247, "info_performance_final": 0.35138824582099915, "step": 419000}
{"episode_reward": 578.6982248520715, "episode": 4191.0, "batch_reward": 8.759673118591309, "critic_loss": 319.5242614746094, "actor_loss": -1572.074462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.5062133073806763, "alpha_loss": 0.1435166895389557, "alpha_value": 0.6407870912421271, "duration": 1.5607259273529053, "info_normalized_performance_mean": 0.7158843874931335, "info_normalized_performance_final": 0.8219954371452332, "info_performance_mean": 0.7158843874931335, "info_performance_final": 0.8219954371452332, "step": 419500}
{"episode_reward": 1431.7687074829912, "episode": 4196.0, "batch_reward": 8.061598777770996, "critic_loss": 616.5450439453125, "actor_loss": -1588.2479248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3337950706481934, "alpha_loss": 0.02081403136253357, "alpha_value": 0.6409329620265379, "step": 420000}
{"duration": 18.238028287887573, "info_normalized_performance_mean": 0.5149899125099182, "info_normalized_performance_final": 0.5732499957084656, "info_performance_mean": 0.5149899125099182, "info_performance_final": 0.5732499957084656, "step": 420000}
{"episode_reward": 1029.980000000001, "episode": 4201.0, "batch_reward": 8.872888565063477, "critic_loss": 680.9118041992188, "actor_loss": -1589.97802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.573386788368225, "alpha_loss": 0.15524110198020935, "alpha_value": 0.6393700848343926, "duration": 1.6185698509216309, "info_normalized_performance_mean": 0.6429226398468018, "info_normalized_performance_final": 0.7310495376586914, "info_performance_mean": 0.6429226398468018, "info_performance_final": 0.7310495376586914, "step": 420500}
{"episode_reward": 1285.845481049561, "episode": 4206.0, "batch_reward": 8.727291107177734, "critic_loss": 392.2372741699219, "actor_loss": -1590.5693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6246148347854614, "alpha_loss": 0.5958462953567505, "alpha_value": 0.6274056406276506, "duration": 1.4580450057983398, "info_normalized_performance_mean": 0.16615737974643707, "info_normalized_performance_final": 0.1979166716337204, "info_performance_mean": 0.16615737974643707, "info_performance_final": 0.1979166716337204, "step": 421000}
{"episode_reward": 332.31481481481467, "episode": 4211.0, "batch_reward": 8.298627853393555, "critic_loss": 864.86083984375, "actor_loss": -1540.6123046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3723771572113037, "alpha_loss": 0.11918541043996811, "alpha_value": 0.6172117712952954, "duration": 1.524848461151123, "info_normalized_performance_mean": 0.46626633405685425, "info_normalized_performance_final": 0.5182291865348816, "info_performance_mean": 0.46626633405685425, "info_performance_final": 0.5182291865348816, "step": 421500}
{"episode_reward": 932.5325520833344, "episode": 4216.0, "batch_reward": 8.280009269714355, "critic_loss": 481.59564208984375, "actor_loss": -1552.197998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5544233322143555, "alpha_loss": 0.16533327102661133, "alpha_value": 0.6081532219168915, "duration": 1.4804792404174805, "info_normalized_performance_mean": 0.703503429889679, "info_normalized_performance_final": 0.8287981748580933, "info_performance_mean": 0.703503429889679, "info_performance_final": 0.8287981748580933, "step": 422000}
{"episode_reward": 1407.0068027210907, "episode": 4221.0, "batch_reward": 8.751733779907227, "critic_loss": 386.6092224121094, "actor_loss": -1553.39404296875, "actor_target_entropy": -3.0, "actor_entropy": 1.5170857906341553, "alpha_loss": 0.05282878875732422, "alpha_value": 0.6089342987580331, "duration": 1.6025896072387695, "info_normalized_performance_mean": 0.608680009841919, "info_normalized_performance_final": 0.6779999732971191, "info_performance_mean": 0.608680009841919, "info_performance_final": 0.6779999732971191, "step": 422500}
{"episode_reward": 1217.3599999999972, "episode": 4226.0, "batch_reward": 8.313129425048828, "critic_loss": 534.7611083984375, "actor_loss": -1573.939208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.487913727760315, "alpha_loss": 0.14916671812534332, "alpha_value": 0.6050702037959739, "duration": 1.5926754474639893, "info_normalized_performance_mean": 0.8524519205093384, "info_normalized_performance_final": 0.9375, "info_performance_mean": 0.8524519205093384, "info_performance_final": 0.9375, "step": 423000}
{"episode_reward": 1704.9038461538462, "episode": 4231.0, "batch_reward": 9.059450149536133, "critic_loss": 827.837646484375, "actor_loss": -1563.87744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.5013949871063232, "alpha_loss": 0.3064187169075012, "alpha_value": 0.5986482927997102, "duration": 1.4876370429992676, "info_normalized_performance_mean": 0.1823764592409134, "info_normalized_performance_final": 0.24470588564872742, "info_performance_mean": 0.1823764592409134, "info_performance_final": 0.24470588564872742, "step": 423500}
{"episode_reward": 364.7529411764705, "episode": 4236.0, "batch_reward": 8.233823776245117, "critic_loss": 794.2965087890625, "actor_loss": -1536.662353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.5773649215698242, "alpha_loss": 0.059846483170986176, "alpha_value": 0.5959080738697221, "duration": 1.6325743198394775, "info_normalized_performance_mean": 0.4512207806110382, "info_normalized_performance_final": 0.5129166841506958, "info_performance_mean": 0.4512207806110382, "info_performance_final": 0.5129166841506958, "step": 424000}
{"episode_reward": 902.4416666666663, "episode": 4241.0, "batch_reward": 8.24211311340332, "critic_loss": 1387.647216796875, "actor_loss": -1540.8804931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.7455668449401855, "alpha_loss": 0.3833111822605133, "alpha_value": 0.5873922919139216, "duration": 1.5651099681854248, "info_normalized_performance_mean": 0.6350734233856201, "info_normalized_performance_final": 0.6985294222831726, "info_performance_mean": 0.6350734233856201, "info_performance_final": 0.6985294222831726, "step": 424500}
{"episode_reward": 1270.1470588235306, "episode": 4246.0, "batch_reward": 7.947721004486084, "critic_loss": 417.87158203125, "actor_loss": -1518.966552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3322937488555908, "alpha_loss": 0.19533053040504456, "alpha_value": 0.5825833739541287, "duration": 1.6536331176757812, "info_normalized_performance_mean": 0.28955742716789246, "info_normalized_performance_final": 0.32295483350753784, "info_performance_mean": 0.28955742716789246, "info_performance_final": 0.32295483350753784, "step": 425000}
{"episode_reward": 579.1147741147754, "episode": 4251.0, "batch_reward": 8.922602653503418, "critic_loss": 350.347412109375, "actor_loss": -1560.8870849609375, "actor_target_entropy": -3.0, "actor_entropy": 1.7224878072738647, "alpha_loss": 0.32538357377052307, "alpha_value": 0.5779808392070386, "duration": 1.4887604713439941, "info_normalized_performance_mean": 0.7966160774230957, "info_normalized_performance_final": 0.8964646458625793, "info_performance_mean": 0.7966160774230957, "info_performance_final": 0.8964646458625793, "step": 425500}
{"episode_reward": 1593.2323232323213, "episode": 4256.0, "batch_reward": 8.230402946472168, "critic_loss": 709.2962036132812, "actor_loss": -1526.5618896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.364601731300354, "alpha_loss": 0.20672263205051422, "alpha_value": 0.5734751290498233, "duration": 1.4997785091400146, "info_normalized_performance_mean": 0.6996874809265137, "info_normalized_performance_final": 0.7578125, "info_performance_mean": 0.6996874809265137, "info_performance_final": 0.7578125, "step": 426000}
{"episode_reward": 1399.375, "episode": 4261.0, "batch_reward": 8.094350814819336, "critic_loss": 376.262939453125, "actor_loss": -1498.9322509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.4782941341400146, "alpha_loss": 0.19919009506702423, "alpha_value": 0.5680321885831547, "duration": 1.6794612407684326, "info_normalized_performance_mean": 0.35804739594459534, "info_normalized_performance_final": 0.4094589650630951, "info_performance_mean": 0.35804739594459534, "info_performance_final": 0.4094589650630951, "step": 426500}
{"episode_reward": 716.0949576739066, "episode": 4266.0, "batch_reward": 8.050566673278809, "critic_loss": 595.1728515625, "actor_loss": -1513.8282470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2985819578170776, "alpha_loss": -0.10889317095279694, "alpha_value": 0.5634383615678322, "duration": 1.5121562480926514, "info_normalized_performance_mean": 0.5418341159820557, "info_normalized_performance_final": 0.601934552192688, "info_performance_mean": 0.5418341159820557, "info_performance_final": 0.601934552192688, "step": 427000}
{"episode_reward": 1083.6681547619046, "episode": 4271.0, "batch_reward": 8.975414276123047, "critic_loss": 663.3718872070312, "actor_loss": -1576.906005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.7675745487213135, "alpha_loss": 0.1904696524143219, "alpha_value": 0.5577680503787443, "duration": 1.6751770973205566, "info_normalized_performance_mean": 0.3884488642215729, "info_normalized_performance_final": 0.42800381779670715, "info_performance_mean": 0.3884488642215729, "info_performance_final": 0.42800381779670715, "step": 427500}
{"episode_reward": 776.8976478067398, "episode": 4276.0, "batch_reward": 7.848501205444336, "critic_loss": 507.8899841308594, "actor_loss": -1517.162841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3426417112350464, "alpha_loss": 0.1752312183380127, "alpha_value": 0.5492293745775025, "duration": 1.6007070541381836, "info_normalized_performance_mean": 0.40620532631874084, "info_normalized_performance_final": 0.456845223903656, "info_performance_mean": 0.40620532631874084, "info_performance_final": 0.456845223903656, "step": 428000}
{"episode_reward": 812.4107142857159, "episode": 4281.0, "batch_reward": 8.255477905273438, "critic_loss": 739.4324951171875, "actor_loss": -1516.522216796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5854438543319702, "alpha_loss": 0.13637293875217438, "alpha_value": 0.5447356263484257, "duration": 1.5287132263183594, "info_normalized_performance_mean": 0.6894623041152954, "info_normalized_performance_final": 0.7837519645690918, "info_performance_mean": 0.6894623041152954, "info_performance_final": 0.7837519645690918, "step": 428500}
{"episode_reward": 1378.92464678179, "episode": 4286.0, "batch_reward": 8.485536575317383, "critic_loss": 472.73297119140625, "actor_loss": -1543.99462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.4461619853973389, "alpha_loss": 0.07327977567911148, "alpha_value": 0.5417155490070867, "duration": 1.4910292625427246, "info_normalized_performance_mean": 0.6504116058349609, "info_normalized_performance_final": 0.7039215564727783, "info_performance_mean": 0.6504116058349609, "info_performance_final": 0.7039215564727783, "step": 429000}
{"episode_reward": 1300.8235294117646, "episode": 4291.0, "batch_reward": 7.963814735412598, "critic_loss": 690.0054321289062, "actor_loss": -1501.7576904296875, "actor_target_entropy": -3.0, "actor_entropy": 1.5890545845031738, "alpha_loss": -0.024759739637374878, "alpha_value": 0.5355134948850361, "duration": 1.44527268409729, "info_normalized_performance_mean": 0.5711904764175415, "info_normalized_performance_final": 0.6269841194152832, "info_performance_mean": 0.5711904764175415, "info_performance_final": 0.6269841194152832, "step": 429500}
{"episode_reward": 1142.3809523809527, "episode": 4296.0, "batch_reward": 8.299249649047852, "critic_loss": 373.69549560546875, "actor_loss": -1511.9786376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.2751266956329346, "alpha_loss": 0.18725654482841492, "alpha_value": 0.5279301090192665, "step": 430000}
{"duration": 19.05692172050476, "info_normalized_performance_mean": 0.6527183055877686, "info_normalized_performance_final": 0.72817462682724, "info_performance_mean": 0.6527183055877686, "info_performance_final": 0.72817462682724, "step": 430000}
{"episode_reward": 1305.436507936507, "episode": 4301.0, "batch_reward": 8.084821701049805, "critic_loss": 733.2347412109375, "actor_loss": -1512.7430419921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3526973724365234, "alpha_loss": 0.28743788599967957, "alpha_value": 0.5200135871270971, "duration": 1.506164312362671, "info_normalized_performance_mean": 0.3823394775390625, "info_normalized_performance_final": 0.4310850501060486, "info_performance_mean": 0.3823394775390625, "info_performance_final": 0.4310850501060486, "step": 430500}
{"episode_reward": 764.6790485500165, "episode": 4306.0, "batch_reward": 8.87327766418457, "critic_loss": 1546.412841796875, "actor_loss": -1547.2021484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3537094593048096, "alpha_loss": 0.12062091380357742, "alpha_value": 0.5131221512107187, "duration": 1.463637351989746, "info_normalized_performance_mean": 0.8200595378875732, "info_normalized_performance_final": 0.8839285969734192, "info_performance_mean": 0.8200595378875732, "info_performance_final": 0.8839285969734192, "step": 431000}
{"episode_reward": 1640.1190476190447, "episode": 4311.0, "batch_reward": 7.780074119567871, "critic_loss": 771.11181640625, "actor_loss": -1494.695068359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2019363641738892, "alpha_loss": -0.08198164403438568, "alpha_value": 0.5075503098885735, "duration": 1.5584092140197754, "info_normalized_performance_mean": 0.43091505765914917, "info_normalized_performance_final": 0.48225000500679016, "info_performance_mean": 0.43091505765914917, "info_performance_final": 0.48225000500679016, "step": 431500}
{"episode_reward": 861.829999999999, "episode": 4316.0, "batch_reward": 8.103028297424316, "critic_loss": 308.63299560546875, "actor_loss": -1488.351806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.495557188987732, "alpha_loss": 0.10074007511138916, "alpha_value": 0.4976972389524727, "duration": 1.5800879001617432, "info_normalized_performance_mean": 0.12440268695354462, "info_normalized_performance_final": 0.18125469982624054, "info_performance_mean": 0.12440268695354462, "info_performance_final": 0.18125469982624054, "step": 432000}
{"episode_reward": 248.80540946656657, "episode": 4321.0, "batch_reward": 8.37033462524414, "critic_loss": 436.6931457519531, "actor_loss": -1508.5836181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.544634461402893, "alpha_loss": -0.0006030425429344177, "alpha_value": 0.49143536373994223, "duration": 1.5620088577270508, "info_normalized_performance_mean": 0.7585989236831665, "info_normalized_performance_final": 0.833791196346283, "info_performance_mean": 0.7585989236831665, "info_performance_final": 0.833791196346283, "step": 432500}
{"episode_reward": 1517.1978021977986, "episode": 4326.0, "batch_reward": 8.737975120544434, "critic_loss": 307.88641357421875, "actor_loss": -1544.896240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2279303073883057, "alpha_loss": 0.0946216732263565, "alpha_value": 0.4831539374959639, "duration": 1.675363540649414, "info_normalized_performance_mean": 0.3536570370197296, "info_normalized_performance_final": 0.3949459493160248, "info_performance_mean": 0.3536570370197296, "info_performance_final": 0.3949459493160248, "step": 433000}
{"episode_reward": 707.3140495867775, "episode": 4331.0, "batch_reward": 8.910143852233887, "critic_loss": 1420.589599609375, "actor_loss": -1515.668701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3586406707763672, "alpha_loss": -0.004327297210693359, "alpha_value": 0.4770243743011502, "duration": 1.4719994068145752, "info_normalized_performance_mean": 0.45687589049339294, "info_normalized_performance_final": 0.5150327086448669, "info_performance_mean": 0.45687589049339294, "info_performance_final": 0.5150327086448669, "step": 433500}
{"episode_reward": 913.7516339869288, "episode": 4336.0, "batch_reward": 8.779787063598633, "critic_loss": 361.59405517578125, "actor_loss": -1506.4111328125, "actor_target_entropy": -3.0, "actor_entropy": 1.484205961227417, "alpha_loss": 0.1075785756111145, "alpha_value": 0.4755677778426987, "duration": 1.5668137073516846, "info_normalized_performance_mean": 0.7498969435691833, "info_normalized_performance_final": 0.8367646932601929, "info_performance_mean": 0.7498969435691833, "info_performance_final": 0.8367646932601929, "step": 434000}
{"episode_reward": 1499.79411764706, "episode": 4341.0, "batch_reward": 8.59007740020752, "critic_loss": 1007.64990234375, "actor_loss": -1465.121337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2212709188461304, "alpha_loss": -0.10800449550151825, "alpha_value": 0.4675351429259851, "duration": 1.4843454360961914, "info_normalized_performance_mean": 0.39276474714279175, "info_normalized_performance_final": 0.4505208432674408, "info_performance_mean": 0.39276474714279175, "info_performance_final": 0.4505208432674408, "step": 434500}
{"episode_reward": 785.5295138888881, "episode": 4346.0, "batch_reward": 8.859872817993164, "critic_loss": 306.43914794921875, "actor_loss": -1489.420166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.305295467376709, "alpha_loss": 0.10027826577425003, "alpha_value": 0.46323442187271757, "duration": 1.4983248710632324, "info_normalized_performance_mean": 0.4935389757156372, "info_normalized_performance_final": 0.5422077775001526, "info_performance_mean": 0.4935389757156372, "info_performance_final": 0.5422077775001526, "step": 435000}
{"episode_reward": 987.0779220779209, "episode": 4351.0, "batch_reward": 8.262609481811523, "critic_loss": 1104.804931640625, "actor_loss": -1477.3291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1609747409820557, "alpha_loss": -0.04822784662246704, "alpha_value": 0.4588147497013968, "duration": 1.5213854312896729, "info_normalized_performance_mean": 0.15704545378684998, "info_normalized_performance_final": 0.30454546213150024, "info_performance_mean": 0.15704545378684998, "info_performance_final": 0.30454546213150024, "step": 435500}
{"episode_reward": 314.09090909090895, "episode": 4356.0, "batch_reward": 7.8612823486328125, "critic_loss": 582.070556640625, "actor_loss": -1506.48681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2400141954421997, "alpha_loss": -0.34520095586776733, "alpha_value": 0.4542927945339283, "duration": 1.470482349395752, "info_normalized_performance_mean": 0.36437103152275085, "info_normalized_performance_final": 0.4124999940395355, "info_performance_mean": 0.36437103152275085, "info_performance_final": 0.4124999940395355, "step": 436000}
{"episode_reward": 728.7421875, "episode": 4361.0, "batch_reward": 8.5331449508667, "critic_loss": 307.3665771484375, "actor_loss": -1519.029541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1718926429748535, "alpha_loss": 0.1584089994430542, "alpha_value": 0.4505893377766169, "duration": 1.68878173828125, "info_normalized_performance_mean": 0.408504456281662, "info_normalized_performance_final": 0.4562937021255493, "info_performance_mean": 0.408504456281662, "info_performance_final": 0.4562937021255493, "step": 436500}
{"episode_reward": 817.0089001907188, "episode": 4366.0, "batch_reward": 8.224939346313477, "critic_loss": 181.67727661132812, "actor_loss": -1444.8277587890625, "actor_target_entropy": -3.0, "actor_entropy": 1.3463704586029053, "alpha_loss": -0.19360020756721497, "alpha_value": 0.44663720847459576, "duration": 1.5108003616333008, "info_normalized_performance_mean": 0.7112846970558167, "info_normalized_performance_final": 0.7690972089767456, "info_performance_mean": 0.7112846970558167, "info_performance_final": 0.7690972089767456, "step": 437000}
{"episode_reward": 1422.5694444444425, "episode": 4371.0, "batch_reward": 8.015844345092773, "critic_loss": 778.3004760742188, "actor_loss": -1461.601318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.1893361806869507, "alpha_loss": -0.09031558036804199, "alpha_value": 0.44431295949321403, "duration": 1.6072616577148438, "info_normalized_performance_mean": 0.4880658984184265, "info_normalized_performance_final": 0.5661008358001709, "info_performance_mean": 0.4880658984184265, "info_performance_final": 0.5661008358001709, "step": 437500}
{"episode_reward": 976.1316872427997, "episode": 4376.0, "batch_reward": 8.234822273254395, "critic_loss": 442.4920654296875, "actor_loss": -1457.05859375, "actor_target_entropy": -3.0, "actor_entropy": 1.2743358612060547, "alpha_loss": 0.010975103825330734, "alpha_value": 0.4422969623017922, "duration": 1.4252088069915771, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 438000}
{"episode_reward": 0.0, "episode": 4381.0, "batch_reward": 8.119002342224121, "critic_loss": 833.8243408203125, "actor_loss": -1469.315673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.1080987453460693, "alpha_loss": -0.1585586965084076, "alpha_value": 0.43866690117897117, "duration": 1.5522618293762207, "info_normalized_performance_mean": 0.4700184762477875, "info_normalized_performance_final": 0.5166666507720947, "info_performance_mean": 0.4700184762477875, "info_performance_final": 0.5166666507720947, "step": 438500}
{"episode_reward": 940.0370370370382, "episode": 4386.0, "batch_reward": 7.0954790115356445, "critic_loss": 2123.31689453125, "actor_loss": -1428.854248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.2913000583648682, "alpha_loss": 0.04664729908108711, "alpha_value": 0.4367169701283678, "duration": 1.4132609367370605, "info_normalized_performance_mean": 0.6219286322593689, "info_normalized_performance_final": 0.6714285612106323, "info_performance_mean": 0.6219286322593689, "info_performance_final": 0.6714285612106323, "step": 439000}
{"episode_reward": 1243.857142857142, "episode": 4391.0, "batch_reward": 8.634666442871094, "critic_loss": 435.77935791015625, "actor_loss": -1481.9383544921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3578364849090576, "alpha_loss": -0.10206501185894012, "alpha_value": 0.43379187732705543, "duration": 1.4976468086242676, "info_normalized_performance_mean": 0.39093002676963806, "info_normalized_performance_final": 0.4293154776096344, "info_performance_mean": 0.39093002676963806, "info_performance_final": 0.4293154776096344, "step": 439500}
{"episode_reward": 781.8601190476187, "episode": 4396.0, "batch_reward": 8.561814308166504, "critic_loss": 802.3375244140625, "actor_loss": -1469.9560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.2327611446380615, "alpha_loss": -0.004114434123039246, "alpha_value": 0.43126247894038, "step": 440000}
{"duration": 18.310412883758545, "info_normalized_performance_mean": 0.5396027565002441, "info_normalized_performance_final": 0.6089285612106323, "info_performance_mean": 0.5396027565002441, "info_performance_final": 0.6089285612106323, "step": 440000}
{"episode_reward": 1079.2053571428576, "episode": 4401.0, "batch_reward": 8.634979248046875, "critic_loss": 378.694580078125, "actor_loss": -1477.3828125, "actor_target_entropy": -3.0, "actor_entropy": 1.281998634338379, "alpha_loss": 0.0014045573770999908, "alpha_value": 0.4284140380447738, "duration": 1.42110276222229, "info_normalized_performance_mean": 0.3519165813922882, "info_normalized_performance_final": 0.3883333206176758, "info_performance_mean": 0.3519165813922882, "info_performance_final": 0.3883333206176758, "step": 440500}
{"episode_reward": 703.8333333333322, "episode": 4406.0, "batch_reward": 8.577262878417969, "critic_loss": 772.6371459960938, "actor_loss": -1517.35205078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7649863958358765, "alpha_loss": -0.04090369492769241, "alpha_value": 0.4253260557107634, "duration": 1.61405611038208, "info_normalized_performance_mean": 0.5388243794441223, "info_normalized_performance_final": 0.601190447807312, "info_performance_mean": 0.5388243794441223, "info_performance_final": 0.601190447807312, "step": 441000}
{"episode_reward": 1077.6488095238096, "episode": 4411.0, "batch_reward": 7.637094020843506, "critic_loss": 436.7967224121094, "actor_loss": -1395.367919921875, "actor_target_entropy": -3.0, "actor_entropy": 1.2795076370239258, "alpha_loss": 0.07475455105304718, "alpha_value": 0.422988927771308, "duration": 1.5468394756317139, "info_normalized_performance_mean": 0.7717031240463257, "info_normalized_performance_final": 0.921875, "info_performance_mean": 0.7717031240463257, "info_performance_final": 0.921875, "step": 441500}
{"episode_reward": 1543.40625, "episode": 4416.0, "batch_reward": 9.455265998840332, "critic_loss": 270.11309814453125, "actor_loss": -1504.33544921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4168661832809448, "alpha_loss": 0.21850235760211945, "alpha_value": 0.4207263209209177, "duration": 1.5548169612884521, "info_normalized_performance_mean": 0.7570684552192688, "info_normalized_performance_final": 0.8764880895614624, "info_performance_mean": 0.7570684552192688, "info_performance_final": 0.8764880895614624, "step": 442000}
{"episode_reward": 1514.1369047619064, "episode": 4421.0, "batch_reward": 8.688603401184082, "critic_loss": 835.7945556640625, "actor_loss": -1467.6572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.4593446254730225, "alpha_loss": 0.00975019857287407, "alpha_value": 0.4192031482265296, "duration": 1.5012946128845215, "info_normalized_performance_mean": 0.40367981791496277, "info_normalized_performance_final": 0.4449218809604645, "info_performance_mean": 0.40367981791496277, "info_performance_final": 0.4449218809604645, "step": 442500}
{"episode_reward": 807.359375, "episode": 4426.0, "batch_reward": 8.631856918334961, "critic_loss": 401.73297119140625, "actor_loss": -1419.596923828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3703012466430664, "alpha_loss": -0.016384383663535118, "alpha_value": 0.415742198839211, "duration": 1.5436346530914307, "info_normalized_performance_mean": 0.5516176223754883, "info_normalized_performance_final": 0.6176470518112183, "info_performance_mean": 0.5516176223754883, "info_performance_final": 0.6176470518112183, "step": 443000}
{"episode_reward": 1103.2352941176464, "episode": 4431.0, "batch_reward": 10.075471878051758, "critic_loss": 495.3921203613281, "actor_loss": -1576.4237060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4619262218475342, "alpha_loss": 0.31470194458961487, "alpha_value": 0.41333385812890094, "duration": 1.5170602798461914, "info_normalized_performance_mean": 0.6088818311691284, "info_normalized_performance_final": 0.7257652878761292, "info_performance_mean": 0.6088818311691284, "info_performance_final": 0.7257652878761292, "step": 443500}
{"episode_reward": 1217.7636054421785, "episode": 4436.0, "batch_reward": 7.642976760864258, "critic_loss": 828.1375732421875, "actor_loss": -1375.60986328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0850415229797363, "alpha_loss": 0.08304805308580399, "alpha_value": 0.41023969785611075, "duration": 1.5122935771942139, "info_normalized_performance_mean": 0.38419264554977417, "info_normalized_performance_final": 0.4231770932674408, "info_performance_mean": 0.38419264554977417, "info_performance_final": 0.4231770932674408, "step": 444000}
{"episode_reward": 768.385416666666, "episode": 4441.0, "batch_reward": 8.356931686401367, "critic_loss": 487.5575866699219, "actor_loss": -1419.229736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.1187629699707031, "alpha_loss": 0.07129848003387451, "alpha_value": 0.4042361231764261, "duration": 1.6321935653686523, "info_normalized_performance_mean": 0.4625229239463806, "info_normalized_performance_final": 0.5231249928474426, "info_performance_mean": 0.4625229239463806, "info_performance_final": 0.5231249928474426, "step": 444500}
{"episode_reward": 925.045833333332, "episode": 4446.0, "batch_reward": 8.538680076599121, "critic_loss": 828.666259765625, "actor_loss": -1430.48193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.1090489625930786, "alpha_loss": -0.10815597325563431, "alpha_value": 0.39989798406900623, "duration": 1.5690021514892578, "info_normalized_performance_mean": 0.46296295523643494, "info_normalized_performance_final": 0.5206789970397949, "info_performance_mean": 0.46296295523643494, "info_performance_final": 0.5206789970397949, "step": 445000}
{"episode_reward": 925.9259259259272, "episode": 4451.0, "batch_reward": 8.964043617248535, "critic_loss": 620.2266845703125, "actor_loss": -1444.37255859375, "actor_target_entropy": -3.0, "actor_entropy": 1.296149492263794, "alpha_loss": -0.005144104361534119, "alpha_value": 0.39809710942974447, "duration": 1.612682580947876, "info_normalized_performance_mean": 0.8035556077957153, "info_normalized_performance_final": 0.9607843160629272, "info_performance_mean": 0.8035556077957153, "info_performance_final": 0.9607843160629272, "step": 445500}
{"episode_reward": 1607.1111111111118, "episode": 4456.0, "batch_reward": 8.861851692199707, "critic_loss": 530.0985717773438, "actor_loss": -1439.986083984375, "actor_target_entropy": -3.0, "actor_entropy": 1.336683750152588, "alpha_loss": -0.02926032990217209, "alpha_value": 0.39650941548286345, "duration": 1.5093348026275635, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 446000}
{"episode_reward": 0.0, "episode": 4461.0, "batch_reward": 8.867010116577148, "critic_loss": 608.5968017578125, "actor_loss": -1433.776611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.2152206897735596, "alpha_loss": -0.2586878836154938, "alpha_value": 0.397600272841135, "duration": 1.4953961372375488, "info_normalized_performance_mean": 0.8675258159637451, "info_normalized_performance_final": 0.9693877696990967, "info_performance_mean": 0.8675258159637451, "info_performance_final": 0.9693877696990967, "step": 446500}
{"episode_reward": 1735.0510204081602, "episode": 4466.0, "batch_reward": 8.711990356445312, "critic_loss": 300.5556640625, "actor_loss": -1447.094970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.4557335376739502, "alpha_loss": -0.022212818264961243, "alpha_value": 0.4003346023430147, "duration": 1.5430514812469482, "info_normalized_performance_mean": 0.8522158861160278, "info_normalized_performance_final": 0.9289772510528564, "info_performance_mean": 0.8522158861160278, "info_performance_final": 0.9289772510528564, "step": 447000}
{"episode_reward": 1704.4318181818205, "episode": 4471.0, "batch_reward": 10.009236335754395, "critic_loss": 419.9979553222656, "actor_loss": -1512.954345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.216146469116211, "alpha_loss": 0.18854883313179016, "alpha_value": 0.4010668103782288, "duration": 1.510880947113037, "info_normalized_performance_mean": 0.3991416096687317, "info_normalized_performance_final": 0.4283333420753479, "info_performance_mean": 0.3991416096687317, "info_performance_final": 0.4283333420753479, "step": 447500}
{"episode_reward": 798.2833333333349, "episode": 4476.0, "batch_reward": 9.019007682800293, "critic_loss": 310.2988586425781, "actor_loss": -1444.498291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.4779837131500244, "alpha_loss": 0.14699845016002655, "alpha_value": 0.4006170350914621, "duration": 1.519517183303833, "info_normalized_performance_mean": 0.3850667476654053, "info_normalized_performance_final": 0.4349951148033142, "info_performance_mean": 0.3850667476654053, "info_performance_final": 0.4349951148033142, "step": 448000}
{"episode_reward": 770.1335940045627, "episode": 4481.0, "batch_reward": 9.112658500671387, "critic_loss": 603.3134765625, "actor_loss": -1423.015869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.567457675933838, "alpha_loss": -0.0523361973464489, "alpha_value": 0.3995038557370516, "duration": 1.576462745666504, "info_normalized_performance_mean": 0.7339428663253784, "info_normalized_performance_final": 0.8371428847312927, "info_performance_mean": 0.7339428663253784, "info_performance_final": 0.8371428847312927, "step": 448500}
{"episode_reward": 1467.885714285717, "episode": 4486.0, "batch_reward": 9.74459457397461, "critic_loss": 594.9970703125, "actor_loss": -1475.658447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3455071449279785, "alpha_loss": 0.006754130125045776, "alpha_value": 0.3999230352091048, "duration": 1.5676367282867432, "info_normalized_performance_mean": 0.8839834332466125, "info_normalized_performance_final": 0.9711538553237915, "info_performance_mean": 0.8839834332466125, "info_performance_final": 0.9711538553237915, "step": 449000}
{"episode_reward": 1767.9670329670319, "episode": 4491.0, "batch_reward": 9.736294746398926, "critic_loss": 650.30859375, "actor_loss": -1476.6275634765625, "actor_target_entropy": -3.0, "actor_entropy": 1.3195066452026367, "alpha_loss": 0.37042173743247986, "alpha_value": 0.3986469636795414, "duration": 1.7837464809417725, "info_normalized_performance_mean": 0.30619025230407715, "info_normalized_performance_final": 0.37608101963996887, "info_performance_mean": 0.30619025230407715, "info_performance_final": 0.37608101963996887, "step": 449500}
{"episode_reward": 612.3805188893944, "episode": 4496.0, "batch_reward": 9.42288589477539, "critic_loss": 450.0464782714844, "actor_loss": -1422.4921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6176750659942627, "alpha_loss": 0.01883615553379059, "alpha_value": 0.3949397200826908, "step": 450000}
{"duration": 18.38910150527954, "info_normalized_performance_mean": 0.43804848194122314, "info_normalized_performance_final": 0.48341837525367737, "info_performance_mean": 0.43804848194122314, "info_performance_final": 0.48341837525367737, "step": 450000}
{"episode_reward": 876.0969387755113, "episode": 4501.0, "batch_reward": 9.021387100219727, "critic_loss": 742.5346069335938, "actor_loss": -1430.313232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.2076303958892822, "alpha_loss": -0.050357647240161896, "alpha_value": 0.3925397124793674, "duration": 1.6170988082885742, "info_normalized_performance_mean": 0.7663315534591675, "info_normalized_performance_final": 0.9109347462654114, "info_performance_mean": 0.7663315534591675, "info_performance_final": 0.9109347462654114, "step": 450500}
{"episode_reward": 1532.6631393298073, "episode": 4506.0, "batch_reward": 9.229816436767578, "critic_loss": 291.9848327636719, "actor_loss": -1441.373779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.2259305715560913, "alpha_loss": -0.22646911442279816, "alpha_value": 0.39166743602564424, "duration": 1.6414780616760254, "info_normalized_performance_mean": 0.7216598391532898, "info_normalized_performance_final": 0.7799999713897705, "info_performance_mean": 0.7216598391532898, "info_performance_final": 0.7799999713897705, "step": 451000}
{"episode_reward": 1443.3199999999986, "episode": 4511.0, "batch_reward": 9.72614860534668, "critic_loss": 246.00259399414062, "actor_loss": -1438.171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5192499160766602, "alpha_loss": 0.08634210377931595, "alpha_value": 0.3881938276638049, "duration": 1.6995232105255127, "info_normalized_performance_mean": 0.367228239774704, "info_normalized_performance_final": 0.41640177369117737, "info_performance_mean": 0.367228239774704, "info_performance_final": 0.41640177369117737, "step": 451500}
{"episode_reward": 734.456452638271, "episode": 4516.0, "batch_reward": 9.933406829833984, "critic_loss": 401.82391357421875, "actor_loss": -1484.9296875, "actor_target_entropy": -3.0, "actor_entropy": 0.935526967048645, "alpha_loss": 0.00812346488237381, "alpha_value": 0.3844059770806055, "duration": 1.5647239685058594, "info_normalized_performance_mean": 0.7226439714431763, "info_normalized_performance_final": 0.8269230723381042, "info_performance_mean": 0.7226439714431763, "info_performance_final": 0.8269230723381042, "step": 452000}
{"episode_reward": 1445.2884615384628, "episode": 4521.0, "batch_reward": 8.961166381835938, "critic_loss": 717.3482666015625, "actor_loss": -1386.6162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1274206638336182, "alpha_loss": -0.13434873521327972, "alpha_value": 0.3816783293301288, "duration": 1.4980876445770264, "info_normalized_performance_mean": 0.6836717128753662, "info_normalized_performance_final": 0.7447916865348816, "info_performance_mean": 0.6836717128753662, "info_performance_final": 0.7447916865348816, "step": 452500}
{"episode_reward": 1367.3437499999993, "episode": 4526.0, "batch_reward": 9.667099952697754, "critic_loss": 986.3949584960938, "actor_loss": -1444.476806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2466015815734863, "alpha_loss": 0.0765371322631836, "alpha_value": 0.3765088400691458, "duration": 1.744612693786621, "info_normalized_performance_mean": 0.47791948914527893, "info_normalized_performance_final": 0.5344328880310059, "info_performance_mean": 0.47791948914527893, "info_performance_final": 0.5344328880310059, "step": 453000}
{"episode_reward": 955.8391203703694, "episode": 4531.0, "batch_reward": 9.385055541992188, "critic_loss": 789.825927734375, "actor_loss": -1425.9052734375, "actor_target_entropy": -3.0, "actor_entropy": 1.4430347681045532, "alpha_loss": 0.031008072197437286, "alpha_value": 0.3726439336077868, "duration": 1.5836513042449951, "info_normalized_performance_mean": 0.8729149103164673, "info_normalized_performance_final": 0.9895424842834473, "info_performance_mean": 0.8729149103164673, "info_performance_final": 0.9895424842834473, "step": 453500}
{"episode_reward": 1745.8300653594738, "episode": 4536.0, "batch_reward": 9.870893478393555, "critic_loss": 369.21905517578125, "actor_loss": -1426.07958984375, "actor_target_entropy": -3.0, "actor_entropy": 1.4541912078857422, "alpha_loss": 0.1959516406059265, "alpha_value": 0.370976829365404, "duration": 1.5633978843688965, "info_normalized_performance_mean": 0.5922461152076721, "info_normalized_performance_final": 0.6695963740348816, "info_performance_mean": 0.5922461152076721, "info_performance_final": 0.6695963740348816, "step": 454000}
{"episode_reward": 1184.4921875000005, "episode": 4541.0, "batch_reward": 8.816692352294922, "critic_loss": 411.4844970703125, "actor_loss": -1376.940185546875, "actor_target_entropy": -3.0, "actor_entropy": 1.1952135562896729, "alpha_loss": 0.18635214865207672, "alpha_value": 0.3686312150513274, "duration": 1.5752861499786377, "info_normalized_performance_mean": 0.8446536064147949, "info_normalized_performance_final": 0.9686274528503418, "info_performance_mean": 0.8446536064147949, "info_performance_final": 0.9686274528503418, "step": 454500}
{"episode_reward": 1689.3071895424796, "episode": 4546.0, "batch_reward": 9.943838119506836, "critic_loss": 404.8471374511719, "actor_loss": -1467.188720703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3830455541610718, "alpha_loss": 0.03133019432425499, "alpha_value": 0.3679069704052582, "duration": 1.5448930263519287, "info_normalized_performance_mean": 0.3524356782436371, "info_normalized_performance_final": 0.389660507440567, "info_performance_mean": 0.3524356782436371, "info_performance_final": 0.389660507440567, "step": 455000}
{"episode_reward": 704.8713991769536, "episode": 4551.0, "batch_reward": 9.895402908325195, "critic_loss": 601.88427734375, "actor_loss": -1452.638916015625, "actor_target_entropy": -3.0, "actor_entropy": 1.3044650554656982, "alpha_loss": 0.08779161423444748, "alpha_value": 0.368136197479326, "duration": 1.6708886623382568, "info_normalized_performance_mean": 0.4106457531452179, "info_normalized_performance_final": 0.4586776793003082, "info_performance_mean": 0.4106457531452179, "info_performance_final": 0.4586776793003082, "step": 455500}
{"episode_reward": 821.2913223140506, "episode": 4556.0, "batch_reward": 9.325918197631836, "critic_loss": 343.4945068359375, "actor_loss": -1416.9658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1726016998291016, "alpha_loss": -0.05433109775185585, "alpha_value": 0.3672285323687268, "duration": 1.599071979522705, "info_normalized_performance_mean": 0.310863196849823, "info_normalized_performance_final": 0.35067781805992126, "info_performance_mean": 0.310863196849823, "info_performance_final": 0.35067781805992126, "step": 456000}
{"episode_reward": 621.7264752791065, "episode": 4561.0, "batch_reward": 9.662517547607422, "critic_loss": 356.9288024902344, "actor_loss": -1460.93505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.363195776939392, "alpha_loss": 0.009923569858074188, "alpha_value": 0.3621790328134694, "duration": 1.5816519260406494, "info_normalized_performance_mean": 0.3375522494316101, "info_normalized_performance_final": 0.3741690516471863, "info_performance_mean": 0.3375522494316101, "info_performance_final": 0.3741690516471863, "step": 456500}
{"episode_reward": 675.1044634377977, "episode": 4566.0, "batch_reward": 10.101280212402344, "critic_loss": 491.0552978515625, "actor_loss": -1471.1253662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1803627014160156, "alpha_loss": -0.1257389485836029, "alpha_value": 0.35861361432377326, "duration": 1.4828388690948486, "info_normalized_performance_mean": 0.5443940162658691, "info_normalized_performance_final": 0.6071428656578064, "info_performance_mean": 0.5443940162658691, "info_performance_final": 0.6071428656578064, "step": 457000}
{"episode_reward": 1088.7878787878778, "episode": 4571.0, "batch_reward": 9.906413078308105, "critic_loss": 761.2283935546875, "actor_loss": -1432.1708984375, "actor_target_entropy": -3.0, "actor_entropy": 1.2216591835021973, "alpha_loss": -0.10511226207017899, "alpha_value": 0.35533445751285775, "duration": 1.647566556930542, "info_normalized_performance_mean": 0.20017758011817932, "info_normalized_performance_final": 0.22168803215026855, "info_performance_mean": 0.20017758011817932, "info_performance_final": 0.22168803215026855, "step": 457500}
{"episode_reward": 400.3552350427349, "episode": 4576.0, "batch_reward": 10.130828857421875, "critic_loss": 291.0528564453125, "actor_loss": -1467.66064453125, "actor_target_entropy": -3.0, "actor_entropy": 1.447670578956604, "alpha_loss": 0.010897085070610046, "alpha_value": 0.35367394871156654, "duration": 1.6387016773223877, "info_normalized_performance_mean": 0.5847980380058289, "info_normalized_performance_final": 0.6378066539764404, "info_performance_mean": 0.5847980380058289, "info_performance_final": 0.6378066539764404, "step": 458000}
{"episode_reward": 1169.5959595959578, "episode": 4581.0, "batch_reward": 10.717423439025879, "critic_loss": 852.5321044921875, "actor_loss": -1460.3017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1238609552383423, "alpha_loss": 0.050823062658309937, "alpha_value": 0.35147804589360004, "duration": 1.5813050270080566, "info_normalized_performance_mean": 0.37193968892097473, "info_normalized_performance_final": 0.414767324924469, "info_performance_mean": 0.37193968892097473, "info_performance_final": 0.414767324924469, "step": 458500}
{"episode_reward": 743.8793922127243, "episode": 4586.0, "batch_reward": 9.13269329071045, "critic_loss": 321.85369873046875, "actor_loss": -1396.105712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9586528539657593, "alpha_loss": 0.07643897086381912, "alpha_value": 0.34951742755737525, "duration": 1.5558412075042725, "info_normalized_performance_mean": 0.6513713598251343, "info_normalized_performance_final": 0.7014285922050476, "info_performance_mean": 0.6513713598251343, "info_performance_final": 0.7014285922050476, "step": 459000}
{"episode_reward": 1302.742857142859, "episode": 4591.0, "batch_reward": 9.618901252746582, "critic_loss": 1115.628662109375, "actor_loss": -1421.354248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.2731469869613647, "alpha_loss": 0.019210800528526306, "alpha_value": 0.35132842561391486, "duration": 1.5858900547027588, "info_normalized_performance_mean": 0.7159713506698608, "info_normalized_performance_final": 0.795714259147644, "info_performance_mean": 0.7159713506698608, "info_performance_final": 0.795714259147644, "step": 459500}
{"episode_reward": 1431.9428571428587, "episode": 4596.0, "batch_reward": 9.789602279663086, "critic_loss": 288.5718994140625, "actor_loss": -1426.315185546875, "actor_target_entropy": -3.0, "actor_entropy": 1.2573082447052002, "alpha_loss": -0.24280858039855957, "alpha_value": 0.3535886356154603, "step": 460000}
{"duration": 18.9112446308136, "info_normalized_performance_mean": 0.46566689014434814, "info_normalized_performance_final": 0.5331307649612427, "info_performance_mean": 0.46566689014434814, "info_performance_final": 0.5331307649612427, "step": 460000}
{"episode_reward": 931.3339120370383, "episode": 4601.0, "batch_reward": 10.58881664276123, "critic_loss": 377.04345703125, "actor_loss": -1463.5745849609375, "actor_target_entropy": -3.0, "actor_entropy": 1.4558045864105225, "alpha_loss": 0.15732917189598083, "alpha_value": 0.3559035077697782, "duration": 1.658370018005371, "info_normalized_performance_mean": 0.7895963788032532, "info_normalized_performance_final": 0.8697090148925781, "info_performance_mean": 0.7895963788032532, "info_performance_final": 0.8697090148925781, "step": 460500}
{"episode_reward": 1579.1931216931187, "episode": 4606.0, "batch_reward": 10.66147232055664, "critic_loss": 431.73309326171875, "actor_loss": -1468.4627685546875, "actor_target_entropy": -3.0, "actor_entropy": 1.533668041229248, "alpha_loss": 0.0781208872795105, "alpha_value": 0.35669900807164356, "duration": 1.5744760036468506, "info_normalized_performance_mean": 0.7085856795310974, "info_normalized_performance_final": 0.7757142782211304, "info_performance_mean": 0.7085856795310974, "info_performance_final": 0.7757142782211304, "step": 461000}
{"episode_reward": 1417.1714285714295, "episode": 4611.0, "batch_reward": 9.975977897644043, "critic_loss": 415.6822204589844, "actor_loss": -1440.1785888671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3371340036392212, "alpha_loss": -0.006074076518416405, "alpha_value": 0.3596238055673597, "duration": 1.6321744918823242, "info_normalized_performance_mean": 0.24211719632148743, "info_normalized_performance_final": 0.27073365449905396, "info_performance_mean": 0.24211719632148743, "info_performance_final": 0.27073365449905396, "step": 461500}
{"episode_reward": 484.23444976076615, "episode": 4616.0, "batch_reward": 10.050481796264648, "critic_loss": 603.5438232421875, "actor_loss": -1424.963623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.2766544818878174, "alpha_loss": 0.08867437392473221, "alpha_value": 0.35931872683320487, "duration": 1.4480323791503906, "info_normalized_performance_mean": 0.28675734996795654, "info_normalized_performance_final": 0.3554421663284302, "info_performance_mean": 0.28675734996795654, "info_performance_final": 0.3554421663284302, "step": 462000}
{"episode_reward": 573.5147392290239, "episode": 4621.0, "batch_reward": 9.375567436218262, "critic_loss": 929.645263671875, "actor_loss": -1397.6097412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2907583713531494, "alpha_loss": -0.01734035275876522, "alpha_value": 0.35822298705940486, "duration": 1.4567229747772217, "info_normalized_performance_mean": 0.840624988079071, "info_normalized_performance_final": 0.9077380895614624, "info_performance_mean": 0.840624988079071, "info_performance_final": 0.9077380895614624, "step": 462500}
{"episode_reward": 1681.2500000000016, "episode": 4626.0, "batch_reward": 8.960489273071289, "critic_loss": 552.8310546875, "actor_loss": -1397.65234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1846497058868408, "alpha_loss": -0.07497420161962509, "alpha_value": 0.3599790923975518, "duration": 1.4539716243743896, "info_normalized_performance_mean": 0.28434067964553833, "info_normalized_performance_final": 0.3131868243217468, "info_performance_mean": 0.28434067964553833, "info_performance_final": 0.3131868243217468, "step": 463000}
{"episode_reward": 568.68131868132, "episode": 4631.0, "batch_reward": 9.643753051757812, "critic_loss": 253.47531127929688, "actor_loss": -1384.41259765625, "actor_target_entropy": -3.0, "actor_entropy": 1.194673776626587, "alpha_loss": 0.11486216634511948, "alpha_value": 0.35828667516312734, "duration": 1.5296893119812012, "info_normalized_performance_mean": 0.8103173971176147, "info_normalized_performance_final": 0.8888888955116272, "info_performance_mean": 0.8103173971176147, "info_performance_final": 0.8888888955116272, "step": 463500}
{"episode_reward": 1620.6349206349228, "episode": 4636.0, "batch_reward": 9.375680923461914, "critic_loss": 719.5108642578125, "actor_loss": -1420.862060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.239524245262146, "alpha_loss": -0.10996149480342865, "alpha_value": 0.3569110228988444, "duration": 1.8036994934082031, "info_normalized_performance_mean": 0.3129870593547821, "info_normalized_performance_final": 0.41055986285209656, "info_performance_mean": 0.3129870593547821, "info_performance_final": 0.41055986285209656, "step": 464000}
{"episode_reward": 625.9740555302689, "episode": 4641.0, "batch_reward": 9.562058448791504, "critic_loss": 261.39990234375, "actor_loss": -1348.639892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.6292563676834106, "alpha_loss": 0.0514138825237751, "alpha_value": 0.3543834237974569, "duration": 1.6146063804626465, "info_normalized_performance_mean": 0.5621527433395386, "info_normalized_performance_final": 0.6163194179534912, "info_performance_mean": 0.5621527433395386, "info_performance_final": 0.6163194179534912, "step": 464500}
{"episode_reward": 1124.3055555555568, "episode": 4646.0, "batch_reward": 10.191410064697266, "critic_loss": 1252.93701171875, "actor_loss": -1432.8623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.346989393234253, "alpha_loss": -0.0467832013964653, "alpha_value": 0.35411745072358514, "duration": 1.492461919784546, "info_normalized_performance_mean": 0.449301153421402, "info_normalized_performance_final": 0.49426522850990295, "info_performance_mean": 0.449301153421402, "info_performance_final": 0.49426522850990295, "step": 465000}
{"episode_reward": 898.6021505376328, "episode": 4651.0, "batch_reward": 9.964256286621094, "critic_loss": 299.3179931640625, "actor_loss": -1420.9720458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3877354860305786, "alpha_loss": 0.012498971074819565, "alpha_value": 0.35143704221744254, "duration": 1.554290771484375, "info_normalized_performance_mean": 0.8211562633514404, "info_normalized_performance_final": 0.90625, "info_performance_mean": 0.8211562633514404, "info_performance_final": 0.90625, "step": 465500}
{"episode_reward": 1642.3125, "episode": 4656.0, "batch_reward": 9.901254653930664, "critic_loss": 208.949462890625, "actor_loss": -1427.997314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.2318896055221558, "alpha_loss": 0.14948612451553345, "alpha_value": 0.3479511104159478, "duration": 1.5094666481018066, "info_normalized_performance_mean": 0.22055552899837494, "info_normalized_performance_final": 0.2378472238779068, "info_performance_mean": 0.22055552899837494, "info_performance_final": 0.2378472238779068, "step": 466000}
{"episode_reward": 441.1111111111119, "episode": 4661.0, "batch_reward": 9.855969429016113, "critic_loss": 336.48321533203125, "actor_loss": -1381.207763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2936590909957886, "alpha_loss": 0.1413482129573822, "alpha_value": 0.344432860179964, "duration": 1.5704984664916992, "info_normalized_performance_mean": 0.11602512001991272, "info_normalized_performance_final": 0.13161376118659973, "info_performance_mean": 0.11602512001991272, "info_performance_final": 0.13161376118659973, "step": 466500}
{"episode_reward": 232.0502645502647, "episode": 4666.0, "batch_reward": 9.49047565460205, "critic_loss": 807.4404296875, "actor_loss": -1357.185302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.2113845348358154, "alpha_loss": 0.05477353185415268, "alpha_value": 0.3424775089580698, "duration": 1.4969122409820557, "info_normalized_performance_mean": 0.4289541244506836, "info_normalized_performance_final": 0.48767006397247314, "info_performance_mean": 0.4289541244506836, "info_performance_final": 0.48767006397247314, "step": 467000}
{"episode_reward": 857.9081632653068, "episode": 4671.0, "batch_reward": 9.61990737915039, "critic_loss": 629.1592407226562, "actor_loss": -1413.6158447265625, "actor_target_entropy": -3.0, "actor_entropy": 0.9754123687744141, "alpha_loss": -0.03965798020362854, "alpha_value": 0.34225792995549725, "duration": 1.590390920639038, "info_normalized_performance_mean": 0.5182085633277893, "info_normalized_performance_final": 0.5600907206535339, "info_performance_mean": 0.5182085633277893, "info_performance_final": 0.5600907206535339, "step": 467500}
{"episode_reward": 1036.417233560089, "episode": 4676.0, "batch_reward": 9.835868835449219, "critic_loss": 509.45806884765625, "actor_loss": -1438.90625, "actor_target_entropy": -3.0, "actor_entropy": 0.8217723965644836, "alpha_loss": -0.13471311330795288, "alpha_value": 0.33897550750911787, "duration": 1.5588576793670654, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 468000}
{"episode_reward": 0.0, "episode": 4681.0, "batch_reward": 9.66634750366211, "critic_loss": 560.5665283203125, "actor_loss": -1421.640869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8759078979492188, "alpha_loss": -0.0393868014216423, "alpha_value": 0.3374900303613682, "duration": 1.4904673099517822, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 468500}
{"episode_reward": 0.0, "episode": 4686.0, "batch_reward": 9.605920791625977, "critic_loss": 627.9098510742188, "actor_loss": -1330.011962890625, "actor_target_entropy": -3.0, "actor_entropy": 1.3266358375549316, "alpha_loss": 0.09353072196245193, "alpha_value": 0.33771660024424954, "duration": 1.580880880355835, "info_normalized_performance_mean": 0.8085876703262329, "info_normalized_performance_final": 0.9075000286102295, "info_performance_mean": 0.8085876703262329, "info_performance_final": 0.9075000286102295, "step": 469000}
{"episode_reward": 1617.1750000000027, "episode": 4691.0, "batch_reward": 9.551828384399414, "critic_loss": 263.605712890625, "actor_loss": -1363.96484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3892234563827515, "alpha_loss": -0.07754503190517426, "alpha_value": 0.3386775325474373, "duration": 1.624675989151001, "info_normalized_performance_mean": 0.6959639191627502, "info_normalized_performance_final": 0.7789115905761719, "info_performance_mean": 0.6959639191627502, "info_performance_final": 0.7789115905761719, "step": 469500}
{"episode_reward": 1391.9274376417247, "episode": 4696.0, "batch_reward": 9.925911903381348, "critic_loss": 428.00128173828125, "actor_loss": -1435.901611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0006054639816284, "alpha_loss": 0.07552579045295715, "alpha_value": 0.3368191673375784, "step": 470000}
{"duration": 18.875362634658813, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 470000}
{"episode_reward": 0.0, "episode": 4701.0, "batch_reward": 9.979307174682617, "critic_loss": 1001.1304931640625, "actor_loss": -1369.472412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1239323616027832, "alpha_loss": 0.20290590822696686, "alpha_value": 0.3382951772137588, "duration": 1.516601324081421, "info_normalized_performance_mean": 0.8183481693267822, "info_normalized_performance_final": 0.8995535969734192, "info_performance_mean": 0.8183481693267822, "info_performance_final": 0.8995535969734192, "step": 470500}
{"episode_reward": 1636.6964285714253, "episode": 4706.0, "batch_reward": 10.304786682128906, "critic_loss": 247.0911407470703, "actor_loss": -1416.9083251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1050753593444824, "alpha_loss": 0.059141501784324646, "alpha_value": 0.3386843305714092, "duration": 1.5836780071258545, "info_normalized_performance_mean": 0.7931249737739563, "info_normalized_performance_final": 0.8806818127632141, "info_performance_mean": 0.7931249737739563, "info_performance_final": 0.8806818127632141, "step": 471000}
{"episode_reward": 1586.2499999999986, "episode": 4711.0, "batch_reward": 9.85293960571289, "critic_loss": 409.37591552734375, "actor_loss": -1424.596435546875, "actor_target_entropy": -3.0, "actor_entropy": 1.1886247396469116, "alpha_loss": -0.10473321378231049, "alpha_value": 0.33829232072098286, "duration": 1.553990125656128, "info_normalized_performance_mean": 0.8283749222755432, "info_normalized_performance_final": 0.9339285492897034, "info_performance_mean": 0.8283749222755432, "info_performance_final": 0.9339285492897034, "step": 471500}
{"episode_reward": 1656.7499999999973, "episode": 4716.0, "batch_reward": 10.557011604309082, "critic_loss": 1364.166259765625, "actor_loss": -1440.8448486328125, "actor_target_entropy": -3.0, "actor_entropy": 1.050748348236084, "alpha_loss": -0.11945237219333649, "alpha_value": 0.3402874619028858, "duration": 1.5409724712371826, "info_normalized_performance_mean": 0.7807691693305969, "info_normalized_performance_final": 0.8713942170143127, "info_performance_mean": 0.7807691693305969, "info_performance_final": 0.8713942170143127, "step": 472000}
{"episode_reward": 1561.5384615384576, "episode": 4721.0, "batch_reward": 9.573209762573242, "critic_loss": 756.4203491210938, "actor_loss": -1414.755615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4637010097503662, "alpha_loss": -0.13912969827651978, "alpha_value": 0.34378646051289913, "duration": 1.5507662296295166, "info_normalized_performance_mean": 0.7990933060646057, "info_normalized_performance_final": 0.8777472376823425, "info_performance_mean": 0.7990933060646057, "info_performance_final": 0.8777472376823425, "step": 472500}
{"episode_reward": 1598.1868131868166, "episode": 4726.0, "batch_reward": 9.63992977142334, "critic_loss": 2729.546142578125, "actor_loss": -1388.654541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1977338790893555, "alpha_loss": -0.19372999668121338, "alpha_value": 0.3425637817657545, "duration": 1.4116270542144775, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 473000}
{"episode_reward": 0.0, "episode": 4731.0, "batch_reward": 9.404794692993164, "critic_loss": 630.00830078125, "actor_loss": -1406.74267578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1518614292144775, "alpha_loss": -0.006460525095462799, "alpha_value": 0.340711897758132, "duration": 1.424468755722046, "info_normalized_performance_mean": 0.8058571815490723, "info_normalized_performance_final": 0.8642857074737549, "info_performance_mean": 0.8058571815490723, "info_performance_final": 0.8642857074737549, "step": 473500}
{"episode_reward": 1611.7142857142846, "episode": 4736.0, "batch_reward": 9.808177947998047, "critic_loss": 495.76080322265625, "actor_loss": -1431.5400390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9098125100135803, "alpha_loss": 0.01481182686984539, "alpha_value": 0.3403797038183081, "duration": 1.537050724029541, "info_normalized_performance_mean": 0.6338304281234741, "info_normalized_performance_final": 0.6954473853111267, "info_performance_mean": 0.6338304281234741, "info_performance_final": 0.6954473853111267, "step": 474000}
{"episode_reward": 1267.660910518054, "episode": 4741.0, "batch_reward": 10.98643684387207, "critic_loss": 750.6944580078125, "actor_loss": -1451.69287109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9346374273300171, "alpha_loss": 0.22843129932880402, "alpha_value": 0.338464649190733, "duration": 1.6200261116027832, "info_normalized_performance_mean": 0.7740915417671204, "info_normalized_performance_final": 0.909166693687439, "info_performance_mean": 0.7740915417671204, "info_performance_final": 0.909166693687439, "step": 474500}
{"episode_reward": 1548.1833333333327, "episode": 4746.0, "batch_reward": 9.856731414794922, "critic_loss": 260.1133117675781, "actor_loss": -1422.5582275390625, "actor_target_entropy": -3.0, "actor_entropy": 0.874703586101532, "alpha_loss": -0.10281510651111603, "alpha_value": 0.3375931042732109, "duration": 1.7305443286895752, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 475000}
{"episode_reward": 0.0, "episode": 4751.0, "batch_reward": 9.926307678222656, "critic_loss": 514.6113891601562, "actor_loss": -1432.134521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0045688152313232, "alpha_loss": -0.11597941815853119, "alpha_value": 0.3393712463531536, "duration": 1.5007472038269043, "info_normalized_performance_mean": 0.4420779347419739, "info_normalized_performance_final": 0.5151515007019043, "info_performance_mean": 0.4420779347419739, "info_performance_final": 0.5151515007019043, "step": 475500}
{"episode_reward": 884.1558441558425, "episode": 4756.0, "batch_reward": 9.753216743469238, "critic_loss": 751.5581665039062, "actor_loss": -1408.29638671875, "actor_target_entropy": -3.0, "actor_entropy": 0.7552536725997925, "alpha_loss": -0.11457949876785278, "alpha_value": 0.3421082517994657, "duration": 1.4776439666748047, "info_normalized_performance_mean": 0.451022744178772, "info_normalized_performance_final": 0.4886363744735718, "info_performance_mean": 0.451022744178772, "info_performance_final": 0.4886363744735718, "step": 476000}
{"episode_reward": 902.0454545454531, "episode": 4761.0, "batch_reward": 9.419023513793945, "critic_loss": 713.7277221679688, "actor_loss": -1376.4613037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1695327758789062, "alpha_loss": -0.12308795750141144, "alpha_value": 0.344385423194266, "duration": 1.6225361824035645, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 476500}
{"episode_reward": 0.0, "episode": 4766.0, "batch_reward": 9.940760612487793, "critic_loss": 391.8774719238281, "actor_loss": -1398.9091796875, "actor_target_entropy": -3.0, "actor_entropy": 1.03450608253479, "alpha_loss": 0.010118771344423294, "alpha_value": 0.35009430136607933, "duration": 1.400109052658081, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 477000}
{"episode_reward": 0.0, "episode": 4771.0, "batch_reward": 9.731781005859375, "critic_loss": 874.4300537109375, "actor_loss": -1434.95556640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8013321161270142, "alpha_loss": -0.1773897111415863, "alpha_value": 0.3544148633096703, "duration": 1.423274040222168, "info_normalized_performance_mean": 0.899218738079071, "info_normalized_performance_final": 0.95703125, "info_performance_mean": 0.899218738079071, "info_performance_final": 0.95703125, "step": 477500}
{"episode_reward": 1798.4375, "episode": 4776.0, "batch_reward": 10.021036148071289, "critic_loss": 279.3382873535156, "actor_loss": -1412.5283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.2551610469818115, "alpha_loss": -0.28929436206817627, "alpha_value": 0.3665051870265372, "duration": 1.4847276210784912, "info_normalized_performance_mean": 0.496337890625, "info_normalized_performance_final": 0.56201171875, "info_performance_mean": 0.496337890625, "info_performance_final": 0.56201171875, "step": 478000}
{"episode_reward": 992.67578125, "episode": 4781.0, "batch_reward": 10.33236312866211, "critic_loss": 217.213134765625, "actor_loss": -1415.63818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2342262268066406, "alpha_loss": 0.09920859336853027, "alpha_value": 0.37299753566961313, "duration": 1.515794038772583, "info_normalized_performance_mean": 0.3271805942058563, "info_normalized_performance_final": 0.35555556416511536, "info_performance_mean": 0.3271805942058563, "info_performance_final": 0.35555556416511536, "step": 478500}
{"episode_reward": 654.3611111111098, "episode": 4786.0, "batch_reward": 9.324699401855469, "critic_loss": 245.061767578125, "actor_loss": -1376.537353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.4583466053009033, "alpha_loss": -0.07927171140909195, "alpha_value": 0.37748644024271294, "duration": 1.5459072589874268, "info_normalized_performance_mean": 0.8124131560325623, "info_normalized_performance_final": 0.9027777910232544, "info_performance_mean": 0.8124131560325623, "info_performance_final": 0.9027777910232544, "step": 479000}
{"episode_reward": 1624.8263888888916, "episode": 4791.0, "batch_reward": 9.598397254943848, "critic_loss": 849.418212890625, "actor_loss": -1466.83984375, "actor_target_entropy": -3.0, "actor_entropy": 1.0960938930511475, "alpha_loss": -0.23626291751861572, "alpha_value": 0.382511742767778, "duration": 1.496056318283081, "info_normalized_performance_mean": 0.8913520574569702, "info_normalized_performance_final": 0.9897959232330322, "info_performance_mean": 0.8913520574569702, "info_performance_final": 0.9897959232330322, "step": 479500}
{"episode_reward": 1782.7040816326557, "episode": 4796.0, "batch_reward": 8.873284339904785, "critic_loss": 493.7233581542969, "actor_loss": -1366.9212646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1377038955688477, "alpha_loss": -0.13164915144443512, "alpha_value": 0.38627600065418144, "step": 480000}
{"duration": 18.732869148254395, "info_normalized_performance_mean": 0.739083468914032, "info_normalized_performance_final": 0.8033333420753479, "info_performance_mean": 0.739083468914032, "info_performance_final": 0.8033333420753479, "step": 480000}
{"episode_reward": 1478.1666666666665, "episode": 4801.0, "batch_reward": 9.292952537536621, "critic_loss": 604.568359375, "actor_loss": -1403.9356689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.1235125064849854, "alpha_loss": -0.040226493030786514, "alpha_value": 0.3912260192485672, "duration": 1.5429728031158447, "info_normalized_performance_mean": 0.30924704670906067, "info_normalized_performance_final": 0.3341176509857178, "info_performance_mean": 0.30924704670906067, "info_performance_final": 0.3341176509857178, "step": 480500}
{"episode_reward": 618.4941176470583, "episode": 4806.0, "batch_reward": 9.49245548248291, "critic_loss": 485.025390625, "actor_loss": -1426.570556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0636372566223145, "alpha_loss": -0.053381018340587616, "alpha_value": 0.3962429649803318, "duration": 1.4406845569610596, "info_normalized_performance_mean": 0.42109215259552, "info_normalized_performance_final": 0.4539141356945038, "info_performance_mean": 0.42109215259552, "info_performance_final": 0.4539141356945038, "step": 481000}
{"episode_reward": 842.1843434343427, "episode": 4811.0, "batch_reward": 10.33659839630127, "critic_loss": 891.0442504882812, "actor_loss": -1467.37744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.3580360412597656, "alpha_loss": 0.08546619117259979, "alpha_value": 0.3981884205094297, "duration": 1.6525917053222656, "info_normalized_performance_mean": 0.7200360298156738, "info_normalized_performance_final": 0.7929292917251587, "info_performance_mean": 0.7200360298156738, "info_performance_final": 0.7929292917251587, "step": 481500}
{"episode_reward": 1440.0721500721531, "episode": 4816.0, "batch_reward": 8.968947410583496, "critic_loss": 626.443359375, "actor_loss": -1417.230712890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2647335529327393, "alpha_loss": -0.2392112761735916, "alpha_value": 0.39809614979798746, "duration": 1.5948655605316162, "info_normalized_performance_mean": 0.6724705696105957, "info_normalized_performance_final": 0.7276018261909485, "info_performance_mean": 0.6724705696105957, "info_performance_final": 0.7276018261909485, "step": 482000}
{"episode_reward": 1344.9411764705885, "episode": 4821.0, "batch_reward": 10.105100631713867, "critic_loss": 356.6660461425781, "actor_loss": -1444.78125, "actor_target_entropy": -3.0, "actor_entropy": 1.511705994606018, "alpha_loss": 0.1088036522269249, "alpha_value": 0.39741996274046343, "duration": 1.4542038440704346, "info_normalized_performance_mean": 0.4041219651699066, "info_normalized_performance_final": 0.443452388048172, "info_performance_mean": 0.4041219651699066, "info_performance_final": 0.443452388048172, "step": 482500}
{"episode_reward": 808.244047619046, "episode": 4826.0, "batch_reward": 10.321800231933594, "critic_loss": 306.1826171875, "actor_loss": -1467.316162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1803823709487915, "alpha_loss": 0.03911504149436951, "alpha_value": 0.3949709467899167, "duration": 1.7151744365692139, "info_normalized_performance_mean": 0.6051493883132935, "info_normalized_performance_final": 0.6813414096832275, "info_performance_mean": 0.6051493883132935, "info_performance_final": 0.6813414096832275, "step": 483000}
{"episode_reward": 1210.298792116974, "episode": 4831.0, "batch_reward": 9.742207527160645, "critic_loss": 456.36834716796875, "actor_loss": -1449.7978515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9991130828857422, "alpha_loss": 0.16317397356033325, "alpha_value": 0.3907540522905097, "duration": 1.5512433052062988, "info_normalized_performance_mean": 0.6016899943351746, "info_normalized_performance_final": 0.7070000171661377, "info_performance_mean": 0.6016899943351746, "info_performance_final": 0.7070000171661377, "step": 483500}
{"episode_reward": 1203.3799999999992, "episode": 4836.0, "batch_reward": 9.563457489013672, "critic_loss": 316.75128173828125, "actor_loss": -1404.651611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.2399017810821533, "alpha_loss": 0.11800956726074219, "alpha_value": 0.3830384181152531, "duration": 1.5794651508331299, "info_normalized_performance_mean": 0.6365348100662231, "info_normalized_performance_final": 0.7272727489471436, "info_performance_mean": 0.6365348100662231, "info_performance_final": 0.7272727489471436, "step": 484000}
{"episode_reward": 1273.0695187165754, "episode": 4841.0, "batch_reward": 8.648323059082031, "critic_loss": 738.1407470703125, "actor_loss": -1416.291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.2492341995239258, "alpha_loss": 0.1053166389465332, "alpha_value": 0.3777718978989197, "duration": 1.6094179153442383, "info_normalized_performance_mean": 0.4622703492641449, "info_normalized_performance_final": 0.5154545307159424, "info_performance_mean": 0.4622703492641449, "info_performance_final": 0.5154545307159424, "step": 484500}
{"episode_reward": 924.540909090907, "episode": 4846.0, "batch_reward": 9.649169921875, "critic_loss": 787.1539916992188, "actor_loss": -1434.6817626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.298781394958496, "alpha_loss": -0.016404706984758377, "alpha_value": 0.37413392261089634, "duration": 1.561896562576294, "info_normalized_performance_mean": 0.8739687204360962, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.8739687204360962, "info_performance_final": 1.0, "step": 485000}
{"episode_reward": 1747.9375, "episode": 4851.0, "batch_reward": 8.859184265136719, "critic_loss": 643.7252197265625, "actor_loss": -1394.41552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1404246091842651, "alpha_loss": -0.055320389568805695, "alpha_value": 0.37013372856047816, "duration": 1.4133098125457764, "info_normalized_performance_mean": 0.6077143549919128, "info_normalized_performance_final": 0.6642857193946838, "info_performance_mean": 0.6077143549919128, "info_performance_final": 0.6642857193946838, "step": 485500}
{"episode_reward": 1215.428571428572, "episode": 4856.0, "batch_reward": 9.489377975463867, "critic_loss": 747.2769775390625, "actor_loss": -1419.386474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1271926164627075, "alpha_loss": -0.2541237771511078, "alpha_value": 0.36600652495140984, "duration": 1.4644298553466797, "info_normalized_performance_mean": 0.5855892300605774, "info_normalized_performance_final": 0.6428571343421936, "info_performance_mean": 0.5855892300605774, "info_performance_final": 0.6428571343421936, "step": 486000}
{"episode_reward": 1171.1785714285718, "episode": 4861.0, "batch_reward": 9.959630966186523, "critic_loss": 479.22125244140625, "actor_loss": -1441.334716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1310350894927979, "alpha_loss": 0.09031073749065399, "alpha_value": 0.3630095455013476, "duration": 1.5642623901367188, "info_normalized_performance_mean": 0.7666345238685608, "info_normalized_performance_final": 0.8516483306884766, "info_performance_mean": 0.7666345238685608, "info_performance_final": 0.8516483306884766, "step": 486500}
{"episode_reward": 1533.2692307692291, "episode": 4866.0, "batch_reward": 10.691757202148438, "critic_loss": 1315.175537109375, "actor_loss": -1466.5137939453125, "actor_target_entropy": -3.0, "actor_entropy": 1.5298280715942383, "alpha_loss": 0.07453732937574387, "alpha_value": 0.3588484034614206, "duration": 1.630124568939209, "info_normalized_performance_mean": 0.6766746044158936, "info_normalized_performance_final": 0.815079391002655, "info_performance_mean": 0.6766746044158936, "info_performance_final": 0.815079391002655, "step": 487000}
{"episode_reward": 1353.3492063492035, "episode": 4871.0, "batch_reward": 9.606813430786133, "critic_loss": 634.996337890625, "actor_loss": -1437.4688720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9435539841651917, "alpha_loss": -0.34705111384391785, "alpha_value": 0.3574854468500802, "duration": 1.6460211277008057, "info_normalized_performance_mean": 0.4989881217479706, "info_normalized_performance_final": 0.5449735522270203, "info_performance_mean": 0.4989881217479706, "info_performance_final": 0.5449735522270203, "step": 487500}
{"episode_reward": 997.9761904761896, "episode": 4876.0, "batch_reward": 9.616586685180664, "critic_loss": 277.01641845703125, "actor_loss": -1433.862548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.224189043045044, "alpha_loss": -0.08607597649097443, "alpha_value": 0.35599419246896125, "duration": 1.7798750400543213, "info_normalized_performance_mean": 0.25342801213264465, "info_normalized_performance_final": 0.3009862005710602, "info_performance_mean": 0.25342801213264465, "info_performance_final": 0.3009862005710602, "step": 488000}
{"episode_reward": 506.8560157790929, "episode": 4881.0, "batch_reward": 10.07011604309082, "critic_loss": 647.899169921875, "actor_loss": -1436.387451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2273070812225342, "alpha_loss": 0.05450477451086044, "alpha_value": 0.35426235738157574, "duration": 1.627798318862915, "info_normalized_performance_mean": 0.48201385140419006, "info_normalized_performance_final": 0.5381944179534912, "info_performance_mean": 0.48201385140419006, "info_performance_final": 0.5381944179534912, "step": 488500}
{"episode_reward": 964.0277777777794, "episode": 4886.0, "batch_reward": 11.124444961547852, "critic_loss": 623.6724853515625, "actor_loss": -1507.080322265625, "actor_target_entropy": -3.0, "actor_entropy": 1.284555435180664, "alpha_loss": -0.06529804319143295, "alpha_value": 0.34975232020849184, "duration": 1.3813283443450928, "info_normalized_performance_mean": 0.8925001621246338, "info_normalized_performance_final": 0.9598214030265808, "info_performance_mean": 0.8925001621246338, "info_performance_final": 0.9598214030265808, "step": 489000}
{"episode_reward": 1785.0000000000034, "episode": 4891.0, "batch_reward": 9.5570707321167, "critic_loss": 758.7219848632812, "actor_loss": -1415.7315673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.0011885166168213, "alpha_loss": -0.1965227872133255, "alpha_value": 0.349035331730856, "duration": 1.7221729755401611, "info_normalized_performance_mean": 0.28416815400123596, "info_normalized_performance_final": 0.3215811848640442, "info_performance_mean": 0.28416815400123596, "info_performance_final": 0.3215811848640442, "step": 489500}
{"episode_reward": 568.3363858363861, "episode": 4896.0, "batch_reward": 10.034765243530273, "critic_loss": 1126.89208984375, "actor_loss": -1430.4248046875, "actor_target_entropy": -3.0, "actor_entropy": 0.965921938419342, "alpha_loss": -0.21376347541809082, "alpha_value": 0.34782488080273954, "step": 490000}
{"duration": 18.750447988510132, "info_normalized_performance_mean": 0.6473438143730164, "info_normalized_performance_final": 0.7142857313156128, "info_performance_mean": 0.6473438143730164, "info_performance_final": 0.7142857313156128, "step": 490000}
{"episode_reward": 1294.6875000000005, "episode": 4901.0, "batch_reward": 10.39744758605957, "critic_loss": 545.736083984375, "actor_loss": -1423.8814697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3273816108703613, "alpha_loss": 0.057007160037755966, "alpha_value": 0.34785953853279156, "duration": 1.4841828346252441, "info_normalized_performance_mean": 0.4624350666999817, "info_normalized_performance_final": 0.5232684016227722, "info_performance_mean": 0.4624350666999817, "info_performance_final": 0.5232684016227722, "step": 490500}
{"episode_reward": 924.870129870129, "episode": 4906.0, "batch_reward": 10.015838623046875, "critic_loss": 619.671630859375, "actor_loss": -1429.137451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1216416358947754, "alpha_loss": -0.07583722472190857, "alpha_value": 0.3454331368083012, "duration": 1.5743136405944824, "info_normalized_performance_mean": 0.23986904323101044, "info_normalized_performance_final": 0.2738095223903656, "info_performance_mean": 0.23986904323101044, "info_performance_final": 0.2738095223903656, "step": 491000}
{"episode_reward": 479.7380952380956, "episode": 4911.0, "batch_reward": 9.600921630859375, "critic_loss": 270.81805419921875, "actor_loss": -1429.207763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8457479476928711, "alpha_loss": -0.05907661095261574, "alpha_value": 0.3457574094392286, "duration": 1.6203219890594482, "info_normalized_performance_mean": 0.6024499535560608, "info_normalized_performance_final": 0.6675000190734863, "info_performance_mean": 0.6024499535560608, "info_performance_final": 0.6675000190734863, "step": 491500}
{"episode_reward": 1204.899999999999, "episode": 4916.0, "batch_reward": 9.575983047485352, "critic_loss": 563.88232421875, "actor_loss": -1396.836669921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3433961868286133, "alpha_loss": -0.17446598410606384, "alpha_value": 0.3481790979308307, "duration": 1.5315680503845215, "info_normalized_performance_mean": 0.6362403035163879, "info_normalized_performance_final": 0.7080062627792358, "info_performance_mean": 0.6362403035163879, "info_performance_final": 0.7080062627792358, "step": 492000}
{"episode_reward": 1272.4803767660908, "episode": 4921.0, "batch_reward": 10.116965293884277, "critic_loss": 463.26922607421875, "actor_loss": -1438.637451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8194683790206909, "alpha_loss": -0.18911400437355042, "alpha_value": 0.35138607036894837, "duration": 1.6163654327392578, "info_normalized_performance_mean": 0.5236830115318298, "info_normalized_performance_final": 0.5848214030265808, "info_performance_mean": 0.5236830115318298, "info_performance_final": 0.5848214030265808, "step": 492500}
{"episode_reward": 1047.3660714285709, "episode": 4926.0, "batch_reward": 9.890335083007812, "critic_loss": 945.9268798828125, "actor_loss": -1395.078857421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9676586389541626, "alpha_loss": -0.005371741950511932, "alpha_value": 0.35423535988796906, "duration": 1.6056861877441406, "info_normalized_performance_mean": 0.6714074015617371, "info_normalized_performance_final": 0.7477499842643738, "info_performance_mean": 0.6714074015617371, "info_performance_final": 0.7477499842643738, "step": 493000}
{"episode_reward": 1342.8149999999996, "episode": 4931.0, "batch_reward": 10.633529663085938, "critic_loss": 477.6213684082031, "actor_loss": -1429.00390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0878292322158813, "alpha_loss": 0.0437220074236393, "alpha_value": 0.3584529725517975, "duration": 1.5295979976654053, "info_normalized_performance_mean": 0.5950651168823242, "info_normalized_performance_final": 0.661057710647583, "info_performance_mean": 0.5950651168823242, "info_performance_final": 0.661057710647583, "step": 493500}
{"episode_reward": 1190.130494505493, "episode": 4936.0, "batch_reward": 10.154542922973633, "critic_loss": 343.79754638671875, "actor_loss": -1412.8182373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3282139301300049, "alpha_loss": -0.024655766785144806, "alpha_value": 0.36002662367025046, "duration": 1.5021543502807617, "info_normalized_performance_mean": 0.40029868483543396, "info_normalized_performance_final": 0.4361990988254547, "info_performance_mean": 0.40029868483543396, "info_performance_final": 0.4361990988254547, "step": 494000}
{"episode_reward": 800.5972850678731, "episode": 4941.0, "batch_reward": 9.668380737304688, "critic_loss": 356.05621337890625, "actor_loss": -1371.119140625, "actor_target_entropy": -3.0, "actor_entropy": 1.1804704666137695, "alpha_loss": -0.16669605672359467, "alpha_value": 0.36240766099149185, "duration": 1.5803070068359375, "info_normalized_performance_mean": 0.38255295157432556, "info_normalized_performance_final": 0.41534391045570374, "info_performance_mean": 0.38255295157432556, "info_performance_final": 0.41534391045570374, "step": 494500}
{"episode_reward": 765.1058201058198, "episode": 4946.0, "batch_reward": 10.25893497467041, "critic_loss": 679.43408203125, "actor_loss": -1437.272216796875, "actor_target_entropy": -3.0, "actor_entropy": 0.9716171026229858, "alpha_loss": 0.09019657224416733, "alpha_value": 0.3673835248406309, "duration": 1.5602993965148926, "info_normalized_performance_mean": 0.8272876143455505, "info_normalized_performance_final": 0.9175000190734863, "info_performance_mean": 0.8272876143455505, "info_performance_final": 0.9175000190734863, "step": 495000}
{"episode_reward": 1654.5749999999978, "episode": 4951.0, "batch_reward": 10.426509857177734, "critic_loss": 372.0157470703125, "actor_loss": -1441.965576171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1097410917282104, "alpha_loss": -0.008104231208562851, "alpha_value": 0.3714013438662439, "duration": 1.4559762477874756, "info_normalized_performance_mean": 0.48717644810676575, "info_normalized_performance_final": 0.5333333611488342, "info_performance_mean": 0.48717644810676575, "info_performance_final": 0.5333333611488342, "step": 495500}
{"episode_reward": 974.3529411764695, "episode": 4956.0, "batch_reward": 10.744771957397461, "critic_loss": 411.96148681640625, "actor_loss": -1451.186279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.2960386276245117, "alpha_loss": 0.08600500971078873, "alpha_value": 0.37601338803811624, "duration": 1.568145751953125, "info_normalized_performance_mean": 0.3993299901485443, "info_normalized_performance_final": 0.4482499957084656, "info_performance_mean": 0.3993299901485443, "info_performance_final": 0.4482499957084656, "step": 496000}
{"episode_reward": 798.6600000000004, "episode": 4961.0, "batch_reward": 9.927375793457031, "critic_loss": 429.2080078125, "actor_loss": -1413.7655029296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3255102634429932, "alpha_loss": -0.15253417193889618, "alpha_value": 0.38029299003431966, "duration": 1.451831340789795, "info_normalized_performance_mean": 0.3805208206176758, "info_normalized_performance_final": 0.4184027910232544, "info_performance_mean": 0.3805208206176758, "info_performance_final": 0.4184027910232544, "step": 496500}
{"episode_reward": 761.0416666666657, "episode": 4966.0, "batch_reward": 10.68058967590332, "critic_loss": 256.9986877441406, "actor_loss": -1477.486083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9881812930107117, "alpha_loss": -0.10659421980381012, "alpha_value": 0.3840353695072649, "duration": 1.5712385177612305, "info_normalized_performance_mean": 0.8019504547119141, "info_normalized_performance_final": 0.8901098966598511, "info_performance_mean": 0.8019504547119141, "info_performance_final": 0.8901098966598511, "step": 497000}
{"episode_reward": 1603.9010989010962, "episode": 4971.0, "batch_reward": 10.508293151855469, "critic_loss": 803.704833984375, "actor_loss": -1418.2174072265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2081910371780396, "alpha_loss": -0.12120314687490463, "alpha_value": 0.38813045768532956, "duration": 1.4736173152923584, "info_normalized_performance_mean": 0.42065536975860596, "info_normalized_performance_final": 0.46484375, "info_performance_mean": 0.42065536975860596, "info_performance_final": 0.46484375, "step": 497500}
{"episode_reward": 841.3107638888889, "episode": 4976.0, "batch_reward": 9.92493724822998, "critic_loss": 442.315673828125, "actor_loss": -1452.443359375, "actor_target_entropy": -3.0, "actor_entropy": 0.8961513638496399, "alpha_loss": 0.08464886248111725, "alpha_value": 0.39275452554622137, "duration": 1.4631531238555908, "info_normalized_performance_mean": 0.5538961291313171, "info_normalized_performance_final": 0.6017315983772278, "info_performance_mean": 0.5538961291313171, "info_performance_final": 0.6017315983772278, "step": 498000}
{"episode_reward": 1107.792207792209, "episode": 4981.0, "batch_reward": 10.445146560668945, "critic_loss": 445.4501647949219, "actor_loss": -1447.46875, "actor_target_entropy": -3.0, "actor_entropy": 1.665043830871582, "alpha_loss": -0.2827557921409607, "alpha_value": 0.4043255232136372, "duration": 1.407273530960083, "info_normalized_performance_mean": 0.30603793263435364, "info_normalized_performance_final": 0.33272284269332886, "info_performance_mean": 0.30603793263435364, "info_performance_final": 0.33272284269332886, "step": 498500}
{"episode_reward": 612.0757020757034, "episode": 4986.0, "batch_reward": 10.604026794433594, "critic_loss": 520.578125, "actor_loss": -1457.402587890625, "actor_target_entropy": -3.0, "actor_entropy": 1.1988844871520996, "alpha_loss": -0.19945523142814636, "alpha_value": 0.4147535850944804, "duration": 1.5653042793273926, "info_normalized_performance_mean": 0.6457571983337402, "info_normalized_performance_final": 0.6957142949104309, "info_performance_mean": 0.6457571983337402, "info_performance_final": 0.6957142949104309, "step": 499000}
{"episode_reward": 1291.5142857142878, "episode": 4991.0, "batch_reward": 9.45654296875, "critic_loss": 788.3342895507812, "actor_loss": -1429.0380859375, "actor_target_entropy": -3.0, "actor_entropy": 1.2117432355880737, "alpha_loss": -0.2783373296260834, "alpha_value": 0.4250291044725339, "duration": 1.408219337463379, "info_normalized_performance_mean": 0.07788234949111938, "info_normalized_performance_final": 0.08403361588716507, "info_performance_mean": 0.07788234949111938, "info_performance_final": 0.08403361588716507, "step": 499500}
{"episode_reward": 155.76470588235267, "episode": 4996.0, "batch_reward": 10.91659164428711, "critic_loss": 1519.4158935546875, "actor_loss": -1488.31494140625, "actor_target_entropy": -3.0, "actor_entropy": 1.5353195667266846, "alpha_loss": -0.07741609960794449, "alpha_value": 0.4342651614217652, "step": 500000}
{"duration": 18.88476061820984, "info_normalized_performance_mean": 0.5679688453674316, "info_normalized_performance_final": 0.6225961446762085, "info_performance_mean": 0.5679688453674316, "info_performance_final": 0.6225961446762085, "step": 500000}
{"episode_reward": 1135.9375000000011, "episode": 5001.0, "batch_reward": 10.376542091369629, "critic_loss": 539.37841796875, "actor_loss": -1515.759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.3613336086273193, "alpha_loss": -0.39333799481391907, "alpha_value": 0.4449788683240596, "duration": 1.5983657836914062, "info_normalized_performance_mean": 0.7916077971458435, "info_normalized_performance_final": 0.8696078658103943, "info_performance_mean": 0.7916077971458435, "info_performance_final": 0.8696078658103943, "step": 500500}
{"episode_reward": 1583.2156862745123, "episode": 5006.0, "batch_reward": 11.006467819213867, "critic_loss": 639.822998046875, "actor_loss": -1499.5887451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3822124004364014, "alpha_loss": -0.03213635832071304, "alpha_value": 0.45657739541580594, "duration": 1.5635402202606201, "info_normalized_performance_mean": 0.8049934506416321, "info_normalized_performance_final": 0.8875817060470581, "info_performance_mean": 0.8049934506416321, "info_performance_final": 0.8875817060470581, "step": 501000}
{"episode_reward": 1609.9869281045733, "episode": 5011.0, "batch_reward": 10.463644027709961, "critic_loss": 547.1041259765625, "actor_loss": -1518.505615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2911936044692993, "alpha_loss": -0.09060493111610413, "alpha_value": 0.464757464287951, "duration": 1.477980136871338, "info_normalized_performance_mean": 0.4126220643520355, "info_normalized_performance_final": 0.45361328125, "info_performance_mean": 0.4126220643520355, "info_performance_final": 0.45361328125, "step": 501500}
{"episode_reward": 825.244140625, "episode": 5016.0, "batch_reward": 10.122220993041992, "critic_loss": 347.4984130859375, "actor_loss": -1479.34326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5109786987304688, "alpha_loss": -0.08296819031238556, "alpha_value": 0.4689068681645733, "duration": 1.5365016460418701, "info_normalized_performance_mean": 0.3136028051376343, "info_normalized_performance_final": 0.3485576808452606, "info_performance_mean": 0.3136028051376343, "info_performance_final": 0.3485576808452606, "step": 502000}
{"episode_reward": 627.205528846154, "episode": 5021.0, "batch_reward": 10.063677787780762, "critic_loss": 468.1889343261719, "actor_loss": -1483.907958984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3728601932525635, "alpha_loss": 0.0721956416964531, "alpha_value": 0.4710225826027748, "duration": 1.429272174835205, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 502500}
{"episode_reward": 0.0, "episode": 5026.0, "batch_reward": 10.8794527053833, "critic_loss": 705.755126953125, "actor_loss": -1525.210205078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4926868677139282, "alpha_loss": -0.027668876573443413, "alpha_value": 0.46742633652604554, "duration": 1.531374216079712, "info_normalized_performance_mean": 0.5609872937202454, "info_normalized_performance_final": 0.6061789989471436, "info_performance_mean": 0.5609872937202454, "info_performance_final": 0.6061789989471436, "step": 503000}
{"episode_reward": 1121.9744318181802, "episode": 5031.0, "batch_reward": 10.7662935256958, "critic_loss": 1167.479248046875, "actor_loss": -1485.846923828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3415018320083618, "alpha_loss": 0.23330965638160706, "alpha_value": 0.4614951248563746, "duration": 1.559307336807251, "info_normalized_performance_mean": 0.4038804769515991, "info_normalized_performance_final": 0.45510661602020264, "info_performance_mean": 0.4038804769515991, "info_performance_final": 0.45510661602020264, "step": 503500}
{"episode_reward": 807.7609427609441, "episode": 5036.0, "batch_reward": 9.910694122314453, "critic_loss": 1143.8056640625, "actor_loss": -1503.91845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2933135032653809, "alpha_loss": -0.19265177845954895, "alpha_value": 0.45393044501794616, "duration": 1.4185011386871338, "info_normalized_performance_mean": 0.7249643206596375, "info_normalized_performance_final": 0.7821428775787354, "info_performance_mean": 0.7249643206596375, "info_performance_final": 0.7821428775787354, "step": 504000}
{"episode_reward": 1449.92857142857, "episode": 5041.0, "batch_reward": 10.434446334838867, "critic_loss": 673.4214477539062, "actor_loss": -1504.39794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3047809600830078, "alpha_loss": -0.008637823164463043, "alpha_value": 0.4469573442896764, "duration": 1.6036405563354492, "info_normalized_performance_mean": 0.4569312334060669, "info_normalized_performance_final": 0.49669313430786133, "info_performance_mean": 0.4569312334060669, "info_performance_final": 0.49669313430786133, "step": 504500}
{"episode_reward": 913.8624338624359, "episode": 5046.0, "batch_reward": 10.100770950317383, "critic_loss": 439.9979248046875, "actor_loss": -1489.255859375, "actor_target_entropy": -3.0, "actor_entropy": 1.35843026638031, "alpha_loss": 0.1568898856639862, "alpha_value": 0.4439139776028523, "duration": 1.5010325908660889, "info_normalized_performance_mean": 0.3594282567501068, "info_normalized_performance_final": 0.39737215638160706, "info_performance_mean": 0.3594282567501068, "info_performance_final": 0.39737215638160706, "step": 505000}
{"episode_reward": 718.8565340909097, "episode": 5051.0, "batch_reward": 9.57989501953125, "critic_loss": 243.16104125976562, "actor_loss": -1441.123779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.1871368885040283, "alpha_loss": 0.06970394402742386, "alpha_value": 0.4413009150753313, "duration": 1.5605800151824951, "info_normalized_performance_mean": 0.7643007040023804, "info_normalized_performance_final": 0.8333333134651184, "info_performance_mean": 0.7643007040023804, "info_performance_final": 0.8333333134651184, "step": 505500}
{"episode_reward": 1528.601190476192, "episode": 5056.0, "batch_reward": 10.36240005493164, "critic_loss": 366.954833984375, "actor_loss": -1509.89794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.473792552947998, "alpha_loss": 0.029024533927440643, "alpha_value": 0.4353246733418664, "duration": 1.6415643692016602, "info_normalized_performance_mean": 0.4687861204147339, "info_normalized_performance_final": 0.5227272510528564, "info_performance_mean": 0.4687861204147339, "info_performance_final": 0.5227272510528564, "step": 506000}
{"episode_reward": 937.5723140495879, "episode": 5061.0, "batch_reward": 10.020492553710938, "critic_loss": 629.9253540039062, "actor_loss": -1490.0006103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1499825716018677, "alpha_loss": -0.030152589082717896, "alpha_value": 0.42722530446305107, "duration": 1.573866605758667, "info_normalized_performance_mean": 0.5397254824638367, "info_normalized_performance_final": 0.5901960730552673, "info_performance_mean": 0.5397254824638367, "info_performance_final": 0.5901960730552673, "step": 506500}
{"episode_reward": 1079.4509803921549, "episode": 5066.0, "batch_reward": 10.516727447509766, "critic_loss": 276.27655029296875, "actor_loss": -1494.28515625, "actor_target_entropy": -3.0, "actor_entropy": 1.411711573600769, "alpha_loss": 0.26940619945526123, "alpha_value": 0.42100603448826934, "duration": 1.508408546447754, "info_normalized_performance_mean": 0.39798203110694885, "info_normalized_performance_final": 0.44050177931785583, "info_performance_mean": 0.39798203110694885, "info_performance_final": 0.44050177931785583, "step": 507000}
{"episode_reward": 795.9641577060943, "episode": 5071.0, "batch_reward": 9.733969688415527, "critic_loss": 310.0362548828125, "actor_loss": -1462.29833984375, "actor_target_entropy": -3.0, "actor_entropy": 1.2697851657867432, "alpha_loss": -0.06265344470739365, "alpha_value": 0.4127948451059076, "duration": 1.475440502166748, "info_normalized_performance_mean": 0.6887667179107666, "info_normalized_performance_final": 0.757631242275238, "info_performance_mean": 0.6887667179107666, "info_performance_final": 0.757631242275238, "step": 507500}
{"episode_reward": 1377.5335775335805, "episode": 5076.0, "batch_reward": 10.190214157104492, "critic_loss": 619.281982421875, "actor_loss": -1478.48388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3458139896392822, "alpha_loss": 0.1597781628370285, "alpha_value": 0.4071915604911088, "duration": 1.5098068714141846, "info_normalized_performance_mean": 0.4870823919773102, "info_normalized_performance_final": 0.5351254343986511, "info_performance_mean": 0.4870823919773102, "info_performance_final": 0.5351254343986511, "step": 508000}
{"episode_reward": 974.1648745519717, "episode": 5081.0, "batch_reward": 10.429633140563965, "critic_loss": 658.125244140625, "actor_loss": -1500.058349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1653404235839844, "alpha_loss": -0.012971922755241394, "alpha_value": 0.40294657618632707, "duration": 1.6060855388641357, "info_normalized_performance_mean": 0.46354979276657104, "info_normalized_performance_final": 0.5028859972953796, "info_performance_mean": 0.46354979276657104, "info_performance_final": 0.5028859972953796, "step": 508500}
{"episode_reward": 927.0995670995682, "episode": 5086.0, "batch_reward": 10.435892105102539, "critic_loss": 791.22021484375, "actor_loss": -1512.521728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.2844641208648682, "alpha_loss": -0.018748287111520767, "alpha_value": 0.39894713342566673, "duration": 1.4793977737426758, "info_normalized_performance_mean": 0.591532826423645, "info_normalized_performance_final": 0.66567462682724, "info_performance_mean": 0.591532826423645, "info_performance_final": 0.66567462682724, "step": 509000}
{"episode_reward": 1183.0654761904752, "episode": 5091.0, "batch_reward": 10.214471817016602, "critic_loss": 388.45501708984375, "actor_loss": -1470.6064453125, "actor_target_entropy": -3.0, "actor_entropy": 1.3347975015640259, "alpha_loss": -0.09280399978160858, "alpha_value": 0.39940094433269313, "duration": 1.4604814052581787, "info_normalized_performance_mean": 0.3648512363433838, "info_normalized_performance_final": 0.40119048953056335, "info_performance_mean": 0.3648512363433838, "info_performance_final": 0.40119048953056335, "step": 509500}
{"episode_reward": 729.7023809523805, "episode": 5096.0, "batch_reward": 8.872331619262695, "critic_loss": 1278.6361083984375, "actor_loss": -1437.623291015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9945333003997803, "alpha_loss": 0.017660900950431824, "alpha_value": 0.39502981936113835, "step": 510000}
{"duration": 18.872617483139038, "info_normalized_performance_mean": 0.6078428626060486, "info_normalized_performance_final": 0.6557142734527588, "info_performance_mean": 0.6078428626060486, "info_performance_final": 0.6557142734527588, "step": 510000}
{"episode_reward": 1215.6857142857145, "episode": 5101.0, "batch_reward": 10.37307357788086, "critic_loss": 459.83477783203125, "actor_loss": -1474.009521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1687533855438232, "alpha_loss": 0.13147729635238647, "alpha_value": 0.389412435849943, "duration": 1.4867665767669678, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 510500}
{"episode_reward": 0.0, "episode": 5106.0, "batch_reward": 10.342557907104492, "critic_loss": 818.6773681640625, "actor_loss": -1510.689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0232014656066895, "alpha_loss": 0.07248997688293457, "alpha_value": 0.3888068285532426, "duration": 1.5297346115112305, "info_normalized_performance_mean": 0.8002678155899048, "info_normalized_performance_final": 0.8785714507102966, "info_performance_mean": 0.8002678155899048, "info_performance_final": 0.8785714507102966, "step": 511000}
{"episode_reward": 1600.5357142857167, "episode": 5111.0, "batch_reward": 11.014842987060547, "critic_loss": 490.64776611328125, "actor_loss": -1541.154052734375, "actor_target_entropy": -3.0, "actor_entropy": 1.235302448272705, "alpha_loss": -0.020674537867307663, "alpha_value": 0.38631625733008124, "duration": 1.4058737754821777, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 511500}
{"episode_reward": 0.0, "episode": 5116.0, "batch_reward": 9.958215713500977, "critic_loss": 884.3508911132812, "actor_loss": -1492.173095703125, "actor_target_entropy": -3.0, "actor_entropy": 1.258537769317627, "alpha_loss": -0.16321061551570892, "alpha_value": 0.3854786640428471, "duration": 1.4175529479980469, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 512000}
{"episode_reward": 0.0, "episode": 5121.0, "batch_reward": 10.376848220825195, "critic_loss": 377.35272216796875, "actor_loss": -1521.24755859375, "actor_target_entropy": -3.0, "actor_entropy": 0.9630088210105896, "alpha_loss": 0.16637448966503143, "alpha_value": 0.38415173090502563, "duration": 1.4310576915740967, "info_normalized_performance_mean": 0.000710470078047365, "info_normalized_performance_final": 0.0010683761211112142, "info_performance_mean": 0.000710470078047365, "info_performance_final": 0.0010683761211112142, "step": 512500}
{"episode_reward": 1.42094017094017, "episode": 5126.0, "batch_reward": 10.285575866699219, "critic_loss": 764.3128051757812, "actor_loss": -1512.60302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0701910257339478, "alpha_loss": 0.015374798327684402, "alpha_value": 0.3800930632679029, "duration": 1.4759132862091064, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 513000}
{"episode_reward": 0.0, "episode": 5131.0, "batch_reward": 10.058732986450195, "critic_loss": 426.24481201171875, "actor_loss": -1500.78564453125, "actor_target_entropy": -3.0, "actor_entropy": 1.231189250946045, "alpha_loss": 0.010853584855794907, "alpha_value": 0.37545584427192497, "duration": 1.466789722442627, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 513500}
{"episode_reward": 0.0, "episode": 5136.0, "batch_reward": 10.872139930725098, "critic_loss": 502.4756774902344, "actor_loss": -1546.3111572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.019493579864502, "alpha_loss": 0.29341819882392883, "alpha_value": 0.3747455824666997, "duration": 1.4063520431518555, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 514000}
{"episode_reward": 0.0, "episode": 5141.0, "batch_reward": 10.350061416625977, "critic_loss": 855.1478881835938, "actor_loss": -1505.4185791015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9052072763442993, "alpha_loss": -0.10031433403491974, "alpha_value": 0.37061116249284337, "duration": 1.5215816497802734, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 514500}
{"episode_reward": 0.0, "episode": 5146.0, "batch_reward": 10.183317184448242, "critic_loss": 917.1756591796875, "actor_loss": -1480.16845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0863392353057861, "alpha_loss": -0.11350591480731964, "alpha_value": 0.3659067701467322, "duration": 1.5429112911224365, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 515000}
{"episode_reward": 0.0, "episode": 5151.0, "batch_reward": 9.149824142456055, "critic_loss": 430.7974548339844, "actor_loss": -1525.8687744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.025730848312378, "alpha_loss": -0.029486805200576782, "alpha_value": 0.36200048921589517, "duration": 1.5334506034851074, "info_normalized_performance_mean": 0.7708929181098938, "info_normalized_performance_final": 0.8392857313156128, "info_performance_mean": 0.7708929181098938, "info_performance_final": 0.8392857313156128, "step": 515500}
{"episode_reward": 1541.7857142857156, "episode": 5156.0, "batch_reward": 8.75876522064209, "critic_loss": 315.2467956542969, "actor_loss": -1483.3018798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7390086650848389, "alpha_loss": 0.18210050463676453, "alpha_value": 0.3572482718037584, "duration": 1.4423396587371826, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 516000}
{"episode_reward": 0.0, "episode": 5161.0, "batch_reward": 9.566411972045898, "critic_loss": 442.31964111328125, "actor_loss": -1506.144287109375, "actor_target_entropy": -3.0, "actor_entropy": 0.7037837505340576, "alpha_loss": 0.10781604796648026, "alpha_value": 0.3533385164135954, "duration": 1.5439753532409668, "info_normalized_performance_mean": 0.7638572454452515, "info_normalized_performance_final": 0.8471428751945496, "info_performance_mean": 0.7638572454452515, "info_performance_final": 0.8471428751945496, "step": 516500}
{"episode_reward": 1527.7142857142844, "episode": 5166.0, "batch_reward": 9.414466857910156, "critic_loss": 736.48681640625, "actor_loss": -1475.412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.6304223537445068, "alpha_loss": -0.0010125525295734406, "alpha_value": 0.3503490204488184, "duration": 1.474945068359375, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 517000}
{"episode_reward": 0.0, "episode": 5171.0, "batch_reward": 9.73253059387207, "critic_loss": 794.1279296875, "actor_loss": -1491.158447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.067426085472107, "alpha_loss": 0.040155746042728424, "alpha_value": 0.3478968530474037, "duration": 1.484982967376709, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 517500}
{"episode_reward": 0.0, "episode": 5176.0, "batch_reward": 9.365129470825195, "critic_loss": 564.0789794921875, "actor_loss": -1524.304931640625, "actor_target_entropy": -3.0, "actor_entropy": 0.7300154566764832, "alpha_loss": 0.03510555624961853, "alpha_value": 0.34621479899762003, "duration": 1.5303397178649902, "info_normalized_performance_mean": 0.8828750848770142, "info_normalized_performance_final": 0.9678571224212646, "info_performance_mean": 0.8828750848770142, "info_performance_final": 0.9678571224212646, "step": 518000}
{"episode_reward": 1765.7500000000018, "episode": 5181.0, "batch_reward": 8.718347549438477, "critic_loss": 467.8702392578125, "actor_loss": -1466.2972412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.6131400465965271, "alpha_loss": -0.0714690163731575, "alpha_value": 0.3449726255933346, "duration": 1.5325584411621094, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 518500}
{"episode_reward": 0.0, "episode": 5186.0, "batch_reward": 9.745285034179688, "critic_loss": 1141.007568359375, "actor_loss": -1473.249755859375, "actor_target_entropy": -3.0, "actor_entropy": 0.8348231315612793, "alpha_loss": -0.041376661509275436, "alpha_value": 0.34219113795947953, "duration": 1.5471138954162598, "info_normalized_performance_mean": 0.6851934790611267, "info_normalized_performance_final": 0.7529761791229248, "info_performance_mean": 0.6851934790611267, "info_performance_final": 0.7529761791229248, "step": 519000}
{"episode_reward": 1370.3869047619069, "episode": 5191.0, "batch_reward": 9.65034294128418, "critic_loss": 244.82354736328125, "actor_loss": -1467.357177734375, "actor_target_entropy": -3.0, "actor_entropy": 0.3871157169342041, "alpha_loss": 0.032466284930706024, "alpha_value": 0.34032211178356553, "duration": 1.551482915878296, "info_normalized_performance_mean": 0.8801832795143127, "info_normalized_performance_final": 0.971666693687439, "info_performance_mean": 0.8801832795143127, "info_performance_final": 0.971666693687439, "step": 519500}
{"episode_reward": 1760.3666666666675, "episode": 5196.0, "batch_reward": 9.06164264678955, "critic_loss": 388.0734558105469, "actor_loss": -1471.21728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0716686248779297, "alpha_loss": -0.19970479607582092, "alpha_value": 0.33826193451576564, "step": 520000}
{"duration": 17.67047667503357, "info_normalized_performance_mean": 0.37415221333503723, "info_normalized_performance_final": 0.412872850894928, "info_performance_mean": 0.37415221333503723, "info_performance_final": 0.412872850894928, "step": 520000}
{"episode_reward": 748.3045525902675, "episode": 5201.0, "batch_reward": 9.737397193908691, "critic_loss": 549.93359375, "actor_loss": -1480.972900390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8218638896942139, "alpha_loss": 0.2477581799030304, "alpha_value": 0.3370905500595629, "duration": 1.4869108200073242, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 520500}
{"episode_reward": 0.0, "episode": 5206.0, "batch_reward": 8.783636093139648, "critic_loss": 342.12200927734375, "actor_loss": -1481.595703125, "actor_target_entropy": -3.0, "actor_entropy": 0.5153310298919678, "alpha_loss": 0.25659555196762085, "alpha_value": 0.33092284272378103, "duration": 1.4734127521514893, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 521000}
{"episode_reward": 0.0, "episode": 5211.0, "batch_reward": 10.010225296020508, "critic_loss": 411.00628662109375, "actor_loss": -1474.240478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7844942808151245, "alpha_loss": 0.050521038472652435, "alpha_value": 0.3259141630380703, "duration": 1.513277530670166, "info_normalized_performance_mean": 0.47198745608329773, "info_normalized_performance_final": 0.5224999785423279, "info_performance_mean": 0.47198745608329773, "info_performance_final": 0.5224999785423279, "step": 521500}
{"episode_reward": 943.9750000000015, "episode": 5216.0, "batch_reward": 9.945892333984375, "critic_loss": 255.0131378173828, "actor_loss": -1458.814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9038609266281128, "alpha_loss": 0.2352762371301651, "alpha_value": 0.32423111827478274, "duration": 1.4359090328216553, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 522000}
{"episode_reward": 0.0, "episode": 5221.0, "batch_reward": 10.267321586608887, "critic_loss": 3519.12548828125, "actor_loss": -1510.24169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.6990698575973511, "alpha_loss": 0.1833501160144806, "alpha_value": 0.32395019417315724, "duration": 1.5700724124908447, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 522500}
{"episode_reward": 0.0, "episode": 5226.0, "batch_reward": 9.895021438598633, "critic_loss": 544.1099853515625, "actor_loss": -1493.431640625, "actor_target_entropy": -3.0, "actor_entropy": 0.7734496593475342, "alpha_loss": 0.10999306291341782, "alpha_value": 0.3217186808061501, "duration": 1.539269208908081, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 523000}
{"episode_reward": 0.0, "episode": 5231.0, "batch_reward": 10.071710586547852, "critic_loss": 568.10400390625, "actor_loss": -1468.01611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.9085662961006165, "alpha_loss": -0.018102314323186874, "alpha_value": 0.3243245773856046, "duration": 1.4557640552520752, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 523500}
{"episode_reward": 0.0, "episode": 5236.0, "batch_reward": 8.691633224487305, "critic_loss": 207.37881469726562, "actor_loss": -1430.823486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.6432936191558838, "alpha_loss": -0.16755640506744385, "alpha_value": 0.3232794263019301, "duration": 1.4427719116210938, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 524000}
{"episode_reward": 0.0, "episode": 5241.0, "batch_reward": 9.339237213134766, "critic_loss": 334.5589599609375, "actor_loss": -1434.198486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.6003370881080627, "alpha_loss": 0.24211177229881287, "alpha_value": 0.3209249151767566, "duration": 1.3767750263214111, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 524500}
{"episode_reward": 0.0, "episode": 5246.0, "batch_reward": 8.730559349060059, "critic_loss": 653.7174072265625, "actor_loss": -1459.872802734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7181693911552429, "alpha_loss": -0.06269080936908722, "alpha_value": 0.31906492588662216, "duration": 1.6224737167358398, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 525000}
{"episode_reward": 0.0, "episode": 5251.0, "batch_reward": 8.842496871948242, "critic_loss": 349.3898620605469, "actor_loss": -1415.511474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.8977018594741821, "alpha_loss": -0.028994571417570114, "alpha_value": 0.31704656601102954, "duration": 1.6782050132751465, "info_normalized_performance_mean": 0.09104232490062714, "info_normalized_performance_final": 0.12983614206314087, "info_performance_mean": 0.09104232490062714, "info_performance_final": 0.12983614206314087, "step": 525500}
{"episode_reward": 182.08466090122872, "episode": 5256.0, "batch_reward": 9.102083206176758, "critic_loss": 344.4052734375, "actor_loss": -1432.91162109375, "actor_target_entropy": -3.0, "actor_entropy": 0.8142070770263672, "alpha_loss": 0.01615268364548683, "alpha_value": 0.3169725805938577, "duration": 1.5643317699432373, "info_normalized_performance_mean": 0.31207820773124695, "info_normalized_performance_final": 0.3572530746459961, "info_performance_mean": 0.31207820773124695, "info_performance_final": 0.3572530746459961, "step": 526000}
{"episode_reward": 624.1563786008218, "episode": 5261.0, "batch_reward": 9.572643280029297, "critic_loss": 309.13580322265625, "actor_loss": -1442.278076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.4512016773223877, "alpha_loss": 0.1503409743309021, "alpha_value": 0.3154725208245256, "duration": 1.4929871559143066, "info_normalized_performance_mean": 0.4096875786781311, "info_normalized_performance_final": 0.4496753215789795, "info_performance_mean": 0.4096875786781311, "info_performance_final": 0.4496753215789795, "step": 526500}
{"episode_reward": 819.3750000000013, "episode": 5266.0, "batch_reward": 9.238384246826172, "critic_loss": 347.4677734375, "actor_loss": -1451.5096435546875, "actor_target_entropy": -3.0, "actor_entropy": 0.5465302467346191, "alpha_loss": -0.04068966209888458, "alpha_value": 0.3137526031336726, "duration": 1.424757480621338, "info_normalized_performance_mean": 0.46848225593566895, "info_normalized_performance_final": 0.5107142925262451, "info_performance_mean": 0.46848225593566895, "info_performance_final": 0.5107142925262451, "step": 527000}
{"episode_reward": 936.964285714284, "episode": 5271.0, "batch_reward": 9.257070541381836, "critic_loss": 716.4580688476562, "actor_loss": -1451.9644775390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9284560680389404, "alpha_loss": -0.0004915222525596619, "alpha_value": 0.311722924448066, "duration": 1.4572248458862305, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 527500}
{"episode_reward": 0.0, "episode": 5276.0, "batch_reward": 9.820655822753906, "critic_loss": 858.8848876953125, "actor_loss": -1441.6611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8000520467758179, "alpha_loss": 0.08311827480792999, "alpha_value": 0.30866862058140493, "duration": 1.436819076538086, "info_normalized_performance_mean": 0.4425213932991028, "info_normalized_performance_final": 0.4841269850730896, "info_performance_mean": 0.4425213932991028, "info_performance_final": 0.4841269850730896, "step": 528000}
{"episode_reward": 885.0427350427336, "episode": 5281.0, "batch_reward": 10.016643524169922, "critic_loss": 400.4191589355469, "actor_loss": -1481.78857421875, "actor_target_entropy": -3.0, "actor_entropy": 0.562580406665802, "alpha_loss": 0.06557279080152512, "alpha_value": 0.30797648969307895, "duration": 1.7659766674041748, "info_normalized_performance_mean": 0.3738986849784851, "info_normalized_performance_final": 0.4326101243495941, "info_performance_mean": 0.3738986849784851, "info_performance_final": 0.4326101243495941, "step": 528500}
{"episode_reward": 747.7975016436566, "episode": 5286.0, "batch_reward": 8.089439392089844, "critic_loss": 411.071044921875, "actor_loss": -1416.701416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.8582245111465454, "alpha_loss": -0.24239030480384827, "alpha_value": 0.31048097028932653, "duration": 1.519998550415039, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 529000}
{"episode_reward": 0.0, "episode": 5291.0, "batch_reward": 8.60307502746582, "critic_loss": 692.19873046875, "actor_loss": -1391.0743408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.4795195460319519, "alpha_loss": 0.03114922344684601, "alpha_value": 0.3120482199120384, "duration": 1.42836594581604, "info_normalized_performance_mean": 0.3497265577316284, "info_normalized_performance_final": 0.38671875, "info_performance_mean": 0.3497265577316284, "info_performance_final": 0.38671875, "step": 529500}
{"episode_reward": 699.453125, "episode": 5296.0, "batch_reward": 9.484511375427246, "critic_loss": 382.62030029296875, "actor_loss": -1410.3946533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1139936447143555, "alpha_loss": -0.03284527733922005, "alpha_value": 0.3154404514490849, "step": 530000}
{"duration": 19.148994207382202, "info_normalized_performance_mean": 0.860791802406311, "info_normalized_performance_final": 0.98416668176651, "info_performance_mean": 0.860791802406311, "info_performance_final": 0.98416668176651, "step": 530000}
{"episode_reward": 1721.583333333334, "episode": 5301.0, "batch_reward": 8.80817985534668, "critic_loss": 470.9229431152344, "actor_loss": -1400.455810546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7941837310791016, "alpha_loss": -0.03205450624227524, "alpha_value": 0.3199355625961086, "duration": 1.5918364524841309, "info_normalized_performance_mean": 0.20947295427322388, "info_normalized_performance_final": 0.23741690814495087, "info_performance_mean": 0.20947295427322388, "info_performance_final": 0.23741690814495087, "step": 530500}
{"episode_reward": 418.9458689458693, "episode": 5306.0, "batch_reward": 9.501078605651855, "critic_loss": 410.58447265625, "actor_loss": -1415.36279296875, "actor_target_entropy": -3.0, "actor_entropy": 0.756527304649353, "alpha_loss": 0.11833217740058899, "alpha_value": 0.3188835323427933, "duration": 1.5393784046173096, "info_normalized_performance_mean": 0.6338800191879272, "info_normalized_performance_final": 0.7070000171661377, "info_performance_mean": 0.6338800191879272, "info_performance_final": 0.7070000171661377, "step": 531000}
{"episode_reward": 1267.7599999999995, "episode": 5311.0, "batch_reward": 9.159137725830078, "critic_loss": 324.2890319824219, "actor_loss": -1431.17578125, "actor_target_entropy": -3.0, "actor_entropy": 0.7962445616722107, "alpha_loss": 0.031850606203079224, "alpha_value": 0.320562660751002, "duration": 1.47450590133667, "info_normalized_performance_mean": 0.4892810881137848, "info_normalized_performance_final": 0.5453296899795532, "info_performance_mean": 0.4892810881137848, "info_performance_final": 0.5453296899795532, "step": 531500}
{"episode_reward": 978.5622710622707, "episode": 5316.0, "batch_reward": 8.422111511230469, "critic_loss": 429.98638916015625, "actor_loss": -1375.8150634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.7368547320365906, "alpha_loss": -0.07620320469141006, "alpha_value": 0.32115206071555924, "duration": 1.5897691249847412, "info_normalized_performance_mean": 0.3785119652748108, "info_normalized_performance_final": 0.41335979104042053, "info_performance_mean": 0.3785119652748108, "info_performance_final": 0.41335979104042053, "step": 532000}
{"episode_reward": 757.0238095238083, "episode": 5321.0, "batch_reward": 9.18397331237793, "critic_loss": 2511.322509765625, "actor_loss": -1400.34423828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9257585406303406, "alpha_loss": -0.05107426643371582, "alpha_value": 0.32122429857584495, "duration": 1.4372599124908447, "info_normalized_performance_mean": 0.36661994457244873, "info_normalized_performance_final": 0.3988095223903656, "info_performance_mean": 0.36661994457244873, "info_performance_final": 0.3988095223903656, "step": 532500}
{"episode_reward": 733.2397959183677, "episode": 5326.0, "batch_reward": 9.744625091552734, "critic_loss": 355.8829345703125, "actor_loss": -1422.4080810546875, "actor_target_entropy": -3.0, "actor_entropy": 1.112945795059204, "alpha_loss": 0.14063498377799988, "alpha_value": 0.3220591103173837, "duration": 1.5911457538604736, "info_normalized_performance_mean": 0.3782896399497986, "info_normalized_performance_final": 0.429583340883255, "info_performance_mean": 0.3782896399497986, "info_performance_final": 0.429583340883255, "step": 533000}
{"episode_reward": 756.5791666666668, "episode": 5331.0, "batch_reward": 8.806747436523438, "critic_loss": 286.93878173828125, "actor_loss": -1375.623779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9301374554634094, "alpha_loss": -0.10250194370746613, "alpha_value": 0.3221703821060749, "duration": 1.5589170455932617, "info_normalized_performance_mean": 0.7242582440376282, "info_normalized_performance_final": 0.8159340620040894, "info_performance_mean": 0.7242582440376282, "info_performance_final": 0.8159340620040894, "step": 533500}
{"episode_reward": 1448.5164835164821, "episode": 5336.0, "batch_reward": 8.810066223144531, "critic_loss": 336.66558837890625, "actor_loss": -1380.292236328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8335599899291992, "alpha_loss": 0.12319284677505493, "alpha_value": 0.32252570544615067, "duration": 1.5471537113189697, "info_normalized_performance_mean": 0.4452216625213623, "info_normalized_performance_final": 0.49186307191848755, "info_performance_mean": 0.4452216625213623, "info_performance_final": 0.49186307191848755, "step": 534000}
{"episode_reward": 890.4433221099891, "episode": 5341.0, "batch_reward": 8.674983024597168, "critic_loss": 343.4659423828125, "actor_loss": -1390.738525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.775926947593689, "alpha_loss": 0.039416685700416565, "alpha_value": 0.3242893587361603, "duration": 1.4430944919586182, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 534500}
{"episode_reward": 0.0, "episode": 5346.0, "batch_reward": 9.401148796081543, "critic_loss": 498.9174499511719, "actor_loss": -1408.3193359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9690170884132385, "alpha_loss": -0.009905489161610603, "alpha_value": 0.32392512557021497, "duration": 1.4987542629241943, "info_normalized_performance_mean": 0.5196134448051453, "info_normalized_performance_final": 0.5815126299858093, "info_performance_mean": 0.5196134448051453, "info_performance_final": 0.5815126299858093, "step": 535000}
{"episode_reward": 1039.226890756304, "episode": 5351.0, "batch_reward": 9.708498001098633, "critic_loss": 271.6588439941406, "actor_loss": -1453.2078857421875, "actor_target_entropy": -3.0, "actor_entropy": 0.5840973854064941, "alpha_loss": 0.05296888202428818, "alpha_value": 0.3264874792747983, "duration": 1.5793921947479248, "info_normalized_performance_mean": 0.37623006105422974, "info_normalized_performance_final": 0.41905900835990906, "info_performance_mean": 0.37623006105422974, "info_performance_final": 0.41905900835990906, "step": 535500}
{"episode_reward": 752.4601275917056, "episode": 5356.0, "batch_reward": 9.753843307495117, "critic_loss": 273.39691162109375, "actor_loss": -1469.36962890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6646949648857117, "alpha_loss": -0.055873606353998184, "alpha_value": 0.3275308226348375, "duration": 1.5457298755645752, "info_normalized_performance_mean": 0.42283564805984497, "info_normalized_performance_final": 0.47453704476356506, "info_performance_mean": 0.42283564805984497, "info_performance_final": 0.47453704476356506, "step": 536000}
{"episode_reward": 845.6712962962968, "episode": 5361.0, "batch_reward": 7.9621477127075195, "critic_loss": 245.35986328125, "actor_loss": -1370.98876953125, "actor_target_entropy": -3.0, "actor_entropy": 0.5565897822380066, "alpha_loss": -0.1337338387966156, "alpha_value": 0.3293884133898584, "duration": 1.659602403640747, "info_normalized_performance_mean": 0.49399471282958984, "info_normalized_performance_final": 0.6177248954772949, "info_performance_mean": 0.49399471282958984, "info_performance_final": 0.6177248954772949, "step": 536500}
{"episode_reward": 987.9894179894168, "episode": 5366.0, "batch_reward": 8.732891082763672, "critic_loss": 494.8298645019531, "actor_loss": -1372.2230224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1235666275024414, "alpha_loss": 0.13543754816055298, "alpha_value": 0.32886329984978385, "duration": 1.5147175788879395, "info_normalized_performance_mean": 0.41546547412872314, "info_normalized_performance_final": 0.4524739682674408, "info_performance_mean": 0.41546547412872314, "info_performance_final": 0.4524739682674408, "step": 537000}
{"episode_reward": 830.9309895833325, "episode": 5371.0, "batch_reward": 8.815664291381836, "critic_loss": 778.7910766601562, "actor_loss": -1384.3912353515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7473099231719971, "alpha_loss": 0.07250024378299713, "alpha_value": 0.32878345140752874, "duration": 1.5082924365997314, "info_normalized_performance_mean": 0.5634379982948303, "info_normalized_performance_final": 0.6326530575752258, "info_performance_mean": 0.5634379982948303, "info_performance_final": 0.6326530575752258, "step": 537500}
{"episode_reward": 1126.875981161695, "episode": 5376.0, "batch_reward": 8.631020545959473, "critic_loss": 616.723876953125, "actor_loss": -1381.404052734375, "actor_target_entropy": -3.0, "actor_entropy": 0.5408750772476196, "alpha_loss": -0.040146246552467346, "alpha_value": 0.32729288295826386, "duration": 1.5108363628387451, "info_normalized_performance_mean": 0.6728825569152832, "info_normalized_performance_final": 0.7525510191917419, "info_performance_mean": 0.6728825569152832, "info_performance_final": 0.7525510191917419, "step": 538000}
{"episode_reward": 1345.7653061224507, "episode": 5381.0, "batch_reward": 8.86068344116211, "critic_loss": 633.6181640625, "actor_loss": -1378.08935546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7924147844314575, "alpha_loss": 0.20465748012065887, "alpha_value": 0.324977131704856, "duration": 1.5569579601287842, "info_normalized_performance_mean": 0.46747612953186035, "info_normalized_performance_final": 0.5023809671401978, "info_performance_mean": 0.46747612953186035, "info_performance_final": 0.5023809671401978, "step": 538500}
{"episode_reward": 934.9523809523802, "episode": 5386.0, "batch_reward": 8.534212112426758, "critic_loss": 575.1742553710938, "actor_loss": -1372.1634521484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7782024145126343, "alpha_loss": -0.07725134491920471, "alpha_value": 0.325662584670169, "duration": 1.5393884181976318, "info_normalized_performance_mean": 0.14330001175403595, "info_normalized_performance_final": 0.2133333384990692, "info_performance_mean": 0.14330001175403595, "info_performance_final": 0.2133333384990692, "step": 539000}
{"episode_reward": 286.5999999999999, "episode": 5391.0, "batch_reward": 9.361173629760742, "critic_loss": 362.82415771484375, "actor_loss": -1384.2574462890625, "actor_target_entropy": -3.0, "actor_entropy": 0.8921352624893188, "alpha_loss": 0.15072736144065857, "alpha_value": 0.32697896133796306, "duration": 1.4043819904327393, "info_normalized_performance_mean": 0.08069899678230286, "info_normalized_performance_final": 0.08979591727256775, "info_performance_mean": 0.08069899678230286, "info_performance_final": 0.08979591727256775, "step": 539500}
{"episode_reward": 161.39795918367335, "episode": 5396.0, "batch_reward": 8.684825897216797, "critic_loss": 850.9439086914062, "actor_loss": -1346.844970703125, "actor_target_entropy": -3.0, "actor_entropy": 0.607824981212616, "alpha_loss": -0.042855262756347656, "alpha_value": 0.3236750893907058, "step": 540000}
{"duration": 18.44920301437378, "info_normalized_performance_mean": 0.21000434458255768, "info_normalized_performance_final": 0.2309027761220932, "info_performance_mean": 0.21000434458255768, "info_performance_final": 0.2309027761220932, "step": 540000}
{"episode_reward": 420.0086805555548, "episode": 5401.0, "batch_reward": 8.62755012512207, "critic_loss": 218.52606201171875, "actor_loss": -1380.395263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8276897668838501, "alpha_loss": -0.05880340188741684, "alpha_value": 0.3198032014604432, "duration": 1.4859881401062012, "info_normalized_performance_mean": 0.6215277314186096, "info_normalized_performance_final": 0.788690447807312, "info_performance_mean": 0.6215277314186096, "info_performance_final": 0.788690447807312, "step": 540500}
{"episode_reward": 1243.055555555557, "episode": 5406.0, "batch_reward": 9.762701034545898, "critic_loss": 970.4673461914062, "actor_loss": -1407.746826171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7743381261825562, "alpha_loss": -0.005950562655925751, "alpha_value": 0.31669227210054346, "duration": 1.4669482707977295, "info_normalized_performance_mean": 0.32329368591308594, "info_normalized_performance_final": 0.3541666567325592, "info_performance_mean": 0.32329368591308594, "info_performance_final": 0.3541666567325592, "step": 541000}
{"episode_reward": 646.5873015873018, "episode": 5411.0, "batch_reward": 8.629735946655273, "critic_loss": 644.6690673828125, "actor_loss": -1369.0372314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7079266309738159, "alpha_loss": 0.08225704729557037, "alpha_value": 0.3180864737532362, "duration": 1.4760117530822754, "info_normalized_performance_mean": 0.4502806067466736, "info_normalized_performance_final": 0.5, "info_performance_mean": 0.4502806067466736, "info_performance_final": 0.5, "step": 541500}
{"episode_reward": 900.5612244897959, "episode": 5416.0, "batch_reward": 9.239350318908691, "critic_loss": 738.441162109375, "actor_loss": -1366.4600830078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8791987895965576, "alpha_loss": -0.009422865696251392, "alpha_value": 0.3153591719298662, "duration": 1.5092604160308838, "info_normalized_performance_mean": 0.8940625190734863, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.8940625190734863, "info_performance_final": 1.0, "step": 542000}
{"episode_reward": 1788.125, "episode": 5421.0, "batch_reward": 9.966557502746582, "critic_loss": 563.5740356445312, "actor_loss": -1429.1722412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.4323633313179016, "alpha_loss": 0.14820954203605652, "alpha_value": 0.3157389735470982, "duration": 1.5868744850158691, "info_normalized_performance_mean": 0.8473572731018066, "info_normalized_performance_final": 0.9357143044471741, "info_performance_mean": 0.8473572731018066, "info_performance_final": 0.9357143044471741, "step": 542500}
{"episode_reward": 1694.7142857142867, "episode": 5426.0, "batch_reward": 7.96156644821167, "critic_loss": 417.8943786621094, "actor_loss": -1307.94921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7119848132133484, "alpha_loss": -0.23569181561470032, "alpha_value": 0.3156256746752327, "duration": 1.597856044769287, "info_normalized_performance_mean": 0.8484976887702942, "info_normalized_performance_final": 0.9723557829856873, "info_performance_mean": 0.8484976887702942, "info_performance_final": 0.9723557829856873, "step": 543000}
{"episode_reward": 1696.9951923076937, "episode": 5431.0, "batch_reward": 9.425741195678711, "critic_loss": 892.6129760742188, "actor_loss": -1431.0531005859375, "actor_target_entropy": -3.0, "actor_entropy": 0.7873450517654419, "alpha_loss": -0.06793880462646484, "alpha_value": 0.3189720082972015, "duration": 1.5861256122589111, "info_normalized_performance_mean": 0.4374522268772125, "info_normalized_performance_final": 0.482045441865921, "info_performance_mean": 0.4374522268772125, "info_performance_final": 0.482045441865921, "step": 543500}
{"episode_reward": 874.9045454545444, "episode": 5436.0, "batch_reward": 8.662628173828125, "critic_loss": 270.7080078125, "actor_loss": -1381.946533203125, "actor_target_entropy": -3.0, "actor_entropy": 0.7350481152534485, "alpha_loss": -0.0896659567952156, "alpha_value": 0.3263159990752111, "duration": 1.5091049671173096, "info_normalized_performance_mean": 0.3993302881717682, "info_normalized_performance_final": 0.43710407614707947, "info_performance_mean": 0.3993302881717682, "info_performance_final": 0.43710407614707947, "step": 544000}
{"episode_reward": 798.6606334841618, "episode": 5441.0, "batch_reward": 8.582554817199707, "critic_loss": 440.69110107421875, "actor_loss": -1411.3736572265625, "actor_target_entropy": -3.0, "actor_entropy": 0.5581116676330566, "alpha_loss": -0.20454628765583038, "alpha_value": 0.3338945565012385, "duration": 1.4501490592956543, "info_normalized_performance_mean": 0.38403624296188354, "info_normalized_performance_final": 0.4217686951160431, "info_performance_mean": 0.38403624296188354, "info_performance_final": 0.4217686951160431, "step": 544500}
{"episode_reward": 768.0725623582778, "episode": 5446.0, "batch_reward": 8.958709716796875, "critic_loss": 1149.3660888671875, "actor_loss": -1379.91259765625, "actor_target_entropy": -3.0, "actor_entropy": 0.563978374004364, "alpha_loss": -0.27994877099990845, "alpha_value": 0.34214029388168604, "duration": 1.600844383239746, "info_normalized_performance_mean": 0.4344998896121979, "info_normalized_performance_final": 0.4781818091869354, "info_performance_mean": 0.4344998896121979, "info_performance_final": 0.4781818091869354, "step": 545000}
{"episode_reward": 869.000000000002, "episode": 5451.0, "batch_reward": 9.729961395263672, "critic_loss": 164.1483154296875, "actor_loss": -1402.9521484375, "actor_target_entropy": -3.0, "actor_entropy": 0.9360998272895813, "alpha_loss": 0.19588199257850647, "alpha_value": 0.3499151054162998, "duration": 1.5941152572631836, "info_normalized_performance_mean": 0.7073411345481873, "info_normalized_performance_final": 0.7896825671195984, "info_performance_mean": 0.7073411345481873, "info_performance_final": 0.7896825671195984, "step": 545500}
{"episode_reward": 1414.6825396825423, "episode": 5456.0, "batch_reward": 8.417319297790527, "critic_loss": 635.3866577148438, "actor_loss": -1402.121337890625, "actor_target_entropy": -3.0, "actor_entropy": 0.4224281907081604, "alpha_loss": -0.013561174273490906, "alpha_value": 0.3576313973208967, "duration": 1.435922622680664, "info_normalized_performance_mean": 0.3861485421657562, "info_normalized_performance_final": 0.41933760046958923, "info_performance_mean": 0.3861485421657562, "info_performance_final": 0.41933760046958923, "step": 546000}
{"episode_reward": 772.2970085470101, "episode": 5461.0, "batch_reward": 9.452595710754395, "critic_loss": 520.4180297851562, "actor_loss": -1398.8939208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.7379566431045532, "alpha_loss": 0.026508182287216187, "alpha_value": 0.3613038405359131, "duration": 1.4819934368133545, "info_normalized_performance_mean": 0.31714338064193726, "info_normalized_performance_final": 0.3476702570915222, "info_performance_mean": 0.31714338064193726, "info_performance_final": 0.3476702570915222, "step": 546500}
{"episode_reward": 634.2867383512546, "episode": 5466.0, "batch_reward": 7.733086109161377, "critic_loss": 419.65924072265625, "actor_loss": -1371.5789794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.5631134510040283, "alpha_loss": -0.1531233936548233, "alpha_value": 0.3660867420513316, "duration": 1.5503196716308594, "info_normalized_performance_mean": 0.8642330765724182, "info_normalized_performance_final": 0.949999988079071, "info_performance_mean": 0.8642330765724182, "info_performance_final": 0.949999988079071, "step": 547000}
{"episode_reward": 1728.4666666666667, "episode": 5471.0, "batch_reward": 9.303129196166992, "critic_loss": 745.50732421875, "actor_loss": -1382.8614501953125, "actor_target_entropy": -3.0, "actor_entropy": 0.676978349685669, "alpha_loss": 0.06144325062632561, "alpha_value": 0.37028444683461204, "duration": 1.540485143661499, "info_normalized_performance_mean": 0.5417919754981995, "info_normalized_performance_final": 0.5900452733039856, "info_performance_mean": 0.5417919754981995, "info_performance_final": 0.5900452733039856, "step": 547500}
{"episode_reward": 1083.5837104072405, "episode": 5476.0, "batch_reward": 8.797133445739746, "critic_loss": 406.40966796875, "actor_loss": -1389.4932861328125, "actor_target_entropy": -3.0, "actor_entropy": 0.6239751577377319, "alpha_loss": -0.028706621378660202, "alpha_value": 0.37437027219049374, "duration": 1.5082025527954102, "info_normalized_performance_mean": 0.25070494413375854, "info_normalized_performance_final": 0.2759999930858612, "info_performance_mean": 0.25070494413375854, "info_performance_final": 0.2759999930858612, "step": 548000}
{"episode_reward": 501.4099999999994, "episode": 5481.0, "batch_reward": 8.702692031860352, "critic_loss": 1943.0120849609375, "actor_loss": -1388.767578125, "actor_target_entropy": -3.0, "actor_entropy": 0.7366646528244019, "alpha_loss": -0.14354386925697327, "alpha_value": 0.37966029027185044, "duration": 1.4440712928771973, "info_normalized_performance_mean": 0.8133928179740906, "info_normalized_performance_final": 0.9107142686843872, "info_performance_mean": 0.8133928179740906, "info_performance_final": 0.9107142686843872, "step": 548500}
{"episode_reward": 1626.7857142857151, "episode": 5486.0, "batch_reward": 9.651799201965332, "critic_loss": 350.6553955078125, "actor_loss": -1417.297119140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8615474104881287, "alpha_loss": 0.010922208428382874, "alpha_value": 0.38251422689531195, "duration": 1.6238150596618652, "info_normalized_performance_mean": 0.579001784324646, "info_normalized_performance_final": 0.6336805820465088, "info_performance_mean": 0.579001784324646, "info_performance_final": 0.6336805820465088, "step": 549000}
{"episode_reward": 1158.0034722222206, "episode": 5491.0, "batch_reward": 9.489141464233398, "critic_loss": 548.5084838867188, "actor_loss": -1412.0152587890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9972565770149231, "alpha_loss": 0.06602694094181061, "alpha_value": 0.38396373455590327, "duration": 1.5943052768707275, "info_normalized_performance_mean": 0.5867013335227966, "info_normalized_performance_final": 0.6409721970558167, "info_performance_mean": 0.5867013335227966, "info_performance_final": 0.6409721970558167, "step": 549500}
{"episode_reward": 1173.4027777777774, "episode": 5496.0, "batch_reward": 9.14653205871582, "critic_loss": 257.6852722167969, "actor_loss": -1423.236083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9011384844779968, "alpha_loss": -0.016236092895269394, "alpha_value": 0.38628920093711766, "step": 550000}
{"duration": 18.83335280418396, "info_normalized_performance_mean": 0.30166152119636536, "info_normalized_performance_final": 0.332561731338501, "info_performance_mean": 0.30166152119636536, "info_performance_final": 0.332561731338501, "step": 550000}
{"episode_reward": 603.3230452674895, "episode": 5501.0, "batch_reward": 8.197198867797852, "critic_loss": 224.22103881835938, "actor_loss": -1341.3544921875, "actor_target_entropy": -3.0, "actor_entropy": 0.9339710474014282, "alpha_loss": 0.1016298234462738, "alpha_value": 0.38979192669909174, "duration": 1.6173486709594727, "info_normalized_performance_mean": 0.24029076099395752, "info_normalized_performance_final": 0.27180713415145874, "info_performance_mean": 0.24029076099395752, "info_performance_final": 0.27180713415145874, "step": 550500}
{"episode_reward": 480.5815237394194, "episode": 5506.0, "batch_reward": 9.35657024383545, "critic_loss": 667.063232421875, "actor_loss": -1442.0784912109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9178296327590942, "alpha_loss": 0.03891456872224808, "alpha_value": 0.3855510722667161, "duration": 1.5316815376281738, "info_normalized_performance_mean": 0.24735592305660248, "info_normalized_performance_final": 0.27314814925193787, "info_performance_mean": 0.24735592305660248, "info_performance_final": 0.27314814925193787, "step": 551000}
{"episode_reward": 494.71193415637975, "episode": 5511.0, "batch_reward": 8.286176681518555, "critic_loss": 472.2891845703125, "actor_loss": -1370.015869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7487396597862244, "alpha_loss": 0.015193354338407516, "alpha_value": 0.3819791723789913, "duration": 1.5900530815124512, "info_normalized_performance_mean": 0.6011830568313599, "info_normalized_performance_final": 0.65625, "info_performance_mean": 0.6011830568313599, "info_performance_final": 0.65625, "step": 551500}
{"episode_reward": 1202.3660714285716, "episode": 5516.0, "batch_reward": 8.711892127990723, "critic_loss": 242.0968017578125, "actor_loss": -1351.8675537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1966221332550049, "alpha_loss": 0.10693462938070297, "alpha_value": 0.37854790082362455, "duration": 1.4219050407409668, "info_normalized_performance_mean": 0.3765178620815277, "info_normalized_performance_final": 0.4799107015132904, "info_performance_mean": 0.3765178620815277, "info_performance_final": 0.4799107015132904, "step": 552000}
{"episode_reward": 753.0357142857154, "episode": 5521.0, "batch_reward": 8.549263000488281, "critic_loss": 397.81256103515625, "actor_loss": -1382.2515869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6304657459259033, "alpha_loss": -0.06681810319423676, "alpha_value": 0.377713253010206, "duration": 1.6760759353637695, "info_normalized_performance_mean": 0.22764191031455994, "info_normalized_performance_final": 0.2591575086116791, "info_performance_mean": 0.22764191031455994, "info_performance_final": 0.2591575086116791, "step": 552500}
{"episode_reward": 455.28388278388326, "episode": 5526.0, "batch_reward": 7.223706245422363, "critic_loss": 280.8716125488281, "actor_loss": -1310.3245849609375, "actor_target_entropy": -3.0, "actor_entropy": 0.9715954065322876, "alpha_loss": 0.004700224846601486, "alpha_value": 0.3809480903969133, "duration": 1.663466453552246, "info_normalized_performance_mean": 0.5117145776748657, "info_normalized_performance_final": 0.5667862892150879, "info_performance_mean": 0.5117145776748657, "info_performance_final": 0.5667862892150879, "step": 553000}
{"episode_reward": 1023.4290271132392, "episode": 5531.0, "batch_reward": 8.942051887512207, "critic_loss": 626.7582397460938, "actor_loss": -1396.4404296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8649494647979736, "alpha_loss": 0.021513022482395172, "alpha_value": 0.37862775912531454, "duration": 1.4486160278320312, "info_normalized_performance_mean": 0.46985793113708496, "info_normalized_performance_final": 0.515625, "info_performance_mean": 0.46985793113708496, "info_performance_final": 0.515625, "step": 553500}
{"episode_reward": 939.7159090909096, "episode": 5536.0, "batch_reward": 10.317380905151367, "critic_loss": 985.6839599609375, "actor_loss": -1475.029541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1161061525344849, "alpha_loss": 0.11516563594341278, "alpha_value": 0.37422844381019016, "duration": 1.6413955688476562, "info_normalized_performance_mean": 0.6737420558929443, "info_normalized_performance_final": 0.7469135522842407, "info_performance_mean": 0.6737420558929443, "info_performance_final": 0.7469135522842407, "step": 554000}
{"episode_reward": 1347.4845679012344, "episode": 5541.0, "batch_reward": 9.287025451660156, "critic_loss": 450.6968994140625, "actor_loss": -1420.54833984375, "actor_target_entropy": -3.0, "actor_entropy": 0.7475346326828003, "alpha_loss": 0.050818298012018204, "alpha_value": 0.3716876571938109, "duration": 1.50404953956604, "info_normalized_performance_mean": 0.87038254737854, "info_normalized_performance_final": 0.9744898080825806, "info_performance_mean": 0.87038254737854, "info_performance_final": 0.9744898080825806, "step": 554500}
{"episode_reward": 1740.765306122445, "episode": 5546.0, "batch_reward": 10.031852722167969, "critic_loss": 530.6221313476562, "actor_loss": -1410.45751953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1499686241149902, "alpha_loss": 0.19008393585681915, "alpha_value": 0.36910394450626643, "duration": 1.453826665878296, "info_normalized_performance_mean": 0.42975762486457825, "info_normalized_performance_final": 0.4681122303009033, "info_performance_mean": 0.42975762486457825, "info_performance_final": 0.4681122303009033, "step": 555000}
{"episode_reward": 859.5153061224474, "episode": 5551.0, "batch_reward": 9.37272834777832, "critic_loss": 1660.45703125, "actor_loss": -1387.5091552734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8555811047554016, "alpha_loss": -0.0329122468829155, "alpha_value": 0.36828753136881637, "duration": 1.6185741424560547, "info_normalized_performance_mean": 0.8070917725563049, "info_normalized_performance_final": 0.9116666913032532, "info_performance_mean": 0.8070917725563049, "info_performance_final": 0.9116666913032532, "step": 555500}
{"episode_reward": 1614.1833333333343, "episode": 5556.0, "batch_reward": 9.700430870056152, "critic_loss": 317.94854736328125, "actor_loss": -1423.915771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.6595108509063721, "alpha_loss": 0.015448963269591331, "alpha_value": 0.36666438197474155, "duration": 1.5997626781463623, "info_normalized_performance_mean": 0.7563166618347168, "info_normalized_performance_final": 0.8125, "info_performance_mean": 0.7563166618347168, "info_performance_final": 0.8125, "step": 556000}
{"episode_reward": 1512.6333333333332, "episode": 5561.0, "batch_reward": 9.802895545959473, "critic_loss": 714.8104858398438, "actor_loss": -1378.348876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.0872398614883423, "alpha_loss": -0.007950004190206528, "alpha_value": 0.36733094105771164, "duration": 1.4710617065429688, "info_normalized_performance_mean": 0.49581173062324524, "info_normalized_performance_final": 0.5422077775001526, "info_performance_mean": 0.49581173062324524, "info_performance_final": 0.5422077775001526, "step": 556500}
{"episode_reward": 991.6233766233754, "episode": 5566.0, "batch_reward": 8.84029769897461, "critic_loss": 1579.4788818359375, "actor_loss": -1345.324462890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9848500490188599, "alpha_loss": 0.049658048897981644, "alpha_value": 0.36494570483940064, "duration": 1.4670867919921875, "info_normalized_performance_mean": 0.5924800634384155, "info_normalized_performance_final": 0.6463293433189392, "info_performance_mean": 0.5924800634384155, "info_performance_final": 0.6463293433189392, "step": 557000}
{"episode_reward": 1184.960317460318, "episode": 5571.0, "batch_reward": 9.499738693237305, "critic_loss": 776.7486572265625, "actor_loss": -1403.8140869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.758557915687561, "alpha_loss": 0.07862363010644913, "alpha_value": 0.36301140399869936, "duration": 1.4508240222930908, "info_normalized_performance_mean": 0.3086925745010376, "info_normalized_performance_final": 0.3335459232330322, "info_performance_mean": 0.3086925745010376, "info_performance_final": 0.3335459232330322, "step": 557500}
{"episode_reward": 617.3852040816329, "episode": 5576.0, "batch_reward": 9.708011627197266, "critic_loss": 349.75262451171875, "actor_loss": -1387.4697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3441009521484375, "alpha_loss": 0.18312399089336395, "alpha_value": 0.36108346936486063, "duration": 1.5832908153533936, "info_normalized_performance_mean": 0.35767510533332825, "info_normalized_performance_final": 0.3973466753959656, "info_performance_mean": 0.35767510533332825, "info_performance_final": 0.3973466753959656, "step": 558000}
{"episode_reward": 715.3501522401046, "episode": 5581.0, "batch_reward": 9.807719230651855, "critic_loss": 635.4521484375, "actor_loss": -1409.6744384765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9942603707313538, "alpha_loss": 0.11073100566864014, "alpha_value": 0.35822736740671507, "duration": 1.5297863483428955, "info_normalized_performance_mean": 0.42015931010246277, "info_normalized_performance_final": 0.45883414149284363, "info_performance_mean": 0.42015931010246277, "info_performance_final": 0.45883414149284363, "step": 558500}
{"episode_reward": 840.3185096153857, "episode": 5586.0, "batch_reward": 9.441364288330078, "critic_loss": 244.37014770507812, "actor_loss": -1390.64697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2027671337127686, "alpha_loss": 0.13606467843055725, "alpha_value": 0.3611710655614701, "duration": 1.5359609127044678, "info_normalized_performance_mean": 0.5405308604240417, "info_normalized_performance_final": 0.595370352268219, "info_performance_mean": 0.5405308604240417, "info_performance_final": 0.595370352268219, "step": 559000}
{"episode_reward": 1081.0617283950608, "episode": 5591.0, "batch_reward": 9.643712997436523, "critic_loss": 308.07867431640625, "actor_loss": -1389.28125, "actor_target_entropy": -3.0, "actor_entropy": 1.4462916851043701, "alpha_loss": -0.06834648549556732, "alpha_value": 0.3644898218074048, "duration": 1.6138715744018555, "info_normalized_performance_mean": 0.6191204190254211, "info_normalized_performance_final": 0.6838624477386475, "info_performance_mean": 0.6191204190254211, "info_performance_final": 0.6838624477386475, "step": 559500}
{"episode_reward": 1238.2407407407406, "episode": 5596.0, "batch_reward": 8.82281494140625, "critic_loss": 684.3460083007812, "actor_loss": -1362.934326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8308924436569214, "alpha_loss": -0.08519503474235535, "alpha_value": 0.366905665017781, "step": 560000}
{"duration": 18.90329647064209, "info_normalized_performance_mean": 0.8830001354217529, "info_normalized_performance_final": 0.9686274528503418, "info_performance_mean": 0.8830001354217529, "info_performance_final": 0.9686274528503418, "step": 560000}
{"episode_reward": 1765.999999999996, "episode": 5601.0, "batch_reward": 10.532088279724121, "critic_loss": 571.9879150390625, "actor_loss": -1412.234375, "actor_target_entropy": -3.0, "actor_entropy": 1.0726649761199951, "alpha_loss": 0.203528493642807, "alpha_value": 0.3669468763133992, "duration": 1.5584080219268799, "info_normalized_performance_mean": 0.4036467373371124, "info_normalized_performance_final": 0.4463437795639038, "info_performance_mean": 0.4036467373371124, "info_performance_final": 0.4463437795639038, "step": 560500}
{"episode_reward": 807.2934472934475, "episode": 5606.0, "batch_reward": 10.291829109191895, "critic_loss": 434.997802734375, "actor_loss": -1418.48486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8527398705482483, "alpha_loss": 0.112088143825531, "alpha_value": 0.3660045172838724, "duration": 1.6190476417541504, "info_normalized_performance_mean": 0.4919480085372925, "info_normalized_performance_final": 0.5339105129241943, "info_performance_mean": 0.4919480085372925, "info_performance_final": 0.5339105129241943, "step": 561000}
{"episode_reward": 983.8961038961047, "episode": 5611.0, "batch_reward": 9.095874786376953, "critic_loss": 617.662841796875, "actor_loss": -1371.69775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1393983364105225, "alpha_loss": 0.1948920488357544, "alpha_value": 0.3674928580567797, "duration": 1.5752298831939697, "info_normalized_performance_mean": 0.8157572150230408, "info_normalized_performance_final": 0.9194711446762085, "info_performance_mean": 0.8157572150230408, "info_performance_final": 0.9194711446762085, "step": 561500}
{"episode_reward": 1631.5144230769245, "episode": 5616.0, "batch_reward": 9.249753952026367, "critic_loss": 576.099365234375, "actor_loss": -1381.469482421875, "actor_target_entropy": -3.0, "actor_entropy": 0.784096360206604, "alpha_loss": 0.00748143345117569, "alpha_value": 0.36680601484882186, "duration": 1.5790793895721436, "info_normalized_performance_mean": 0.4017670452594757, "info_normalized_performance_final": 0.4448351562023163, "info_performance_mean": 0.4017670452594757, "info_performance_final": 0.4448351562023163, "step": 562000}
{"episode_reward": 803.5340659340674, "episode": 5621.0, "batch_reward": 9.002796173095703, "critic_loss": 548.6943969726562, "actor_loss": -1381.6787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.0260040760040283, "alpha_loss": 0.1840415894985199, "alpha_value": 0.3694862890163531, "duration": 1.54119873046875, "info_normalized_performance_mean": 0.2879064679145813, "info_normalized_performance_final": 0.31870129704475403, "info_performance_mean": 0.2879064679145813, "info_performance_final": 0.31870129704475403, "step": 562500}
{"episode_reward": 575.812987012987, "episode": 5626.0, "batch_reward": 8.666187286376953, "critic_loss": 508.43701171875, "actor_loss": -1333.179931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0619633197784424, "alpha_loss": 0.0453621931374073, "alpha_value": 0.37054752136351965, "duration": 1.6290283203125, "info_normalized_performance_mean": 0.6249855756759644, "info_normalized_performance_final": 0.6875901818275452, "info_performance_mean": 0.6249855756759644, "info_performance_final": 0.6875901818275452, "step": 563000}
{"episode_reward": 1249.97113997114, "episode": 5631.0, "batch_reward": 8.944900512695312, "critic_loss": 360.8638916015625, "actor_loss": -1383.2664794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.0021750926971436, "alpha_loss": 0.14736467599868774, "alpha_value": 0.36882537073049254, "duration": 1.5347709655761719, "info_normalized_performance_mean": 0.8351567983627319, "info_normalized_performance_final": 0.9509803652763367, "info_performance_mean": 0.8351567983627319, "info_performance_final": 0.9509803652763367, "step": 563500}
{"episode_reward": 1670.3137254901949, "episode": 5636.0, "batch_reward": 8.617196083068848, "critic_loss": 1361.4189453125, "actor_loss": -1349.4945068359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9331311583518982, "alpha_loss": -0.16484907269477844, "alpha_value": 0.36789963737366155, "duration": 1.622126817703247, "info_normalized_performance_mean": 0.39854222536087036, "info_normalized_performance_final": 0.4285714328289032, "info_performance_mean": 0.39854222536087036, "info_performance_final": 0.4285714328289032, "step": 564000}
{"episode_reward": 797.0845481049554, "episode": 5641.0, "batch_reward": 10.233057022094727, "critic_loss": 325.8559875488281, "actor_loss": -1380.649169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.0897679328918457, "alpha_loss": 0.045025281608104706, "alpha_value": 0.368290807436706, "duration": 1.69077467918396, "info_normalized_performance_mean": 0.44065940380096436, "info_normalized_performance_final": 0.4941460192203522, "info_performance_mean": 0.44065940380096436, "info_performance_final": 0.4941460192203522, "step": 564500}
{"episode_reward": 881.318870523415, "episode": 5646.0, "batch_reward": 9.745574951171875, "critic_loss": 187.31045532226562, "actor_loss": -1390.98974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.318418264389038, "alpha_loss": 0.15008023381233215, "alpha_value": 0.36921589729887927, "duration": 1.5797216892242432, "info_normalized_performance_mean": 0.49158337712287903, "info_normalized_performance_final": 0.5400000214576721, "info_performance_mean": 0.49158337712287903, "info_performance_final": 0.5400000214576721, "step": 565000}
{"episode_reward": 983.166666666665, "episode": 5651.0, "batch_reward": 9.026031494140625, "critic_loss": 371.7236328125, "actor_loss": -1372.664306640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0145680904388428, "alpha_loss": 0.026887021958827972, "alpha_value": 0.3706180944235141, "duration": 1.6988599300384521, "info_normalized_performance_mean": 0.26387566328048706, "info_normalized_performance_final": 0.29580026865005493, "info_performance_mean": 0.26387566328048706, "info_performance_final": 0.29580026865005493, "step": 565500}
{"episode_reward": 527.7513227513215, "episode": 5656.0, "batch_reward": 8.875020980834961, "critic_loss": 551.8412475585938, "actor_loss": -1397.6563720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.7086448073387146, "alpha_loss": -0.16110730171203613, "alpha_value": 0.36909345071724586, "duration": 1.5627131462097168, "info_normalized_performance_mean": 0.3108295500278473, "info_normalized_performance_final": 0.3425000011920929, "info_performance_mean": 0.3108295500278473, "info_performance_final": 0.3425000011920929, "step": 566000}
{"episode_reward": 621.6590909090919, "episode": 5661.0, "batch_reward": 9.651683807373047, "critic_loss": 456.3023681640625, "actor_loss": -1390.363525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9411504864692688, "alpha_loss": 0.17594186961650848, "alpha_value": 0.3640235057443394, "duration": 1.4386234283447266, "info_normalized_performance_mean": 0.3852296471595764, "info_normalized_performance_final": 0.4204059839248657, "info_performance_mean": 0.3852296471595764, "info_performance_final": 0.4204059839248657, "step": 566500}
{"episode_reward": 770.4594017094, "episode": 5666.0, "batch_reward": 9.999412536621094, "critic_loss": 786.1942749023438, "actor_loss": -1420.0010986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.9424160718917847, "alpha_loss": 0.037554360926151276, "alpha_value": 0.35818732024830235, "duration": 1.516791582107544, "info_normalized_performance_mean": 0.385161429643631, "info_normalized_performance_final": 0.42342033982276917, "info_performance_mean": 0.385161429643631, "info_performance_final": 0.42342033982276917, "step": 567000}
{"episode_reward": 770.3228021978025, "episode": 5671.0, "batch_reward": 9.715836524963379, "critic_loss": 210.63938903808594, "actor_loss": -1403.4254150390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1297028064727783, "alpha_loss": -0.05158358812332153, "alpha_value": 0.3546844725211122, "duration": 1.6971559524536133, "info_normalized_performance_mean": 0.3558502495288849, "info_normalized_performance_final": 0.42053401470184326, "info_performance_mean": 0.3558502495288849, "info_performance_final": 0.42053401470184326, "step": 567500}
{"episode_reward": 711.7005721551162, "episode": 5676.0, "batch_reward": 9.909823417663574, "critic_loss": 722.3379516601562, "actor_loss": -1431.131103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7176259756088257, "alpha_loss": 0.18032214045524597, "alpha_value": 0.35031887607479356, "duration": 1.636772632598877, "info_normalized_performance_mean": 0.7489097118377686, "info_normalized_performance_final": 0.8402777910232544, "info_performance_mean": 0.7489097118377686, "info_performance_final": 0.8402777910232544, "step": 568000}
{"episode_reward": 1497.8194444444468, "episode": 5681.0, "batch_reward": 9.253692626953125, "critic_loss": 561.178955078125, "actor_loss": -1371.809326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6686913371086121, "alpha_loss": 0.09825189411640167, "alpha_value": 0.3446308071650087, "duration": 1.5651931762695312, "info_normalized_performance_mean": 0.8375811576843262, "info_normalized_performance_final": 0.9188311696052551, "info_performance_mean": 0.8375811576843262, "info_performance_final": 0.9188311696052551, "step": 568500}
{"episode_reward": 1675.1623376623397, "episode": 5686.0, "batch_reward": 8.661659240722656, "critic_loss": 288.7603759765625, "actor_loss": -1371.74951171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8366026878356934, "alpha_loss": -0.17036092281341553, "alpha_value": 0.3413877476258042, "duration": 1.5033798217773438, "info_normalized_performance_mean": 0.7830730676651001, "info_normalized_performance_final": 0.8723958134651184, "info_performance_mean": 0.7830730676651001, "info_performance_final": 0.8723958134651184, "step": 569000}
{"episode_reward": 1566.1458333333348, "episode": 5691.0, "batch_reward": 9.984636306762695, "critic_loss": 450.59735107421875, "actor_loss": -1389.4403076171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8360483646392822, "alpha_loss": 0.07301297038793564, "alpha_value": 0.3387997096173723, "duration": 1.5791432857513428, "info_normalized_performance_mean": 0.6590973138809204, "info_normalized_performance_final": 0.7280092835426331, "info_performance_mean": 0.6590973138809204, "info_performance_final": 0.7280092835426331, "step": 569500}
{"episode_reward": 1318.194444444446, "episode": 5696.0, "batch_reward": 8.419071197509766, "critic_loss": 560.63623046875, "actor_loss": -1321.57080078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7444567084312439, "alpha_loss": -0.002503206953406334, "alpha_value": 0.33308192010617454, "step": 570000}
{"duration": 18.38170075416565, "info_normalized_performance_mean": 0.4873706102371216, "info_normalized_performance_final": 0.5431736707687378, "info_performance_mean": 0.4873706102371216, "info_performance_final": 0.5431736707687378, "step": 570000}
{"episode_reward": 974.7409579667662, "episode": 5701.0, "batch_reward": 9.199254989624023, "critic_loss": 2584.48779296875, "actor_loss": -1343.025146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.6572788953781128, "alpha_loss": -0.10860118269920349, "alpha_value": 0.3300448255105672, "duration": 1.4237196445465088, "info_normalized_performance_mean": 0.6370938420295715, "info_normalized_performance_final": 0.7281249761581421, "info_performance_mean": 0.6370938420295715, "info_performance_final": 0.7281249761581421, "step": 570500}
{"episode_reward": 1274.1875, "episode": 5706.0, "batch_reward": 8.972408294677734, "critic_loss": 190.23904418945312, "actor_loss": -1347.345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.212786078453064, "alpha_loss": 0.021636562421917915, "alpha_value": 0.32715213548015204, "duration": 1.4462039470672607, "info_normalized_performance_mean": 0.5820634961128235, "info_normalized_performance_final": 0.6349206566810608, "info_performance_mean": 0.5820634961128235, "info_performance_final": 0.6349206566810608, "step": 571000}
{"episode_reward": 1164.1269841269834, "episode": 5711.0, "batch_reward": 9.087518692016602, "critic_loss": 659.4981689453125, "actor_loss": -1347.588134765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8767101168632507, "alpha_loss": 0.16172966361045837, "alpha_value": 0.322004108624366, "duration": 1.5566606521606445, "info_normalized_performance_mean": 0.36841756105422974, "info_normalized_performance_final": 0.40656566619873047, "info_performance_mean": 0.36841756105422974, "info_performance_final": 0.40656566619873047, "step": 571500}
{"episode_reward": 736.835016835017, "episode": 5716.0, "batch_reward": 8.560545921325684, "critic_loss": 374.2665100097656, "actor_loss": -1314.90185546875, "actor_target_entropy": -3.0, "actor_entropy": 0.8508479595184326, "alpha_loss": 0.1453445851802826, "alpha_value": 0.3188434607774554, "duration": 1.486814022064209, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 572000}
{"episode_reward": 0.0, "episode": 5721.0, "batch_reward": 9.37152099609375, "critic_loss": 167.8229522705078, "actor_loss": -1381.1317138671875, "actor_target_entropy": -3.0, "actor_entropy": 0.6361072063446045, "alpha_loss": -0.04927237704396248, "alpha_value": 0.3176906141572402, "duration": 1.5253949165344238, "info_normalized_performance_mean": 0.7692604064941406, "info_normalized_performance_final": 0.8554621934890747, "info_performance_mean": 0.7692604064941406, "info_performance_final": 0.8554621934890747, "step": 572500}
{"episode_reward": 1538.5210084033636, "episode": 5726.0, "batch_reward": 8.989498138427734, "critic_loss": 679.063720703125, "actor_loss": -1355.94091796875, "actor_target_entropy": -3.0, "actor_entropy": 0.4615054130554199, "alpha_loss": 0.020976709201931953, "alpha_value": 0.31499195381949635, "duration": 1.6537482738494873, "info_normalized_performance_mean": 0.4080512225627899, "info_normalized_performance_final": 0.47237929701805115, "info_performance_mean": 0.4080512225627899, "info_performance_final": 0.47237929701805115, "step": 573000}
{"episode_reward": 816.1026533275339, "episode": 5731.0, "batch_reward": 8.839597702026367, "critic_loss": 621.458251953125, "actor_loss": -1307.169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.838067889213562, "alpha_loss": 0.07414550334215164, "alpha_value": 0.3127201648693422, "duration": 1.5330219268798828, "info_normalized_performance_mean": 0.29322388768196106, "info_normalized_performance_final": 0.4113355875015259, "info_performance_mean": 0.29322388768196106, "info_performance_final": 0.4113355875015259, "step": 573500}
{"episode_reward": 586.4478114478114, "episode": 5736.0, "batch_reward": 9.660592079162598, "critic_loss": 1488.9171142578125, "actor_loss": -1379.238525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8687669634819031, "alpha_loss": 0.07545939832925797, "alpha_value": 0.31299930196909576, "duration": 1.4628212451934814, "info_normalized_performance_mean": 0.49714288115501404, "info_normalized_performance_final": 0.5452806353569031, "info_performance_mean": 0.49714288115501404, "info_performance_final": 0.5452806353569031, "step": 574000}
{"episode_reward": 994.2857142857138, "episode": 5741.0, "batch_reward": 8.965424537658691, "critic_loss": 290.3017578125, "actor_loss": -1313.934814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7992398738861084, "alpha_loss": 0.030755333602428436, "alpha_value": 0.31087210604186233, "duration": 1.4387340545654297, "info_normalized_performance_mean": 0.3086962103843689, "info_normalized_performance_final": 0.3304988741874695, "info_performance_mean": 0.3086962103843689, "info_performance_final": 0.3304988741874695, "step": 574500}
{"episode_reward": 617.3922902494319, "episode": 5746.0, "batch_reward": 9.06759262084961, "critic_loss": 252.7640380859375, "actor_loss": -1317.37744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7166606187820435, "alpha_loss": 0.11293788254261017, "alpha_value": 0.31077161434309303, "duration": 1.5319924354553223, "info_normalized_performance_mean": 0.6857286691665649, "info_normalized_performance_final": 0.7599999904632568, "info_performance_mean": 0.6857286691665649, "info_performance_final": 0.7599999904632568, "step": 575000}
{"episode_reward": 1371.4571428571453, "episode": 5751.0, "batch_reward": 9.527205467224121, "critic_loss": 355.89581298828125, "actor_loss": -1383.362548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.504206120967865, "alpha_loss": 0.006895134225487709, "alpha_value": 0.31061617585106405, "duration": 1.4941082000732422, "info_normalized_performance_mean": 0.34454864263534546, "info_normalized_performance_final": 0.3764880895614624, "info_performance_mean": 0.34454864263534546, "info_performance_final": 0.3764880895614624, "step": 575500}
{"episode_reward": 689.0972222222233, "episode": 5756.0, "batch_reward": 9.725048065185547, "critic_loss": 361.48968505859375, "actor_loss": -1356.2642822265625, "actor_target_entropy": -3.0, "actor_entropy": 0.8311581611633301, "alpha_loss": 0.030848193913698196, "alpha_value": 0.31476358172737756, "duration": 1.5247626304626465, "info_normalized_performance_mean": 0.7683117389678955, "info_normalized_performance_final": 0.8327922224998474, "info_performance_mean": 0.7683117389678955, "info_performance_final": 0.8327922224998474, "step": 576000}
{"episode_reward": 1536.6233766233752, "episode": 5761.0, "batch_reward": 9.388381958007812, "critic_loss": 579.2098388671875, "actor_loss": -1359.704345703125, "actor_target_entropy": -3.0, "actor_entropy": 0.7231143712997437, "alpha_loss": -0.11427713185548782, "alpha_value": 0.31793725482138, "duration": 1.5321145057678223, "info_normalized_performance_mean": 0.8287326097488403, "info_normalized_performance_final": 0.8940972089767456, "info_performance_mean": 0.8287326097488403, "info_performance_final": 0.8940972089767456, "step": 576500}
{"episode_reward": 1657.4652777777749, "episode": 5766.0, "batch_reward": 9.540990829467773, "critic_loss": 502.6146545410156, "actor_loss": -1396.6539306640625, "actor_target_entropy": -3.0, "actor_entropy": 0.3859332203865051, "alpha_loss": 0.08336487412452698, "alpha_value": 0.3205135796549242, "duration": 1.5989587306976318, "info_normalized_performance_mean": 0.5252519845962524, "info_normalized_performance_final": 0.5942857265472412, "info_performance_mean": 0.5252519845962524, "info_performance_final": 0.5942857265472412, "step": 577000}
{"episode_reward": 1050.5038961038947, "episode": 5771.0, "batch_reward": 9.295673370361328, "critic_loss": 341.20135498046875, "actor_loss": -1359.15478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8888798952102661, "alpha_loss": -0.014716669917106628, "alpha_value": 0.3205690248420909, "duration": 1.5294554233551025, "info_normalized_performance_mean": 0.7610832452774048, "info_normalized_performance_final": 0.8349999785423279, "info_performance_mean": 0.7610832452774048, "info_performance_final": 0.8349999785423279, "step": 577500}
{"episode_reward": 1522.166666666669, "episode": 5776.0, "batch_reward": 9.223730087280273, "critic_loss": 372.25927734375, "actor_loss": -1366.0562744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7140741944313049, "alpha_loss": 0.004339488223195076, "alpha_value": 0.3214535333836715, "duration": 1.5401616096496582, "info_normalized_performance_mean": 0.8308749198913574, "info_normalized_performance_final": 0.9142857193946838, "info_performance_mean": 0.8308749198913574, "info_performance_final": 0.9142857193946838, "step": 578000}
{"episode_reward": 1661.749999999999, "episode": 5781.0, "batch_reward": 10.226502418518066, "critic_loss": 435.9037780761719, "actor_loss": -1402.787841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0334734916687012, "alpha_loss": 0.07891489565372467, "alpha_value": 0.3209840486632128, "duration": 1.5885424613952637, "info_normalized_performance_mean": 0.6525419354438782, "info_normalized_performance_final": 0.727463960647583, "info_performance_mean": 0.6525419354438782, "info_performance_final": 0.727463960647583, "step": 578500}
{"episode_reward": 1305.0841346153832, "episode": 5786.0, "batch_reward": 9.125677108764648, "critic_loss": 412.320068359375, "actor_loss": -1373.6474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.7274621725082397, "alpha_loss": -0.03847535699605942, "alpha_value": 0.31822227982708917, "duration": 1.4799144268035889, "info_normalized_performance_mean": 0.7466269135475159, "info_normalized_performance_final": 0.9345238208770752, "info_performance_mean": 0.7466269135475159, "info_performance_final": 0.9345238208770752, "step": 579000}
{"episode_reward": 1493.2539682539666, "episode": 5791.0, "batch_reward": 9.422891616821289, "critic_loss": 333.9664306640625, "actor_loss": -1344.7913818359375, "actor_target_entropy": -3.0, "actor_entropy": 0.6580837368965149, "alpha_loss": 0.12752516567707062, "alpha_value": 0.3155730504959896, "duration": 1.5677580833435059, "info_normalized_performance_mean": 0.38590508699417114, "info_normalized_performance_final": 0.43174999952316284, "info_performance_mean": 0.38590508699417114, "info_performance_final": 0.43174999952316284, "step": 579500}
{"episode_reward": 771.8099999999994, "episode": 5796.0, "batch_reward": 9.27684211730957, "critic_loss": 431.9198913574219, "actor_loss": -1350.582275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0481380224227905, "alpha_loss": -0.02349100261926651, "alpha_value": 0.3155922063471655, "step": 580000}
{"duration": 18.583795309066772, "info_normalized_performance_mean": 0.8005381226539612, "info_normalized_performance_final": 0.8888888955116272, "info_performance_mean": 0.8005381226539612, "info_performance_final": 0.8888888955116272, "step": 580000}
{"episode_reward": 1601.0763888888919, "episode": 5801.0, "batch_reward": 8.78952407836914, "critic_loss": 230.61001586914062, "actor_loss": -1299.8521728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1300183534622192, "alpha_loss": -0.04679320752620697, "alpha_value": 0.3137082361534984, "duration": 1.5562539100646973, "info_normalized_performance_mean": 0.7995311617851257, "info_normalized_performance_final": 0.9045138955116272, "info_performance_mean": 0.7995311617851257, "info_performance_final": 0.9045138955116272, "step": 580500}
{"episode_reward": 1599.0625000000027, "episode": 5806.0, "batch_reward": 10.478096008300781, "critic_loss": 540.2952880859375, "actor_loss": -1391.6619873046875, "actor_target_entropy": -3.0, "actor_entropy": 0.6976733803749084, "alpha_loss": 0.14277715981006622, "alpha_value": 0.31284268398292076, "duration": 1.5843064785003662, "info_normalized_performance_mean": 0.4240609109401703, "info_normalized_performance_final": 0.4623015820980072, "info_performance_mean": 0.4240609109401703, "info_performance_final": 0.4623015820980072, "step": 581000}
{"episode_reward": 848.1216931216952, "episode": 5811.0, "batch_reward": 8.900033950805664, "critic_loss": 268.2689208984375, "actor_loss": -1322.38818359375, "actor_target_entropy": -3.0, "actor_entropy": 0.7855240702629089, "alpha_loss": -0.058777548372745514, "alpha_value": 0.3111268001311382, "duration": 1.5817430019378662, "info_normalized_performance_mean": 0.456745982170105, "info_normalized_performance_final": 0.49537035822868347, "info_performance_mean": 0.456745982170105, "info_performance_final": 0.49537035822868347, "step": 581500}
{"episode_reward": 913.4920634920626, "episode": 5816.0, "batch_reward": 9.35547161102295, "critic_loss": 367.27191162109375, "actor_loss": -1328.283203125, "actor_target_entropy": -3.0, "actor_entropy": 0.9449464082717896, "alpha_loss": 0.08381875604391098, "alpha_value": 0.30767786275654596, "duration": 1.5018508434295654, "info_normalized_performance_mean": 0.5867247581481934, "info_normalized_performance_final": 0.6440746784210205, "info_performance_mean": 0.5867247581481934, "info_performance_final": 0.6440746784210205, "step": 582000}
{"episode_reward": 1173.4496753246751, "episode": 5821.0, "batch_reward": 9.75660514831543, "critic_loss": 410.205078125, "actor_loss": -1351.42529296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9503417611122131, "alpha_loss": 0.17517852783203125, "alpha_value": 0.30861351569006523, "duration": 1.5857226848602295, "info_normalized_performance_mean": 0.6781066060066223, "info_normalized_performance_final": 0.7630385756492615, "info_performance_mean": 0.6781066060066223, "info_performance_final": 0.7630385756492615, "step": 582500}
{"episode_reward": 1356.213151927438, "episode": 5826.0, "batch_reward": 9.671957969665527, "critic_loss": 1038.231201171875, "actor_loss": -1330.9794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.4997590184211731, "alpha_loss": -0.014845386147499084, "alpha_value": 0.3072437761573756, "duration": 1.6379342079162598, "info_normalized_performance_mean": 0.29241427779197693, "info_normalized_performance_final": 0.33911484479904175, "info_performance_mean": 0.29241427779197693, "info_performance_final": 0.33911484479904175, "step": 583000}
{"episode_reward": 584.828548644338, "episode": 5831.0, "batch_reward": 8.613214492797852, "critic_loss": 684.7520751953125, "actor_loss": -1319.737548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.762057900428772, "alpha_loss": 0.021805129945278168, "alpha_value": 0.30580215072970257, "duration": 1.5528302192687988, "info_normalized_performance_mean": 0.8537304401397705, "info_normalized_performance_final": 0.962890625, "info_performance_mean": 0.8537304401397705, "info_performance_final": 0.962890625, "step": 583500}
{"episode_reward": 1707.4609375, "episode": 5836.0, "batch_reward": 9.035133361816406, "critic_loss": 354.96453857421875, "actor_loss": -1329.11669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.4898505210876465, "alpha_loss": -0.07665015757083893, "alpha_value": 0.3054340180672486, "duration": 1.6304960250854492, "info_normalized_performance_mean": 0.42364388704299927, "info_normalized_performance_final": 0.47010987997055054, "info_performance_mean": 0.42364388704299927, "info_performance_final": 0.47010987997055054, "step": 584000}
{"episode_reward": 847.2879120879103, "episode": 5841.0, "batch_reward": 9.391866683959961, "critic_loss": 696.6503295898438, "actor_loss": -1312.0855712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7583978176116943, "alpha_loss": 0.029511457309126854, "alpha_value": 0.3047190258482715, "duration": 1.4962725639343262, "info_normalized_performance_mean": 0.5120441317558289, "info_normalized_performance_final": 0.595588207244873, "info_performance_mean": 0.5120441317558289, "info_performance_final": 0.595588207244873, "step": 584500}
{"episode_reward": 1024.088235294116, "episode": 5846.0, "batch_reward": 8.984345436096191, "critic_loss": 1007.1331787109375, "actor_loss": -1274.4560546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7965131998062134, "alpha_loss": 0.06561463326215744, "alpha_value": 0.305347715573918, "duration": 1.586233139038086, "info_normalized_performance_mean": 0.7335293292999268, "info_normalized_performance_final": 0.8088235259056091, "info_performance_mean": 0.7335293292999268, "info_performance_final": 0.8088235259056091, "step": 585000}
{"episode_reward": 1467.0588235294117, "episode": 5851.0, "batch_reward": 8.674274444580078, "critic_loss": 657.98388671875, "actor_loss": -1306.66748046875, "actor_target_entropy": -3.0, "actor_entropy": 0.69911789894104, "alpha_loss": -0.09673424065113068, "alpha_value": 0.3059866490866607, "duration": 1.5467586517333984, "info_normalized_performance_mean": 0.8337299823760986, "info_normalized_performance_final": 0.9186508059501648, "info_performance_mean": 0.8337299823760986, "info_performance_final": 0.9186508059501648, "step": 585500}
{"episode_reward": 1667.4603174603194, "episode": 5856.0, "batch_reward": 10.106536865234375, "critic_loss": 467.29449462890625, "actor_loss": -1417.39111328125, "actor_target_entropy": -3.0, "actor_entropy": 0.5506681799888611, "alpha_loss": -0.016476280987262726, "alpha_value": 0.30583099463909336, "duration": 1.5575034618377686, "info_normalized_performance_mean": 0.36139219999313354, "info_normalized_performance_final": 0.40597403049468994, "info_performance_mean": 0.36139219999313354, "info_performance_final": 0.40597403049468994, "step": 586000}
{"episode_reward": 722.7844155844151, "episode": 5861.0, "batch_reward": 8.98245620727539, "critic_loss": 455.59375, "actor_loss": -1347.507568359375, "actor_target_entropy": -3.0, "actor_entropy": 0.4617656171321869, "alpha_loss": 0.004369556903839111, "alpha_value": 0.3054857791902964, "duration": 1.5133676528930664, "info_normalized_performance_mean": 0.4483644962310791, "info_normalized_performance_final": 0.49594154953956604, "info_performance_mean": 0.4483644962310791, "info_performance_final": 0.49594154953956604, "step": 586500}
{"episode_reward": 896.7288961038955, "episode": 5866.0, "batch_reward": 9.829626083374023, "critic_loss": 1006.5202026367188, "actor_loss": -1354.86279296875, "actor_target_entropy": -3.0, "actor_entropy": 0.44724202156066895, "alpha_loss": 0.0730140209197998, "alpha_value": 0.3043534620955192, "duration": 1.474644660949707, "info_normalized_performance_mean": 0.5160446166992188, "info_normalized_performance_final": 0.5785714387893677, "info_performance_mean": 0.5160446166992188, "info_performance_final": 0.5785714387893677, "step": 587000}
{"episode_reward": 1032.0892857142849, "episode": 5871.0, "batch_reward": 9.893545150756836, "critic_loss": 211.916259765625, "actor_loss": -1378.7705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.719193160533905, "alpha_loss": -0.0736405998468399, "alpha_value": 0.3034054888372014, "duration": 1.516204595565796, "info_normalized_performance_mean": 0.8338999152183533, "info_normalized_performance_final": 0.9480000138282776, "info_performance_mean": 0.8338999152183533, "info_performance_final": 0.9480000138282776, "step": 587500}
{"episode_reward": 1667.800000000002, "episode": 5876.0, "batch_reward": 9.835269927978516, "critic_loss": 181.45635986328125, "actor_loss": -1345.134033203125, "actor_target_entropy": -3.0, "actor_entropy": 0.6290425062179565, "alpha_loss": 0.0918988585472107, "alpha_value": 0.3039049483498708, "duration": 1.6989047527313232, "info_normalized_performance_mean": 0.38926735520362854, "info_normalized_performance_final": 0.4408773183822632, "info_performance_mean": 0.38926735520362854, "info_performance_final": 0.4408773183822632, "step": 588000}
{"episode_reward": 778.5346471710111, "episode": 5881.0, "batch_reward": 8.68333911895752, "critic_loss": 1662.1767578125, "actor_loss": -1308.782958984375, "actor_target_entropy": -3.0, "actor_entropy": 0.49227407574653625, "alpha_loss": -0.1532614529132843, "alpha_value": 0.30444783431486305, "duration": 1.6140704154968262, "info_normalized_performance_mean": 0.6989681720733643, "info_normalized_performance_final": 0.7888888716697693, "info_performance_mean": 0.6989681720733643, "info_performance_final": 0.7888888716697693, "step": 588500}
{"episode_reward": 1397.9365079365107, "episode": 5886.0, "batch_reward": 9.32183837890625, "critic_loss": 262.7908630371094, "actor_loss": -1357.55322265625, "actor_target_entropy": -3.0, "actor_entropy": 0.5933228731155396, "alpha_loss": -0.060234345495700836, "alpha_value": 0.3036353051662019, "duration": 1.6205227375030518, "info_normalized_performance_mean": 0.36559733748435974, "info_normalized_performance_final": 0.409951776266098, "info_performance_mean": 0.36559733748435974, "info_performance_final": 0.409951776266098, "step": 589000}
{"episode_reward": 731.1949035812659, "episode": 5891.0, "batch_reward": 10.085319519042969, "critic_loss": 817.5865478515625, "actor_loss": -1383.485595703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6472398042678833, "alpha_loss": 0.08269350230693817, "alpha_value": 0.30111779531635935, "duration": 1.552907943725586, "info_normalized_performance_mean": 0.0010090700816363096, "info_normalized_performance_final": 0.0011337868636474013, "info_performance_mean": 0.0010090700816363096, "info_performance_final": 0.0011337868636474013, "step": 589500}
{"episode_reward": 2.018140589569158, "episode": 5896.0, "batch_reward": 9.526090621948242, "critic_loss": 567.505126953125, "actor_loss": -1362.6259765625, "actor_target_entropy": -3.0, "actor_entropy": 0.789353609085083, "alpha_loss": -0.010556593537330627, "alpha_value": 0.30027978350927054, "step": 590000}
{"duration": 19.081859827041626, "info_normalized_performance_mean": 0.6241699457168579, "info_normalized_performance_final": 0.6915032863616943, "info_performance_mean": 0.6241699457168579, "info_performance_final": 0.6915032863616943, "step": 590000}
{"episode_reward": 1248.3398692810463, "episode": 5901.0, "batch_reward": 9.024181365966797, "critic_loss": 669.4942626953125, "actor_loss": -1333.298583984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8996307849884033, "alpha_loss": -0.12361139804124832, "alpha_value": 0.3000242501938058, "duration": 1.5619921684265137, "info_normalized_performance_mean": 0.31100529432296753, "info_normalized_performance_final": 0.3452380895614624, "info_performance_mean": 0.31100529432296753, "info_performance_final": 0.3452380895614624, "step": 590500}
{"episode_reward": 622.010582010583, "episode": 5906.0, "batch_reward": 9.05120849609375, "critic_loss": 258.0018310546875, "actor_loss": -1338.4873046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8570379018783569, "alpha_loss": -0.06042615324258804, "alpha_value": 0.298590977118747, "duration": 1.5948503017425537, "info_normalized_performance_mean": 0.45960766077041626, "info_normalized_performance_final": 0.5124675035476685, "info_performance_mean": 0.45960766077041626, "info_performance_final": 0.5124675035476685, "step": 591000}
{"episode_reward": 919.2155844155837, "episode": 5911.0, "batch_reward": 10.28274154663086, "critic_loss": 1346.1904296875, "actor_loss": -1380.0413818359375, "actor_target_entropy": -3.0, "actor_entropy": 0.3981775641441345, "alpha_loss": -0.12502199411392212, "alpha_value": 0.29871777445627096, "duration": 1.465451955795288, "info_normalized_performance_mean": 0.8518437147140503, "info_normalized_performance_final": 0.953125, "info_performance_mean": 0.8518437147140503, "info_performance_final": 0.953125, "step": 591500}
{"episode_reward": 1703.6875, "episode": 5916.0, "batch_reward": 9.952528953552246, "critic_loss": 295.2496337890625, "actor_loss": -1333.94580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8402799367904663, "alpha_loss": -0.08813545107841492, "alpha_value": 0.29872480692785086, "duration": 1.5454277992248535, "info_normalized_performance_mean": 0.41039812564849854, "info_normalized_performance_final": 0.452160507440567, "info_performance_mean": 0.41039812564849854, "info_performance_final": 0.452160507440567, "step": 592000}
{"episode_reward": 820.796296296295, "episode": 5921.0, "batch_reward": 9.445022583007812, "critic_loss": 220.9453887939453, "actor_loss": -1355.8134765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8659184575080872, "alpha_loss": 0.08289188146591187, "alpha_value": 0.2987918034875446, "duration": 1.5561151504516602, "info_normalized_performance_mean": 0.8386218547821045, "info_normalized_performance_final": 0.902521014213562, "info_performance_mean": 0.8386218547821045, "info_performance_final": 0.902521014213562, "step": 592500}
{"episode_reward": 1677.2436974789896, "episode": 5926.0, "batch_reward": 10.08365535736084, "critic_loss": 250.27610778808594, "actor_loss": -1382.7630615234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8022619485855103, "alpha_loss": -0.09448091685771942, "alpha_value": 0.2984211739957927, "duration": 1.5569369792938232, "info_normalized_performance_mean": 0.2167821079492569, "info_normalized_performance_final": 0.23593074083328247, "info_performance_mean": 0.2167821079492569, "info_performance_final": 0.23593074083328247, "step": 593000}
{"episode_reward": 433.5642135642143, "episode": 5931.0, "batch_reward": 9.29736328125, "critic_loss": 226.44586181640625, "actor_loss": -1362.2359619140625, "actor_target_entropy": -3.0, "actor_entropy": 0.9446406364440918, "alpha_loss": -0.045570701360702515, "alpha_value": 0.30161015958298815, "duration": 1.603891134262085, "info_normalized_performance_mean": 0.6044679284095764, "info_normalized_performance_final": 0.6690962314605713, "info_performance_mean": 0.6044679284095764, "info_performance_final": 0.6690962314605713, "step": 593500}
{"episode_reward": 1208.935860058311, "episode": 5936.0, "batch_reward": 10.127463340759277, "critic_loss": 340.7261962890625, "actor_loss": -1323.222412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.856716513633728, "alpha_loss": 0.1229197308421135, "alpha_value": 0.30478820096516723, "duration": 1.5879321098327637, "info_normalized_performance_mean": 0.7286848425865173, "info_normalized_performance_final": 0.8321995735168457, "info_performance_mean": 0.7286848425865173, "info_performance_final": 0.8321995735168457, "step": 594000}
{"episode_reward": 1457.3696145124732, "episode": 5941.0, "batch_reward": 10.201183319091797, "critic_loss": 872.3995361328125, "actor_loss": -1404.17138671875, "actor_target_entropy": -3.0, "actor_entropy": 0.6479639410972595, "alpha_loss": -0.10030399262905121, "alpha_value": 0.3058956528161414, "duration": 1.446220874786377, "info_normalized_performance_mean": 0.622668445110321, "info_normalized_performance_final": 0.6933673620223999, "info_performance_mean": 0.622668445110321, "info_performance_final": 0.6933673620223999, "step": 594500}
{"episode_reward": 1245.336734693878, "episode": 5946.0, "batch_reward": 10.270313262939453, "critic_loss": 265.4420471191406, "actor_loss": -1374.4298095703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6699469089508057, "alpha_loss": 0.00827702134847641, "alpha_value": 0.3081223262046254, "duration": 1.5651750564575195, "info_normalized_performance_mean": 0.6996626257896423, "info_normalized_performance_final": 0.8162500262260437, "info_performance_mean": 0.6996626257896423, "info_performance_final": 0.8162500262260437, "step": 595000}
{"episode_reward": 1399.3250000000007, "episode": 5951.0, "batch_reward": 10.645835876464844, "critic_loss": 182.5432586669922, "actor_loss": -1379.7764892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.9731199741363525, "alpha_loss": -0.038996849209070206, "alpha_value": 0.3110807008886709, "duration": 1.530759572982788, "info_normalized_performance_mean": 0.9039323329925537, "info_normalized_performance_final": 0.9973958134651184, "info_performance_mean": 0.9039323329925537, "info_performance_final": 0.9973958134651184, "step": 595500}
{"episode_reward": 1807.8645833333355, "episode": 5956.0, "batch_reward": 9.450931549072266, "critic_loss": 163.65475463867188, "actor_loss": -1304.081298828125, "actor_target_entropy": -3.0, "actor_entropy": 1.1953320503234863, "alpha_loss": -0.18971827626228333, "alpha_value": 0.3132430856840221, "duration": 1.4561288356781006, "info_normalized_performance_mean": 0.09102985262870789, "info_normalized_performance_final": 0.11186079680919647, "info_performance_mean": 0.09102985262870789, "info_performance_final": 0.11186079680919647, "step": 596000}
{"episode_reward": 182.05965909090892, "episode": 5961.0, "batch_reward": 9.49258041381836, "critic_loss": 422.8392639160156, "actor_loss": -1313.23291015625, "actor_target_entropy": -3.0, "actor_entropy": 0.7302958965301514, "alpha_loss": 0.18202002346515656, "alpha_value": 0.3149674664733983, "duration": 1.6755568981170654, "info_normalized_performance_mean": 0.4881472885608673, "info_normalized_performance_final": 0.543732762336731, "info_performance_mean": 0.4881472885608673, "info_performance_final": 0.543732762336731, "step": 596500}
{"episode_reward": 976.2947658402212, "episode": 5966.0, "batch_reward": 10.67536735534668, "critic_loss": 643.3471069335938, "actor_loss": -1369.098388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.0280489921569824, "alpha_loss": 0.041409656405448914, "alpha_value": 0.3151628172810913, "duration": 1.5003318786621094, "info_normalized_performance_mean": 0.43045103549957275, "info_normalized_performance_final": 0.4751420319080353, "info_performance_mean": 0.43045103549957275, "info_performance_final": 0.4751420319080353, "step": 597000}
{"episode_reward": 860.9019886363632, "episode": 5971.0, "batch_reward": 10.221260070800781, "critic_loss": 610.0780029296875, "actor_loss": -1377.22119140625, "actor_target_entropy": -3.0, "actor_entropy": 0.833869218826294, "alpha_loss": -0.02108752727508545, "alpha_value": 0.3167301865095105, "duration": 1.5023188591003418, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 597500}
{"episode_reward": 0.0, "episode": 5976.0, "batch_reward": 10.620110511779785, "critic_loss": 869.330322265625, "actor_loss": -1455.295654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.691016435623169, "alpha_loss": -0.03203627094626427, "alpha_value": 0.3176917635482192, "duration": 1.5257971286773682, "info_normalized_performance_mean": 0.5765734910964966, "info_normalized_performance_final": 0.6367647051811218, "info_performance_mean": 0.5765734910964966, "info_performance_final": 0.6367647051811218, "step": 598000}
{"episode_reward": 1153.1470588235302, "episode": 5981.0, "batch_reward": 9.815954208374023, "critic_loss": 435.05511474609375, "actor_loss": -1374.3804931640625, "actor_target_entropy": -3.0, "actor_entropy": 0.7129309177398682, "alpha_loss": -0.12610271573066711, "alpha_value": 0.31672645526481874, "duration": 1.4764204025268555, "info_normalized_performance_mean": 0.44973212480545044, "info_normalized_performance_final": 0.4965277910232544, "info_performance_mean": 0.44973212480545044, "info_performance_final": 0.4965277910232544, "step": 598500}
{"episode_reward": 899.4642857142848, "episode": 5986.0, "batch_reward": 8.902000427246094, "critic_loss": 280.41485595703125, "actor_loss": -1290.965576171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8057183027267456, "alpha_loss": -0.14287583529949188, "alpha_value": 0.3166091594961709, "duration": 1.5926673412322998, "info_normalized_performance_mean": 0.4942038655281067, "info_normalized_performance_final": 0.5520833134651184, "info_performance_mean": 0.4942038655281067, "info_performance_final": 0.5520833134651184, "step": 599000}
{"episode_reward": 988.4077380952368, "episode": 5991.0, "batch_reward": 10.589506149291992, "critic_loss": 616.5557250976562, "actor_loss": -1401.76708984375, "actor_target_entropy": -3.0, "actor_entropy": 1.072380542755127, "alpha_loss": 0.16559728980064392, "alpha_value": 0.31379478221939044, "duration": 1.6584179401397705, "info_normalized_performance_mean": 0.5341336727142334, "info_normalized_performance_final": 0.5886243581771851, "info_performance_mean": 0.5341336727142334, "info_performance_final": 0.5886243581771851, "step": 599500}
{"episode_reward": 1068.2671957671964, "episode": 5996.0, "batch_reward": 9.969683647155762, "critic_loss": 338.4447021484375, "actor_loss": -1328.883056640625, "actor_target_entropy": -3.0, "actor_entropy": 0.9525271058082581, "alpha_loss": 0.12926526367664337, "alpha_value": 0.31481602643372375, "step": 600000}
{"duration": 18.65575623512268, "info_normalized_performance_mean": 0.3645153045654297, "info_normalized_performance_final": 0.42091837525367737, "info_performance_mean": 0.3645153045654297, "info_performance_final": 0.42091837525367737, "step": 600000}
{"episode_reward": 729.0306122448989, "episode": 6001.0, "batch_reward": 10.093482971191406, "critic_loss": 401.66949462890625, "actor_loss": -1357.474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1980705261230469, "alpha_loss": 0.15821324288845062, "alpha_value": 0.31496580844009486, "duration": 1.5518183708190918, "info_normalized_performance_mean": 0.3966759443283081, "info_normalized_performance_final": 0.4456790089607239, "info_performance_mean": 0.3966759443283081, "info_performance_final": 0.4456790089607239, "step": 600500}
{"episode_reward": 793.3518518518531, "episode": 6006.0, "batch_reward": 10.160236358642578, "critic_loss": 266.54766845703125, "actor_loss": -1382.3912353515625, "actor_target_entropy": -3.0, "actor_entropy": 0.6970664262771606, "alpha_loss": -0.09675262868404388, "alpha_value": 0.31433671169391586, "duration": 1.522627830505371, "info_normalized_performance_mean": 0.9062753319740295, "info_normalized_performance_final": 0.9948979616165161, "info_performance_mean": 0.9062753319740295, "info_performance_final": 0.9948979616165161, "step": 601000}
{"episode_reward": 1812.551020408165, "episode": 6011.0, "batch_reward": 9.711003303527832, "critic_loss": 625.0149536132812, "actor_loss": -1362.9295654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8464117050170898, "alpha_loss": 0.07917474210262299, "alpha_value": 0.3133188135060315, "duration": 1.5100011825561523, "info_normalized_performance_mean": 0.359018474817276, "info_normalized_performance_final": 0.40154320001602173, "info_performance_mean": 0.359018474817276, "info_performance_final": 0.40154320001602173, "step": 601500}
{"episode_reward": 718.037037037037, "episode": 6016.0, "batch_reward": 9.26651668548584, "critic_loss": 374.6957092285156, "actor_loss": -1340.83740234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8695295453071594, "alpha_loss": -0.12362553179264069, "alpha_value": 0.3155237715567511, "duration": 1.5829379558563232, "info_normalized_performance_mean": 0.8663637042045593, "info_normalized_performance_final": 0.9659090638160706, "info_performance_mean": 0.8663637042045593, "info_performance_final": 0.9659090638160706, "step": 602000}
{"episode_reward": 1732.7272727272718, "episode": 6021.0, "batch_reward": 9.646865844726562, "critic_loss": 446.44915771484375, "actor_loss": -1373.327880859375, "actor_target_entropy": -3.0, "actor_entropy": 0.7657804489135742, "alpha_loss": -0.03460780531167984, "alpha_value": 0.3178976322938077, "duration": 1.620652198791504, "info_normalized_performance_mean": 0.5919840335845947, "info_normalized_performance_final": 0.6633597612380981, "info_performance_mean": 0.5919840335845947, "info_performance_final": 0.6633597612380981, "step": 602500}
{"episode_reward": 1183.9682539682526, "episode": 6026.0, "batch_reward": 10.225051879882812, "critic_loss": 334.74932861328125, "actor_loss": -1363.9814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.8682636618614197, "alpha_loss": 0.0673966258764267, "alpha_value": 0.3204922027513829, "duration": 1.6708686351776123, "info_normalized_performance_mean": 0.3930785059928894, "info_normalized_performance_final": 0.4491758346557617, "info_performance_mean": 0.3930785059928894, "info_performance_final": 0.4491758346557617, "step": 603000}
{"episode_reward": 786.1568986568996, "episode": 6031.0, "batch_reward": 10.46978759765625, "critic_loss": 684.1563720703125, "actor_loss": -1417.322509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.1490064859390259, "alpha_loss": -0.05950132757425308, "alpha_value": 0.3230973203645225, "duration": 1.7664084434509277, "info_normalized_performance_mean": 0.22427219152450562, "info_normalized_performance_final": 0.2649572789669037, "info_performance_mean": 0.22427219152450562, "info_performance_final": 0.2649572789669037, "step": 603500}
{"episode_reward": 448.54437869822516, "episode": 6036.0, "batch_reward": 10.914591789245605, "critic_loss": 217.37191772460938, "actor_loss": -1407.580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.9344436526298523, "alpha_loss": 0.025271359831094742, "alpha_value": 0.32611322834526824, "duration": 1.5982189178466797, "info_normalized_performance_mean": 0.293889582157135, "info_normalized_performance_final": 0.32755184173583984, "info_performance_mean": 0.293889582157135, "info_performance_final": 0.32755184173583984, "step": 604000}
{"episode_reward": 587.7791068580543, "episode": 6041.0, "batch_reward": 9.577743530273438, "critic_loss": 223.24298095703125, "actor_loss": -1381.275390625, "actor_target_entropy": -3.0, "actor_entropy": 0.92632657289505, "alpha_loss": -0.20700789988040924, "alpha_value": 0.3311745491571513, "duration": 1.567345142364502, "info_normalized_performance_mean": 0.35813507437705994, "info_normalized_performance_final": 0.4044155776500702, "info_performance_mean": 0.35813507437705994, "info_performance_final": 0.4044155776500702, "step": 604500}
{"episode_reward": 716.2701298701306, "episode": 6046.0, "batch_reward": 9.84402084350586, "critic_loss": 487.78094482421875, "actor_loss": -1340.8616943359375, "actor_target_entropy": -3.0, "actor_entropy": 1.025935411453247, "alpha_loss": -0.014120452105998993, "alpha_value": 0.3348105379354706, "duration": 1.5392000675201416, "info_normalized_performance_mean": 0.8084501028060913, "info_normalized_performance_final": 0.903333306312561, "info_performance_mean": 0.8084501028060913, "info_performance_final": 0.903333306312561, "step": 605000}
{"episode_reward": 1616.8999999999996, "episode": 6051.0, "batch_reward": 9.695594787597656, "critic_loss": 204.79974365234375, "actor_loss": -1360.9141845703125, "actor_target_entropy": -3.0, "actor_entropy": 0.8850224614143372, "alpha_loss": -0.11493145674467087, "alpha_value": 0.3385905107130199, "duration": 1.4664201736450195, "info_normalized_performance_mean": 0.3976339101791382, "info_normalized_performance_final": 0.4387175440788269, "info_performance_mean": 0.3976339101791382, "info_performance_final": 0.4387175440788269, "step": 605500}
{"episode_reward": 795.2678571428555, "episode": 6056.0, "batch_reward": 10.110380172729492, "critic_loss": 746.0230712890625, "actor_loss": -1421.3330078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7315441966056824, "alpha_loss": -0.013729222118854523, "alpha_value": 0.34259537224931025, "duration": 1.5874898433685303, "info_normalized_performance_mean": 0.6047599911689758, "info_normalized_performance_final": 0.6520000100135803, "info_performance_mean": 0.6047599911689758, "info_performance_final": 0.6520000100135803, "step": 606000}
{"episode_reward": 1209.5199999999984, "episode": 6061.0, "batch_reward": 9.380595207214355, "critic_loss": 223.77072143554688, "actor_loss": -1376.704833984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9562603831291199, "alpha_loss": 0.05215994641184807, "alpha_value": 0.34163699839974265, "duration": 1.5032377243041992, "info_normalized_performance_mean": 0.28614580631256104, "info_normalized_performance_final": 0.3173828125, "info_performance_mean": 0.28614580631256104, "info_performance_final": 0.3173828125, "step": 606500}
{"episode_reward": 572.2916666666667, "episode": 6066.0, "batch_reward": 9.945585250854492, "critic_loss": 382.92877197265625, "actor_loss": -1399.520263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8398926854133606, "alpha_loss": -0.06439018994569778, "alpha_value": 0.3447673063810103, "duration": 1.4283270835876465, "info_normalized_performance_mean": 0.3344374895095825, "info_normalized_performance_final": 0.359375, "info_performance_mean": 0.3344374895095825, "info_performance_final": 0.359375, "step": 607000}
{"episode_reward": 668.875, "episode": 6071.0, "batch_reward": 9.588029861450195, "critic_loss": 351.54302978515625, "actor_loss": -1362.925537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.708742618560791, "alpha_loss": -0.13263332843780518, "alpha_value": 0.34732344210443317, "duration": 1.626279592514038, "info_normalized_performance_mean": 0.3978426456451416, "info_normalized_performance_final": 0.43002915382385254, "info_performance_mean": 0.3978426456451416, "info_performance_final": 0.43002915382385254, "step": 607500}
{"episode_reward": 795.685131195336, "episode": 6076.0, "batch_reward": 10.19453239440918, "critic_loss": 495.439208984375, "actor_loss": -1437.165771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.6040704250335693, "alpha_loss": -0.08902305364608765, "alpha_value": 0.3487729791867273, "duration": 1.6359169483184814, "info_normalized_performance_mean": 0.3469231128692627, "info_normalized_performance_final": 0.39234450459480286, "info_performance_mean": 0.3469231128692627, "info_performance_final": 0.39234450459480286, "step": 608000}
{"episode_reward": 693.8461538461536, "episode": 6081.0, "batch_reward": 9.196516990661621, "critic_loss": 163.63504028320312, "actor_loss": -1374.3419189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7106378674507141, "alpha_loss": 0.06507506966590881, "alpha_value": 0.348898118576423, "duration": 1.5670301914215088, "info_normalized_performance_mean": 0.4490925669670105, "info_normalized_performance_final": 0.49424999952316284, "info_performance_mean": 0.4490925669670105, "info_performance_final": 0.49424999952316284, "step": 608500}
{"episode_reward": 898.1849999999994, "episode": 6086.0, "batch_reward": 9.555118560791016, "critic_loss": 404.32513427734375, "actor_loss": -1360.321533203125, "actor_target_entropy": -3.0, "actor_entropy": 0.8029218912124634, "alpha_loss": 0.012518185190856457, "alpha_value": 0.3507424162177782, "duration": 1.6305994987487793, "info_normalized_performance_mean": 0.74186110496521, "info_normalized_performance_final": 0.8125, "info_performance_mean": 0.74186110496521, "info_performance_final": 0.8125, "step": 609000}
{"episode_reward": 1483.7222222222222, "episode": 6091.0, "batch_reward": 9.714725494384766, "critic_loss": 367.9286193847656, "actor_loss": -1398.7216796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8425343036651611, "alpha_loss": -0.0011449865996837616, "alpha_value": 0.35252363807513076, "duration": 1.568040370941162, "info_normalized_performance_mean": 0.395303338766098, "info_normalized_performance_final": 0.4421977996826172, "info_performance_mean": 0.395303338766098, "info_performance_final": 0.4421977996826172, "step": 609500}
{"episode_reward": 790.6065934065932, "episode": 6096.0, "batch_reward": 9.857073783874512, "critic_loss": 784.5795288085938, "actor_loss": -1398.513427734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7916085720062256, "alpha_loss": -0.037056371569633484, "alpha_value": 0.3526156963116159, "step": 610000}
{"duration": 19.025632858276367, "info_normalized_performance_mean": 0.3776203989982605, "info_normalized_performance_final": 0.4227272868156433, "info_performance_mean": 0.3776203989982605, "info_performance_final": 0.4227272868156433, "step": 610000}
{"episode_reward": 755.24090909091, "episode": 6101.0, "batch_reward": 9.4530029296875, "critic_loss": 336.73504638671875, "actor_loss": -1391.9337158203125, "actor_target_entropy": -3.0, "actor_entropy": 0.6538106203079224, "alpha_loss": -0.17825891077518463, "alpha_value": 0.3531791447979055, "duration": 1.528764009475708, "info_normalized_performance_mean": 0.8970536589622498, "info_normalized_performance_final": 0.9955357313156128, "info_performance_mean": 0.8970536589622498, "info_performance_final": 0.9955357313156128, "step": 610500}
{"episode_reward": 1794.1071428571415, "episode": 6106.0, "batch_reward": 9.752500534057617, "critic_loss": 336.65008544921875, "actor_loss": -1400.8184814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9953859448432922, "alpha_loss": -0.165665864944458, "alpha_value": 0.3540608050319483, "duration": 1.617537498474121, "info_normalized_performance_mean": 0.45302483439445496, "info_normalized_performance_final": 0.487609326839447, "info_performance_mean": 0.45302483439445496, "info_performance_final": 0.487609326839447, "step": 611000}
{"episode_reward": 906.0495626822163, "episode": 6111.0, "batch_reward": 9.113883972167969, "critic_loss": 315.4952087402344, "actor_loss": -1363.9468994140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8067119121551514, "alpha_loss": -0.19663050770759583, "alpha_value": 0.3546615524036599, "duration": 1.5749337673187256, "info_normalized_performance_mean": 0.6595166921615601, "info_normalized_performance_final": 0.7166666388511658, "info_performance_mean": 0.6595166921615601, "info_performance_final": 0.7166666388511658, "step": 611500}
{"episode_reward": 1319.0333333333328, "episode": 6116.0, "batch_reward": 9.47284984588623, "critic_loss": 211.56344604492188, "actor_loss": -1328.50927734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1803737878799438, "alpha_loss": -0.01493237353861332, "alpha_value": 0.35593520101336723, "duration": 1.5418286323547363, "info_normalized_performance_mean": 0.75298672914505, "info_normalized_performance_final": 0.8279221057891846, "info_performance_mean": 0.75298672914505, "info_performance_final": 0.8279221057891846, "step": 612000}
{"episode_reward": 1505.9740259740247, "episode": 6121.0, "batch_reward": 10.613143920898438, "critic_loss": 211.12631225585938, "actor_loss": -1400.4560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4354946613311768, "alpha_loss": 0.14495757222175598, "alpha_value": 0.3559443016819232, "duration": 1.562804937362671, "info_normalized_performance_mean": 0.42772728204727173, "info_normalized_performance_final": 0.47186148166656494, "info_performance_mean": 0.42772728204727173, "info_performance_final": 0.47186148166656494, "step": 612500}
{"episode_reward": 855.4545454545469, "episode": 6126.0, "batch_reward": 10.150385856628418, "critic_loss": 326.3563232421875, "actor_loss": -1399.212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.978393018245697, "alpha_loss": 0.19662389159202576, "alpha_value": 0.35313053268729633, "duration": 1.4417822360992432, "info_normalized_performance_mean": 0.8537855744361877, "info_normalized_performance_final": 0.9214285612106323, "info_performance_mean": 0.8537855744361877, "info_performance_final": 0.9214285612106323, "step": 613000}
{"episode_reward": 1707.5714285714255, "episode": 6131.0, "batch_reward": 9.323673248291016, "critic_loss": 288.447509765625, "actor_loss": -1344.996337890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9286751747131348, "alpha_loss": 0.11672189831733704, "alpha_value": 0.3501909775120041, "duration": 1.4658217430114746, "info_normalized_performance_mean": 0.49900802969932556, "info_normalized_performance_final": 0.5441468358039856, "info_performance_mean": 0.49900802969932556, "info_performance_final": 0.5441468358039856, "step": 613500}
{"episode_reward": 998.0158730158728, "episode": 6136.0, "batch_reward": 10.440362930297852, "critic_loss": 312.3364562988281, "actor_loss": -1404.542236328125, "actor_target_entropy": -3.0, "actor_entropy": 0.92741858959198, "alpha_loss": 0.15119877457618713, "alpha_value": 0.3446871492767961, "duration": 1.611001968383789, "info_normalized_performance_mean": 0.6331750750541687, "info_normalized_performance_final": 0.6741666793823242, "info_performance_mean": 0.6331750750541687, "info_performance_final": 0.6741666793823242, "step": 614000}
{"episode_reward": 1266.3500000000013, "episode": 6141.0, "batch_reward": 10.382007598876953, "critic_loss": 420.180419921875, "actor_loss": -1402.8502197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.39220818877220154, "alpha_loss": 0.2596287429332733, "alpha_value": 0.33937710507217633, "duration": 1.59051513671875, "info_normalized_performance_mean": 0.4407978057861328, "info_normalized_performance_final": 0.4938461482524872, "info_performance_mean": 0.4407978057861328, "info_performance_final": 0.4938461482524872, "step": 614500}
{"episode_reward": 881.5956043956027, "episode": 6146.0, "batch_reward": 9.211977005004883, "critic_loss": 1246.847900390625, "actor_loss": -1383.2825927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7529330849647522, "alpha_loss": -0.006264921277761459, "alpha_value": 0.33294303825516136, "duration": 1.5602357387542725, "info_normalized_performance_mean": 0.6378353238105774, "info_normalized_performance_final": 0.6870588064193726, "info_performance_mean": 0.6378353238105774, "info_performance_final": 0.6870588064193726, "step": 615000}
{"episode_reward": 1275.6705882352946, "episode": 6151.0, "batch_reward": 9.879584312438965, "critic_loss": 592.1044921875, "actor_loss": -1406.657958984375, "actor_target_entropy": -3.0, "actor_entropy": 0.903009295463562, "alpha_loss": 0.07969845086336136, "alpha_value": 0.3279632079431446, "duration": 1.563159704208374, "info_normalized_performance_mean": 0.8118040561676025, "info_normalized_performance_final": 0.8892045617103577, "info_performance_mean": 0.8118040561676025, "info_performance_final": 0.8892045617103577, "step": 615500}
{"episode_reward": 1623.6079545454559, "episode": 6156.0, "batch_reward": 10.541638374328613, "critic_loss": 409.42266845703125, "actor_loss": -1407.2706298828125, "actor_target_entropy": -3.0, "actor_entropy": 0.6448891758918762, "alpha_loss": 0.1450687050819397, "alpha_value": 0.32257372673449874, "duration": 1.4904119968414307, "info_normalized_performance_mean": 0.6059128046035767, "info_normalized_performance_final": 0.6691468358039856, "info_performance_mean": 0.6059128046035767, "info_performance_final": 0.6691468358039856, "step": 616000}
{"episode_reward": 1211.8253968253953, "episode": 6161.0, "batch_reward": 10.785135269165039, "critic_loss": 170.7163543701172, "actor_loss": -1392.936279296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8038183450698853, "alpha_loss": 0.17210698127746582, "alpha_value": 0.31828430818305725, "duration": 1.4882097244262695, "info_normalized_performance_mean": 0.4884188771247864, "info_normalized_performance_final": 0.538690447807312, "info_performance_mean": 0.4884188771247864, "info_performance_final": 0.538690447807312, "step": 616500}
{"episode_reward": 976.8377976190473, "episode": 6166.0, "batch_reward": 9.817625045776367, "critic_loss": 228.59991455078125, "actor_loss": -1380.5516357421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0124343633651733, "alpha_loss": 0.12734776735305786, "alpha_value": 0.3141429461368376, "duration": 1.594672679901123, "info_normalized_performance_mean": 0.46320468187332153, "info_normalized_performance_final": 0.5185714364051819, "info_performance_mean": 0.46320468187332153, "info_performance_final": 0.5185714364051819, "step": 617000}
{"episode_reward": 926.4095238095257, "episode": 6171.0, "batch_reward": 9.898052215576172, "critic_loss": 365.5372314453125, "actor_loss": -1377.34326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7205352783203125, "alpha_loss": 0.09065082669258118, "alpha_value": 0.31050968566931214, "duration": 1.660203218460083, "info_normalized_performance_mean": 0.34736329317092896, "info_normalized_performance_final": 0.38763508200645447, "info_performance_mean": 0.34736329317092896, "info_performance_final": 0.38763508200645447, "step": 617500}
{"episode_reward": 694.7266369993634, "episode": 6176.0, "batch_reward": 10.919231414794922, "critic_loss": 202.1971435546875, "actor_loss": -1399.986572265625, "actor_target_entropy": -3.0, "actor_entropy": 0.8366624116897583, "alpha_loss": 0.09078921377658844, "alpha_value": 0.30981131866789385, "duration": 1.5822601318359375, "info_normalized_performance_mean": 0.34611591696739197, "info_normalized_performance_final": 0.3884090781211853, "info_performance_mean": 0.34611591696739197, "info_performance_final": 0.3884090781211853, "step": 618000}
{"episode_reward": 692.2318181818174, "episode": 6181.0, "batch_reward": 10.36345100402832, "critic_loss": 460.5458679199219, "actor_loss": -1417.618408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.9342716932296753, "alpha_loss": -0.06216156482696533, "alpha_value": 0.30783661407083573, "duration": 1.4396231174468994, "info_normalized_performance_mean": 0.4185594916343689, "info_normalized_performance_final": 0.4553571343421936, "info_performance_mean": 0.4185594916343689, "info_performance_final": 0.4553571343421936, "step": 618500}
{"episode_reward": 837.1190476190482, "episode": 6186.0, "batch_reward": 10.655409812927246, "critic_loss": 794.6358642578125, "actor_loss": -1444.951416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9691418409347534, "alpha_loss": 0.027291998267173767, "alpha_value": 0.3061902552950628, "duration": 1.486203670501709, "info_normalized_performance_mean": 0.5298363566398621, "info_normalized_performance_final": 0.5915178656578064, "info_performance_mean": 0.5298363566398621, "info_performance_final": 0.5915178656578064, "step": 619000}
{"episode_reward": 1059.6726190476181, "episode": 6191.0, "batch_reward": 10.296594619750977, "critic_loss": 194.77255249023438, "actor_loss": -1377.5709228515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0405864715576172, "alpha_loss": 0.08523838222026825, "alpha_value": 0.30435739877288454, "duration": 1.620448350906372, "info_normalized_performance_mean": 0.5574479103088379, "info_normalized_performance_final": 0.6684027910232544, "info_performance_mean": 0.5574479103088379, "info_performance_final": 0.6684027910232544, "step": 619500}
{"episode_reward": 1114.8958333333333, "episode": 6196.0, "batch_reward": 10.551698684692383, "critic_loss": 408.22198486328125, "actor_loss": -1392.681640625, "actor_target_entropy": -3.0, "actor_entropy": 0.47775930166244507, "alpha_loss": 0.02470315620303154, "alpha_value": 0.30159708651221306, "step": 620000}
{"duration": 19.058526277542114, "info_normalized_performance_mean": 0.32666972279548645, "info_normalized_performance_final": 0.3565610945224762, "info_performance_mean": 0.32666972279548645, "info_performance_final": 0.3565610945224762, "step": 620000}
{"episode_reward": 653.3393665158374, "episode": 6201.0, "batch_reward": 9.098456382751465, "critic_loss": 690.7330932617188, "actor_loss": -1317.90380859375, "actor_target_entropy": -3.0, "actor_entropy": 1.0199941396713257, "alpha_loss": -0.12193267047405243, "alpha_value": 0.30117567268642836, "duration": 1.5970962047576904, "info_normalized_performance_mean": 0.5133506655693054, "info_normalized_performance_final": 0.5546875, "info_performance_mean": 0.5133506655693054, "info_performance_final": 0.5546875, "step": 620500}
{"episode_reward": 1026.701388888889, "episode": 6206.0, "batch_reward": 11.34256362915039, "critic_loss": 348.34661865234375, "actor_loss": -1454.7269287109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9540348052978516, "alpha_loss": 0.17761045694351196, "alpha_value": 0.30113463123822154, "duration": 1.5891382694244385, "info_normalized_performance_mean": 0.6451600790023804, "info_normalized_performance_final": 0.6949999928474426, "info_performance_mean": 0.6451600790023804, "info_performance_final": 0.6949999928474426, "step": 621000}
{"episode_reward": 1290.3200000000006, "episode": 6211.0, "batch_reward": 10.427474975585938, "critic_loss": 245.028076171875, "actor_loss": -1401.7894287109375, "actor_target_entropy": -3.0, "actor_entropy": 0.6447291374206543, "alpha_loss": 0.142495259642601, "alpha_value": 0.3007367498567978, "duration": 1.5090000629425049, "info_normalized_performance_mean": 0.600338876247406, "info_normalized_performance_final": 0.6868131756782532, "info_performance_mean": 0.600338876247406, "info_performance_final": 0.6868131756782532, "step": 621500}
{"episode_reward": 1200.677655677655, "episode": 6216.0, "batch_reward": 9.837451934814453, "critic_loss": 407.7141418457031, "actor_loss": -1402.525634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.37430623173713684, "alpha_loss": -0.07500507682561874, "alpha_value": 0.30078227889337206, "duration": 1.5343513488769531, "info_normalized_performance_mean": 0.7673046588897705, "info_normalized_performance_final": 0.826171875, "info_performance_mean": 0.7673046588897705, "info_performance_final": 0.826171875, "step": 622000}
{"episode_reward": 1534.609375, "episode": 6221.0, "batch_reward": 10.850881576538086, "critic_loss": 347.1638488769531, "actor_loss": -1426.66845703125, "actor_target_entropy": -3.0, "actor_entropy": 0.8023397922515869, "alpha_loss": 0.12911835312843323, "alpha_value": 0.29951887485242706, "duration": 1.4923968315124512, "info_normalized_performance_mean": 0.4506417214870453, "info_normalized_performance_final": 0.49197861552238464, "info_performance_mean": 0.4506417214870453, "info_performance_final": 0.49197861552238464, "step": 622500}
{"episode_reward": 901.2834224598937, "episode": 6226.0, "batch_reward": 9.717615127563477, "critic_loss": 276.5857238769531, "actor_loss": -1387.9671630859375, "actor_target_entropy": -3.0, "actor_entropy": 0.45747822523117065, "alpha_loss": -0.007414434105157852, "alpha_value": 0.2973245002411793, "duration": 1.6007072925567627, "info_normalized_performance_mean": 0.34814584255218506, "info_normalized_performance_final": 0.44776827096939087, "info_performance_mean": 0.34814584255218506, "info_performance_final": 0.44776827096939087, "step": 623000}
{"episode_reward": 696.2915479582153, "episode": 6231.0, "batch_reward": 11.437789916992188, "critic_loss": 257.87396240234375, "actor_loss": -1417.2353515625, "actor_target_entropy": -3.0, "actor_entropy": 0.687765896320343, "alpha_loss": 0.24315038323402405, "alpha_value": 0.2950060707321596, "duration": 1.4579463005065918, "info_normalized_performance_mean": 0.6127542853355408, "info_normalized_performance_final": 0.6677489280700684, "info_performance_mean": 0.6127542853355408, "info_performance_final": 0.6677489280700684, "step": 623500}
{"episode_reward": 1225.5086580086581, "episode": 6236.0, "batch_reward": 10.290811538696289, "critic_loss": 390.4414367675781, "actor_loss": -1379.480712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.3613044023513794, "alpha_loss": -0.022622568532824516, "alpha_value": 0.2928579271488929, "duration": 1.5018630027770996, "info_normalized_performance_mean": 0.31722304224967957, "info_normalized_performance_final": 0.35085228085517883, "info_performance_mean": 0.31722304224967957, "info_performance_final": 0.35085228085517883, "step": 624000}
{"episode_reward": 634.4460227272731, "episode": 6241.0, "batch_reward": 10.500848770141602, "critic_loss": 320.8231506347656, "actor_loss": -1417.914794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.5563875436782837, "alpha_loss": 0.03473344445228577, "alpha_value": 0.288961010276154, "duration": 1.4249134063720703, "info_normalized_performance_mean": 0.415854811668396, "info_normalized_performance_final": 0.4465811848640442, "info_performance_mean": 0.415854811668396, "info_performance_final": 0.4465811848640442, "step": 624500}
{"episode_reward": 831.7094017093999, "episode": 6246.0, "batch_reward": 10.570657730102539, "critic_loss": 459.06085205078125, "actor_loss": -1392.846923828125, "actor_target_entropy": -3.0, "actor_entropy": 0.6527827978134155, "alpha_loss": -0.023481402546167374, "alpha_value": 0.28625823397215255, "duration": 1.5359013080596924, "info_normalized_performance_mean": 0.8230729699134827, "info_normalized_performance_final": 0.8958333134651184, "info_performance_mean": 0.8230729699134827, "info_performance_final": 0.8958333134651184, "step": 625000}
{"episode_reward": 1646.1458333333348, "episode": 6251.0, "batch_reward": 10.39452075958252, "critic_loss": 210.56619262695312, "actor_loss": -1368.466552734375, "actor_target_entropy": -3.0, "actor_entropy": 0.5523935556411743, "alpha_loss": -0.024180321022868156, "alpha_value": 0.28566721321677, "duration": 1.5946290493011475, "info_normalized_performance_mean": 0.5490931272506714, "info_normalized_performance_final": 0.6350902318954468, "info_performance_mean": 0.5490931272506714, "info_performance_final": 0.6350902318954468, "step": 625500}
{"episode_reward": 1098.186134852801, "episode": 6256.0, "batch_reward": 11.229887008666992, "critic_loss": 526.7776489257812, "actor_loss": -1478.31103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.18921072781085968, "alpha_loss": -0.054088182747364044, "alpha_value": 0.28221640601144893, "duration": 1.5309298038482666, "info_normalized_performance_mean": 0.6165227293968201, "info_normalized_performance_final": 0.6966248154640198, "info_performance_mean": 0.6165227293968201, "info_performance_final": 0.6966248154640198, "step": 626000}
{"episode_reward": 1233.0455259026687, "episode": 6261.0, "batch_reward": 10.291792869567871, "critic_loss": 623.9536743164062, "actor_loss": -1367.0147705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.4965645372867584, "alpha_loss": 0.0744677409529686, "alpha_value": 0.2793963153926947, "duration": 1.4430716037750244, "info_normalized_performance_mean": 0.5364564657211304, "info_normalized_performance_final": 0.59375, "info_performance_mean": 0.5364564657211304, "info_performance_final": 0.59375, "step": 626500}
{"episode_reward": 1072.9129464285716, "episode": 6266.0, "batch_reward": 10.921119689941406, "critic_loss": 191.94271850585938, "actor_loss": -1393.747802734375, "actor_target_entropy": -3.0, "actor_entropy": 0.22001215815544128, "alpha_loss": 0.03596944734454155, "alpha_value": 0.2783235307661811, "duration": 1.5011887550354004, "info_normalized_performance_mean": 0.30337047576904297, "info_normalized_performance_final": 0.3381696343421936, "info_performance_mean": 0.30337047576904297, "info_performance_final": 0.3381696343421936, "step": 627000}
{"episode_reward": 606.7410714285711, "episode": 6271.0, "batch_reward": 10.34595012664795, "critic_loss": 414.24212646484375, "actor_loss": -1400.197021484375, "actor_target_entropy": -3.0, "actor_entropy": 0.4631943106651306, "alpha_loss": -0.25254952907562256, "alpha_value": 0.27659192043288544, "duration": 1.5806074142456055, "info_normalized_performance_mean": 0.4557255804538727, "info_normalized_performance_final": 0.5272108912467957, "info_performance_mean": 0.4557255804538727, "info_performance_final": 0.5272108912467957, "step": 627500}
{"episode_reward": 911.4512471655322, "episode": 6276.0, "batch_reward": 11.120063781738281, "critic_loss": 475.72467041015625, "actor_loss": -1406.824951171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7114354372024536, "alpha_loss": 0.12936311960220337, "alpha_value": 0.2755506691453663, "duration": 1.7619335651397705, "info_normalized_performance_mean": 0.5501129031181335, "info_normalized_performance_final": 0.6703296899795532, "info_performance_mean": 0.5501129031181335, "info_performance_final": 0.6703296899795532, "step": 628000}
{"episode_reward": 1100.2258852258851, "episode": 6281.0, "batch_reward": 10.84740161895752, "critic_loss": 575.2730712890625, "actor_loss": -1388.1578369140625, "actor_target_entropy": -3.0, "actor_entropy": 0.3255522847175598, "alpha_loss": 0.1283237636089325, "alpha_value": 0.27571332220539674, "duration": 1.5911996364593506, "info_normalized_performance_mean": 0.6955093145370483, "info_normalized_performance_final": 0.7615740895271301, "info_performance_mean": 0.6955093145370483, "info_performance_final": 0.7615740895271301, "step": 628500}
{"episode_reward": 1391.0185185185205, "episode": 6286.0, "batch_reward": 11.116052627563477, "critic_loss": 277.38104248046875, "actor_loss": -1473.3265380859375, "actor_target_entropy": -3.0, "actor_entropy": 0.36720412969589233, "alpha_loss": -0.07224392145872116, "alpha_value": 0.2771634535487602, "duration": 1.7015631198883057, "info_normalized_performance_mean": 0.41207244992256165, "info_normalized_performance_final": 0.4909408688545227, "info_performance_mean": 0.41207244992256165, "info_performance_final": 0.4909408688545227, "step": 629000}
{"episode_reward": 824.144945963127, "episode": 6291.0, "batch_reward": 11.251180648803711, "critic_loss": 289.150390625, "actor_loss": -1446.281494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.5632755756378174, "alpha_loss": 0.1345062553882599, "alpha_value": 0.276369343182273, "duration": 1.6358716487884521, "info_normalized_performance_mean": 0.4718360900878906, "info_normalized_performance_final": 0.5420653820037842, "info_performance_mean": 0.4718360900878906, "info_performance_final": 0.5420653820037842, "step": 629500}
{"episode_reward": 943.6722488038262, "episode": 6296.0, "batch_reward": 10.691036224365234, "critic_loss": 792.5432739257812, "actor_loss": -1435.5294189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.014686785638332367, "alpha_loss": -0.09374655038118362, "alpha_value": 0.2745919489661964, "step": 630000}
{"duration": 18.400220155715942, "info_normalized_performance_mean": 0.917593777179718, "info_normalized_performance_final": 0.9781249761581421, "info_performance_mean": 0.917593777179718, "info_performance_final": 0.9781249761581421, "step": 630000}
{"episode_reward": 1835.1875, "episode": 6301.0, "batch_reward": 10.858663558959961, "critic_loss": 312.2790832519531, "actor_loss": -1398.584228515625, "actor_target_entropy": -3.0, "actor_entropy": 0.5850526094436646, "alpha_loss": 0.17663802206516266, "alpha_value": 0.27378521538817613, "duration": 1.5285520553588867, "info_normalized_performance_mean": 0.8378627300262451, "info_normalized_performance_final": 0.9627450704574585, "info_performance_mean": 0.8378627300262451, "info_performance_final": 0.9627450704574585, "step": 630500}
{"episode_reward": 1675.7254901960785, "episode": 6306.0, "batch_reward": 10.9539213180542, "critic_loss": 449.8597106933594, "actor_loss": -1384.08837890625, "actor_target_entropy": -3.0, "actor_entropy": 0.4997577667236328, "alpha_loss": 0.1615029275417328, "alpha_value": 0.2715426577047178, "duration": 1.595759391784668, "info_normalized_performance_mean": 0.4887329936027527, "info_normalized_performance_final": 0.5331632494926453, "info_performance_mean": 0.4887329936027527, "info_performance_final": 0.5331632494926453, "step": 631000}
{"episode_reward": 977.4659863945566, "episode": 6311.0, "batch_reward": 10.393070220947266, "critic_loss": 298.42401123046875, "actor_loss": -1378.48974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.3979243040084839, "alpha_loss": 0.007961027324199677, "alpha_value": 0.27273210285703076, "duration": 1.651721715927124, "info_normalized_performance_mean": 0.555800199508667, "info_normalized_performance_final": 0.6514550447463989, "info_performance_mean": 0.555800199508667, "info_performance_final": 0.6514550447463989, "step": 631500}
{"episode_reward": 1111.6005291005306, "episode": 6316.0, "batch_reward": 10.805377960205078, "critic_loss": 810.9837036132812, "actor_loss": -1425.593017578125, "actor_target_entropy": -3.0, "actor_entropy": 0.524249792098999, "alpha_loss": -0.04625600576400757, "alpha_value": 0.270820648053448, "duration": 1.4593048095703125, "info_normalized_performance_mean": 0.41626831889152527, "info_normalized_performance_final": 0.45192307233810425, "info_performance_mean": 0.41626831889152527, "info_performance_final": 0.45192307233810425, "step": 632000}
{"episode_reward": 832.5366300366306, "episode": 6321.0, "batch_reward": 10.829081535339355, "critic_loss": 344.69683837890625, "actor_loss": -1423.89306640625, "actor_target_entropy": -3.0, "actor_entropy": 0.5405747890472412, "alpha_loss": -0.03918011486530304, "alpha_value": 0.2720934862627519, "duration": 1.4725141525268555, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 632500}
{"episode_reward": 0.0, "episode": 6326.0, "batch_reward": 10.309026718139648, "critic_loss": 478.2674560546875, "actor_loss": -1389.38671875, "actor_target_entropy": -3.0, "actor_entropy": 0.5263238549232483, "alpha_loss": -0.07879891246557236, "alpha_value": 0.2741702262065491, "duration": 1.6203367710113525, "info_normalized_performance_mean": 0.48057544231414795, "info_normalized_performance_final": 0.648809552192688, "info_performance_mean": 0.48057544231414795, "info_performance_final": 0.648809552192688, "step": 633000}
{"episode_reward": 961.1507936507937, "episode": 6331.0, "batch_reward": 11.027894973754883, "critic_loss": 279.24835205078125, "actor_loss": -1402.0938720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6815890073776245, "alpha_loss": -0.12769915163516998, "alpha_value": 0.2788540654080986, "duration": 1.4069361686706543, "info_normalized_performance_mean": 0.5729592442512512, "info_normalized_performance_final": 0.6071428656578064, "info_performance_mean": 0.5729592442512512, "info_performance_final": 0.6071428656578064, "step": 633500}
{"episode_reward": 1145.9183673469377, "episode": 6336.0, "batch_reward": 10.543462753295898, "critic_loss": 237.9696807861328, "actor_loss": -1398.157470703125, "actor_target_entropy": -3.0, "actor_entropy": 0.7307857275009155, "alpha_loss": -0.11533844470977783, "alpha_value": 0.280842634010957, "duration": 1.4756560325622559, "info_normalized_performance_mean": 0.4192871153354645, "info_normalized_performance_final": 0.46142578125, "info_performance_mean": 0.4192871153354645, "info_performance_final": 0.46142578125, "step": 634000}
{"episode_reward": 838.57421875, "episode": 6341.0, "batch_reward": 11.28724479675293, "critic_loss": 224.5419464111328, "actor_loss": -1424.544677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7089844942092896, "alpha_loss": 0.1288483738899231, "alpha_value": 0.2817984569864542, "duration": 1.518266201019287, "info_normalized_performance_mean": 0.5366033911705017, "info_normalized_performance_final": 0.6142113208770752, "info_performance_mean": 0.5366033911705017, "info_performance_final": 0.6142113208770752, "step": 634500}
{"episode_reward": 1073.2068452380936, "episode": 6346.0, "batch_reward": 10.531746864318848, "critic_loss": 330.9625244140625, "actor_loss": -1377.821533203125, "actor_target_entropy": -3.0, "actor_entropy": 0.5285780429840088, "alpha_loss": -0.12856198847293854, "alpha_value": 0.2839708862699574, "duration": 1.5505397319793701, "info_normalized_performance_mean": 0.375903844833374, "info_normalized_performance_final": 0.41662338376045227, "info_performance_mean": 0.375903844833374, "info_performance_final": 0.41662338376045227, "step": 635000}
{"episode_reward": 751.8077922077916, "episode": 6351.0, "batch_reward": 10.282159805297852, "critic_loss": 475.343017578125, "actor_loss": -1383.698486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.34072646498680115, "alpha_loss": -0.11542081087827682, "alpha_value": 0.28649120681693396, "duration": 1.56172776222229, "info_normalized_performance_mean": 0.7927603125572205, "info_normalized_performance_final": 0.9097222089767456, "info_performance_mean": 0.7927603125572205, "info_performance_final": 0.9097222089767456, "step": 635500}
{"episode_reward": 1585.5208333333317, "episode": 6356.0, "batch_reward": 11.251276969909668, "critic_loss": 374.641357421875, "actor_loss": -1418.5257568359375, "actor_target_entropy": -3.0, "actor_entropy": 0.43986836075782776, "alpha_loss": 0.048265472054481506, "alpha_value": 0.2874755302832845, "duration": 1.6244914531707764, "info_normalized_performance_mean": 0.5091593265533447, "info_normalized_performance_final": 0.5721726417541504, "info_performance_mean": 0.5091593265533447, "info_performance_final": 0.5721726417541504, "step": 636000}
{"episode_reward": 1018.3184523809541, "episode": 6361.0, "batch_reward": 9.947635650634766, "critic_loss": 244.29383850097656, "actor_loss": -1405.477294921875, "actor_target_entropy": -3.0, "actor_entropy": 0.613815188407898, "alpha_loss": 0.03586907312273979, "alpha_value": 0.2863669350456226, "duration": 1.5486209392547607, "info_normalized_performance_mean": 0.7294530272483826, "info_normalized_performance_final": 0.8031250238418579, "info_performance_mean": 0.7294530272483826, "info_performance_final": 0.8031250238418579, "step": 636500}
{"episode_reward": 1458.90625, "episode": 6366.0, "batch_reward": 10.342020988464355, "critic_loss": 359.2803649902344, "actor_loss": -1405.9527587890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7397446036338806, "alpha_loss": -0.17037028074264526, "alpha_value": 0.285747249550097, "duration": 1.6409144401550293, "info_normalized_performance_mean": 0.8128665089607239, "info_normalized_performance_final": 0.9049999713897705, "info_performance_mean": 0.8128665089607239, "info_performance_final": 0.9049999713897705, "step": 637000}
{"episode_reward": 1625.7333333333302, "episode": 6371.0, "batch_reward": 10.32241153717041, "critic_loss": 454.92376708984375, "actor_loss": -1391.580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.46370577812194824, "alpha_loss": -0.06649129092693329, "alpha_value": 0.2843730708216215, "duration": 1.591423511505127, "info_normalized_performance_mean": 0.3302582800388336, "info_normalized_performance_final": 0.37062498927116394, "info_performance_mean": 0.3302582800388336, "info_performance_final": 0.37062498927116394, "step": 637500}
{"episode_reward": 660.5166666666678, "episode": 6376.0, "batch_reward": 9.832232475280762, "critic_loss": 407.1741943359375, "actor_loss": -1405.4007568359375, "actor_target_entropy": -3.0, "actor_entropy": 0.241387277841568, "alpha_loss": -0.13813282549381256, "alpha_value": 0.28352848032659717, "duration": 1.5554609298706055, "info_normalized_performance_mean": 0.9012001156806946, "info_normalized_performance_final": 0.996666669845581, "info_performance_mean": 0.9012001156806946, "info_performance_final": 0.996666669845581, "step": 638000}
{"episode_reward": 1802.400000000001, "episode": 6381.0, "batch_reward": 11.277996063232422, "critic_loss": 167.57594299316406, "actor_loss": -1419.990478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7727818489074707, "alpha_loss": 0.09806443750858307, "alpha_value": 0.2816975086072116, "duration": 1.567836046218872, "info_normalized_performance_mean": 0.4430208206176758, "info_normalized_performance_final": 0.4704861044883728, "info_performance_mean": 0.4430208206176758, "info_performance_final": 0.4704861044883728, "step": 638500}
{"episode_reward": 886.0416666666649, "episode": 6386.0, "batch_reward": 12.245092391967773, "critic_loss": 276.66986083984375, "actor_loss": -1464.6312255859375, "actor_target_entropy": -3.0, "actor_entropy": 0.6493352651596069, "alpha_loss": -0.007649559527635574, "alpha_value": 0.2830754964831105, "duration": 1.6426541805267334, "info_normalized_performance_mean": 0.7899126410484314, "info_normalized_performance_final": 0.8849206566810608, "info_performance_mean": 0.7899126410484314, "info_performance_final": 0.8849206566810608, "step": 639000}
{"episode_reward": 1579.8253968253978, "episode": 6391.0, "batch_reward": 11.256429672241211, "critic_loss": 166.09506225585938, "actor_loss": -1407.844482421875, "actor_target_entropy": -3.0, "actor_entropy": 0.7508451342582703, "alpha_loss": 0.12180972099304199, "alpha_value": 0.2820362257287324, "duration": 1.5324375629425049, "info_normalized_performance_mean": 0.7939494848251343, "info_normalized_performance_final": 0.8773109316825867, "info_performance_mean": 0.7939494848251343, "info_performance_final": 0.8773109316825867, "step": 639500}
{"episode_reward": 1587.8991596638673, "episode": 6396.0, "batch_reward": 10.7889404296875, "critic_loss": 180.29150390625, "actor_loss": -1372.5421142578125, "actor_target_entropy": -3.0, "actor_entropy": 0.7359305620193481, "alpha_loss": 0.1107238307595253, "alpha_value": 0.2791887382457713, "step": 640000}
{"duration": 18.231436729431152, "info_normalized_performance_mean": 0.5304512977600098, "info_normalized_performance_final": 0.61557537317276, "info_performance_mean": 0.5304512977600098, "info_performance_final": 0.61557537317276, "step": 640000}
{"episode_reward": 1060.9027777777785, "episode": 6401.0, "batch_reward": 10.469827651977539, "critic_loss": 271.81488037109375, "actor_loss": -1373.425048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8436188101768494, "alpha_loss": -0.16759204864501953, "alpha_value": 0.277409811559137, "duration": 1.6490809917449951, "info_normalized_performance_mean": 0.4069083333015442, "info_normalized_performance_final": 0.4650000035762787, "info_performance_mean": 0.4069083333015442, "info_performance_final": 0.4650000035762787, "step": 640500}
{"episode_reward": 813.8166666666656, "episode": 6406.0, "batch_reward": 10.853487014770508, "critic_loss": 486.05499267578125, "actor_loss": -1352.6361083984375, "actor_target_entropy": -3.0, "actor_entropy": 1.1017160415649414, "alpha_loss": 0.2621691823005676, "alpha_value": 0.27450649884618866, "duration": 1.5060791969299316, "info_normalized_performance_mean": 0.38565483689308167, "info_normalized_performance_final": 0.414682537317276, "info_performance_mean": 0.38565483689308167, "info_performance_final": 0.414682537317276, "step": 641000}
{"episode_reward": 771.3095238095249, "episode": 6411.0, "batch_reward": 10.421306610107422, "critic_loss": 548.4567260742188, "actor_loss": -1414.590576171875, "actor_target_entropy": -3.0, "actor_entropy": 0.5191372632980347, "alpha_loss": -0.016811281442642212, "alpha_value": 0.27464834509430647, "duration": 1.6045057773590088, "info_normalized_performance_mean": 0.458187460899353, "info_normalized_performance_final": 0.49097222089767456, "info_performance_mean": 0.458187460899353, "info_performance_final": 0.49097222089767456, "step": 641500}
{"episode_reward": 916.3750000000009, "episode": 6416.0, "batch_reward": 10.609884262084961, "critic_loss": 194.37359619140625, "actor_loss": -1398.947265625, "actor_target_entropy": -3.0, "actor_entropy": 0.8101338148117065, "alpha_loss": 0.01723470911383629, "alpha_value": 0.2753624218580991, "duration": 1.6771256923675537, "info_normalized_performance_mean": 0.31504449248313904, "info_normalized_performance_final": 0.35473617911338806, "info_performance_mean": 0.31504449248313904, "info_performance_final": 0.35473617911338806, "step": 642000}
{"episode_reward": 630.0890019071824, "episode": 6421.0, "batch_reward": 11.318816184997559, "critic_loss": 230.51495361328125, "actor_loss": -1425.388427734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8122304677963257, "alpha_loss": 0.14685696363449097, "alpha_value": 0.278634200918445, "duration": 1.5422499179840088, "info_normalized_performance_mean": 0.30804526805877686, "info_normalized_performance_final": 0.3452380895614624, "info_performance_mean": 0.30804526805877686, "info_performance_final": 0.3452380895614624, "step": 642500}
{"episode_reward": 616.0904761904771, "episode": 6426.0, "batch_reward": 10.982295036315918, "critic_loss": 509.1396179199219, "actor_loss": -1451.9200439453125, "actor_target_entropy": -3.0, "actor_entropy": 0.8007559776306152, "alpha_loss": -0.15545406937599182, "alpha_value": 0.28151319617621, "duration": 1.5590815544128418, "info_normalized_performance_mean": 0.37358078360557556, "info_normalized_performance_final": 0.4098307192325592, "info_performance_mean": 0.37358078360557556, "info_performance_final": 0.4098307192325592, "step": 643000}
{"episode_reward": 747.1614583333339, "episode": 6431.0, "batch_reward": 10.718389511108398, "critic_loss": 232.6324920654297, "actor_loss": -1399.6904296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7372012138366699, "alpha_loss": -0.02363639697432518, "alpha_value": 0.2853119050138048, "duration": 1.6326451301574707, "info_normalized_performance_mean": 0.4794445037841797, "info_normalized_performance_final": 0.5396825671195984, "info_performance_mean": 0.4794445037841797, "info_performance_final": 0.5396825671195984, "step": 643500}
{"episode_reward": 958.8888888888905, "episode": 6436.0, "batch_reward": 11.673449516296387, "critic_loss": 224.3217010498047, "actor_loss": -1448.9354248046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8122639656066895, "alpha_loss": -0.07139761745929718, "alpha_value": 0.28948987966532347, "duration": 1.4764776229858398, "info_normalized_performance_mean": 0.4793059527873993, "info_normalized_performance_final": 0.5482954382896423, "info_performance_mean": 0.4793059527873993, "info_performance_final": 0.5482954382896423, "step": 644000}
{"episode_reward": 958.6120129870138, "episode": 6441.0, "batch_reward": 11.264251708984375, "critic_loss": 1110.279296875, "actor_loss": -1452.669189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6059900522232056, "alpha_loss": -0.1664351224899292, "alpha_value": 0.2954298918560044, "duration": 1.5538852214813232, "info_normalized_performance_mean": 0.673797607421875, "info_normalized_performance_final": 0.7604166865348816, "info_performance_mean": 0.673797607421875, "info_performance_final": 0.7604166865348816, "step": 644500}
{"episode_reward": 1347.5954861111104, "episode": 6446.0, "batch_reward": 11.300419807434082, "critic_loss": 249.10906982421875, "actor_loss": -1445.50927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7147327661514282, "alpha_loss": -0.06702594459056854, "alpha_value": 0.30242842419222477, "duration": 1.567223310470581, "info_normalized_performance_mean": 0.4416232407093048, "info_normalized_performance_final": 0.4756944477558136, "info_performance_mean": 0.4416232407093048, "info_performance_final": 0.4756944477558136, "step": 645000}
{"episode_reward": 883.2465277777793, "episode": 6451.0, "batch_reward": 10.774811744689941, "critic_loss": 832.0765991210938, "actor_loss": -1445.32958984375, "actor_target_entropy": -3.0, "actor_entropy": 0.3477751314640045, "alpha_loss": -0.28198179602622986, "alpha_value": 0.3083550402436574, "duration": 1.5894110202789307, "info_normalized_performance_mean": 0.60052490234375, "info_normalized_performance_final": 0.6452488899230957, "info_performance_mean": 0.60052490234375, "info_performance_final": 0.6452488899230957, "step": 645500}
{"episode_reward": 1201.0497737556564, "episode": 6456.0, "batch_reward": 11.665101051330566, "critic_loss": 391.79876708984375, "actor_loss": -1469.8662109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9062037467956543, "alpha_loss": -0.16483543813228607, "alpha_value": 0.3179012330371009, "duration": 1.4764811992645264, "info_normalized_performance_mean": 0.04886364936828613, "info_normalized_performance_final": 0.05113636329770088, "info_performance_mean": 0.04886364936828613, "info_performance_final": 0.05113636329770088, "step": 646000}
{"episode_reward": 97.72727272727255, "episode": 6461.0, "batch_reward": 11.361190795898438, "critic_loss": 563.6263427734375, "actor_loss": -1438.476318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9509087800979614, "alpha_loss": -0.17418256402015686, "alpha_value": 0.3252092398902341, "duration": 1.5734453201293945, "info_normalized_performance_mean": 0.5650586485862732, "info_normalized_performance_final": 0.6068627238273621, "info_performance_mean": 0.5650586485862732, "info_performance_final": 0.6068627238273621, "step": 646500}
{"episode_reward": 1130.1176470588236, "episode": 6466.0, "batch_reward": 9.846307754516602, "critic_loss": 227.1201171875, "actor_loss": -1391.9844970703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6222661733627319, "alpha_loss": -0.19927479326725006, "alpha_value": 0.3328642383191602, "duration": 1.5905883312225342, "info_normalized_performance_mean": 0.5118599534034729, "info_normalized_performance_final": 0.6394285559654236, "info_performance_mean": 0.5118599534034729, "info_performance_final": 0.6394285559654236, "step": 647000}
{"episode_reward": 1023.7200000000006, "episode": 6471.0, "batch_reward": 10.86579704284668, "critic_loss": 388.5809326171875, "actor_loss": -1351.36083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9159219264984131, "alpha_loss": -0.06268532574176788, "alpha_value": 0.33729341268225793, "duration": 1.6016676425933838, "info_normalized_performance_mean": 0.5395409464836121, "info_normalized_performance_final": 0.5892857313156128, "info_performance_mean": 0.5395409464836121, "info_performance_final": 0.5892857313156128, "step": 647500}
{"episode_reward": 1079.0816326530628, "episode": 6476.0, "batch_reward": 10.030661582946777, "critic_loss": 194.4503173828125, "actor_loss": -1377.98681640625, "actor_target_entropy": -3.0, "actor_entropy": 0.7728114128112793, "alpha_loss": -0.060282811522483826, "alpha_value": 0.33993416517429065, "duration": 1.5655760765075684, "info_normalized_performance_mean": 0.3981896936893463, "info_normalized_performance_final": 0.4424999952316284, "info_performance_mean": 0.3981896936893463, "info_performance_final": 0.4424999952316284, "step": 648000}
{"episode_reward": 796.379166666668, "episode": 6481.0, "batch_reward": 10.952281951904297, "critic_loss": 355.720703125, "actor_loss": -1462.2022705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7025483846664429, "alpha_loss": -0.04319360852241516, "alpha_value": 0.3422207238854719, "duration": 1.5490751266479492, "info_normalized_performance_mean": 0.4284449815750122, "info_normalized_performance_final": 0.4783567786216736, "info_performance_mean": 0.4284449815750122, "info_performance_final": 0.4783567786216736, "step": 648500}
{"episode_reward": 856.8899917287026, "episode": 6486.0, "batch_reward": 10.807870864868164, "critic_loss": 667.9677124023438, "actor_loss": -1409.036865234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8881913423538208, "alpha_loss": 0.021719329059123993, "alpha_value": 0.3469905147702109, "duration": 1.6410043239593506, "info_normalized_performance_mean": 0.3338731527328491, "info_normalized_performance_final": 0.3734901547431946, "info_performance_mean": 0.3338731527328491, "info_performance_final": 0.3734901547431946, "step": 649000}
{"episode_reward": 667.7463445645266, "episode": 6491.0, "batch_reward": 10.963284492492676, "critic_loss": 442.6376953125, "actor_loss": -1447.51416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.849273681640625, "alpha_loss": -0.17771019041538239, "alpha_value": 0.3510846194484007, "duration": 1.5060911178588867, "info_normalized_performance_mean": 0.35520264506340027, "info_normalized_performance_final": 0.38692811131477356, "info_performance_mean": 0.35520264506340027, "info_performance_final": 0.38692811131477356, "step": 649500}
{"episode_reward": 710.4052287581684, "episode": 6496.0, "batch_reward": 9.910385131835938, "critic_loss": 636.963134765625, "actor_loss": -1414.0537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.8836760520935059, "alpha_loss": -0.20938463509082794, "alpha_value": 0.3553161464887373, "step": 650000}
{"duration": 18.68192458152771, "info_normalized_performance_mean": 0.7605953216552734, "info_normalized_performance_final": 0.8154761791229248, "info_performance_mean": 0.7605953216552734, "info_performance_final": 0.8154761791229248, "step": 650000}
{"episode_reward": 1521.1904761904784, "episode": 6501.0, "batch_reward": 10.795303344726562, "critic_loss": 440.278076171875, "actor_loss": -1447.0390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9647310376167297, "alpha_loss": -0.20744214951992035, "alpha_value": 0.35926872507078605, "duration": 1.6300675868988037, "info_normalized_performance_mean": 0.44232726097106934, "info_normalized_performance_final": 0.5, "info_performance_mean": 0.44232726097106934, "info_performance_final": 0.5, "step": 650500}
{"episode_reward": 884.6545454545455, "episode": 6506.0, "batch_reward": 11.005474090576172, "critic_loss": 1195.98046875, "actor_loss": -1479.54443359375, "actor_target_entropy": -3.0, "actor_entropy": 0.8482828140258789, "alpha_loss": 0.10547266900539398, "alpha_value": 0.36098568247439117, "duration": 1.542595386505127, "info_normalized_performance_mean": 0.8271527290344238, "info_normalized_performance_final": 0.9027777910232544, "info_performance_mean": 0.8271527290344238, "info_performance_final": 0.9027777910232544, "step": 651000}
{"episode_reward": 1654.3055555555586, "episode": 6511.0, "batch_reward": 11.1312255859375, "critic_loss": 805.79345703125, "actor_loss": -1429.7490234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1610918045043945, "alpha_loss": -0.01729857549071312, "alpha_value": 0.3632813649983655, "duration": 1.5960044860839844, "info_normalized_performance_mean": 0.8856862783432007, "info_normalized_performance_final": 0.9947712421417236, "info_performance_mean": 0.8856862783432007, "info_performance_final": 0.9947712421417236, "step": 651500}
{"episode_reward": 1771.3725490196043, "episode": 6516.0, "batch_reward": 10.771480560302734, "critic_loss": 288.29248046875, "actor_loss": -1467.36669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8717914819717407, "alpha_loss": -0.04610811918973923, "alpha_value": 0.3620153705240687, "duration": 1.6643750667572021, "info_normalized_performance_mean": 0.2822069525718689, "info_normalized_performance_final": 0.3185286819934845, "info_performance_mean": 0.2822069525718689, "info_performance_final": 0.3185286819934845, "step": 652000}
{"episode_reward": 564.4139194139194, "episode": 6521.0, "batch_reward": 11.780004501342773, "critic_loss": 1002.9908447265625, "actor_loss": -1503.2044677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.092780590057373, "alpha_loss": 0.1259327381849289, "alpha_value": 0.36024578498314763, "duration": 1.4657080173492432, "info_normalized_performance_mean": 0.5121995806694031, "info_normalized_performance_final": 0.5566893219947815, "info_performance_mean": 0.5121995806694031, "info_performance_final": 0.5566893219947815, "step": 652500}
{"episode_reward": 1024.3990929705208, "episode": 6526.0, "batch_reward": 10.207138061523438, "critic_loss": 759.780517578125, "actor_loss": -1463.748779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7287925481796265, "alpha_loss": -0.028149455785751343, "alpha_value": 0.35753447887216333, "duration": 1.5594205856323242, "info_normalized_performance_mean": 0.44580256938934326, "info_normalized_performance_final": 0.4955844283103943, "info_performance_mean": 0.44580256938934326, "info_performance_final": 0.4955844283103943, "step": 653000}
{"episode_reward": 891.6051948051938, "episode": 6531.0, "batch_reward": 10.533157348632812, "critic_loss": 804.8277587890625, "actor_loss": -1463.1610107421875, "actor_target_entropy": -3.0, "actor_entropy": 0.5569849014282227, "alpha_loss": -0.039062730967998505, "alpha_value": 0.3561128238479461, "duration": 1.4107904434204102, "info_normalized_performance_mean": 0.04439796507358551, "info_normalized_performance_final": 0.04897959157824516, "info_performance_mean": 0.04439796507358551, "info_performance_final": 0.04897959157824516, "step": 653500}
{"episode_reward": 88.79591836734699, "episode": 6536.0, "batch_reward": 10.947303771972656, "critic_loss": 439.81414794921875, "actor_loss": -1447.535888671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9055129289627075, "alpha_loss": 0.1136932373046875, "alpha_value": 0.35280147571272946, "duration": 1.4922423362731934, "info_normalized_performance_mean": 0.9263986945152283, "info_normalized_performance_final": 0.9970238208770752, "info_performance_mean": 0.9263986945152283, "info_performance_final": 0.9970238208770752, "step": 654000}
{"episode_reward": 1852.7976190476165, "episode": 6541.0, "batch_reward": 11.343374252319336, "critic_loss": 455.91845703125, "actor_loss": -1498.4541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.0670520067214966, "alpha_loss": 0.03686143457889557, "alpha_value": 0.3499743710831759, "duration": 1.590233564376831, "info_normalized_performance_mean": 0.43414923548698425, "info_normalized_performance_final": 0.4661458432674408, "info_performance_mean": 0.43414923548698425, "info_performance_final": 0.4661458432674408, "step": 654500}
{"episode_reward": 868.2986111111101, "episode": 6546.0, "batch_reward": 11.617888450622559, "critic_loss": 209.35060119628906, "actor_loss": -1523.921142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.0223857164382935, "alpha_loss": 0.1334482729434967, "alpha_value": 0.34738941596593437, "duration": 1.4025132656097412, "info_normalized_performance_mean": 0.6143572330474854, "info_normalized_performance_final": 0.6535714268684387, "info_performance_mean": 0.6143572330474854, "info_performance_final": 0.6535714268684387, "step": 655000}
{"episode_reward": 1228.7142857142865, "episode": 6551.0, "batch_reward": 11.259828567504883, "critic_loss": 798.4828491210938, "actor_loss": -1478.998779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7886276245117188, "alpha_loss": 0.1295090764760971, "alpha_value": 0.34464165934397, "duration": 1.5199239253997803, "info_normalized_performance_mean": 0.3684670925140381, "info_normalized_performance_final": 0.40694788098335266, "info_performance_mean": 0.3684670925140381, "info_performance_final": 0.40694788098335266, "step": 655500}
{"episode_reward": 736.9341053212006, "episode": 6556.0, "batch_reward": 10.646013259887695, "critic_loss": 323.54937744140625, "actor_loss": -1485.80126953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7222059369087219, "alpha_loss": -0.0495731458067894, "alpha_value": 0.34585404721844404, "duration": 1.4740879535675049, "info_normalized_performance_mean": 0.48101410269737244, "info_normalized_performance_final": 0.5350765585899353, "info_performance_mean": 0.48101410269737244, "info_performance_final": 0.5350765585899353, "step": 656000}
{"episode_reward": 962.0280612244912, "episode": 6561.0, "batch_reward": 11.072347640991211, "critic_loss": 230.03013610839844, "actor_loss": -1479.205322265625, "actor_target_entropy": -3.0, "actor_entropy": 0.6641268730163574, "alpha_loss": 0.12294066697359085, "alpha_value": 0.3403476993072283, "duration": 1.5182855129241943, "info_normalized_performance_mean": 0.6139400005340576, "info_normalized_performance_final": 0.6520000100135803, "info_performance_mean": 0.6139400005340576, "info_performance_final": 0.6520000100135803, "step": 656500}
{"episode_reward": 1227.8799999999985, "episode": 6566.0, "batch_reward": 10.531511306762695, "critic_loss": 381.92681884765625, "actor_loss": -1423.39794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.5590373277664185, "alpha_loss": 0.09084716439247131, "alpha_value": 0.3362972119952095, "duration": 1.533277988433838, "info_normalized_performance_mean": 0.6037439703941345, "info_normalized_performance_final": 0.6785714030265808, "info_performance_mean": 0.6037439703941345, "info_performance_final": 0.6785714030265808, "step": 657000}
{"episode_reward": 1207.488226059655, "episode": 6571.0, "batch_reward": 10.991945266723633, "critic_loss": 290.0561828613281, "actor_loss": -1465.779541015625, "actor_target_entropy": -3.0, "actor_entropy": 0.6716350317001343, "alpha_loss": 0.19640091061592102, "alpha_value": 0.33392820100936754, "duration": 1.5295729637145996, "info_normalized_performance_mean": 0.5972999334335327, "info_normalized_performance_final": 0.6675823926925659, "info_performance_mean": 0.5972999334335327, "info_performance_final": 0.6675823926925659, "step": 657500}
{"episode_reward": 1194.5996860282562, "episode": 6576.0, "batch_reward": 10.519035339355469, "critic_loss": 752.7383422851562, "actor_loss": -1467.606201171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8017860651016235, "alpha_loss": -0.021112672984600067, "alpha_value": 0.3290852403819624, "duration": 1.5372333526611328, "info_normalized_performance_mean": 0.8001344203948975, "info_normalized_performance_final": 0.88067227602005, "info_performance_mean": 0.8001344203948975, "info_performance_final": 0.88067227602005, "step": 658000}
{"episode_reward": 1600.2689075630249, "episode": 6581.0, "batch_reward": 10.139960289001465, "critic_loss": 354.5478515625, "actor_loss": -1433.486083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.5639822483062744, "alpha_loss": -0.04238114133477211, "alpha_value": 0.32488226490511035, "duration": 1.599503993988037, "info_normalized_performance_mean": 0.6547744870185852, "info_normalized_performance_final": 0.7029411792755127, "info_performance_mean": 0.6547744870185852, "info_performance_final": 0.7029411792755127, "step": 658500}
{"episode_reward": 1309.5490196078404, "episode": 6586.0, "batch_reward": 10.755105972290039, "critic_loss": 481.2404479980469, "actor_loss": -1489.408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.585138201713562, "alpha_loss": -0.07133930921554565, "alpha_value": 0.3203485252887511, "duration": 1.5453813076019287, "info_normalized_performance_mean": 0.3675595223903656, "info_normalized_performance_final": 0.4047619104385376, "info_performance_mean": 0.3675595223903656, "info_performance_final": 0.4047619104385376, "step": 659000}
{"episode_reward": 735.1190476190465, "episode": 6591.0, "batch_reward": 11.084115982055664, "critic_loss": 567.3524169921875, "actor_loss": -1462.0106201171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7315088510513306, "alpha_loss": 0.20895399153232574, "alpha_value": 0.31725019483669614, "duration": 1.6171207427978516, "info_normalized_performance_mean": 0.7918384075164795, "info_normalized_performance_final": 0.9246153831481934, "info_performance_mean": 0.7918384075164795, "info_performance_final": 0.9246153831481934, "step": 659500}
{"episode_reward": 1583.6769230769255, "episode": 6596.0, "batch_reward": 10.807027816772461, "critic_loss": 358.18365478515625, "actor_loss": -1493.86181640625, "actor_target_entropy": -3.0, "actor_entropy": 0.6237092018127441, "alpha_loss": 0.11696961522102356, "alpha_value": 0.31430769748792814, "step": 660000}
{"duration": 18.836405754089355, "info_normalized_performance_mean": 0.5704706311225891, "info_normalized_performance_final": 0.8125, "info_performance_mean": 0.5704706311225891, "info_performance_final": 0.8125, "step": 660000}
{"episode_reward": 1140.9413580246915, "episode": 6601.0, "batch_reward": 10.340622901916504, "critic_loss": 350.0313720703125, "actor_loss": -1440.76904296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7682579755783081, "alpha_loss": 0.11353029310703278, "alpha_value": 0.30743368709787167, "duration": 1.5695219039916992, "info_normalized_performance_mean": 0.7938280701637268, "info_normalized_performance_final": 0.8580729365348816, "info_performance_mean": 0.7938280701637268, "info_performance_final": 0.8580729365348816, "step": 660500}
{"episode_reward": 1587.6562499999984, "episode": 6606.0, "batch_reward": 10.893974304199219, "critic_loss": 1180.453857421875, "actor_loss": -1470.9830322265625, "actor_target_entropy": -3.0, "actor_entropy": 0.7357970476150513, "alpha_loss": 0.1401006132364273, "alpha_value": 0.30454618358783864, "duration": 1.4962639808654785, "info_normalized_performance_mean": 0.6805656552314758, "info_normalized_performance_final": 0.7688491940498352, "info_performance_mean": 0.6805656552314758, "info_performance_final": 0.7688491940498352, "step": 661000}
{"episode_reward": 1361.1309523809512, "episode": 6611.0, "batch_reward": 10.806329727172852, "critic_loss": 453.6325378417969, "actor_loss": -1468.614990234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5935109853744507, "alpha_loss": 0.0927947461605072, "alpha_value": 0.30041160289349605, "duration": 1.489464521408081, "info_normalized_performance_mean": 0.30815833806991577, "info_normalized_performance_final": 0.3491666615009308, "info_performance_mean": 0.30815833806991577, "info_performance_final": 0.3491666615009308, "step": 661500}
{"episode_reward": 616.3166666666672, "episode": 6616.0, "batch_reward": 11.192607879638672, "critic_loss": 404.31939697265625, "actor_loss": -1508.71630859375, "actor_target_entropy": -3.0, "actor_entropy": 0.6528371572494507, "alpha_loss": 0.09713764488697052, "alpha_value": 0.2972704125938194, "duration": 1.4337973594665527, "info_normalized_performance_mean": 0.33420196175575256, "info_normalized_performance_final": 0.3738839328289032, "info_performance_mean": 0.33420196175575256, "info_performance_final": 0.3738839328289032, "step": 662000}
{"episode_reward": 668.4040178571422, "episode": 6621.0, "batch_reward": 11.34385871887207, "critic_loss": 298.369384765625, "actor_loss": -1460.6990966796875, "actor_target_entropy": -3.0, "actor_entropy": 0.3752641975879669, "alpha_loss": 0.11083878576755524, "alpha_value": 0.2951728949356711, "duration": 1.7290260791778564, "info_normalized_performance_mean": 0.34349003434181213, "info_normalized_performance_final": 0.3945152461528778, "info_performance_mean": 0.34349003434181213, "info_performance_final": 0.3945152461528778, "step": 662500}
{"episode_reward": 686.9799726900332, "episode": 6626.0, "batch_reward": 10.868648529052734, "critic_loss": 457.0406188964844, "actor_loss": -1537.2945556640625, "actor_target_entropy": -3.0, "actor_entropy": 0.3821166157722473, "alpha_loss": -0.06608157604932785, "alpha_value": 0.28940297704126833, "duration": 1.5911436080932617, "info_normalized_performance_mean": 0.44454047083854675, "info_normalized_performance_final": 0.4954761862754822, "info_performance_mean": 0.44454047083854675, "info_performance_final": 0.4954761862754822, "step": 663000}
{"episode_reward": 889.0809523809509, "episode": 6631.0, "batch_reward": 10.176227569580078, "critic_loss": 614.5401000976562, "actor_loss": -1492.6297607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.28869107365608215, "alpha_loss": -0.04964248463511467, "alpha_value": 0.28616818945443734, "duration": 1.537954330444336, "info_normalized_performance_mean": 0.5495973825454712, "info_normalized_performance_final": 0.5970553159713745, "info_performance_mean": 0.5495973825454712, "info_performance_final": 0.5970553159713745, "step": 663500}
{"episode_reward": 1099.1947115384592, "episode": 6636.0, "batch_reward": 10.744281768798828, "critic_loss": 496.230224609375, "actor_loss": -1460.8175048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.4163215160369873, "alpha_loss": -0.03239430859684944, "alpha_value": 0.2838677763867189, "duration": 1.6007537841796875, "info_normalized_performance_mean": 0.5846898555755615, "info_normalized_performance_final": 0.639971137046814, "info_performance_mean": 0.5846898555755615, "info_performance_final": 0.639971137046814, "step": 664000}
{"episode_reward": 1169.3795093795093, "episode": 6641.0, "batch_reward": 10.15471076965332, "critic_loss": 353.906982421875, "actor_loss": -1381.2037353515625, "actor_target_entropy": -3.0, "actor_entropy": 0.520376980304718, "alpha_loss": -0.03720229119062424, "alpha_value": 0.280222460222762, "duration": 1.582430124282837, "info_normalized_performance_mean": 0.8469429016113281, "info_normalized_performance_final": 0.9357143044471741, "info_performance_mean": 0.8469429016113281, "info_performance_final": 0.9357143044471741, "step": 664500}
{"episode_reward": 1693.8857142857153, "episode": 6646.0, "batch_reward": 11.048295974731445, "critic_loss": 558.9421997070312, "actor_loss": -1450.586181640625, "actor_target_entropy": -3.0, "actor_entropy": 0.4531722664833069, "alpha_loss": 0.09496958553791046, "alpha_value": 0.27759381586838416, "duration": 1.5534183979034424, "info_normalized_performance_mean": 0.7988908290863037, "info_normalized_performance_final": 0.8873949646949768, "info_performance_mean": 0.7988908290863037, "info_performance_final": 0.8873949646949768, "step": 665000}
{"episode_reward": 1597.7815126050414, "episode": 6651.0, "batch_reward": 10.991283416748047, "critic_loss": 355.1120910644531, "actor_loss": -1437.11474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.5694580674171448, "alpha_loss": 0.052271123975515366, "alpha_value": 0.27448954100423684, "duration": 1.577317714691162, "info_normalized_performance_mean": 0.4524180591106415, "info_normalized_performance_final": 0.5048249363899231, "info_performance_mean": 0.4524180591106415, "info_performance_final": 0.5048249363899231, "step": 665500}
{"episode_reward": 904.8359525778889, "episode": 6656.0, "batch_reward": 10.562191009521484, "critic_loss": 966.4002685546875, "actor_loss": -1489.459228515625, "actor_target_entropy": -3.0, "actor_entropy": 0.003924086689949036, "alpha_loss": -0.12233174592256546, "alpha_value": 0.27139471934505105, "duration": 1.4354724884033203, "info_normalized_performance_mean": 0.30466797947883606, "info_normalized_performance_final": 0.32421875, "info_performance_mean": 0.30466797947883606, "info_performance_final": 0.32421875, "step": 666000}
{"episode_reward": 609.3359375, "episode": 6661.0, "batch_reward": 11.055929183959961, "critic_loss": 350.7587585449219, "actor_loss": -1422.32763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.5258514881134033, "alpha_loss": 0.19590917229652405, "alpha_value": 0.2674030489684573, "duration": 1.5743987560272217, "info_normalized_performance_mean": 0.8331648111343384, "info_normalized_performance_final": 0.9341176748275757, "info_performance_mean": 0.8331648111343384, "info_performance_final": 0.9341176748275757, "step": 666500}
{"episode_reward": 1666.3294117647065, "episode": 6666.0, "batch_reward": 11.606806755065918, "critic_loss": 404.1080017089844, "actor_loss": -1503.925048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7090483903884888, "alpha_loss": 0.10072885453701019, "alpha_value": 0.2642588564693379, "duration": 1.5358972549438477, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 667000}
{"episode_reward": 0.0, "episode": 6671.0, "batch_reward": 10.777986526489258, "critic_loss": 718.8175048828125, "actor_loss": -1428.37109375, "actor_target_entropy": -3.0, "actor_entropy": 0.2997475266456604, "alpha_loss": 0.08552367985248566, "alpha_value": 0.26245155214502414, "duration": 1.558349847793579, "info_normalized_performance_mean": 0.7382091283798218, "info_normalized_performance_final": 0.8100961446762085, "info_performance_mean": 0.7382091283798218, "info_performance_final": 0.8100961446762085, "step": 667500}
{"episode_reward": 1476.4182692307704, "episode": 6676.0, "batch_reward": 10.434678077697754, "critic_loss": 569.4901123046875, "actor_loss": -1482.4447021484375, "actor_target_entropy": -3.0, "actor_entropy": 0.26760220527648926, "alpha_loss": -0.06849727034568787, "alpha_value": 0.2597998014192328, "duration": 1.41074800491333, "info_normalized_performance_mean": 0.41696181893348694, "info_normalized_performance_final": 0.4461805522441864, "info_performance_mean": 0.41696181893348694, "info_performance_final": 0.4461805522441864, "step": 668000}
{"episode_reward": 833.9236111111096, "episode": 6681.0, "batch_reward": 10.366793632507324, "critic_loss": 714.2262573242188, "actor_loss": -1407.3524169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.2693345546722412, "alpha_loss": -0.13663597404956818, "alpha_value": 0.25786667264670055, "duration": 1.6262032985687256, "info_normalized_performance_mean": 0.7614721655845642, "info_normalized_performance_final": 0.8444444537162781, "info_performance_mean": 0.7614721655845642, "info_performance_final": 0.8444444537162781, "step": 668500}
{"episode_reward": 1522.9444444444462, "episode": 6686.0, "batch_reward": 10.862115859985352, "critic_loss": 393.8938903808594, "actor_loss": -1439.49951171875, "actor_target_entropy": -3.0, "actor_entropy": 0.36554980278015137, "alpha_loss": -0.1109880581498146, "alpha_value": 0.25597631360225104, "duration": 1.5892775058746338, "info_normalized_performance_mean": 0.7295570373535156, "info_normalized_performance_final": 0.7985714077949524, "info_performance_mean": 0.7295570373535156, "info_performance_final": 0.7985714077949524, "step": 669000}
{"episode_reward": 1459.1142857142836, "episode": 6691.0, "batch_reward": 10.95321273803711, "critic_loss": 244.09033203125, "actor_loss": -1440.4913330078125, "actor_target_entropy": -3.0, "actor_entropy": 0.16796839237213135, "alpha_loss": 0.09364451467990875, "alpha_value": 0.2552421666481478, "duration": 1.471937894821167, "info_normalized_performance_mean": 0.39458832144737244, "info_normalized_performance_final": 0.42352941632270813, "info_performance_mean": 0.39458832144737244, "info_performance_final": 0.42352941632270813, "step": 669500}
{"episode_reward": 789.176470588237, "episode": 6696.0, "batch_reward": 11.280162811279297, "critic_loss": 311.2636413574219, "actor_loss": -1509.3251953125, "actor_target_entropy": -3.0, "actor_entropy": 0.22164463996887207, "alpha_loss": 0.04160642996430397, "alpha_value": 0.2538249966320307, "step": 670000}
{"duration": 18.50835156440735, "info_normalized_performance_mean": 0.8835046291351318, "info_normalized_performance_final": 0.9553571343421936, "info_performance_mean": 0.8835046291351318, "info_performance_final": 0.9553571343421936, "step": 670000}
{"episode_reward": 1767.0089285714303, "episode": 6701.0, "batch_reward": 10.692256927490234, "critic_loss": 639.1566772460938, "actor_loss": -1496.265869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.10942122340202332, "alpha_loss": 0.07906433194875717, "alpha_value": 0.25308087067238016, "duration": 1.610016107559204, "info_normalized_performance_mean": 0.47687751054763794, "info_normalized_performance_final": 0.5242499709129333, "info_performance_mean": 0.47687751054763794, "info_performance_final": 0.5242499709129333, "step": 670500}
{"episode_reward": 953.755000000001, "episode": 6706.0, "batch_reward": 10.659821510314941, "critic_loss": 341.0009460449219, "actor_loss": -1469.416259765625, "actor_target_entropy": -3.0, "actor_entropy": -0.03467532992362976, "alpha_loss": -0.03589777648448944, "alpha_value": 0.25437435315124657, "duration": 1.5799205303192139, "info_normalized_performance_mean": 0.4366419315338135, "info_normalized_performance_final": 0.5086419582366943, "info_performance_mean": 0.4366419315338135, "info_performance_final": 0.5086419582366943, "step": 671000}
{"episode_reward": 873.2839506172852, "episode": 6711.0, "batch_reward": 11.669721603393555, "critic_loss": 396.74591064453125, "actor_loss": -1476.365234375, "actor_target_entropy": -3.0, "actor_entropy": 0.16328373551368713, "alpha_loss": 0.049937717616558075, "alpha_value": 0.2545149763485137, "duration": 1.4906902313232422, "info_normalized_performance_mean": 0.5564149022102356, "info_normalized_performance_final": 0.622710645198822, "info_performance_mean": 0.5564149022102356, "info_performance_final": 0.622710645198822, "step": 671500}
{"episode_reward": 1112.8296703296694, "episode": 6716.0, "batch_reward": 10.80661392211914, "critic_loss": 432.35870361328125, "actor_loss": -1426.6011962890625, "actor_target_entropy": -3.0, "actor_entropy": 0.27685344219207764, "alpha_loss": -0.011268742382526398, "alpha_value": 0.25584704204023284, "duration": 1.5360972881317139, "info_normalized_performance_mean": 0.7876372337341309, "info_normalized_performance_final": 0.8516483306884766, "info_performance_mean": 0.7876372337341309, "info_performance_final": 0.8516483306884766, "step": 672000}
{"episode_reward": 1575.2747252747236, "episode": 6721.0, "batch_reward": 11.399538040161133, "critic_loss": 432.5750732421875, "actor_loss": -1480.94677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.3835565745830536, "alpha_loss": -0.13048380613327026, "alpha_value": 0.25964627910438615, "duration": 1.5583961009979248, "info_normalized_performance_mean": 0.49087005853652954, "info_normalized_performance_final": 0.5472727417945862, "info_performance_mean": 0.49087005853652954, "info_performance_final": 0.5472727417945862, "step": 672500}
{"episode_reward": 981.7402597402615, "episode": 6726.0, "batch_reward": 9.779542922973633, "critic_loss": 759.8226318359375, "actor_loss": -1392.8359375, "actor_target_entropy": -3.0, "actor_entropy": -0.00224226713180542, "alpha_loss": -0.14651747047901154, "alpha_value": 0.2625881967556055, "duration": 1.479095697402954, "info_normalized_performance_mean": 0.6326144933700562, "info_normalized_performance_final": 0.7147436141967773, "info_performance_mean": 0.6326144933700562, "info_performance_final": 0.7147436141967773, "step": 673000}
{"episode_reward": 1265.2289377289396, "episode": 6731.0, "batch_reward": 10.7180757522583, "critic_loss": 798.2237548828125, "actor_loss": -1409.545166015625, "actor_target_entropy": -3.0, "actor_entropy": 0.41260814666748047, "alpha_loss": 0.08904899656772614, "alpha_value": 0.2646689465648353, "duration": 1.4944586753845215, "info_normalized_performance_mean": 0.6649513244628906, "info_normalized_performance_final": 0.7272727489471436, "info_performance_mean": 0.6649513244628906, "info_performance_final": 0.7272727489471436, "step": 673500}
{"episode_reward": 1329.9025974025956, "episode": 6736.0, "batch_reward": 10.67154312133789, "critic_loss": 579.087646484375, "actor_loss": -1441.2227783203125, "actor_target_entropy": -3.0, "actor_entropy": -0.002672731876373291, "alpha_loss": -0.06469982117414474, "alpha_value": 0.26554571521485976, "duration": 1.549992322921753, "info_normalized_performance_mean": 0.7736077904701233, "info_normalized_performance_final": 0.8457516431808472, "info_performance_mean": 0.7736077904701233, "info_performance_final": 0.8457516431808472, "step": 674000}
{"episode_reward": 1547.215686274509, "episode": 6741.0, "batch_reward": 10.922252655029297, "critic_loss": 288.3639831542969, "actor_loss": -1442.861572265625, "actor_target_entropy": -3.0, "actor_entropy": 0.03920314460992813, "alpha_loss": -0.05318475514650345, "alpha_value": 0.2663061922619756, "duration": 1.562807559967041, "info_normalized_performance_mean": 0.7486458420753479, "info_normalized_performance_final": 0.8159722089767456, "info_performance_mean": 0.7486458420753479, "info_performance_final": 0.8159722089767456, "step": 674500}
{"episode_reward": 1497.2916666666642, "episode": 6746.0, "batch_reward": 10.701977729797363, "critic_loss": 592.65966796875, "actor_loss": -1467.92919921875, "actor_target_entropy": -3.0, "actor_entropy": 0.04431547597050667, "alpha_loss": -0.10301581025123596, "alpha_value": 0.2690453051549606, "duration": 1.5960209369659424, "info_normalized_performance_mean": 0.5395067930221558, "info_normalized_performance_final": 0.5875850319862366, "info_performance_mean": 0.5395067930221558, "info_performance_final": 0.5875850319862366, "step": 675000}
{"episode_reward": 1079.0136054421741, "episode": 6751.0, "batch_reward": 11.682150840759277, "critic_loss": 611.1253662109375, "actor_loss": -1459.5335693359375, "actor_target_entropy": -3.0, "actor_entropy": 0.3332536220550537, "alpha_loss": 0.07985018938779831, "alpha_value": 0.27199464338833024, "duration": 1.7272975444793701, "info_normalized_performance_mean": 0.5610775947570801, "info_normalized_performance_final": 0.642246663570404, "info_performance_mean": 0.5610775947570801, "info_performance_final": 0.642246663570404, "step": 675500}
{"episode_reward": 1122.155067155066, "episode": 6756.0, "batch_reward": 11.020625114440918, "critic_loss": 360.5951232910156, "actor_loss": -1446.714111328125, "actor_target_entropy": -3.0, "actor_entropy": 0.47222310304641724, "alpha_loss": -0.11159181594848633, "alpha_value": 0.2727283275095817, "duration": 1.6339876651763916, "info_normalized_performance_mean": 0.4815104603767395, "info_normalized_performance_final": 0.5304166674613953, "info_performance_mean": 0.4815104603767395, "info_performance_final": 0.5304166674613953, "step": 676000}
{"episode_reward": 963.0208333333342, "episode": 6761.0, "batch_reward": 11.546850204467773, "critic_loss": 276.6044616699219, "actor_loss": -1491.6085205078125, "actor_target_entropy": -3.0, "actor_entropy": 0.6397877931594849, "alpha_loss": -0.005677137523889542, "alpha_value": 0.27229661038205843, "duration": 1.4907965660095215, "info_normalized_performance_mean": 0.48062098026275635, "info_normalized_performance_final": 0.5300324559211731, "info_performance_mean": 0.48062098026275635, "info_performance_final": 0.5300324559211731, "step": 676500}
{"episode_reward": 961.2418831168853, "episode": 6766.0, "batch_reward": 11.283228874206543, "critic_loss": 623.421142578125, "actor_loss": -1484.357177734375, "actor_target_entropy": -3.0, "actor_entropy": 0.34149473905563354, "alpha_loss": 0.005465996451675892, "alpha_value": 0.2729730997749307, "duration": 1.6167643070220947, "info_normalized_performance_mean": 0.7672217488288879, "info_normalized_performance_final": 0.8235294222831726, "info_performance_mean": 0.7672217488288879, "info_performance_final": 0.8235294222831726, "step": 677000}
{"episode_reward": 1534.443438914029, "episode": 6771.0, "batch_reward": 11.189062118530273, "critic_loss": 397.0670471191406, "actor_loss": -1514.536376953125, "actor_target_entropy": -3.0, "actor_entropy": 0.4276460111141205, "alpha_loss": 0.060325343161821365, "alpha_value": 0.2725998869756466, "duration": 1.5540831089019775, "info_normalized_performance_mean": 0.5448600053787231, "info_normalized_performance_final": 0.6145833134651184, "info_performance_mean": 0.5448600053787231, "info_performance_final": 0.6145833134651184, "step": 677500}
{"episode_reward": 1089.7200520833323, "episode": 6776.0, "batch_reward": 10.259064674377441, "critic_loss": 246.17189025878906, "actor_loss": -1429.609375, "actor_target_entropy": -3.0, "actor_entropy": 0.33818453550338745, "alpha_loss": -0.1099870353937149, "alpha_value": 0.2720016061248983, "duration": 1.4156920909881592, "info_normalized_performance_mean": 0.5728511810302734, "info_normalized_performance_final": 0.6386904716491699, "info_performance_mean": 0.5728511810302734, "info_performance_final": 0.6386904716491699, "step": 678000}
{"episode_reward": 1145.7023809523816, "episode": 6781.0, "batch_reward": 10.911633491516113, "critic_loss": 231.70346069335938, "actor_loss": -1436.67919921875, "actor_target_entropy": -3.0, "actor_entropy": 0.4210045039653778, "alpha_loss": 0.02454628050327301, "alpha_value": 0.27234258429739105, "duration": 1.6129746437072754, "info_normalized_performance_mean": 0.4869643449783325, "info_normalized_performance_final": 0.5305059552192688, "info_performance_mean": 0.4869643449783325, "info_performance_final": 0.5305059552192688, "step": 678500}
{"episode_reward": 973.9285714285706, "episode": 6786.0, "batch_reward": 11.625720977783203, "critic_loss": 350.83056640625, "actor_loss": -1458.233642578125, "actor_target_entropy": -3.0, "actor_entropy": 0.3831602931022644, "alpha_loss": 0.12338924407958984, "alpha_value": 0.27221435814755873, "duration": 1.4379806518554688, "info_normalized_performance_mean": 0.892578125, "info_normalized_performance_final": 0.94921875, "info_performance_mean": 0.892578125, "info_performance_final": 0.94921875, "step": 679000}
{"episode_reward": 1785.15625, "episode": 6791.0, "batch_reward": 11.105974197387695, "critic_loss": 358.73974609375, "actor_loss": -1473.722900390625, "actor_target_entropy": -3.0, "actor_entropy": 0.2498607039451599, "alpha_loss": -0.04421459138393402, "alpha_value": 0.2726482134377885, "duration": 1.5287830829620361, "info_normalized_performance_mean": 0.8108000159263611, "info_normalized_performance_final": 0.8964706063270569, "info_performance_mean": 0.8108000159263611, "info_performance_final": 0.8964706063270569, "step": 679500}
{"episode_reward": 1621.6000000000008, "episode": 6796.0, "batch_reward": 12.19797134399414, "critic_loss": 431.560546875, "actor_loss": -1487.175048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.4833332300186157, "alpha_loss": 0.0749855786561966, "alpha_value": 0.2747301659635208, "step": 680000}
{"duration": 18.678735971450806, "info_normalized_performance_mean": 0.4936719536781311, "info_normalized_performance_final": 0.5409226417541504, "info_performance_mean": 0.4936719536781311, "info_performance_final": 0.5409226417541504, "step": 680000}
{"episode_reward": 987.3437500000018, "episode": 6801.0, "batch_reward": 10.786642074584961, "critic_loss": 168.4100341796875, "actor_loss": -1454.14013671875, "actor_target_entropy": -3.0, "actor_entropy": 0.3140248656272888, "alpha_loss": -0.04759746044874191, "alpha_value": 0.27592030418835267, "duration": 1.6296396255493164, "info_normalized_performance_mean": 0.145735964179039, "info_normalized_performance_final": 0.1746031790971756, "info_performance_mean": 0.145735964179039, "info_performance_final": 0.1746031790971756, "step": 680500}
{"episode_reward": 291.4718614718616, "episode": 6806.0, "batch_reward": 11.064886093139648, "critic_loss": 214.21128845214844, "actor_loss": -1466.139892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.8367644548416138, "alpha_loss": -0.14267213642597198, "alpha_value": 0.2808000631356624, "duration": 1.5595085620880127, "info_normalized_performance_mean": 0.7579394578933716, "info_normalized_performance_final": 0.8145604133605957, "info_performance_mean": 0.7579394578933716, "info_performance_final": 0.8145604133605957, "step": 681000}
{"episode_reward": 1515.8791208791229, "episode": 6811.0, "batch_reward": 10.772411346435547, "critic_loss": 400.75054931640625, "actor_loss": -1471.6055908203125, "actor_target_entropy": -3.0, "actor_entropy": 0.32898572087287903, "alpha_loss": -0.325621634721756, "alpha_value": 0.2853555111129102, "duration": 1.4853239059448242, "info_normalized_performance_mean": 0.7685165405273438, "info_normalized_performance_final": 0.8630050420761108, "info_performance_mean": 0.7685165405273438, "info_performance_final": 0.8630050420761108, "step": 681500}
{"episode_reward": 1537.032828282827, "episode": 6816.0, "batch_reward": 11.257200241088867, "critic_loss": 253.2105712890625, "actor_loss": -1450.247314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7003164887428284, "alpha_loss": -0.016229450702667236, "alpha_value": 0.2905249282935554, "duration": 1.5740642547607422, "info_normalized_performance_mean": 0.05555317550897598, "info_normalized_performance_final": 0.06528964638710022, "info_performance_mean": 0.05555317550897598, "info_performance_final": 0.06528964638710022, "step": 682000}
{"episode_reward": 111.10636277302942, "episode": 6821.0, "batch_reward": 10.982027053833008, "critic_loss": 346.5455017089844, "actor_loss": -1466.981689453125, "actor_target_entropy": -3.0, "actor_entropy": 0.36021915078163147, "alpha_loss": -0.13545937836170197, "alpha_value": 0.2929977748082719, "duration": 1.4591000080108643, "info_normalized_performance_mean": 0.5131745934486389, "info_normalized_performance_final": 0.5654761791229248, "info_performance_mean": 0.5131745934486389, "info_performance_final": 0.5654761791229248, "step": 682500}
{"episode_reward": 1026.3492063492079, "episode": 6826.0, "batch_reward": 10.596985816955566, "critic_loss": 559.9127197265625, "actor_loss": -1445.7491455078125, "actor_target_entropy": -3.0, "actor_entropy": 0.6655782461166382, "alpha_loss": -0.11203005164861679, "alpha_value": 0.29647121251151565, "duration": 1.4238922595977783, "info_normalized_performance_mean": 0.33688127994537354, "info_normalized_performance_final": 0.3622449040412903, "info_performance_mean": 0.33688127994537354, "info_performance_final": 0.3622449040412903, "step": 683000}
{"episode_reward": 673.7627551020396, "episode": 6831.0, "batch_reward": 10.438728332519531, "critic_loss": 661.7667236328125, "actor_loss": -1399.6695556640625, "actor_target_entropy": -3.0, "actor_entropy": 0.47933775186538696, "alpha_loss": 0.015777915716171265, "alpha_value": 0.2973534659804457, "duration": 1.7162137031555176, "info_normalized_performance_mean": 0.3601706624031067, "info_normalized_performance_final": 0.42332175374031067, "info_performance_mean": 0.3601706624031067, "info_performance_final": 0.42332175374031067, "step": 683500}
{"episode_reward": 720.3414351851842, "episode": 6836.0, "batch_reward": 11.212215423583984, "critic_loss": 311.572998046875, "actor_loss": -1441.707763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.823638916015625, "alpha_loss": 0.1057552769780159, "alpha_value": 0.2970709810178475, "duration": 1.6065773963928223, "info_normalized_performance_mean": 0.6995792984962463, "info_normalized_performance_final": 0.7873015999794006, "info_performance_mean": 0.6995792984962463, "info_performance_final": 0.7873015999794006, "step": 684000}
{"episode_reward": 1399.1587301587297, "episode": 6841.0, "batch_reward": 11.396055221557617, "critic_loss": 449.417236328125, "actor_loss": -1507.969970703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6741987466812134, "alpha_loss": 0.06465241312980652, "alpha_value": 0.29835459246124774, "duration": 1.4630427360534668, "info_normalized_performance_mean": 0.5166018605232239, "info_normalized_performance_final": 0.5714285969734192, "info_performance_mean": 0.5166018605232239, "info_performance_final": 0.5714285969734192, "step": 684500}
{"episode_reward": 1033.203463203464, "episode": 6846.0, "batch_reward": 10.45120620727539, "critic_loss": 345.1805419921875, "actor_loss": -1441.8668212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6265033483505249, "alpha_loss": -0.0912967324256897, "alpha_value": 0.2983641127451144, "duration": 1.6271893978118896, "info_normalized_performance_mean": 0.5011011362075806, "info_normalized_performance_final": 0.5628571510314941, "info_performance_mean": 0.5011011362075806, "info_performance_final": 0.5628571510314941, "step": 685000}
{"episode_reward": 1002.2021978021985, "episode": 6851.0, "batch_reward": 11.509153366088867, "critic_loss": 355.5793151855469, "actor_loss": -1494.303466796875, "actor_target_entropy": -3.0, "actor_entropy": 0.386648565530777, "alpha_loss": 0.0994751900434494, "alpha_value": 0.29911008989586085, "duration": 1.6926233768463135, "info_normalized_performance_mean": 0.42998573184013367, "info_normalized_performance_final": 0.4860139787197113, "info_performance_mean": 0.42998573184013367, "info_performance_final": 0.4860139787197113, "step": 685500}
{"episode_reward": 859.9713922441185, "episode": 6856.0, "batch_reward": 10.873435020446777, "critic_loss": 391.5638122558594, "actor_loss": -1438.721923828125, "actor_target_entropy": -3.0, "actor_entropy": 0.4576846659183502, "alpha_loss": -0.05443233996629715, "alpha_value": 0.29986152695378737, "duration": 1.624626874923706, "info_normalized_performance_mean": 0.6567619442939758, "info_normalized_performance_final": 0.741428554058075, "info_performance_mean": 0.6567619442939758, "info_performance_final": 0.741428554058075, "step": 686000}
{"episode_reward": 1313.5238095238092, "episode": 6861.0, "batch_reward": 11.349164962768555, "critic_loss": 276.26776123046875, "actor_loss": -1464.740966796875, "actor_target_entropy": -3.0, "actor_entropy": 0.379504919052124, "alpha_loss": -0.021237406879663467, "alpha_value": 0.2987366002555644, "duration": 1.5321025848388672, "info_normalized_performance_mean": 0.8279544115066528, "info_normalized_performance_final": 0.8920454382896423, "info_performance_mean": 0.8279544115066528, "info_performance_final": 0.8920454382896423, "step": 686500}
{"episode_reward": 1655.9090909090894, "episode": 6866.0, "batch_reward": 11.299735069274902, "critic_loss": 202.31124877929688, "actor_loss": -1413.823486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.23886364698410034, "alpha_loss": -0.04601723328232765, "alpha_value": 0.2972620668771729, "duration": 1.765503168106079, "info_normalized_performance_mean": 0.5829303860664368, "info_normalized_performance_final": 0.6775030493736267, "info_performance_mean": 0.5829303860664368, "info_performance_final": 0.6775030493736267, "step": 687000}
{"episode_reward": 1165.860805860804, "episode": 6871.0, "batch_reward": 11.695457458496094, "critic_loss": 199.44073486328125, "actor_loss": -1418.484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7688627243041992, "alpha_loss": 0.19826526939868927, "alpha_value": 0.29436850347776855, "duration": 1.574073314666748, "info_normalized_performance_mean": 0.5703528523445129, "info_normalized_performance_final": 0.6039215922355652, "info_performance_mean": 0.5703528523445129, "info_performance_final": 0.6039215922355652, "step": 687500}
{"episode_reward": 1140.705882352942, "episode": 6876.0, "batch_reward": 11.423991203308105, "critic_loss": 299.5580139160156, "actor_loss": -1441.173095703125, "actor_target_entropy": -3.0, "actor_entropy": 0.766149640083313, "alpha_loss": 0.25817936658859253, "alpha_value": 0.293311541006756, "duration": 1.5616052150726318, "info_normalized_performance_mean": 0.7985678315162659, "info_normalized_performance_final": 0.8645833134651184, "info_performance_mean": 0.7985678315162659, "info_performance_final": 0.8645833134651184, "step": 688000}
{"episode_reward": 1597.1354166666683, "episode": 6881.0, "batch_reward": 10.901705741882324, "critic_loss": 415.2012023925781, "actor_loss": -1451.504150390625, "actor_target_entropy": -3.0, "actor_entropy": 0.4913135766983032, "alpha_loss": 0.05554642900824547, "alpha_value": 0.2897872490080992, "duration": 1.478736400604248, "info_normalized_performance_mean": 0.5399951338768005, "info_normalized_performance_final": 0.5897817611694336, "info_performance_mean": 0.5399951338768005, "info_performance_final": 0.5897817611694336, "step": 688500}
{"episode_reward": 1079.9900793650804, "episode": 6886.0, "batch_reward": 10.538299560546875, "critic_loss": 244.1917724609375, "actor_loss": -1416.183837890625, "actor_target_entropy": -3.0, "actor_entropy": 0.31667327880859375, "alpha_loss": 0.0006438121199607849, "alpha_value": 0.288625790892204, "duration": 1.4512670040130615, "info_normalized_performance_mean": 0.5465177297592163, "info_normalized_performance_final": 0.5982142686843872, "info_performance_mean": 0.5465177297592163, "info_performance_final": 0.5982142686843872, "step": 689000}
{"episode_reward": 1093.0357142857129, "episode": 6891.0, "batch_reward": 10.946062088012695, "critic_loss": 198.47122192382812, "actor_loss": -1434.711669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7296403646469116, "alpha_loss": 0.11514653265476227, "alpha_value": 0.28859608276078985, "duration": 1.5199964046478271, "info_normalized_performance_mean": 0.43292975425720215, "info_normalized_performance_final": 0.4786931872367859, "info_performance_mean": 0.43292975425720215, "info_performance_final": 0.4786931872367859, "step": 689500}
{"episode_reward": 865.8593749999993, "episode": 6896.0, "batch_reward": 10.702007293701172, "critic_loss": 582.8125610351562, "actor_loss": -1408.519775390625, "actor_target_entropy": -3.0, "actor_entropy": 0.42341387271881104, "alpha_loss": 0.0801629051566124, "alpha_value": 0.2869367988798506, "step": 690000}
{"duration": 18.898452043533325, "info_normalized_performance_mean": 0.5759693384170532, "info_normalized_performance_final": 0.6522108912467957, "info_performance_mean": 0.5759693384170532, "info_performance_final": 0.6522108912467957, "step": 690000}
{"episode_reward": 1151.9387755102046, "episode": 6901.0, "batch_reward": 11.21746826171875, "critic_loss": 288.21539306640625, "actor_loss": -1457.162841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8537561297416687, "alpha_loss": -0.06421757489442825, "alpha_value": 0.28817982371146655, "duration": 1.724020004272461, "info_normalized_performance_mean": 0.2620934545993805, "info_normalized_performance_final": 0.30570024251937866, "info_performance_mean": 0.2620934545993805, "info_performance_final": 0.30570024251937866, "step": 690500}
{"episode_reward": 524.1869212962966, "episode": 6906.0, "batch_reward": 11.28874397277832, "critic_loss": 316.281005859375, "actor_loss": -1463.945556640625, "actor_target_entropy": -3.0, "actor_entropy": 0.29495811462402344, "alpha_loss": -0.14054393768310547, "alpha_value": 0.29056246465537977, "duration": 1.5592880249023438, "info_normalized_performance_mean": 0.7874311804771423, "info_normalized_performance_final": 0.8530219793319702, "info_performance_mean": 0.7874311804771423, "info_performance_final": 0.8530219793319702, "step": 691000}
{"episode_reward": 1574.8626373626387, "episode": 6911.0, "batch_reward": 11.608643531799316, "critic_loss": 516.72509765625, "actor_loss": -1458.2025146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.5361733436584473, "alpha_loss": -0.012395188212394714, "alpha_value": 0.2951511468263051, "duration": 1.5968990325927734, "info_normalized_performance_mean": 0.3593670725822449, "info_normalized_performance_final": 0.4016963839530945, "info_performance_mean": 0.3593670725822449, "info_performance_final": 0.4016963839530945, "step": 691500}
{"episode_reward": 718.734232274902, "episode": 6916.0, "batch_reward": 11.725462913513184, "critic_loss": 237.5875244140625, "actor_loss": -1453.24560546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7058397531509399, "alpha_loss": -0.0022910870611667633, "alpha_value": 0.2973858775816805, "duration": 1.5977222919464111, "info_normalized_performance_mean": 0.7066582441329956, "info_normalized_performance_final": 0.8133333325386047, "info_performance_mean": 0.7066582441329956, "info_performance_final": 0.8133333325386047, "step": 692000}
{"episode_reward": 1413.316666666666, "episode": 6921.0, "batch_reward": 11.290910720825195, "critic_loss": 353.5113830566406, "actor_loss": -1440.5775146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.099193811416626, "alpha_loss": -0.017055034637451172, "alpha_value": 0.29971226176438154, "duration": 1.5683472156524658, "info_normalized_performance_mean": 0.04280000180006027, "info_normalized_performance_final": 0.046666666865348816, "info_performance_mean": 0.04280000180006027, "info_performance_final": 0.046666666865348816, "step": 692500}
{"episode_reward": 85.59999999999998, "episode": 6926.0, "batch_reward": 10.428267478942871, "critic_loss": 657.339111328125, "actor_loss": -1424.22509765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8074280619621277, "alpha_loss": -0.06585496664047241, "alpha_value": 0.30059087571330073, "duration": 1.5068740844726562, "info_normalized_performance_mean": 0.5539360642433167, "info_normalized_performance_final": 0.6108630895614624, "info_performance_mean": 0.5539360642433167, "info_performance_final": 0.6108630895614624, "step": 693000}
{"episode_reward": 1107.8720238095252, "episode": 6931.0, "batch_reward": 11.19569206237793, "critic_loss": 224.83709716796875, "actor_loss": -1415.2979736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0729639530181885, "alpha_loss": 0.11266034841537476, "alpha_value": 0.3023531789238575, "duration": 1.4651222229003906, "info_normalized_performance_mean": 0.6229854822158813, "info_normalized_performance_final": 0.6691086888313293, "info_performance_mean": 0.6229854822158813, "info_performance_final": 0.6691086888313293, "step": 693500}
{"episode_reward": 1245.9706959706948, "episode": 6936.0, "batch_reward": 10.20142936706543, "critic_loss": 362.26348876953125, "actor_loss": -1372.50537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.44148415327072144, "alpha_loss": -0.20917552709579468, "alpha_value": 0.3018124338749471, "duration": 1.487673044204712, "info_normalized_performance_mean": 0.7282297015190125, "info_normalized_performance_final": 0.8003662824630737, "info_performance_mean": 0.7282297015190125, "info_performance_final": 0.8003662824630737, "step": 694000}
{"episode_reward": 1456.4590964590939, "episode": 6941.0, "batch_reward": 10.656400680541992, "critic_loss": 544.494140625, "actor_loss": -1416.359130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.5720305442810059, "alpha_loss": 0.06819304823875427, "alpha_value": 0.3017816895585607, "duration": 1.5317275524139404, "info_normalized_performance_mean": 0.40074869990348816, "info_normalized_performance_final": 0.4560546875, "info_performance_mean": 0.40074869990348816, "info_performance_final": 0.4560546875, "step": 694500}
{"episode_reward": 801.4973958333329, "episode": 6946.0, "batch_reward": 11.874841690063477, "critic_loss": 358.74237060546875, "actor_loss": -1478.165283203125, "actor_target_entropy": -3.0, "actor_entropy": 0.5949423313140869, "alpha_loss": 0.07936514914035797, "alpha_value": 0.3036016924458227, "duration": 1.5393807888031006, "info_normalized_performance_mean": 0.7882421612739563, "info_normalized_performance_final": 0.8515625, "info_performance_mean": 0.7882421612739563, "info_performance_final": 0.8515625, "step": 695000}
{"episode_reward": 1576.484375, "episode": 6951.0, "batch_reward": 11.696065902709961, "critic_loss": 931.0589599609375, "actor_loss": -1518.2122802734375, "actor_target_entropy": -3.0, "actor_entropy": 0.5371792316436768, "alpha_loss": -0.032604340463876724, "alpha_value": 0.3054060328432686, "duration": 1.5415585041046143, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 695500}
{"episode_reward": 0.0, "episode": 6956.0, "batch_reward": 10.921608924865723, "critic_loss": 884.151123046875, "actor_loss": -1439.714599609375, "actor_target_entropy": -3.0, "actor_entropy": 0.6926476955413818, "alpha_loss": 0.06417432427406311, "alpha_value": 0.305667739974731, "duration": 1.5106244087219238, "info_normalized_performance_mean": 0.33149996399879456, "info_normalized_performance_final": 0.36666667461395264, "info_performance_mean": 0.33149996399879456, "info_performance_final": 0.36666667461395264, "step": 696000}
{"episode_reward": 663.0000000000002, "episode": 6961.0, "batch_reward": 11.056785583496094, "critic_loss": 377.3682861328125, "actor_loss": -1480.1739501953125, "actor_target_entropy": -3.0, "actor_entropy": 0.449394166469574, "alpha_loss": -0.1418205201625824, "alpha_value": 0.3072358156618018, "duration": 1.5873768329620361, "info_normalized_performance_mean": 0.38125717639923096, "info_normalized_performance_final": 0.42197802662849426, "info_performance_mean": 0.38125717639923096, "info_performance_final": 0.42197802662849426, "step": 696500}
{"episode_reward": 762.5142857142856, "episode": 6966.0, "batch_reward": 10.957226753234863, "critic_loss": 131.3475341796875, "actor_loss": -1428.28857421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9549064636230469, "alpha_loss": -0.08726704120635986, "alpha_value": 0.31205459250723505, "duration": 1.7107207775115967, "info_normalized_performance_mean": 0.3533376455307007, "info_normalized_performance_final": 0.3930387794971466, "info_performance_mean": 0.3533376455307007, "info_performance_final": 0.3930387794971466, "step": 697000}
{"episode_reward": 706.6751430387808, "episode": 6971.0, "batch_reward": 11.46177864074707, "critic_loss": 364.5609130859375, "actor_loss": -1448.90087890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9302340149879456, "alpha_loss": -0.10683362185955048, "alpha_value": 0.3174741696764886, "duration": 1.5149729251861572, "info_normalized_performance_mean": 0.8799488544464111, "info_normalized_performance_final": 0.9795918464660645, "info_performance_mean": 0.8799488544464111, "info_performance_final": 0.9795918464660645, "step": 697500}
{"episode_reward": 1759.8979591836767, "episode": 6976.0, "batch_reward": 11.011144638061523, "critic_loss": 1058.7138671875, "actor_loss": -1429.959228515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9292089939117432, "alpha_loss": -0.10754360258579254, "alpha_value": 0.32268068091092655, "duration": 1.5349411964416504, "info_normalized_performance_mean": 0.809776782989502, "info_normalized_performance_final": 0.875, "info_performance_mean": 0.809776782989502, "info_performance_final": 0.875, "step": 698000}
{"episode_reward": 1619.5535714285716, "episode": 6981.0, "batch_reward": 11.315049171447754, "critic_loss": 209.52987670898438, "actor_loss": -1399.1700439453125, "actor_target_entropy": -3.0, "actor_entropy": 0.8830092549324036, "alpha_loss": 0.23957398533821106, "alpha_value": 0.32742823175440366, "duration": 1.485450267791748, "info_normalized_performance_mean": 0.5452589392662048, "info_normalized_performance_final": 0.5814393758773804, "info_performance_mean": 0.5452589392662048, "info_performance_final": 0.5814393758773804, "step": 698500}
{"episode_reward": 1090.5176767676771, "episode": 6986.0, "batch_reward": 11.24742317199707, "critic_loss": 384.4427795410156, "actor_loss": -1460.915771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0841470956802368, "alpha_loss": -0.009454457089304924, "alpha_value": 0.3317099360254023, "duration": 1.5218513011932373, "info_normalized_performance_mean": 0.5224499702453613, "info_normalized_performance_final": 0.5550000071525574, "info_performance_mean": 0.5224499702453613, "info_performance_final": 0.5550000071525574, "step": 699000}
{"episode_reward": 1044.9000000000012, "episode": 6991.0, "batch_reward": 10.337141990661621, "critic_loss": 194.48043823242188, "actor_loss": -1414.2432861328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7426512837409973, "alpha_loss": -0.0023673977702856064, "alpha_value": 0.33434429258713266, "duration": 1.5311956405639648, "info_normalized_performance_mean": 0.32868751883506775, "info_normalized_performance_final": 0.4115000069141388, "info_performance_mean": 0.32868751883506775, "info_performance_final": 0.4115000069141388, "step": 699500}
{"episode_reward": 657.3750000000008, "episode": 6996.0, "batch_reward": 10.348360061645508, "critic_loss": 573.3576049804688, "actor_loss": -1371.631103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9695001244544983, "alpha_loss": -0.07712496817111969, "alpha_value": 0.3379024060006467, "step": 700000}
{"duration": 18.49780249595642, "info_normalized_performance_mean": 0.26813197135925293, "info_normalized_performance_final": 0.29984050989151, "info_performance_mean": 0.26813197135925293, "info_performance_final": 0.29984050989151, "step": 700000}
{"episode_reward": 536.2639553429026, "episode": 7001.0, "batch_reward": 10.980009078979492, "critic_loss": 734.034912109375, "actor_loss": -1480.033447265625, "actor_target_entropy": -3.0, "actor_entropy": 0.63768470287323, "alpha_loss": -0.3487924337387085, "alpha_value": 0.3422164812752209, "duration": 1.4819025993347168, "info_normalized_performance_mean": 0.291218638420105, "info_normalized_performance_final": 0.3245106041431427, "info_performance_mean": 0.291218638420105, "info_performance_final": 0.3245106041431427, "step": 700500}
{"episode_reward": 582.4372759856633, "episode": 7006.0, "batch_reward": 11.000127792358398, "critic_loss": 445.43194580078125, "actor_loss": -1384.71923828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9706037640571594, "alpha_loss": 0.038400810211896896, "alpha_value": 0.34412464845511326, "duration": 1.5579309463500977, "info_normalized_performance_mean": 0.7774146795272827, "info_normalized_performance_final": 0.8536931872367859, "info_performance_mean": 0.7774146795272827, "info_performance_final": 0.8536931872367859, "step": 701000}
{"episode_reward": 1554.8295454545482, "episode": 7011.0, "batch_reward": 9.982925415039062, "critic_loss": 808.0775756835938, "actor_loss": -1413.8505859375, "actor_target_entropy": -3.0, "actor_entropy": 0.5806209444999695, "alpha_loss": -0.032578207552433014, "alpha_value": 0.3431766591623156, "duration": 1.540090560913086, "info_normalized_performance_mean": 0.4589919149875641, "info_normalized_performance_final": 0.5252976417541504, "info_performance_mean": 0.4589919149875641, "info_performance_final": 0.5252976417541504, "step": 701500}
{"episode_reward": 917.9836309523811, "episode": 7016.0, "batch_reward": 11.509709358215332, "critic_loss": 293.8896484375, "actor_loss": -1467.0283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.048844814300537, "alpha_loss": -0.04025767743587494, "alpha_value": 0.3422376334160819, "duration": 1.556828498840332, "info_normalized_performance_mean": 0.7730206847190857, "info_normalized_performance_final": 0.8497023582458496, "info_performance_mean": 0.7730206847190857, "info_performance_final": 0.8497023582458496, "step": 702000}
{"episode_reward": 1546.041666666668, "episode": 7021.0, "batch_reward": 11.025346755981445, "critic_loss": 441.4694519042969, "actor_loss": -1441.115478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8941073417663574, "alpha_loss": 0.08221309632062912, "alpha_value": 0.341322823882117, "duration": 1.5399713516235352, "info_normalized_performance_mean": 0.2187645584344864, "info_normalized_performance_final": 0.2420833259820938, "info_performance_mean": 0.2187645584344864, "info_performance_final": 0.2420833259820938, "step": 702500}
{"episode_reward": 437.52916666666573, "episode": 7026.0, "batch_reward": 10.354290008544922, "critic_loss": 507.58477783203125, "actor_loss": -1413.420166015625, "actor_target_entropy": -3.0, "actor_entropy": 0.5374038219451904, "alpha_loss": -0.10675634443759918, "alpha_value": 0.3395101846426453, "duration": 1.4108738899230957, "info_normalized_performance_mean": 0.9299553632736206, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9299553632736206, "info_performance_final": 1.0, "step": 703000}
{"episode_reward": 1859.9107142857142, "episode": 7031.0, "batch_reward": 11.519180297851562, "critic_loss": 493.4669189453125, "actor_loss": -1472.226806640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8532812595367432, "alpha_loss": 0.25922858715057373, "alpha_value": 0.33496820582018794, "duration": 1.69673490524292, "info_normalized_performance_mean": 0.3179960250854492, "info_normalized_performance_final": 0.37435898184776306, "info_performance_mean": 0.3179960250854492, "info_performance_final": 0.37435898184776306, "step": 703500}
{"episode_reward": 635.9921104536486, "episode": 7036.0, "batch_reward": 10.897720336914062, "critic_loss": 602.165771484375, "actor_loss": -1376.5128173828125, "actor_target_entropy": -3.0, "actor_entropy": 0.37362438440322876, "alpha_loss": 0.1744692325592041, "alpha_value": 0.32984567087181366, "duration": 1.4775347709655762, "info_normalized_performance_mean": 0.910281240940094, "info_normalized_performance_final": 0.96875, "info_performance_mean": 0.910281240940094, "info_performance_final": 0.96875, "step": 704000}
{"episode_reward": 1820.5625, "episode": 7041.0, "batch_reward": 10.82406997680664, "critic_loss": 386.7105712890625, "actor_loss": -1419.439453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7204095125198364, "alpha_loss": 0.019960859790444374, "alpha_value": 0.32497963376549693, "duration": 1.705662488937378, "info_normalized_performance_mean": 0.3859598934650421, "info_normalized_performance_final": 0.4342021644115448, "info_performance_mean": 0.3859598934650421, "info_performance_final": 0.4342021644115448, "step": 704500}
{"episode_reward": 771.9198982835346, "episode": 7046.0, "batch_reward": 10.985243797302246, "critic_loss": 541.21435546875, "actor_loss": -1496.2747802734375, "actor_target_entropy": -3.0, "actor_entropy": 0.0901525691151619, "alpha_loss": -0.028016433119773865, "alpha_value": 0.32249577511151756, "duration": 1.5522830486297607, "info_normalized_performance_mean": 0.4549768567085266, "info_normalized_performance_final": 0.5, "info_performance_mean": 0.4549768567085266, "info_performance_final": 0.5, "step": 705000}
{"episode_reward": 909.9537037037037, "episode": 7051.0, "batch_reward": 10.257204055786133, "critic_loss": 1025.4656982421875, "actor_loss": -1391.4276123046875, "actor_target_entropy": -3.0, "actor_entropy": 0.1736099123954773, "alpha_loss": -0.06046869605779648, "alpha_value": 0.3186718630935971, "duration": 1.4541101455688477, "info_normalized_performance_mean": 0.5696930289268494, "info_normalized_performance_final": 0.6194196343421936, "info_performance_mean": 0.5696930289268494, "info_performance_final": 0.6194196343421936, "step": 705500}
{"episode_reward": 1139.386160714287, "episode": 7056.0, "batch_reward": 11.09045696258545, "critic_loss": 374.91632080078125, "actor_loss": -1431.4886474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.11791728436946869, "alpha_loss": 0.031171109527349472, "alpha_value": 0.31593560757616806, "duration": 1.4256794452667236, "info_normalized_performance_mean": 0.5161951184272766, "info_normalized_performance_final": 0.5755494236946106, "info_performance_mean": 0.5161951184272766, "info_performance_final": 0.5755494236946106, "step": 706000}
{"episode_reward": 1032.390109890108, "episode": 7061.0, "batch_reward": 10.571541786193848, "critic_loss": 356.62945556640625, "actor_loss": -1405.133544921875, "actor_target_entropy": -3.0, "actor_entropy": 0.49371063709259033, "alpha_loss": 0.0436854250729084, "alpha_value": 0.31495169824341324, "duration": 1.421567678451538, "info_normalized_performance_mean": 0.8328216075897217, "info_normalized_performance_final": 0.8964285850524902, "info_performance_mean": 0.8328216075897217, "info_performance_final": 0.8964285850524902, "step": 706500}
{"episode_reward": 1665.6428571428544, "episode": 7066.0, "batch_reward": 10.932345390319824, "critic_loss": 203.1728515625, "actor_loss": -1400.408935546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7518151998519897, "alpha_loss": 0.18294183909893036, "alpha_value": 0.31168658323655063, "duration": 1.7083137035369873, "info_normalized_performance_mean": 0.4947282671928406, "info_normalized_performance_final": 0.553113579750061, "info_performance_mean": 0.4947282671928406, "info_performance_final": 0.553113579750061, "step": 707000}
{"episode_reward": 989.4566544566535, "episode": 7071.0, "batch_reward": 11.580531120300293, "critic_loss": 726.1572265625, "actor_loss": -1448.38134765625, "actor_target_entropy": -3.0, "actor_entropy": 0.7352629899978638, "alpha_loss": 0.05594903975725174, "alpha_value": 0.3089089503276005, "duration": 1.5973694324493408, "info_normalized_performance_mean": 0.7987974286079407, "info_normalized_performance_final": 0.8784313797950745, "info_performance_mean": 0.7987974286079407, "info_performance_final": 0.8784313797950745, "step": 707500}
{"episode_reward": 1597.5947712418294, "episode": 7076.0, "batch_reward": 11.529656410217285, "critic_loss": 784.25537109375, "actor_loss": -1437.0992431640625, "actor_target_entropy": -3.0, "actor_entropy": 0.6330409049987793, "alpha_loss": 0.12496230006217957, "alpha_value": 0.30711514852314353, "duration": 1.5451838970184326, "info_normalized_performance_mean": 0.5977516770362854, "info_normalized_performance_final": 0.6392157077789307, "info_performance_mean": 0.5977516770362854, "info_performance_final": 0.6392157077789307, "step": 708000}
{"episode_reward": 1195.5032679738551, "episode": 7081.0, "batch_reward": 11.992467880249023, "critic_loss": 365.5423583984375, "actor_loss": -1476.4892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6655594706535339, "alpha_loss": 0.09629648923873901, "alpha_value": 0.30295577577377975, "duration": 1.478966474533081, "info_normalized_performance_mean": 0.5460867285728455, "info_normalized_performance_final": 0.5866910815238953, "info_performance_mean": 0.5460867285728455, "info_performance_final": 0.5866910815238953, "step": 708500}
{"episode_reward": 1092.1733821733828, "episode": 7086.0, "batch_reward": 11.646589279174805, "critic_loss": 263.8813171386719, "actor_loss": -1460.612548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.4448680281639099, "alpha_loss": 0.1972522735595703, "alpha_value": 0.29793896638368716, "duration": 1.4879474639892578, "info_normalized_performance_mean": 0.5366751551628113, "info_normalized_performance_final": 0.5756802558898926, "info_performance_mean": 0.5366751551628113, "info_performance_final": 0.5756802558898926, "step": 709000}
{"episode_reward": 1073.3503401360542, "episode": 7091.0, "batch_reward": 11.252525329589844, "critic_loss": 699.90673828125, "actor_loss": -1425.9090576171875, "actor_target_entropy": -3.0, "actor_entropy": 0.47306883335113525, "alpha_loss": 0.04883598908782005, "alpha_value": 0.2934747270192972, "duration": 1.5987038612365723, "info_normalized_performance_mean": 0.45896488428115845, "info_normalized_performance_final": 0.517568826675415, "info_performance_mean": 0.45896488428115845, "info_performance_final": 0.517568826675415, "step": 709500}
{"episode_reward": 917.9297245963904, "episode": 7096.0, "batch_reward": 11.6478853225708, "critic_loss": 476.2319641113281, "actor_loss": -1501.5069580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.2275775969028473, "alpha_loss": 0.05508933961391449, "alpha_value": 0.2889615889708487, "step": 710000}
{"duration": 18.36837935447693, "info_normalized_performance_mean": 0.8311904668807983, "info_normalized_performance_final": 0.898809552192688, "info_performance_mean": 0.8311904668807983, "info_performance_final": 0.898809552192688, "step": 710000}
{"episode_reward": 1662.380952380949, "episode": 7101.0, "batch_reward": 11.294265747070312, "critic_loss": 824.4119262695312, "actor_loss": -1419.55908203125, "actor_target_entropy": -3.0, "actor_entropy": 0.6378967761993408, "alpha_loss": 0.24260959029197693, "alpha_value": 0.28609531632182944, "duration": 1.4910013675689697, "info_normalized_performance_mean": 0.8359150886535645, "info_normalized_performance_final": 0.9040178656578064, "info_performance_mean": 0.8359150886535645, "info_performance_final": 0.9040178656578064, "step": 710500}
{"episode_reward": 1671.8303571428555, "episode": 7106.0, "batch_reward": 11.61535358428955, "critic_loss": 249.37356567382812, "actor_loss": -1430.82177734375, "actor_target_entropy": -3.0, "actor_entropy": 0.49360349774360657, "alpha_loss": 0.02217017114162445, "alpha_value": 0.28515332024520723, "duration": 1.5283653736114502, "info_normalized_performance_mean": 0.7010000348091125, "info_normalized_performance_final": 0.7568627595901489, "info_performance_mean": 0.7010000348091125, "info_performance_final": 0.7568627595901489, "step": 711000}
{"episode_reward": 1402.0000000000018, "episode": 7111.0, "batch_reward": 11.574522018432617, "critic_loss": 465.667236328125, "actor_loss": -1486.4630126953125, "actor_target_entropy": -3.0, "actor_entropy": 0.36346232891082764, "alpha_loss": -0.11906783282756805, "alpha_value": 0.28744085139821346, "duration": 1.5131146907806396, "info_normalized_performance_mean": 0.6289756894111633, "info_normalized_performance_final": 0.6892361044883728, "info_performance_mean": 0.6289756894111633, "info_performance_final": 0.6892361044883728, "step": 711500}
{"episode_reward": 1257.951388888886, "episode": 7116.0, "batch_reward": 10.979995727539062, "critic_loss": 250.4519500732422, "actor_loss": -1441.494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.09534016996622086, "alpha_loss": -0.06902698427438736, "alpha_value": 0.2890849484442947, "duration": 1.4969141483306885, "info_normalized_performance_mean": 0.6420351266860962, "info_normalized_performance_final": 0.6882086396217346, "info_performance_mean": 0.6420351266860962, "info_performance_final": 0.6882086396217346, "step": 712000}
{"episode_reward": 1284.0702947845834, "episode": 7121.0, "batch_reward": 11.381743431091309, "critic_loss": 187.56204223632812, "actor_loss": -1433.733154296875, "actor_target_entropy": -3.0, "actor_entropy": 0.21728689968585968, "alpha_loss": -0.20499226450920105, "alpha_value": 0.29371561549362124, "duration": 1.478022575378418, "info_normalized_performance_mean": 0.6313278079032898, "info_normalized_performance_final": 0.7069597244262695, "info_performance_mean": 0.6313278079032898, "info_performance_final": 0.7069597244262695, "step": 712500}
{"episode_reward": 1262.655677655679, "episode": 7126.0, "batch_reward": 11.711634635925293, "critic_loss": 254.6846160888672, "actor_loss": -1442.7940673828125, "actor_target_entropy": -3.0, "actor_entropy": 0.2959340810775757, "alpha_loss": 0.16210588812828064, "alpha_value": 0.2962080645278004, "duration": 1.4929618835449219, "info_normalized_performance_mean": 0.6615476012229919, "info_normalized_performance_final": 0.718406617641449, "info_performance_mean": 0.6615476012229919, "info_performance_final": 0.718406617641449, "step": 713000}
{"episode_reward": 1323.0952380952394, "episode": 7131.0, "batch_reward": 11.484647750854492, "critic_loss": 391.96356201171875, "actor_loss": -1453.220703125, "actor_target_entropy": -3.0, "actor_entropy": 0.3020469546318054, "alpha_loss": -0.022826679050922394, "alpha_value": 0.29890779934900386, "duration": 1.49566650390625, "info_normalized_performance_mean": 0.7245507836341858, "info_normalized_performance_final": 0.78125, "info_performance_mean": 0.7245507836341858, "info_performance_final": 0.78125, "step": 713500}
{"episode_reward": 1449.1015625, "episode": 7136.0, "batch_reward": 10.742308616638184, "critic_loss": 208.07852172851562, "actor_loss": -1365.9329833984375, "actor_target_entropy": -3.0, "actor_entropy": 0.3596900701522827, "alpha_loss": -0.09933658689260483, "alpha_value": 0.3039939034238416, "duration": 1.5664639472961426, "info_normalized_performance_mean": 0.6433069109916687, "info_normalized_performance_final": 0.6904761791229248, "info_performance_mean": 0.6433069109916687, "info_performance_final": 0.6904761791229248, "step": 714000}
{"episode_reward": 1286.6137566137586, "episode": 7141.0, "batch_reward": 11.480576515197754, "critic_loss": 388.1795654296875, "actor_loss": -1461.7364501953125, "actor_target_entropy": -3.0, "actor_entropy": 0.1362430453300476, "alpha_loss": -0.027450479567050934, "alpha_value": 0.30899007100235887, "duration": 1.4411184787750244, "info_normalized_performance_mean": 0.5201561450958252, "info_normalized_performance_final": 0.5531250238418579, "info_performance_mean": 0.5201561450958252, "info_performance_final": 0.5531250238418579, "step": 714500}
{"episode_reward": 1040.3125, "episode": 7146.0, "batch_reward": 11.883771896362305, "critic_loss": 303.6914978027344, "actor_loss": -1467.2451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7283278703689575, "alpha_loss": -0.020487934350967407, "alpha_value": 0.3108043624531325, "duration": 1.5837650299072266, "info_normalized_performance_mean": 0.7578709125518799, "info_normalized_performance_final": 0.8324176073074341, "info_performance_mean": 0.7578709125518799, "info_performance_final": 0.8324176073074341, "step": 715000}
{"episode_reward": 1515.7417582417615, "episode": 7151.0, "batch_reward": 11.815692901611328, "critic_loss": 172.24050903320312, "actor_loss": -1476.83447265625, "actor_target_entropy": -3.0, "actor_entropy": 0.4197791814804077, "alpha_loss": 0.12471723556518555, "alpha_value": 0.31478326719864896, "duration": 1.580463171005249, "info_normalized_performance_mean": 0.8165571689605713, "info_normalized_performance_final": 0.8885714411735535, "info_performance_mean": 0.8165571689605713, "info_performance_final": 0.8885714411735535, "step": 715500}
{"episode_reward": 1633.114285714284, "episode": 7156.0, "batch_reward": 10.982199668884277, "critic_loss": 274.1290283203125, "actor_loss": -1441.4234619140625, "actor_target_entropy": -3.0, "actor_entropy": 0.3702518343925476, "alpha_loss": -0.0748959630727768, "alpha_value": 0.31806200263076545, "duration": 1.538433313369751, "info_normalized_performance_mean": 0.5564284920692444, "info_normalized_performance_final": 0.6236263513565063, "info_performance_mean": 0.5564284920692444, "info_performance_final": 0.6236263513565063, "step": 716000}
{"episode_reward": 1112.8571428571404, "episode": 7161.0, "batch_reward": 11.090015411376953, "critic_loss": 304.2542724609375, "actor_loss": -1462.94091796875, "actor_target_entropy": -3.0, "actor_entropy": 0.5050654411315918, "alpha_loss": -0.057737797498703, "alpha_value": 0.31810963579526264, "duration": 1.6132307052612305, "info_normalized_performance_mean": 0.636233389377594, "info_normalized_performance_final": 0.6850000023841858, "info_performance_mean": 0.636233389377594, "info_performance_final": 0.6850000023841858, "step": 716500}
{"episode_reward": 1272.4666666666687, "episode": 7166.0, "batch_reward": 11.732366561889648, "critic_loss": 582.746826171875, "actor_loss": -1471.812744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.4767668843269348, "alpha_loss": 0.10575567185878754, "alpha_value": 0.31718640607921694, "duration": 1.6127166748046875, "info_normalized_performance_mean": 0.5570833683013916, "info_normalized_performance_final": 0.621279776096344, "info_performance_mean": 0.5570833683013916, "info_performance_final": 0.621279776096344, "step": 717000}
{"episode_reward": 1114.166666666664, "episode": 7171.0, "batch_reward": 10.710795402526855, "critic_loss": 588.475830078125, "actor_loss": -1418.150390625, "actor_target_entropy": -3.0, "actor_entropy": 0.5116925239562988, "alpha_loss": -0.06917369365692139, "alpha_value": 0.31522090953897997, "duration": 1.5745501518249512, "info_normalized_performance_mean": 0.4953715205192566, "info_normalized_performance_final": 0.5548052191734314, "info_performance_mean": 0.4953715205192566, "info_performance_final": 0.5548052191734314, "step": 717500}
{"episode_reward": 990.742857142855, "episode": 7176.0, "batch_reward": 11.596031188964844, "critic_loss": 178.2036590576172, "actor_loss": -1447.6165771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.9123654365539551, "alpha_loss": 0.08716905862092972, "alpha_value": 0.31421195986928463, "duration": 1.3684282302856445, "info_normalized_performance_mean": 0.8289734125137329, "info_normalized_performance_final": 0.8928571343421936, "info_performance_mean": 0.8289734125137329, "info_performance_final": 0.8928571343421936, "step": 718000}
{"episode_reward": 1657.9464285714303, "episode": 7181.0, "batch_reward": 11.541264533996582, "critic_loss": 400.6007385253906, "actor_loss": -1460.8265380859375, "actor_target_entropy": -3.0, "actor_entropy": 0.7854615449905396, "alpha_loss": 0.041774649173021317, "alpha_value": 0.31325436078057883, "duration": 1.4431052207946777, "info_normalized_performance_mean": 0.6240774393081665, "info_normalized_performance_final": 0.6696428656578064, "info_performance_mean": 0.6240774393081665, "info_performance_final": 0.6696428656578064, "step": 718500}
{"episode_reward": 1248.1547619047606, "episode": 7186.0, "batch_reward": 11.782732009887695, "critic_loss": 151.6553955078125, "actor_loss": -1463.596435546875, "actor_target_entropy": -3.0, "actor_entropy": 0.5167612433433533, "alpha_loss": -0.047465670853853226, "alpha_value": 0.3125193099600929, "duration": 1.7210485935211182, "info_normalized_performance_mean": 0.42842018604278564, "info_normalized_performance_final": 0.4830729067325592, "info_performance_mean": 0.42842018604278564, "info_performance_final": 0.4830729067325592, "step": 719000}
{"episode_reward": 856.8402777777787, "episode": 7191.0, "batch_reward": 10.502540588378906, "critic_loss": 305.9083251953125, "actor_loss": -1445.224609375, "actor_target_entropy": -3.0, "actor_entropy": 0.5790879130363464, "alpha_loss": -0.11542633920907974, "alpha_value": 0.3137498163023725, "duration": 1.5653610229492188, "info_normalized_performance_mean": 0.2748778760433197, "info_normalized_performance_final": 0.2950226366519928, "info_performance_mean": 0.2748778760433197, "info_performance_final": 0.2950226366519928, "step": 719500}
{"episode_reward": 549.7556561085975, "episode": 7196.0, "batch_reward": 11.667083740234375, "critic_loss": 1166.58056640625, "actor_loss": -1430.615966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.107636570930481, "alpha_loss": 0.002304479479789734, "alpha_value": 0.3158174110121557, "step": 720000}
{"duration": 19.08109951019287, "info_normalized_performance_mean": 0.7576236128807068, "info_normalized_performance_final": 0.818823516368866, "info_performance_mean": 0.7576236128807068, "info_performance_final": 0.818823516368866, "step": 720000}
{"episode_reward": 1515.2470588235328, "episode": 7201.0, "batch_reward": 11.647462844848633, "critic_loss": 321.00244140625, "actor_loss": -1475.23486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8165915012359619, "alpha_loss": 0.060653481632471085, "alpha_value": 0.3187273251525604, "duration": 1.5400810241699219, "info_normalized_performance_mean": 0.6614530682563782, "info_normalized_performance_final": 0.703125, "info_performance_mean": 0.6614530682563782, "info_performance_final": 0.703125, "step": 720500}
{"episode_reward": 1322.90625, "episode": 7206.0, "batch_reward": 11.720809936523438, "critic_loss": 435.248779296875, "actor_loss": -1521.5810546875, "actor_target_entropy": -3.0, "actor_entropy": 0.5967341065406799, "alpha_loss": -0.2009047120809555, "alpha_value": 0.3223028221427562, "duration": 1.611513376235962, "info_normalized_performance_mean": 0.5427900552749634, "info_normalized_performance_final": 0.5825892686843872, "info_performance_mean": 0.5427900552749634, "info_performance_final": 0.5825892686843872, "step": 721000}
{"episode_reward": 1085.5803571428555, "episode": 7211.0, "batch_reward": 11.597128868103027, "critic_loss": 309.9238586425781, "actor_loss": -1421.9774169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8984913229942322, "alpha_loss": 0.02500729262828827, "alpha_value": 0.326122938597825, "duration": 1.4657843112945557, "info_normalized_performance_mean": 0.2280654013156891, "info_normalized_performance_final": 0.24575163424015045, "info_performance_mean": 0.2280654013156891, "info_performance_final": 0.24575163424015045, "step": 721500}
{"episode_reward": 456.13071895424787, "episode": 7216.0, "batch_reward": 11.51431655883789, "critic_loss": 747.3203125, "actor_loss": -1509.025146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.3962327241897583, "alpha_loss": -0.06966708600521088, "alpha_value": 0.32763242386330516, "duration": 1.6156821250915527, "info_normalized_performance_mean": 0.8316181898117065, "info_normalized_performance_final": 0.9409090876579285, "info_performance_mean": 0.8316181898117065, "info_performance_final": 0.9409090876579285, "step": 722000}
{"episode_reward": 1663.236363636363, "episode": 7221.0, "batch_reward": 11.081991195678711, "critic_loss": 314.7524719238281, "actor_loss": -1447.06494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8901137113571167, "alpha_loss": -0.014163091778755188, "alpha_value": 0.32928780692782017, "duration": 1.476438045501709, "info_normalized_performance_mean": 0.3692187964916229, "info_normalized_performance_final": 0.40535715222358704, "info_performance_mean": 0.3692187964916229, "info_performance_final": 0.40535715222358704, "step": 722500}
{"episode_reward": 738.4375000000002, "episode": 7226.0, "batch_reward": 11.150861740112305, "critic_loss": 512.71044921875, "actor_loss": -1442.697509765625, "actor_target_entropy": -3.0, "actor_entropy": 0.7163814306259155, "alpha_loss": -0.018899790942668915, "alpha_value": 0.3326572731258853, "duration": 1.434743881225586, "info_normalized_performance_mean": 0.01176562812179327, "info_normalized_performance_final": 0.012500000186264515, "info_performance_mean": 0.01176562812179327, "info_performance_final": 0.012500000186264515, "step": 723000}
{"episode_reward": 23.53125, "episode": 7231.0, "batch_reward": 11.743988037109375, "critic_loss": 338.85833740234375, "actor_loss": -1512.618896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.022142767906189, "alpha_loss": 0.09370073676109314, "alpha_value": 0.33641652254711685, "duration": 1.507906436920166, "info_normalized_performance_mean": 0.6583616137504578, "info_normalized_performance_final": 0.7147321701049805, "info_performance_mean": 0.6583616137504578, "info_performance_final": 0.7147321701049805, "step": 723500}
{"episode_reward": 1316.7232142857156, "episode": 7236.0, "batch_reward": 11.168495178222656, "critic_loss": 516.8587646484375, "actor_loss": -1500.7918701171875, "actor_target_entropy": -3.0, "actor_entropy": 0.81135094165802, "alpha_loss": -0.11572152376174927, "alpha_value": 0.3356587559085046, "duration": 1.5149462223052979, "info_normalized_performance_mean": 0.5161666870117188, "info_normalized_performance_final": 0.5622222423553467, "info_performance_mean": 0.5161666870117188, "info_performance_final": 0.5622222423553467, "step": 724000}
{"episode_reward": 1032.3333333333323, "episode": 7241.0, "batch_reward": 11.307312965393066, "critic_loss": 1136.891357421875, "actor_loss": -1510.975341796875, "actor_target_entropy": -3.0, "actor_entropy": 0.39049267768859863, "alpha_loss": -0.11340518295764923, "alpha_value": 0.33705910580200155, "duration": 1.5639963150024414, "info_normalized_performance_mean": 0.596352219581604, "info_normalized_performance_final": 0.6691706776618958, "info_performance_mean": 0.596352219581604, "info_performance_final": 0.6691706776618958, "step": 724500}
{"episode_reward": 1192.7043269230778, "episode": 7246.0, "batch_reward": 10.58289909362793, "critic_loss": 354.2275390625, "actor_loss": -1464.5869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.1318352222442627, "alpha_loss": -0.023219019174575806, "alpha_value": 0.3358838899347398, "duration": 1.5272016525268555, "info_normalized_performance_mean": 0.4737405478954315, "info_normalized_performance_final": 0.5272075533866882, "info_performance_mean": 0.4737405478954315, "info_performance_final": 0.5272075533866882, "step": 725000}
{"episode_reward": 947.4812642554589, "episode": 7251.0, "batch_reward": 10.871371269226074, "critic_loss": 219.05755615234375, "actor_loss": -1424.0740966796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7455157041549683, "alpha_loss": 0.17098504304885864, "alpha_value": 0.3336419196409801, "duration": 1.5342652797698975, "info_normalized_performance_mean": 0.7591177225112915, "info_normalized_performance_final": 0.8196078538894653, "info_performance_mean": 0.7591177225112915, "info_performance_final": 0.8196078538894653, "step": 725500}
{"episode_reward": 1518.2352941176493, "episode": 7256.0, "batch_reward": 11.944113731384277, "critic_loss": 283.594482421875, "actor_loss": -1486.32568359375, "actor_target_entropy": -3.0, "actor_entropy": 0.45087701082229614, "alpha_loss": 0.03500683978199959, "alpha_value": 0.33176981825622165, "duration": 1.5284397602081299, "info_normalized_performance_mean": 0.8153346180915833, "info_normalized_performance_final": 0.8883928656578064, "info_performance_mean": 0.8153346180915833, "info_performance_final": 0.8883928656578064, "step": 726000}
{"episode_reward": 1630.6696428571413, "episode": 7261.0, "batch_reward": 12.369545936584473, "critic_loss": 447.44366455078125, "actor_loss": -1524.2371826171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6192892789840698, "alpha_loss": 0.04714483767747879, "alpha_value": 0.32939701282392986, "duration": 1.6269481182098389, "info_normalized_performance_mean": 0.6982175707817078, "info_normalized_performance_final": 0.7453703880310059, "info_performance_mean": 0.6982175707817078, "info_performance_final": 0.7453703880310059, "step": 726500}
{"episode_reward": 1396.435185185184, "episode": 7266.0, "batch_reward": 10.988365173339844, "critic_loss": 526.3954467773438, "actor_loss": -1478.287353515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9183163642883301, "alpha_loss": 0.10609970986843109, "alpha_value": 0.3302573345004959, "duration": 1.6089730262756348, "info_normalized_performance_mean": 0.5991024971008301, "info_normalized_performance_final": 0.6600189805030823, "info_performance_mean": 0.5991024971008301, "info_performance_final": 0.6600189805030823, "step": 727000}
{"episode_reward": 1198.2051282051268, "episode": 7271.0, "batch_reward": 11.540472030639648, "critic_loss": 324.9051818847656, "actor_loss": -1500.253173828125, "actor_target_entropy": -3.0, "actor_entropy": 0.6272227168083191, "alpha_loss": 0.13536323606967926, "alpha_value": 0.329320030868303, "duration": 1.5325567722320557, "info_normalized_performance_mean": 0.6763529777526855, "info_normalized_performance_final": 0.7277311086654663, "info_performance_mean": 0.6763529777526855, "info_performance_final": 0.7277311086654663, "step": 727500}
{"episode_reward": 1352.7058823529437, "episode": 7276.0, "batch_reward": 10.921589851379395, "critic_loss": 385.77423095703125, "actor_loss": -1462.9598388671875, "actor_target_entropy": -3.0, "actor_entropy": 0.6225919723510742, "alpha_loss": -0.18045847117900848, "alpha_value": 0.3290341306308065, "duration": 1.5318915843963623, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 728000}
{"episode_reward": 0.0, "episode": 7281.0, "batch_reward": 11.531834602355957, "critic_loss": 499.61724853515625, "actor_loss": -1497.61328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8933824300765991, "alpha_loss": 0.06295914202928543, "alpha_value": 0.3288612564938603, "duration": 1.5236101150512695, "info_normalized_performance_mean": 0.8093575835227966, "info_normalized_performance_final": 0.8732638955116272, "info_performance_mean": 0.8093575835227966, "info_performance_final": 0.8732638955116272, "step": 728500}
{"episode_reward": 1618.7152777777808, "episode": 7286.0, "batch_reward": 11.119732856750488, "critic_loss": 208.04974365234375, "actor_loss": -1491.29296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7191094160079956, "alpha_loss": 0.11380527913570404, "alpha_value": 0.32930146188269627, "duration": 1.5082836151123047, "info_normalized_performance_mean": 0.9024062156677246, "info_normalized_performance_final": 0.9593750238418579, "info_performance_mean": 0.9024062156677246, "info_performance_final": 0.9593750238418579, "step": 729000}
{"episode_reward": 1804.8125, "episode": 7291.0, "batch_reward": 10.658968925476074, "critic_loss": 448.1748046875, "actor_loss": -1473.456787109375, "actor_target_entropy": -3.0, "actor_entropy": 0.893832802772522, "alpha_loss": 0.027147557586431503, "alpha_value": 0.3280545430459071, "duration": 1.4832720756530762, "info_normalized_performance_mean": 0.6135917901992798, "info_normalized_performance_final": 0.6627551317214966, "info_performance_mean": 0.6135917901992798, "info_performance_final": 0.6627551317214966, "step": 729500}
{"episode_reward": 1227.1836734693907, "episode": 7296.0, "batch_reward": 11.711915969848633, "critic_loss": 210.87118530273438, "actor_loss": -1540.811279296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8669050931930542, "alpha_loss": 0.0492992177605629, "alpha_value": 0.3278749091242955, "step": 730000}
{"duration": 18.892704010009766, "info_normalized_performance_mean": 0.7807562351226807, "info_normalized_performance_final": 0.8395061492919922, "info_performance_mean": 0.7807562351226807, "info_performance_final": 0.8395061492919922, "step": 730000}
{"episode_reward": 1561.512345679009, "episode": 7301.0, "batch_reward": 11.800373077392578, "critic_loss": 308.1796875, "actor_loss": -1493.79443359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9716646075248718, "alpha_loss": 0.31882160902023315, "alpha_value": 0.32742243513015884, "duration": 1.5195937156677246, "info_normalized_performance_mean": 0.8458037376403809, "info_normalized_performance_final": 0.9241071343421936, "info_performance_mean": 0.8458037376403809, "info_performance_final": 0.9241071343421936, "step": 730500}
{"episode_reward": 1691.6071428571445, "episode": 7306.0, "batch_reward": 10.299894332885742, "critic_loss": 592.1256103515625, "actor_loss": -1429.042724609375, "actor_target_entropy": -3.0, "actor_entropy": 0.6541051864624023, "alpha_loss": -0.04949191212654114, "alpha_value": 0.32659213838769474, "duration": 1.5058908462524414, "info_normalized_performance_mean": 0.7460514903068542, "info_normalized_performance_final": 0.8134920597076416, "info_performance_mean": 0.7460514903068542, "info_performance_final": 0.8134920597076416, "step": 731000}
{"episode_reward": 1492.1031746031745, "episode": 7311.0, "batch_reward": 11.786029815673828, "critic_loss": 371.3074035644531, "actor_loss": -1546.2242431640625, "actor_target_entropy": -3.0, "actor_entropy": 0.9419388771057129, "alpha_loss": 0.0366024523973465, "alpha_value": 0.3265510957856874, "duration": 1.4217936992645264, "info_normalized_performance_mean": 0.3318452835083008, "info_normalized_performance_final": 0.3526785671710968, "info_performance_mean": 0.3318452835083008, "info_performance_final": 0.3526785671710968, "step": 731500}
{"episode_reward": 663.6904761904769, "episode": 7316.0, "batch_reward": 10.862884521484375, "critic_loss": 670.1348266601562, "actor_loss": -1484.0023193359375, "actor_target_entropy": -3.0, "actor_entropy": 0.6595103144645691, "alpha_loss": -0.11271242052316666, "alpha_value": 0.32659782573528284, "duration": 1.628349781036377, "info_normalized_performance_mean": 0.6375500559806824, "info_normalized_performance_final": 0.6833333373069763, "info_performance_mean": 0.6375500559806824, "info_performance_final": 0.6833333373069763, "step": 732000}
{"episode_reward": 1275.1000000000004, "episode": 7321.0, "batch_reward": 11.383386611938477, "critic_loss": 347.66827392578125, "actor_loss": -1501.6927490234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5880462527275085, "alpha_loss": 0.07228733599185944, "alpha_value": 0.32550047415270955, "duration": 1.6012141704559326, "info_normalized_performance_mean": 0.13220959901809692, "info_normalized_performance_final": 0.14634615182876587, "info_performance_mean": 0.13220959901809692, "info_performance_final": 0.14634615182876587, "step": 732500}
{"episode_reward": 264.4192307692312, "episode": 7326.0, "batch_reward": 11.663713455200195, "critic_loss": 163.63230895996094, "actor_loss": -1502.5634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9625399708747864, "alpha_loss": 0.24017995595932007, "alpha_value": 0.3235627627882216, "duration": 1.4481236934661865, "info_normalized_performance_mean": 0.515045702457428, "info_normalized_performance_final": 0.5686812996864319, "info_performance_mean": 0.515045702457428, "info_performance_final": 0.5686812996864319, "step": 733000}
{"episode_reward": 1030.0915750915763, "episode": 7331.0, "batch_reward": 10.969871520996094, "critic_loss": 287.586181640625, "actor_loss": -1499.584716796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7502809762954712, "alpha_loss": 0.015286512672901154, "alpha_value": 0.32201794050594346, "duration": 1.6041321754455566, "info_normalized_performance_mean": 0.8083235025405884, "info_normalized_performance_final": 0.9039215445518494, "info_performance_mean": 0.8083235025405884, "info_performance_final": 0.9039215445518494, "step": 733500}
{"episode_reward": 1616.6470588235281, "episode": 7336.0, "batch_reward": 11.349425315856934, "critic_loss": 348.7551574707031, "actor_loss": -1521.31982421875, "actor_target_entropy": -3.0, "actor_entropy": 0.7268999814987183, "alpha_loss": 0.015115843154489994, "alpha_value": 0.32076636331464004, "duration": 1.4711718559265137, "info_normalized_performance_mean": 0.6930229067802429, "info_normalized_performance_final": 0.7417091727256775, "info_performance_mean": 0.6930229067802429, "info_performance_final": 0.7417091727256775, "step": 734000}
{"episode_reward": 1386.0459183673477, "episode": 7341.0, "batch_reward": 10.836037635803223, "critic_loss": 337.9381408691406, "actor_loss": -1444.597900390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8407143354415894, "alpha_loss": 0.06174435466527939, "alpha_value": 0.3221395507561927, "duration": 1.5671226978302002, "info_normalized_performance_mean": 0.6022005081176758, "info_normalized_performance_final": 0.6595051884651184, "info_performance_mean": 0.6022005081176758, "info_performance_final": 0.6595051884651184, "step": 734500}
{"episode_reward": 1204.4010416666665, "episode": 7346.0, "batch_reward": 10.879048347473145, "critic_loss": 385.7022705078125, "actor_loss": -1457.8087158203125, "actor_target_entropy": -3.0, "actor_entropy": 0.8013466000556946, "alpha_loss": -0.026906615123152733, "alpha_value": 0.3220521641575838, "duration": 1.8110787868499756, "info_normalized_performance_mean": 0.25209730863571167, "info_normalized_performance_final": 0.28836292028427124, "info_performance_mean": 0.25209730863571167, "info_performance_final": 0.28836292028427124, "step": 735000}
{"episode_reward": 504.19460880999276, "episode": 7351.0, "batch_reward": 10.8785982131958, "critic_loss": 314.63458251953125, "actor_loss": -1428.91943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.6829243302345276, "alpha_loss": 0.04683111980557442, "alpha_value": 0.3210289832380538, "duration": 1.6149563789367676, "info_normalized_performance_mean": 0.21208679676055908, "info_normalized_performance_final": 0.23915289342403412, "info_performance_mean": 0.21208679676055908, "info_performance_final": 0.23915289342403412, "step": 735500}
{"episode_reward": 424.17355371900857, "episode": 7356.0, "batch_reward": 11.878494262695312, "critic_loss": 316.1978759765625, "actor_loss": -1531.59912109375, "actor_target_entropy": -3.0, "actor_entropy": 0.8400561809539795, "alpha_loss": 0.0817471519112587, "alpha_value": 0.3203128168032636, "duration": 1.5503780841827393, "info_normalized_performance_mean": 0.8465626239776611, "info_normalized_performance_final": 0.9303977489471436, "info_performance_mean": 0.8465626239776611, "info_performance_final": 0.9303977489471436, "step": 736000}
{"episode_reward": 1693.1249999999977, "episode": 7361.0, "batch_reward": 11.438888549804688, "critic_loss": 348.02667236328125, "actor_loss": -1460.4493408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.7789914608001709, "alpha_loss": 0.05537428334355354, "alpha_value": 0.3199539974306843, "duration": 1.5347940921783447, "info_normalized_performance_mean": 0.31883639097213745, "info_normalized_performance_final": 0.35480520129203796, "info_performance_mean": 0.31883639097213745, "info_performance_final": 0.35480520129203796, "step": 736500}
{"episode_reward": 637.6727272727264, "episode": 7366.0, "batch_reward": 11.466536521911621, "critic_loss": 485.8059997558594, "actor_loss": -1500.2774658203125, "actor_target_entropy": -3.0, "actor_entropy": 0.4430527985095978, "alpha_loss": 0.04377741366624832, "alpha_value": 0.3228484935792437, "duration": 1.4905824661254883, "info_normalized_performance_mean": 0.7067857384681702, "info_normalized_performance_final": 0.7847222089767456, "info_performance_mean": 0.7067857384681702, "info_performance_final": 0.7847222089767456, "step": 737000}
{"episode_reward": 1413.5714285714268, "episode": 7371.0, "batch_reward": 11.895620346069336, "critic_loss": 708.225830078125, "actor_loss": -1525.8314208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9035720825195312, "alpha_loss": 0.07691505551338196, "alpha_value": 0.3276924921192213, "duration": 1.4097778797149658, "info_normalized_performance_mean": 0.29558035731315613, "info_normalized_performance_final": 0.3125, "info_performance_mean": 0.29558035731315613, "info_performance_final": 0.3125, "step": 737500}
{"episode_reward": 591.1607142857142, "episode": 7376.0, "batch_reward": 11.455756187438965, "critic_loss": 577.4302978515625, "actor_loss": -1510.027587890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9866557121276855, "alpha_loss": -0.020475175231695175, "alpha_value": 0.3314652376147168, "duration": 1.5543758869171143, "info_normalized_performance_mean": 0.613466739654541, "info_normalized_performance_final": 0.6633333563804626, "info_performance_mean": 0.613466739654541, "info_performance_final": 0.6633333563804626, "step": 738000}
{"episode_reward": 1226.9333333333323, "episode": 7381.0, "batch_reward": 11.12253475189209, "critic_loss": 444.416259765625, "actor_loss": -1469.86669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.800280749797821, "alpha_loss": -0.19843003153800964, "alpha_value": 0.33946915263367705, "duration": 1.5149047374725342, "info_normalized_performance_mean": 0.7538278102874756, "info_normalized_performance_final": 0.8177655935287476, "info_performance_mean": 0.7538278102874756, "info_performance_final": 0.8177655935287476, "step": 738500}
{"episode_reward": 1507.6556776556777, "episode": 7386.0, "batch_reward": 11.048039436340332, "critic_loss": 313.0751037597656, "actor_loss": -1493.1312255859375, "actor_target_entropy": -3.0, "actor_entropy": 0.8143028020858765, "alpha_loss": -0.2038092315196991, "alpha_value": 0.34808800146479346, "duration": 1.4860241413116455, "info_normalized_performance_mean": 0.45278820395469666, "info_normalized_performance_final": 0.4947240352630615, "info_performance_mean": 0.45278820395469666, "info_performance_final": 0.4947240352630615, "step": 739000}
{"episode_reward": 905.5762987013003, "episode": 7391.0, "batch_reward": 11.328325271606445, "critic_loss": 526.5484619140625, "actor_loss": -1529.202880859375, "actor_target_entropy": -3.0, "actor_entropy": 0.5404327511787415, "alpha_loss": -0.3446742296218872, "alpha_value": 0.35930157003189933, "duration": 1.5802521705627441, "info_normalized_performance_mean": 0.740456223487854, "info_normalized_performance_final": 0.7916666865348816, "info_performance_mean": 0.740456223487854, "info_performance_final": 0.7916666865348816, "step": 739500}
{"episode_reward": 1480.9126984126972, "episode": 7396.0, "batch_reward": 12.362308502197266, "critic_loss": 263.9697570800781, "actor_loss": -1600.885986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.953188955783844, "alpha_loss": -0.22219662368297577, "alpha_value": 0.3699073759748431, "step": 740000}
{"duration": 18.590477466583252, "info_normalized_performance_mean": 0.6763351559638977, "info_normalized_performance_final": 0.7346938848495483, "info_performance_mean": 0.6763351559638977, "info_performance_final": 0.7346938848495483, "step": 740000}
{"episode_reward": 1352.6700680272113, "episode": 7401.0, "batch_reward": 11.967597961425781, "critic_loss": 285.3120422363281, "actor_loss": -1588.222900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0746694803237915, "alpha_loss": -0.04524175077676773, "alpha_value": 0.37784584395006693, "duration": 1.5694303512573242, "info_normalized_performance_mean": 0.8194229006767273, "info_normalized_performance_final": 0.8846153616905212, "info_performance_mean": 0.8194229006767273, "info_performance_final": 0.8846153616905212, "step": 740500}
{"episode_reward": 1638.8461538461524, "episode": 7406.0, "batch_reward": 11.355802536010742, "critic_loss": 774.87841796875, "actor_loss": -1546.3109130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.5978966951370239, "alpha_loss": -0.3505252003669739, "alpha_value": 0.38602748919383, "duration": 1.4550869464874268, "info_normalized_performance_mean": 0.6014881134033203, "info_normalized_performance_final": 0.6520562767982483, "info_performance_mean": 0.6014881134033203, "info_performance_final": 0.6520562767982483, "step": 741000}
{"episode_reward": 1202.9761904761897, "episode": 7411.0, "batch_reward": 11.07815933227539, "critic_loss": 371.3529052734375, "actor_loss": -1572.6151123046875, "actor_target_entropy": -3.0, "actor_entropy": 0.7851124405860901, "alpha_loss": -0.1273210495710373, "alpha_value": 0.3961813594630737, "duration": 1.5873692035675049, "info_normalized_performance_mean": 0.790255606174469, "info_normalized_performance_final": 0.8577777743339539, "info_performance_mean": 0.790255606174469, "info_performance_final": 0.8577777743339539, "step": 741500}
{"episode_reward": 1580.5111111111119, "episode": 7416.0, "batch_reward": 10.747278213500977, "critic_loss": 586.8795776367188, "actor_loss": -1528.1998291015625, "actor_target_entropy": -3.0, "actor_entropy": 0.726731538772583, "alpha_loss": -0.019817445427179337, "alpha_value": 0.40306219564951346, "duration": 1.545250654220581, "info_normalized_performance_mean": 0.5529915690422058, "info_normalized_performance_final": 0.6100260615348816, "info_performance_mean": 0.5529915690422058, "info_performance_final": 0.6100260615348816, "step": 742000}
{"episode_reward": 1105.9830729166674, "episode": 7421.0, "batch_reward": 11.18375015258789, "critic_loss": 1551.04833984375, "actor_loss": -1542.19873046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9980050325393677, "alpha_loss": -0.31105268001556396, "alpha_value": 0.40812458455505873, "duration": 1.4669780731201172, "info_normalized_performance_mean": 0.7157070636749268, "info_normalized_performance_final": 0.7676767706871033, "info_performance_mean": 0.7157070636749268, "info_performance_final": 0.7676767706871033, "step": 742500}
{"episode_reward": 1431.4141414141402, "episode": 7426.0, "batch_reward": 11.618560791015625, "critic_loss": 349.94427490234375, "actor_loss": -1567.269775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1142804622650146, "alpha_loss": -0.03279680013656616, "alpha_value": 0.41393899854847854, "duration": 1.581357717514038, "info_normalized_performance_mean": 0.8269702196121216, "info_normalized_performance_final": 0.9110000133514404, "info_performance_mean": 0.8269702196121216, "info_performance_final": 0.9110000133514404, "step": 743000}
{"episode_reward": 1653.9400000000019, "episode": 7431.0, "batch_reward": 11.972496032714844, "critic_loss": 448.9873046875, "actor_loss": -1603.870361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0785564184188843, "alpha_loss": 0.15936806797981262, "alpha_value": 0.41787140591203464, "duration": 1.4729328155517578, "info_normalized_performance_mean": 0.6541427373886108, "info_normalized_performance_final": 0.704081654548645, "info_performance_mean": 0.6541427373886108, "info_performance_final": 0.704081654548645, "step": 743500}
{"episode_reward": 1308.2857142857129, "episode": 7436.0, "batch_reward": 11.072766304016113, "critic_loss": 687.2646484375, "actor_loss": -1571.749267578125, "actor_target_entropy": -3.0, "actor_entropy": 0.9183196425437927, "alpha_loss": -0.17831915616989136, "alpha_value": 0.42293564294358515, "duration": 1.4847991466522217, "info_normalized_performance_mean": 0.9172024726867676, "info_normalized_performance_final": 0.9910714030265808, "info_performance_mean": 0.9172024726867676, "info_performance_final": 0.9910714030265808, "step": 744000}
{"episode_reward": 1834.4047619047653, "episode": 7441.0, "batch_reward": 11.891242980957031, "critic_loss": 467.9029235839844, "actor_loss": -1652.153076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2500889301300049, "alpha_loss": 0.026625731959939003, "alpha_value": 0.42845862116035555, "duration": 1.5649631023406982, "info_normalized_performance_mean": 0.7303123474121094, "info_normalized_performance_final": 0.801682710647583, "info_performance_mean": 0.7303123474121094, "info_performance_final": 0.801682710647583, "step": 744500}
{"episode_reward": 1460.6249999999982, "episode": 7446.0, "batch_reward": 12.266870498657227, "critic_loss": 468.6069641113281, "actor_loss": -1649.219482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.2365152835845947, "alpha_loss": -0.21259154379367828, "alpha_value": 0.4369587083126397, "duration": 1.4864282608032227, "info_normalized_performance_mean": 0.6373562812805176, "info_normalized_performance_final": 0.6846011281013489, "info_performance_mean": 0.6373562812805176, "info_performance_final": 0.6846011281013489, "step": 745000}
{"episode_reward": 1274.7124304267134, "episode": 7451.0, "batch_reward": 10.994789123535156, "critic_loss": 675.2454833984375, "actor_loss": -1604.727294921875, "actor_target_entropy": -3.0, "actor_entropy": 0.941154956817627, "alpha_loss": -0.0851982980966568, "alpha_value": 0.4495273257463042, "duration": 1.5178842544555664, "info_normalized_performance_mean": 0.43751171231269836, "info_normalized_performance_final": 0.46759259700775146, "info_performance_mean": 0.43751171231269836, "info_performance_final": 0.46759259700775146, "step": 745500}
{"episode_reward": 875.0231481481478, "episode": 7456.0, "batch_reward": 11.675966262817383, "critic_loss": 667.581298828125, "actor_loss": -1609.631591796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0596668720245361, "alpha_loss": -0.29042327404022217, "alpha_value": 0.46240692194070504, "duration": 1.5821363925933838, "info_normalized_performance_mean": 0.8012998700141907, "info_normalized_performance_final": 0.8812500238418579, "info_performance_mean": 0.8012998700141907, "info_performance_final": 0.8812500238418579, "step": 746000}
{"episode_reward": 1602.6000000000001, "episode": 7461.0, "batch_reward": 11.168329238891602, "critic_loss": 601.6884765625, "actor_loss": -1623.841064453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0059645175933838, "alpha_loss": -0.21822497248649597, "alpha_value": 0.4752714945118002, "duration": 1.453089952468872, "info_normalized_performance_mean": 0.30000001192092896, "info_normalized_performance_final": 0.3218750059604645, "info_performance_mean": 0.30000001192092896, "info_performance_final": 0.3218750059604645, "step": 746500}
{"episode_reward": 600.0, "episode": 7466.0, "batch_reward": 11.171581268310547, "critic_loss": 882.9722900390625, "actor_loss": -1610.91943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.990037739276886, "alpha_loss": -0.4628048539161682, "alpha_value": 0.49029041577775073, "duration": 1.5991368293762207, "info_normalized_performance_mean": 0.8396666646003723, "info_normalized_performance_final": 0.9392156600952148, "info_performance_mean": 0.8396666646003723, "info_performance_final": 0.9392156600952148, "step": 747000}
{"episode_reward": 1679.3333333333314, "episode": 7471.0, "batch_reward": 11.785211563110352, "critic_loss": 369.8880920410156, "actor_loss": -1657.532470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2129011154174805, "alpha_loss": -0.4557190537452698, "alpha_value": 0.5048913404460164, "duration": 1.6291234493255615, "info_normalized_performance_mean": 0.766203761100769, "info_normalized_performance_final": 0.8225308656692505, "info_performance_mean": 0.766203761100769, "info_performance_final": 0.8225308656692505, "step": 747500}
{"episode_reward": 1532.4074074074051, "episode": 7476.0, "batch_reward": 10.731263160705566, "critic_loss": 430.0527038574219, "actor_loss": -1591.8525390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0745854377746582, "alpha_loss": -0.670950174331665, "alpha_value": 0.5184186286461911, "duration": 1.553981065750122, "info_normalized_performance_mean": 0.8013212084770203, "info_normalized_performance_final": 0.8792613744735718, "info_performance_mean": 0.8013212084770203, "info_performance_final": 0.8792613744735718, "step": 748000}
{"episode_reward": 1602.6420454545441, "episode": 7481.0, "batch_reward": 11.612768173217773, "critic_loss": 730.4942016601562, "actor_loss": -1694.033935546875, "actor_target_entropy": -3.0, "actor_entropy": 1.1224956512451172, "alpha_loss": -0.5187671184539795, "alpha_value": 0.532926809134167, "duration": 1.4975202083587646, "info_normalized_performance_mean": 0.8594048023223877, "info_normalized_performance_final": 0.925595223903656, "info_performance_mean": 0.8594048023223877, "info_performance_final": 0.925595223903656, "step": 748500}
{"episode_reward": 1718.8095238095273, "episode": 7486.0, "batch_reward": 11.336849212646484, "critic_loss": 1083.3995361328125, "actor_loss": -1656.273193359375, "actor_target_entropy": -3.0, "actor_entropy": 0.964363694190979, "alpha_loss": -0.39373040199279785, "alpha_value": 0.5464287605697592, "duration": 1.5265822410583496, "info_normalized_performance_mean": 0.8448436856269836, "info_normalized_performance_final": 0.9088541865348816, "info_performance_mean": 0.8448436856269836, "info_performance_final": 0.9088541865348816, "step": 749000}
{"episode_reward": 1689.6874999999982, "episode": 7491.0, "batch_reward": 12.566131591796875, "critic_loss": 466.3092346191406, "actor_loss": -1754.87255859375, "actor_target_entropy": -3.0, "actor_entropy": 1.358093500137329, "alpha_loss": -0.21329867839813232, "alpha_value": 0.5591117161697433, "duration": 1.6129019260406494, "info_normalized_performance_mean": 0.5717669725418091, "info_normalized_performance_final": 0.6126543283462524, "info_performance_mean": 0.5717669725418091, "info_performance_final": 0.6126543283462524, "step": 749500}
{"episode_reward": 1143.533950617285, "episode": 7496.0, "batch_reward": 11.454948425292969, "critic_loss": 342.9704284667969, "actor_loss": -1698.916748046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5696277618408203, "alpha_loss": -0.20932716131210327, "alpha_value": 0.5681621869591548, "step": 750000}
{"duration": 18.754454135894775, "info_normalized_performance_mean": 0.7338749170303345, "info_normalized_performance_final": 0.815833330154419, "info_performance_mean": 0.7338749170303345, "info_performance_final": 0.815833330154419, "step": 750000}
{"episode_reward": 1467.75, "episode": 7501.0, "batch_reward": 11.85073184967041, "critic_loss": 650.391845703125, "actor_loss": -1718.569580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4400050640106201, "alpha_loss": 0.008304653689265251, "alpha_value": 0.5724671713236245, "duration": 1.5472264289855957, "info_normalized_performance_mean": 0.6753646731376648, "info_normalized_performance_final": 0.7211764454841614, "info_performance_mean": 0.6753646731376648, "info_performance_final": 0.7211764454841614, "step": 750500}
{"episode_reward": 1350.7294117647061, "episode": 7506.0, "batch_reward": 12.50015640258789, "critic_loss": 775.7413330078125, "actor_loss": -1790.71875, "actor_target_entropy": -3.0, "actor_entropy": 1.1570725440979004, "alpha_loss": -0.33080193400382996, "alpha_value": 0.576492483303601, "duration": 1.5779907703399658, "info_normalized_performance_mean": 0.5075922608375549, "info_normalized_performance_final": 0.5664935111999512, "info_performance_mean": 0.5075922608375549, "info_performance_final": 0.5664935111999512, "step": 751000}
{"episode_reward": 1015.184415584418, "episode": 7511.0, "batch_reward": 12.032615661621094, "critic_loss": 290.43438720703125, "actor_loss": -1822.954345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.479776382446289, "alpha_loss": 0.24643711745738983, "alpha_value": 0.5845365217724813, "duration": 1.5826728343963623, "info_normalized_performance_mean": 0.5759423971176147, "info_normalized_performance_final": 0.6150793433189392, "info_performance_mean": 0.5759423971176147, "info_performance_final": 0.6150793433189392, "step": 751500}
{"episode_reward": 1151.8849206349214, "episode": 7516.0, "batch_reward": 10.935051918029785, "critic_loss": 758.0333862304688, "actor_loss": -1734.835205078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4153395891189575, "alpha_loss": 0.008676007390022278, "alpha_value": 0.5851906350101972, "duration": 1.7263379096984863, "info_normalized_performance_mean": 0.23397104442119598, "info_normalized_performance_final": 0.2862590253353119, "info_performance_mean": 0.23397104442119598, "info_performance_final": 0.2862590253353119, "step": 752000}
{"episode_reward": 467.94214332675784, "episode": 7521.0, "batch_reward": 11.113873481750488, "critic_loss": 448.4385681152344, "actor_loss": -1730.675537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.5446255207061768, "alpha_loss": 0.032856959849596024, "alpha_value": 0.5848777560899712, "duration": 1.4700360298156738, "info_normalized_performance_mean": 0.6618593335151672, "info_normalized_performance_final": 0.7125850319862366, "info_performance_mean": 0.6618593335151672, "info_performance_final": 0.7125850319862366, "step": 752500}
{"episode_reward": 1323.7188208616749, "episode": 7526.0, "batch_reward": 12.17093563079834, "critic_loss": 239.95077514648438, "actor_loss": -1762.533447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3702949285507202, "alpha_loss": 0.21826079487800598, "alpha_value": 0.5823468094034484, "duration": 1.5530266761779785, "info_normalized_performance_mean": 0.4185101389884949, "info_normalized_performance_final": 0.46043771505355835, "info_performance_mean": 0.4185101389884949, "info_performance_final": 0.46043771505355835, "step": 753000}
{"episode_reward": 837.0202020202005, "episode": 7531.0, "batch_reward": 11.807999610900879, "critic_loss": 576.9334716796875, "actor_loss": -1799.608642578125, "actor_target_entropy": -3.0, "actor_entropy": 1.270429015159607, "alpha_loss": 0.07588925957679749, "alpha_value": 0.5811600345047243, "duration": 1.513143539428711, "info_normalized_performance_mean": 0.8327734470367432, "info_normalized_performance_final": 0.89453125, "info_performance_mean": 0.8327734470367432, "info_performance_final": 0.89453125, "step": 753500}
{"episode_reward": 1665.546875, "episode": 7536.0, "batch_reward": 11.991308212280273, "critic_loss": 450.04693603515625, "actor_loss": -1801.73779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3144655227661133, "alpha_loss": 0.006667666137218475, "alpha_value": 0.5791796333688463, "duration": 1.51389741897583, "info_normalized_performance_mean": 0.6200687885284424, "info_normalized_performance_final": 0.682692289352417, "info_performance_mean": 0.6200687885284424, "info_performance_final": 0.682692289352417, "step": 754000}
{"episode_reward": 1240.1373626373643, "episode": 7541.0, "batch_reward": 12.358377456665039, "critic_loss": 347.1575622558594, "actor_loss": -1837.5438232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.4383049011230469, "alpha_loss": 0.17899443209171295, "alpha_value": 0.5758193940630792, "duration": 1.4592981338500977, "info_normalized_performance_mean": 0.7060626149177551, "info_normalized_performance_final": 0.7593749761581421, "info_performance_mean": 0.7060626149177551, "info_performance_final": 0.7593749761581421, "step": 754500}
{"episode_reward": 1412.125, "episode": 7546.0, "batch_reward": 12.018173217773438, "critic_loss": 131.79771423339844, "actor_loss": -1781.28173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.2110865116119385, "alpha_loss": 0.1005384624004364, "alpha_value": 0.5675860263059059, "duration": 1.7654221057891846, "info_normalized_performance_mean": 0.5206798315048218, "info_normalized_performance_final": 0.5912126302719116, "info_performance_mean": 0.5206798315048218, "info_performance_final": 0.5912126302719116, "step": 755000}
{"episode_reward": 1041.3595085470106, "episode": 7551.0, "batch_reward": 11.624040603637695, "critic_loss": 242.85198974609375, "actor_loss": -1792.1658935546875, "actor_target_entropy": -3.0, "actor_entropy": 1.2359105348587036, "alpha_loss": 0.113917276263237, "alpha_value": 0.5633723708251399, "duration": 1.415494680404663, "info_normalized_performance_mean": 0.6263986229896545, "info_normalized_performance_final": 0.6785714030265808, "info_performance_mean": 0.6263986229896545, "info_performance_final": 0.6785714030265808, "step": 755500}
{"episode_reward": 1252.79761904762, "episode": 7556.0, "batch_reward": 12.372087478637695, "critic_loss": 531.2908935546875, "actor_loss": -1827.9798583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.048416018486023, "alpha_loss": 0.08608084917068481, "alpha_value": 0.5583991263181302, "duration": 1.5614125728607178, "info_normalized_performance_mean": 0.34230902791023254, "info_normalized_performance_final": 0.38415583968162537, "info_performance_mean": 0.34230902791023254, "info_performance_final": 0.38415583968162537, "step": 756000}
{"episode_reward": 684.6181818181826, "episode": 7561.0, "batch_reward": 12.19114875793457, "critic_loss": 275.82550048828125, "actor_loss": -1817.83447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.455413818359375, "alpha_loss": 0.07110846787691116, "alpha_value": 0.5542850350204626, "duration": 1.5893819332122803, "info_normalized_performance_mean": 0.34475821256637573, "info_normalized_performance_final": 0.385934054851532, "info_performance_mean": 0.34475821256637573, "info_performance_final": 0.385934054851532, "step": 756500}
{"episode_reward": 689.5164835164835, "episode": 7566.0, "batch_reward": 11.310287475585938, "critic_loss": 418.2275085449219, "actor_loss": -1768.96630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.4918893575668335, "alpha_loss": 0.21811288595199585, "alpha_value": 0.5524064964527159, "duration": 1.5172889232635498, "info_normalized_performance_mean": 0.8174405097961426, "info_normalized_performance_final": 0.8789682388305664, "info_performance_mean": 0.8174405097961426, "info_performance_final": 0.8789682388305664, "step": 757000}
{"episode_reward": 1634.8809523809512, "episode": 7571.0, "batch_reward": 12.07903003692627, "critic_loss": 229.13729858398438, "actor_loss": -1844.353759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.4685887098312378, "alpha_loss": 0.12319007515907288, "alpha_value": 0.5460716601668254, "duration": 1.5848848819732666, "info_normalized_performance_mean": 0.4902384281158447, "info_normalized_performance_final": 0.5524691343307495, "info_performance_mean": 0.4902384281158447, "info_performance_final": 0.5524691343307495, "step": 757500}
{"episode_reward": 980.4769921436604, "episode": 7576.0, "batch_reward": 11.44476318359375, "critic_loss": 412.14483642578125, "actor_loss": -1791.289794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.384197473526001, "alpha_loss": -0.098957359790802, "alpha_value": 0.5442396789258739, "duration": 1.5075795650482178, "info_normalized_performance_mean": 0.6745747327804565, "info_normalized_performance_final": 0.7227891087532043, "info_performance_mean": 0.6745747327804565, "info_performance_final": 0.7227891087532043, "step": 758000}
{"episode_reward": 1349.1496598639437, "episode": 7581.0, "batch_reward": 11.72273063659668, "critic_loss": 251.0296173095703, "actor_loss": -1848.434814453125, "actor_target_entropy": -3.0, "actor_entropy": 1.2502567768096924, "alpha_loss": 0.20737019181251526, "alpha_value": 0.5398972337018945, "duration": 1.5366466045379639, "info_normalized_performance_mean": 0.6078000664710999, "info_normalized_performance_final": 0.6439999938011169, "info_performance_mean": 0.6078000664710999, "info_performance_final": 0.6439999938011169, "step": 758500}
{"episode_reward": 1215.6000000000013, "episode": 7586.0, "batch_reward": 11.796426773071289, "critic_loss": 1086.7177734375, "actor_loss": -1840.865478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.3575422763824463, "alpha_loss": 0.24447263777256012, "alpha_value": 0.5371522133905117, "duration": 1.5677716732025146, "info_normalized_performance_mean": 0.8183528184890747, "info_normalized_performance_final": 0.8789916038513184, "info_performance_mean": 0.8183528184890747, "info_performance_final": 0.8789916038513184, "step": 759000}
{"episode_reward": 1636.705882352938, "episode": 7591.0, "batch_reward": 12.664731979370117, "critic_loss": 617.0804443359375, "actor_loss": -1853.2406005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1488633155822754, "alpha_loss": 0.06200817972421646, "alpha_value": 0.5365411451598686, "duration": 1.5327095985412598, "info_normalized_performance_mean": 0.8271428942680359, "info_normalized_performance_final": 0.90625, "info_performance_mean": 0.8271428942680359, "info_performance_final": 0.90625, "step": 759500}
{"episode_reward": 1654.2857142857142, "episode": 7596.0, "batch_reward": 12.495760917663574, "critic_loss": 210.1507568359375, "actor_loss": -1865.189697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.663712739944458, "alpha_loss": 0.04263214394450188, "alpha_value": 0.5343906897459985, "step": 760000}
{"duration": 19.083160400390625, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 760000}
{"episode_reward": 0.0, "episode": 7601.0, "batch_reward": 12.769392013549805, "critic_loss": 718.5721435546875, "actor_loss": -1865.663818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3065229654312134, "alpha_loss": 0.22562427818775177, "alpha_value": 0.5332721756789344, "duration": 1.516923189163208, "info_normalized_performance_mean": 0.5558075308799744, "info_normalized_performance_final": 0.6128246784210205, "info_performance_mean": 0.5558075308799744, "info_performance_final": 0.6128246784210205, "step": 760500}
{"episode_reward": 1111.6152597402593, "episode": 7606.0, "batch_reward": 12.50808334350586, "critic_loss": 406.10662841796875, "actor_loss": -1867.939453125, "actor_target_entropy": -3.0, "actor_entropy": 1.5075947046279907, "alpha_loss": 0.14478668570518494, "alpha_value": 0.5303674236553678, "duration": 1.46596360206604, "info_normalized_performance_mean": 0.5883991718292236, "info_normalized_performance_final": 0.6320152878761292, "info_performance_mean": 0.5883991718292236, "info_performance_final": 0.6320152878761292, "step": 761000}
{"episode_reward": 1176.7984693877563, "episode": 7611.0, "batch_reward": 11.783483505249023, "critic_loss": 339.6417236328125, "actor_loss": -1870.4310302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.2896062135696411, "alpha_loss": -0.057851023972034454, "alpha_value": 0.5280967284782064, "duration": 1.5010294914245605, "info_normalized_performance_mean": 0.7877499461174011, "info_normalized_performance_final": 0.8642857074737549, "info_performance_mean": 0.7877499461174011, "info_performance_final": 0.8642857074737549, "step": 761500}
{"episode_reward": 1575.4999999999993, "episode": 7616.0, "batch_reward": 10.871352195739746, "critic_loss": 208.36016845703125, "actor_loss": -1784.082763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.443583607673645, "alpha_loss": 0.11827725917100906, "alpha_value": 0.5278857995640718, "duration": 1.4888029098510742, "info_normalized_performance_mean": 0.7759279608726501, "info_normalized_performance_final": 0.8421717286109924, "info_performance_mean": 0.7759279608726501, "info_performance_final": 0.8421717286109924, "step": 762000}
{"episode_reward": 1551.8560606060614, "episode": 7621.0, "batch_reward": 11.976457595825195, "critic_loss": 806.8402099609375, "actor_loss": -1832.2044677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.4195643663406372, "alpha_loss": 0.15792548656463623, "alpha_value": 0.530673630016606, "duration": 1.667393445968628, "info_normalized_performance_mean": 0.4948008060455322, "info_normalized_performance_final": 0.5576156377792358, "info_performance_mean": 0.4948008060455322, "info_performance_final": 0.5576156377792358, "step": 762500}
{"episode_reward": 989.601275917067, "episode": 7626.0, "batch_reward": 11.400601387023926, "critic_loss": 254.92861938476562, "actor_loss": -1850.252685546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4569270610809326, "alpha_loss": -0.13876602053642273, "alpha_value": 0.5305271273975193, "duration": 1.5058791637420654, "info_normalized_performance_mean": 0.6836889386177063, "info_normalized_performance_final": 0.7503924369812012, "info_performance_mean": 0.6836889386177063, "info_performance_final": 0.7503924369812012, "step": 763000}
{"episode_reward": 1367.3783359497656, "episode": 7631.0, "batch_reward": 11.56903076171875, "critic_loss": 391.74822998046875, "actor_loss": -1808.59912109375, "actor_target_entropy": -3.0, "actor_entropy": 1.5409855842590332, "alpha_loss": 0.2614843249320984, "alpha_value": 0.5279163158041686, "duration": 1.6119270324707031, "info_normalized_performance_mean": 0.7281824350357056, "info_normalized_performance_final": 0.7928571701049805, "info_performance_mean": 0.7281824350357056, "info_performance_final": 0.7928571701049805, "step": 763500}
{"episode_reward": 1456.3650793650809, "episode": 7636.0, "batch_reward": 11.498729705810547, "critic_loss": 141.6420440673828, "actor_loss": -1825.883544921875, "actor_target_entropy": -3.0, "actor_entropy": 1.5473475456237793, "alpha_loss": 0.11112552881240845, "alpha_value": 0.5238792493817294, "duration": 1.515096664428711, "info_normalized_performance_mean": 0.21336880326271057, "info_normalized_performance_final": 0.5721153616905212, "info_performance_mean": 0.21336880326271057, "info_performance_final": 0.5721153616905212, "step": 764000}
{"episode_reward": 426.73763736263703, "episode": 7641.0, "batch_reward": 12.861098289489746, "critic_loss": 759.476806640625, "actor_loss": -1880.4102783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.8264176845550537, "alpha_loss": 0.3495311141014099, "alpha_value": 0.5190861886583511, "duration": 1.6142807006835938, "info_normalized_performance_mean": 0.8010749816894531, "info_normalized_performance_final": 0.8916666507720947, "info_performance_mean": 0.8010749816894531, "info_performance_final": 0.8916666507720947, "step": 764500}
{"episode_reward": 1602.1499999999985, "episode": 7646.0, "batch_reward": 11.276174545288086, "critic_loss": 380.0091552734375, "actor_loss": -1825.5047607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3319995403289795, "alpha_loss": 0.22380447387695312, "alpha_value": 0.5124572816637067, "duration": 1.638075828552246, "info_normalized_performance_mean": 0.6584590077400208, "info_normalized_performance_final": 0.7387565970420837, "info_performance_mean": 0.6584590077400208, "info_performance_final": 0.7387565970420837, "step": 765000}
{"episode_reward": 1316.91798941799, "episode": 7651.0, "batch_reward": 12.114314079284668, "critic_loss": 1063.741943359375, "actor_loss": -1848.052734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0325090885162354, "alpha_loss": 0.38082200288772583, "alpha_value": 0.5053461604411233, "duration": 1.5685536861419678, "info_normalized_performance_mean": 0.8306321501731873, "info_normalized_performance_final": 0.8911764621734619, "info_performance_mean": 0.8306321501731873, "info_performance_final": 0.8911764621734619, "step": 765500}
{"episode_reward": 1661.2647058823518, "episode": 7656.0, "batch_reward": 11.519281387329102, "critic_loss": 1771.2294921875, "actor_loss": -1864.3990478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.7132797241210938, "alpha_loss": 0.27898746728897095, "alpha_value": 0.5002090571104266, "duration": 1.7025363445281982, "info_normalized_performance_mean": 0.21911785006523132, "info_normalized_performance_final": 0.2628205120563507, "info_performance_mean": 0.21911785006523132, "info_performance_final": 0.2628205120563507, "step": 766000}
{"episode_reward": 438.23565323565384, "episode": 7661.0, "batch_reward": 11.961328506469727, "critic_loss": 212.3754119873047, "actor_loss": -1862.028564453125, "actor_target_entropy": -3.0, "actor_entropy": 1.4183692932128906, "alpha_loss": 0.07592636346817017, "alpha_value": 0.49208088497507774, "duration": 1.5665428638458252, "info_normalized_performance_mean": 0.6807882785797119, "info_normalized_performance_final": 0.7317647337913513, "info_performance_mean": 0.6807882785797119, "info_performance_final": 0.7317647337913513, "step": 766500}
{"episode_reward": 1361.5764705882373, "episode": 7666.0, "batch_reward": 10.672950744628906, "critic_loss": 525.2701416015625, "actor_loss": -1822.9517822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.1638779640197754, "alpha_loss": -0.2777926027774811, "alpha_value": 0.4860095929686336, "duration": 1.522928237915039, "info_normalized_performance_mean": 0.7803995013237, "info_normalized_performance_final": 0.8570601940155029, "info_performance_mean": 0.7803995013237, "info_performance_final": 0.8570601940155029, "step": 767000}
{"episode_reward": 1560.7986111111106, "episode": 7671.0, "batch_reward": 11.616582870483398, "critic_loss": 285.7707214355469, "actor_loss": -1858.2978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.532762885093689, "alpha_loss": 0.1644536405801773, "alpha_value": 0.4787972245483455, "duration": 1.5072808265686035, "info_normalized_performance_mean": 0.5850585699081421, "info_normalized_performance_final": 0.63525390625, "info_performance_mean": 0.5850585699081421, "info_performance_final": 0.63525390625, "step": 767500}
{"episode_reward": 1170.1171875, "episode": 7676.0, "batch_reward": 11.746427536010742, "critic_loss": 290.6043701171875, "actor_loss": -1805.6134033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.3408002853393555, "alpha_loss": 0.21195271611213684, "alpha_value": 0.47012997296711306, "duration": 1.5828614234924316, "info_normalized_performance_mean": 0.7515413165092468, "info_normalized_performance_final": 0.8117647171020508, "info_performance_mean": 0.7515413165092468, "info_performance_final": 0.8117647171020508, "step": 768000}
{"episode_reward": 1503.0823529411775, "episode": 7681.0, "batch_reward": 11.159265518188477, "critic_loss": 560.8544921875, "actor_loss": -1842.8997802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3508915901184082, "alpha_loss": -0.2461727261543274, "alpha_value": 0.46148707639061765, "duration": 1.6017627716064453, "info_normalized_performance_mean": 0.6137760877609253, "info_normalized_performance_final": 0.6597222089767456, "info_performance_mean": 0.6137760877609253, "info_performance_final": 0.6597222089767456, "step": 768500}
{"episode_reward": 1227.5520833333326, "episode": 7686.0, "batch_reward": 12.04233169555664, "critic_loss": 307.7771911621094, "actor_loss": -1839.633056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1885030269622803, "alpha_loss": 0.18394356966018677, "alpha_value": 0.4557837036915366, "duration": 1.5177254676818848, "info_normalized_performance_mean": 0.8411605358123779, "info_normalized_performance_final": 0.9040178656578064, "info_performance_mean": 0.8411605358123779, "info_performance_final": 0.9040178656578064, "step": 769000}
{"episode_reward": 1682.3214285714268, "episode": 7691.0, "batch_reward": 11.639899253845215, "critic_loss": 547.0383911132812, "actor_loss": -1804.7633056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1824204921722412, "alpha_loss": 0.04528156667947769, "alpha_value": 0.4483292319464125, "duration": 1.4897525310516357, "info_normalized_performance_mean": 0.24093875288963318, "info_normalized_performance_final": 0.2649177014827728, "info_performance_mean": 0.24093875288963318, "info_performance_final": 0.2649177014827728, "step": 769500}
{"episode_reward": 481.87757201645974, "episode": 7696.0, "batch_reward": 12.094954490661621, "critic_loss": 770.4703369140625, "actor_loss": -1864.213623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1581201553344727, "alpha_loss": 0.11673720926046371, "alpha_value": 0.4422315345465461, "step": 770000}
{"duration": 19.355458736419678, "info_normalized_performance_mean": 0.8308103680610657, "info_normalized_performance_final": 0.9134615659713745, "info_performance_mean": 0.8308103680610657, "info_performance_final": 0.9134615659713745, "step": 770000}
{"episode_reward": 1661.620879120876, "episode": 7701.0, "batch_reward": 11.684429168701172, "critic_loss": 329.23846435546875, "actor_loss": -1834.373779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.0445092916488647, "alpha_loss": 0.0972139835357666, "alpha_value": 0.43492447889328023, "duration": 1.546022653579712, "info_normalized_performance_mean": 0.7904396057128906, "info_normalized_performance_final": 0.8708791136741638, "info_performance_mean": 0.7904396057128906, "info_performance_final": 0.8708791136741638, "step": 770500}
{"episode_reward": 1580.8791208791215, "episode": 7706.0, "batch_reward": 11.935538291931152, "critic_loss": 615.4735717773438, "actor_loss": -1837.94189453125, "actor_target_entropy": -3.0, "actor_entropy": 1.7245821952819824, "alpha_loss": -0.1219359040260315, "alpha_value": 0.4292941639112146, "duration": 1.6158945560455322, "info_normalized_performance_mean": 0.6995224952697754, "info_normalized_performance_final": 0.7526041865348816, "info_performance_mean": 0.6995224952697754, "info_performance_final": 0.7526041865348816, "step": 771000}
{"episode_reward": 1399.045138888888, "episode": 7711.0, "batch_reward": 12.51513671875, "critic_loss": 471.122314453125, "actor_loss": -1822.6553955078125, "actor_target_entropy": -3.0, "actor_entropy": 1.001645803451538, "alpha_loss": 0.3053061068058014, "alpha_value": 0.4247824912371562, "duration": 1.6077985763549805, "info_normalized_performance_mean": 0.6174044609069824, "info_normalized_performance_final": 0.6710069179534912, "info_performance_mean": 0.6174044609069824, "info_performance_final": 0.6710069179534912, "step": 771500}
{"episode_reward": 1234.8090277777794, "episode": 7716.0, "batch_reward": 10.705526351928711, "critic_loss": 288.8872985839844, "actor_loss": -1788.621826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1400752067565918, "alpha_loss": -0.15455669164657593, "alpha_value": 0.41925268955080386, "duration": 1.529808521270752, "info_normalized_performance_mean": 0.6784536242485046, "info_normalized_performance_final": 0.729411780834198, "info_performance_mean": 0.6784536242485046, "info_performance_final": 0.729411780834198, "step": 772000}
{"episode_reward": 1356.9075630252091, "episode": 7721.0, "batch_reward": 11.92133903503418, "critic_loss": 248.8338623046875, "actor_loss": -1813.9293212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0426104068756104, "alpha_loss": 0.029906708747148514, "alpha_value": 0.4156250304970782, "duration": 1.5845012664794922, "info_normalized_performance_mean": 0.8484706878662109, "info_normalized_performance_final": 0.9098039269447327, "info_performance_mean": 0.8484706878662109, "info_performance_final": 0.9098039269447327, "step": 772500}
{"episode_reward": 1696.9411764705912, "episode": 7726.0, "batch_reward": 12.19676399230957, "critic_loss": 192.30838012695312, "actor_loss": -1834.18359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3310787677764893, "alpha_loss": 0.243064746260643, "alpha_value": 0.4124279214237333, "duration": 1.494138479232788, "info_normalized_performance_mean": 0.6508979201316833, "info_normalized_performance_final": 0.6974489688873291, "info_performance_mean": 0.6508979201316833, "info_performance_final": 0.6974489688873291, "step": 773000}
{"episode_reward": 1301.7959183673456, "episode": 7731.0, "batch_reward": 12.43713092803955, "critic_loss": 960.118896484375, "actor_loss": -1827.0567626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.4547481536865234, "alpha_loss": 0.1771395206451416, "alpha_value": 0.40719241029467085, "duration": 1.6080026626586914, "info_normalized_performance_mean": 0.880983293056488, "info_normalized_performance_final": 0.9491666555404663, "info_performance_mean": 0.880983293056488, "info_performance_final": 0.9491666555404663, "step": 773500}
{"episode_reward": 1761.9666666666678, "episode": 7736.0, "batch_reward": 12.11201286315918, "critic_loss": 1070.867919921875, "actor_loss": -1818.0087890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7935818433761597, "alpha_loss": 0.1324392855167389, "alpha_value": 0.40625035775444523, "duration": 1.550276756286621, "info_normalized_performance_mean": 0.9296915531158447, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9296915531158447, "info_performance_final": 1.0, "step": 774000}
{"episode_reward": 1859.3831168831168, "episode": 7741.0, "batch_reward": 12.13994026184082, "critic_loss": 332.8643798828125, "actor_loss": -1810.03515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0521559715270996, "alpha_loss": 0.06699928641319275, "alpha_value": 0.4030558374347854, "duration": 1.563148021697998, "info_normalized_performance_mean": 0.6792150735855103, "info_normalized_performance_final": 0.7554945349693298, "info_performance_mean": 0.6792150735855103, "info_performance_final": 0.7554945349693298, "step": 774500}
{"episode_reward": 1358.4301412872835, "episode": 7746.0, "batch_reward": 11.496169090270996, "critic_loss": 289.884765625, "actor_loss": -1788.280029296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3219430446624756, "alpha_loss": -0.16615110635757446, "alpha_value": 0.39796151245957306, "duration": 1.5747311115264893, "info_normalized_performance_mean": 0.7844793796539307, "info_normalized_performance_final": 0.8616071343421936, "info_performance_mean": 0.7844793796539307, "info_performance_final": 0.8616071343421936, "step": 775000}
{"episode_reward": 1568.9583333333348, "episode": 7751.0, "batch_reward": 11.759845733642578, "critic_loss": 996.0584716796875, "actor_loss": -1778.8033447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2296894788742065, "alpha_loss": 0.2454243004322052, "alpha_value": 0.3965961657677817, "duration": 1.4951603412628174, "info_normalized_performance_mean": 0.8837498426437378, "info_normalized_performance_final": 0.949404776096344, "info_performance_mean": 0.8837498426437378, "info_performance_final": 0.949404776096344, "step": 775500}
{"episode_reward": 1767.4999999999966, "episode": 7756.0, "batch_reward": 11.699718475341797, "critic_loss": 194.58497619628906, "actor_loss": -1775.582763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1518187522888184, "alpha_loss": 0.15000946819782257, "alpha_value": 0.39166578910144606, "duration": 1.5756070613861084, "info_normalized_performance_mean": 0.44614434242248535, "info_normalized_performance_final": 0.491927832365036, "info_performance_mean": 0.44614434242248535, "info_performance_final": 0.491927832365036, "step": 776000}
{"episode_reward": 892.2886989553666, "episode": 7761.0, "batch_reward": 11.774842262268066, "critic_loss": 222.7222900390625, "actor_loss": -1775.698974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3083691596984863, "alpha_loss": 0.15692350268363953, "alpha_value": 0.3892689459004524, "duration": 1.722839117050171, "info_normalized_performance_mean": 0.18940699100494385, "info_normalized_performance_final": 0.23274162411689758, "info_performance_mean": 0.18940699100494385, "info_performance_final": 0.23274162411689758, "step": 776500}
{"episode_reward": 378.81393819855367, "episode": 7766.0, "batch_reward": 12.496389389038086, "critic_loss": 229.174560546875, "actor_loss": -1804.583251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.3602579832077026, "alpha_loss": 0.17111936211585999, "alpha_value": 0.3877731661527916, "duration": 1.4411859512329102, "info_normalized_performance_mean": 0.9297856688499451, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9297856688499451, "info_performance_final": 1.0, "step": 777000}
{"episode_reward": 1859.5714285714284, "episode": 7771.0, "batch_reward": 11.380643844604492, "critic_loss": 1231.19921875, "actor_loss": -1733.322998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3749961853027344, "alpha_loss": -0.23315824568271637, "alpha_value": 0.38673975262968613, "duration": 1.6772315502166748, "info_normalized_performance_mean": 0.4351668655872345, "info_normalized_performance_final": 0.48474252223968506, "info_performance_mean": 0.4351668655872345, "info_performance_final": 0.48474252223968506, "step": 777500}
{"episode_reward": 870.3337571519394, "episode": 7776.0, "batch_reward": 11.676107406616211, "critic_loss": 192.28201293945312, "actor_loss": -1767.5728759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.3993111848831177, "alpha_loss": 0.15535935759544373, "alpha_value": 0.3855078362064272, "duration": 1.5311896800994873, "info_normalized_performance_mean": 0.9003126621246338, "info_normalized_performance_final": 0.9709821343421936, "info_performance_mean": 0.9003126621246338, "info_performance_final": 0.9709821343421936, "step": 778000}
{"episode_reward": 1800.6250000000018, "episode": 7781.0, "batch_reward": 12.263716697692871, "critic_loss": 425.954345703125, "actor_loss": -1810.149658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4528703689575195, "alpha_loss": -0.08541395515203476, "alpha_value": 0.3837162403317061, "duration": 1.5499374866485596, "info_normalized_performance_mean": 0.7636964917182922, "info_normalized_performance_final": 0.8321428298950195, "info_performance_mean": 0.7636964917182922, "info_performance_final": 0.8321428298950195, "step": 778500}
{"episode_reward": 1527.3928571428555, "episode": 7786.0, "batch_reward": 12.269262313842773, "critic_loss": 357.3912048339844, "actor_loss": -1784.8226318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.4228081703186035, "alpha_loss": -0.09817060828208923, "alpha_value": 0.38017239720135204, "duration": 1.4981658458709717, "info_normalized_performance_mean": 0.6028759479522705, "info_normalized_performance_final": 0.6552734375, "info_performance_mean": 0.6028759479522705, "info_performance_final": 0.6552734375, "step": 779000}
{"episode_reward": 1205.751953125, "episode": 7791.0, "batch_reward": 12.323545455932617, "critic_loss": 341.8172912597656, "actor_loss": -1756.583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.1698024272918701, "alpha_loss": 0.05585118383169174, "alpha_value": 0.37662166116276713, "duration": 1.527831792831421, "info_normalized_performance_mean": 0.38286730647087097, "info_normalized_performance_final": 0.43038323521614075, "info_performance_mean": 0.38286730647087097, "info_performance_final": 0.43038323521614075, "step": 779500}
{"episode_reward": 765.7347670250892, "episode": 7796.0, "batch_reward": 11.543067932128906, "critic_loss": 301.907470703125, "actor_loss": -1747.94140625, "actor_target_entropy": -3.0, "actor_entropy": 1.024907112121582, "alpha_loss": 0.02048370987176895, "alpha_value": 0.3756948219709392, "step": 780000}
{"duration": 19.03023672103882, "info_normalized_performance_mean": 0.5480586290359497, "info_normalized_performance_final": 0.5885226130485535, "info_performance_mean": 0.5480586290359497, "info_performance_final": 0.5885226130485535, "step": 780000}
{"episode_reward": 1096.1172161172171, "episode": 7801.0, "batch_reward": 10.93104362487793, "critic_loss": 542.9705810546875, "actor_loss": -1687.6824951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2765964269638062, "alpha_loss": 0.05374087393283844, "alpha_value": 0.37387458691864633, "duration": 1.458509922027588, "info_normalized_performance_mean": 0.5395703315734863, "info_normalized_performance_final": 0.57421875, "info_performance_mean": 0.5395703315734863, "info_performance_final": 0.57421875, "step": 780500}
{"episode_reward": 1079.140625, "episode": 7806.0, "batch_reward": 11.15119743347168, "critic_loss": 2309.80322265625, "actor_loss": -1680.594482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.1175179481506348, "alpha_loss": -0.05798463523387909, "alpha_value": 0.3734243239755713, "duration": 1.4901437759399414, "info_normalized_performance_mean": 0.3065623939037323, "info_normalized_performance_final": 0.33789506554603577, "info_performance_mean": 0.3065623939037323, "info_performance_final": 0.33789506554603577, "step": 781000}
{"episode_reward": 613.1247963506023, "episode": 7811.0, "batch_reward": 12.323068618774414, "critic_loss": 825.86865234375, "actor_loss": -1769.230224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.174316167831421, "alpha_loss": -0.0146623644977808, "alpha_value": 0.3720683656582486, "duration": 1.4905130863189697, "info_normalized_performance_mean": 0.725321352481842, "info_normalized_performance_final": 0.7928571701049805, "info_performance_mean": 0.725321352481842, "info_performance_final": 0.7928571701049805, "step": 781500}
{"episode_reward": 1450.6428571428587, "episode": 7816.0, "batch_reward": 11.915264129638672, "critic_loss": 183.39944458007812, "actor_loss": -1766.0908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4989893436431885, "alpha_loss": 0.160541370511055, "alpha_value": 0.3731606950205595, "duration": 1.5634446144104004, "info_normalized_performance_mean": 0.803932249546051, "info_normalized_performance_final": 0.8671875, "info_performance_mean": 0.803932249546051, "info_performance_final": 0.8671875, "step": 782000}
{"episode_reward": 1607.8645833333335, "episode": 7821.0, "batch_reward": 11.669893264770508, "critic_loss": 458.2882385253906, "actor_loss": -1741.80859375, "actor_target_entropy": -3.0, "actor_entropy": 1.3529871702194214, "alpha_loss": -0.29132965207099915, "alpha_value": 0.37529382584948906, "duration": 1.5710971355438232, "info_normalized_performance_mean": 0.2389153689146042, "info_normalized_performance_final": 0.261904776096344, "info_performance_mean": 0.2389153689146042, "info_performance_final": 0.261904776096344, "step": 782500}
{"episode_reward": 477.830687830688, "episode": 7826.0, "batch_reward": 12.062891960144043, "critic_loss": 259.16033935546875, "actor_loss": -1768.9757080078125, "actor_target_entropy": -3.0, "actor_entropy": 1.212775468826294, "alpha_loss": -0.09116476029157639, "alpha_value": 0.3755693714874978, "duration": 1.5424082279205322, "info_normalized_performance_mean": 0.8978247046470642, "info_normalized_performance_final": 0.9983766078948975, "info_performance_mean": 0.8978247046470642, "info_performance_final": 0.9983766078948975, "step": 783000}
{"episode_reward": 1795.6493506493505, "episode": 7831.0, "batch_reward": 11.917451858520508, "critic_loss": 323.58123779296875, "actor_loss": -1744.24072265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2114540338516235, "alpha_loss": -0.0185178741812706, "alpha_value": 0.37644694704131776, "duration": 1.5570414066314697, "info_normalized_performance_mean": 0.9340624809265137, "info_normalized_performance_final": 0.994140625, "info_performance_mean": 0.9340624809265137, "info_performance_final": 0.994140625, "step": 783500}
{"episode_reward": 1868.125, "episode": 7836.0, "batch_reward": 11.218996047973633, "critic_loss": 186.9842529296875, "actor_loss": -1708.52197265625, "actor_target_entropy": -3.0, "actor_entropy": 1.4043166637420654, "alpha_loss": -0.014531824737787247, "alpha_value": 0.3757031625635219, "duration": 1.5603675842285156, "info_normalized_performance_mean": 0.8142319321632385, "info_normalized_performance_final": 0.887499988079071, "info_performance_mean": 0.8142319321632385, "info_performance_final": 0.887499988079071, "step": 784000}
{"episode_reward": 1628.4642857142858, "episode": 7841.0, "batch_reward": 11.775598526000977, "critic_loss": 368.1552734375, "actor_loss": -1734.759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.1691310405731201, "alpha_loss": 0.05942009761929512, "alpha_value": 0.37811563612203253, "duration": 1.480499267578125, "info_normalized_performance_mean": 0.8111560344696045, "info_normalized_performance_final": 0.871874988079071, "info_performance_mean": 0.8111560344696045, "info_performance_final": 0.871874988079071, "step": 784500}
{"episode_reward": 1622.3125, "episode": 7846.0, "batch_reward": 12.86416244506836, "critic_loss": 161.12548828125, "actor_loss": -1784.6474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.5039498805999756, "alpha_loss": -0.20310968160629272, "alpha_value": 0.3788181915101603, "duration": 1.5686562061309814, "info_normalized_performance_mean": 0.42802274227142334, "info_normalized_performance_final": 0.47295454144477844, "info_performance_mean": 0.42802274227142334, "info_performance_final": 0.47295454144477844, "step": 785000}
{"episode_reward": 856.0454545454555, "episode": 7851.0, "batch_reward": 11.631002426147461, "critic_loss": 292.51934814453125, "actor_loss": -1720.26513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3450829982757568, "alpha_loss": -0.04336618259549141, "alpha_value": 0.37864337138217885, "duration": 1.5166361331939697, "info_normalized_performance_mean": 0.7682653069496155, "info_normalized_performance_final": 0.8405612111091614, "info_performance_mean": 0.7682653069496155, "info_performance_final": 0.8405612111091614, "step": 785500}
{"episode_reward": 1536.530612244897, "episode": 7856.0, "batch_reward": 11.653495788574219, "critic_loss": 237.95547485351562, "actor_loss": -1760.997314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0673387050628662, "alpha_loss": 0.13630026578903198, "alpha_value": 0.37799221481400413, "duration": 1.6052250862121582, "info_normalized_performance_mean": 0.7933951020240784, "info_normalized_performance_final": 0.8509700298309326, "info_performance_mean": 0.7933951020240784, "info_performance_final": 0.8509700298309326, "step": 786000}
{"episode_reward": 1586.7901234567926, "episode": 7861.0, "batch_reward": 12.151931762695312, "critic_loss": 293.598388671875, "actor_loss": -1758.0040283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4153037071228027, "alpha_loss": 0.04663331061601639, "alpha_value": 0.3753882727331614, "duration": 1.4972286224365234, "info_normalized_performance_mean": 0.5137683749198914, "info_normalized_performance_final": 0.5586080551147461, "info_performance_mean": 0.5137683749198914, "info_performance_final": 0.5586080551147461, "step": 786500}
{"episode_reward": 1027.5366300366297, "episode": 7866.0, "batch_reward": 12.433232307434082, "critic_loss": 376.70379638671875, "actor_loss": -1727.95947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2381223440170288, "alpha_loss": 0.033845968544483185, "alpha_value": 0.3732592848108275, "duration": 1.492319107055664, "info_normalized_performance_mean": 0.4756777584552765, "info_normalized_performance_final": 0.5563187003135681, "info_performance_mean": 0.4756777584552765, "info_performance_final": 0.5563187003135681, "step": 787000}
{"episode_reward": 951.3553113553103, "episode": 7871.0, "batch_reward": 11.562767028808594, "critic_loss": 261.81201171875, "actor_loss": -1710.353759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.2007055282592773, "alpha_loss": -0.12462536245584488, "alpha_value": 0.3714857936745353, "duration": 1.6049370765686035, "info_normalized_performance_mean": 0.784474790096283, "info_normalized_performance_final": 0.8424999713897705, "info_performance_mean": 0.784474790096283, "info_performance_final": 0.8424999713897705, "step": 787500}
{"episode_reward": 1568.949999999998, "episode": 7876.0, "batch_reward": 12.172317504882812, "critic_loss": 477.953125, "actor_loss": -1765.2109375, "actor_target_entropy": -3.0, "actor_entropy": 1.4550676345825195, "alpha_loss": -0.013282015919685364, "alpha_value": 0.36960614634545547, "duration": 1.5071382522583008, "info_normalized_performance_mean": 0.5202566981315613, "info_normalized_performance_final": 0.5751488208770752, "info_performance_mean": 0.5202566981315613, "info_performance_final": 0.5751488208770752, "step": 788000}
{"episode_reward": 1040.5133928571413, "episode": 7881.0, "batch_reward": 11.708778381347656, "critic_loss": 622.2186889648438, "actor_loss": -1750.3193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.5523958206176758, "alpha_loss": -0.05164581164717674, "alpha_value": 0.3669139247912224, "duration": 1.6312801837921143, "info_normalized_performance_mean": 0.7724164724349976, "info_normalized_performance_final": 0.8470588326454163, "info_performance_mean": 0.7724164724349976, "info_performance_final": 0.8470588326454163, "step": 788500}
{"episode_reward": 1544.8325791855234, "episode": 7886.0, "batch_reward": 11.819438934326172, "critic_loss": 292.1591796875, "actor_loss": -1722.974365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1294152736663818, "alpha_loss": -0.03728576377034187, "alpha_value": 0.36842936445746594, "duration": 1.5084428787231445, "info_normalized_performance_mean": 0.5724088549613953, "info_normalized_performance_final": 0.61328125, "info_performance_mean": 0.5724088549613953, "info_performance_final": 0.61328125, "step": 789000}
{"episode_reward": 1144.8177083333335, "episode": 7891.0, "batch_reward": 11.825551986694336, "critic_loss": 398.6016845703125, "actor_loss": -1704.95458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.4499733448028564, "alpha_loss": 0.025213835760951042, "alpha_value": 0.368218698675213, "duration": 1.6422057151794434, "info_normalized_performance_mean": 0.568585991859436, "info_normalized_performance_final": 0.6100583076477051, "info_performance_mean": 0.568585991859436, "info_performance_final": 0.6100583076477051, "step": 789500}
{"episode_reward": 1137.172011661809, "episode": 7896.0, "batch_reward": 12.182254791259766, "critic_loss": 412.745361328125, "actor_loss": -1735.5081787109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9833776950836182, "alpha_loss": -0.1750735491514206, "alpha_value": 0.3685922131012353, "step": 790000}
{"duration": 18.632410049438477, "info_normalized_performance_mean": 0.6444752216339111, "info_normalized_performance_final": 0.6895043849945068, "info_performance_mean": 0.6444752216339111, "info_performance_final": 0.6895043849945068, "step": 790000}
{"episode_reward": 1288.9504373177817, "episode": 7901.0, "batch_reward": 12.248098373413086, "critic_loss": 164.36305236816406, "actor_loss": -1721.669677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.6135213375091553, "alpha_loss": -0.10715313255786896, "alpha_value": 0.36652990992658013, "duration": 1.592902660369873, "info_normalized_performance_mean": 0.5707322955131531, "info_normalized_performance_final": 0.6242985129356384, "info_performance_mean": 0.5707322955131531, "info_performance_final": 0.6242985129356384, "step": 790500}
{"episode_reward": 1141.4646464646466, "episode": 7906.0, "batch_reward": 12.27609634399414, "critic_loss": 278.40911865234375, "actor_loss": -1747.0186767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1395025253295898, "alpha_loss": -0.22469881176948547, "alpha_value": 0.3678835847442701, "duration": 1.6581885814666748, "info_normalized_performance_mean": 0.8125555515289307, "info_normalized_performance_final": 0.8826388716697693, "info_performance_mean": 0.8125555515289307, "info_performance_final": 0.8826388716697693, "step": 791000}
{"episode_reward": 1625.111111111114, "episode": 7911.0, "batch_reward": 11.706480979919434, "critic_loss": 289.8974914550781, "actor_loss": -1742.731689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0913851261138916, "alpha_loss": -0.18165017664432526, "alpha_value": 0.36707950334294553, "duration": 1.5491936206817627, "info_normalized_performance_mean": 0.8102258443832397, "info_normalized_performance_final": 0.8611111044883728, "info_performance_mean": 0.8102258443832397, "info_performance_final": 0.8611111044883728, "step": 791500}
{"episode_reward": 1620.4513888888857, "episode": 7916.0, "batch_reward": 12.454009056091309, "critic_loss": 214.1824493408203, "actor_loss": -1741.299072265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3769850730895996, "alpha_loss": 0.07734666764736176, "alpha_value": 0.36816265125074427, "duration": 1.5941572189331055, "info_normalized_performance_mean": 0.5589917898178101, "info_normalized_performance_final": 0.6111111044883728, "info_performance_mean": 0.5589917898178101, "info_performance_final": 0.6111111044883728, "step": 792000}
{"episode_reward": 1117.983539094648, "episode": 7921.0, "batch_reward": 12.803007125854492, "critic_loss": 238.7850799560547, "actor_loss": -1776.7132568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.45268976688385, "alpha_loss": 0.20787879824638367, "alpha_value": 0.3705847511721215, "duration": 1.5701167583465576, "info_normalized_performance_mean": 0.4954497516155243, "info_normalized_performance_final": 0.5326278805732727, "info_performance_mean": 0.4954497516155243, "info_performance_final": 0.5326278805732727, "step": 792500}
{"episode_reward": 990.8994708994718, "episode": 7926.0, "batch_reward": 11.861775398254395, "critic_loss": 390.406494140625, "actor_loss": -1686.5546875, "actor_target_entropy": -3.0, "actor_entropy": 1.352333903312683, "alpha_loss": 0.08287610113620758, "alpha_value": 0.37009149925858814, "duration": 1.5568077564239502, "info_normalized_performance_mean": 0.8868154883384705, "info_normalized_performance_final": 0.9851190447807312, "info_performance_mean": 0.8868154883384705, "info_performance_final": 0.9851190447807312, "step": 793000}
{"episode_reward": 1773.6309523809532, "episode": 7931.0, "batch_reward": 11.949761390686035, "critic_loss": 273.6942138671875, "actor_loss": -1759.58544921875, "actor_target_entropy": -3.0, "actor_entropy": 1.0538463592529297, "alpha_loss": -0.25461864471435547, "alpha_value": 0.3710042134542082, "duration": 1.5527265071868896, "info_normalized_performance_mean": 0.422948956489563, "info_normalized_performance_final": 0.47250279784202576, "info_performance_mean": 0.422948956489563, "info_performance_final": 0.47250279784202576, "step": 793500}
{"episode_reward": 845.8978675645335, "episode": 7936.0, "batch_reward": 12.25990104675293, "critic_loss": 100.54997253417969, "actor_loss": -1734.2723388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.4216076135635376, "alpha_loss": 0.058350756764411926, "alpha_value": 0.37309604275186203, "duration": 1.4924464225769043, "info_normalized_performance_mean": 0.47575080394744873, "info_normalized_performance_final": 0.5236957669258118, "info_performance_mean": 0.47575080394744873, "info_performance_final": 0.5236957669258118, "step": 794000}
{"episode_reward": 951.5013938669839, "episode": 7941.0, "batch_reward": 12.874706268310547, "critic_loss": 148.91567993164062, "actor_loss": -1767.190185546875, "actor_target_entropy": -3.0, "actor_entropy": 1.377833366394043, "alpha_loss": 0.11010901629924774, "alpha_value": 0.37250379011576695, "duration": 1.4851975440979004, "info_normalized_performance_mean": 0.6662756204605103, "info_normalized_performance_final": 0.7130101919174194, "info_performance_mean": 0.6662756204605103, "info_performance_final": 0.7130101919174194, "step": 794500}
{"episode_reward": 1332.5510204081656, "episode": 7946.0, "batch_reward": 12.447880744934082, "critic_loss": 442.6611633300781, "actor_loss": -1737.4066162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2711374759674072, "alpha_loss": 0.1446933001279831, "alpha_value": 0.37037295772147744, "duration": 1.598891258239746, "info_normalized_performance_mean": 0.3678405284881592, "info_normalized_performance_final": 0.4288095235824585, "info_performance_mean": 0.3678405284881592, "info_performance_final": 0.4288095235824585, "step": 795000}
{"episode_reward": 735.680952380954, "episode": 7951.0, "batch_reward": 11.63333511352539, "critic_loss": 768.68701171875, "actor_loss": -1706.8907470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.004901647567749, "alpha_loss": 0.13050924241542816, "alpha_value": 0.36726268695873115, "duration": 1.4847939014434814, "info_normalized_performance_mean": 0.544935941696167, "info_normalized_performance_final": 0.5915750861167908, "info_performance_mean": 0.544935941696167, "info_performance_final": 0.5915750861167908, "step": 795500}
{"episode_reward": 1089.8717948717929, "episode": 7956.0, "batch_reward": 11.72906494140625, "critic_loss": 234.5542755126953, "actor_loss": -1671.57666015625, "actor_target_entropy": -3.0, "actor_entropy": 0.8464934825897217, "alpha_loss": 0.209518164396286, "alpha_value": 0.3656748574707614, "duration": 1.4643549919128418, "info_normalized_performance_mean": 0.5522072315216064, "info_normalized_performance_final": 0.5997023582458496, "info_performance_mean": 0.5522072315216064, "info_performance_final": 0.5997023582458496, "step": 796000}
{"episode_reward": 1104.4146825396815, "episode": 7961.0, "batch_reward": 11.929437637329102, "critic_loss": 490.08563232421875, "actor_loss": -1688.9344482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.325773000717163, "alpha_loss": 0.04163333773612976, "alpha_value": 0.363560458527091, "duration": 1.5529472827911377, "info_normalized_performance_mean": 0.7792206406593323, "info_normalized_performance_final": 0.8571428656578064, "info_performance_mean": 0.7792206406593323, "info_performance_final": 0.8571428656578064, "step": 796500}
{"episode_reward": 1558.441558441557, "episode": 7966.0, "batch_reward": 11.166093826293945, "critic_loss": 128.4547576904297, "actor_loss": -1679.6297607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9619132280349731, "alpha_loss": 0.03943830728530884, "alpha_value": 0.3642352090586016, "duration": 1.583078145980835, "info_normalized_performance_mean": 0.8472549915313721, "info_normalized_performance_final": 0.9254902005195618, "info_performance_mean": 0.8472549915313721, "info_performance_final": 0.9254902005195618, "step": 797000}
{"episode_reward": 1694.509803921568, "episode": 7971.0, "batch_reward": 11.473163604736328, "critic_loss": 328.35687255859375, "actor_loss": -1670.328857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.1974172592163086, "alpha_loss": -0.14995160698890686, "alpha_value": 0.3622363729441309, "duration": 1.587843656539917, "info_normalized_performance_mean": 0.4857064187526703, "info_normalized_performance_final": 0.5444155931472778, "info_performance_mean": 0.4857064187526703, "info_performance_final": 0.5444155931472778, "step": 797500}
{"episode_reward": 971.4129870129852, "episode": 7976.0, "batch_reward": 12.783747673034668, "critic_loss": 229.08554077148438, "actor_loss": -1730.59619140625, "actor_target_entropy": -3.0, "actor_entropy": 1.4088486433029175, "alpha_loss": 0.16994360089302063, "alpha_value": 0.36199878847489536, "duration": 1.5715305805206299, "info_normalized_performance_mean": 0.3968674838542938, "info_normalized_performance_final": 0.4449999928474426, "info_performance_mean": 0.3968674838542938, "info_performance_final": 0.4449999928474426, "step": 798000}
{"episode_reward": 793.7349999999988, "episode": 7981.0, "batch_reward": 12.815223693847656, "critic_loss": 215.03915405273438, "actor_loss": -1764.82373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.395400881767273, "alpha_loss": -0.0384795218706131, "alpha_value": 0.35821286434031574, "duration": 1.4707746505737305, "info_normalized_performance_mean": 0.9296428561210632, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9296428561210632, "info_performance_final": 1.0, "step": 798500}
{"episode_reward": 1859.2857142857142, "episode": 7986.0, "batch_reward": 11.745914459228516, "critic_loss": 271.9124450683594, "actor_loss": -1711.83349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.0465583801269531, "alpha_loss": 0.06240468472242355, "alpha_value": 0.3595352124398241, "duration": 1.4414284229278564, "info_normalized_performance_mean": 0.6091468334197998, "info_normalized_performance_final": 0.6805555820465088, "info_performance_mean": 0.6091468334197998, "info_performance_final": 0.6805555820465088, "step": 799000}
{"episode_reward": 1218.293650793649, "episode": 7991.0, "batch_reward": 11.979878425598145, "critic_loss": 527.3120727539062, "actor_loss": -1690.5240478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.2904736995697021, "alpha_loss": -0.032335370779037476, "alpha_value": 0.3568315374603886, "duration": 1.4471051692962646, "info_normalized_performance_mean": 0.9399375319480896, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9399375319480896, "info_performance_final": 1.0, "step": 799500}
{"episode_reward": 1879.875, "episode": 7996.0, "batch_reward": 12.20887565612793, "critic_loss": 148.84072875976562, "actor_loss": -1717.199951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3838119506835938, "alpha_loss": -0.1537959724664688, "alpha_value": 0.3546035221345581, "step": 800000}
{"duration": 18.882558345794678, "info_normalized_performance_mean": 0.4811384677886963, "info_normalized_performance_final": 0.5290178656578064, "info_performance_mean": 0.4811384677886963, "info_performance_final": 0.5290178656578064, "step": 800000}
{"episode_reward": 962.2767857142849, "episode": 8001.0, "batch_reward": 12.704984664916992, "critic_loss": 359.5614318847656, "actor_loss": -1698.6202392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.5350860357284546, "alpha_loss": 0.21372690796852112, "alpha_value": 0.3513774627732417, "duration": 1.5618541240692139, "info_normalized_performance_mean": 0.505361020565033, "info_normalized_performance_final": 0.551805317401886, "info_performance_mean": 0.505361020565033, "info_performance_final": 0.551805317401886, "step": 800500}
{"episode_reward": 1010.7221350078511, "episode": 8006.0, "batch_reward": 12.609489440917969, "critic_loss": 274.0205078125, "actor_loss": -1736.84423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.6914653778076172, "alpha_loss": 0.02624574489891529, "alpha_value": 0.35149230199244935, "duration": 1.4988815784454346, "info_normalized_performance_mean": 0.448823481798172, "info_normalized_performance_final": 0.47999998927116394, "info_performance_mean": 0.448823481798172, "info_performance_final": 0.47999998927116394, "step": 801000}
{"episode_reward": 897.6470588235308, "episode": 8011.0, "batch_reward": 12.741604804992676, "critic_loss": 418.005126953125, "actor_loss": -1741.1004638671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1957547664642334, "alpha_loss": -0.12166240811347961, "alpha_value": 0.3492367198868098, "duration": 1.534442663192749, "info_normalized_performance_mean": 0.8614453077316284, "info_normalized_performance_final": 0.93359375, "info_performance_mean": 0.8614453077316284, "info_performance_final": 0.93359375, "step": 801500}
{"episode_reward": 1722.890625, "episode": 8016.0, "batch_reward": 12.370511054992676, "critic_loss": 185.91934204101562, "actor_loss": -1726.87548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.2723801136016846, "alpha_loss": 0.10413265228271484, "alpha_value": 0.3462419264003893, "duration": 1.5428192615509033, "info_normalized_performance_mean": 0.8226607441902161, "info_normalized_performance_final": 0.9035714268684387, "info_performance_mean": 0.8226607441902161, "info_performance_final": 0.9035714268684387, "step": 802000}
{"episode_reward": 1645.3214285714314, "episode": 8021.0, "batch_reward": 12.14162540435791, "critic_loss": 126.82061767578125, "actor_loss": -1694.510009765625, "actor_target_entropy": -3.0, "actor_entropy": 1.182058572769165, "alpha_loss": 0.014207355678081512, "alpha_value": 0.34664528336463896, "duration": 1.5080108642578125, "info_normalized_performance_mean": 0.6097253561019897, "info_normalized_performance_final": 0.6552197933197021, "info_performance_mean": 0.6097253561019897, "info_performance_final": 0.6552197933197021, "step": 802500}
{"episode_reward": 1219.450549450549, "episode": 8026.0, "batch_reward": 12.238813400268555, "critic_loss": 201.89688110351562, "actor_loss": -1721.4659423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3246526718139648, "alpha_loss": -0.18553975224494934, "alpha_value": 0.3472457859030807, "duration": 1.5516040325164795, "info_normalized_performance_mean": 0.4399057626724243, "info_normalized_performance_final": 0.5040000081062317, "info_performance_mean": 0.4399057626724243, "info_performance_final": 0.5040000081062317, "step": 803000}
{"episode_reward": 879.8114285714298, "episode": 8031.0, "batch_reward": 12.67123031616211, "critic_loss": 163.238525390625, "actor_loss": -1722.5640869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.0611969232559204, "alpha_loss": 0.18137511610984802, "alpha_value": 0.3450636017662701, "duration": 1.575822353363037, "info_normalized_performance_mean": 0.7686262726783752, "info_normalized_performance_final": 0.8255494236946106, "info_performance_mean": 0.7686262726783752, "info_performance_final": 0.8255494236946106, "step": 803500}
{"episode_reward": 1537.2527472527481, "episode": 8036.0, "batch_reward": 12.45580005645752, "critic_loss": 415.7093505859375, "actor_loss": -1727.2462158203125, "actor_target_entropy": -3.0, "actor_entropy": 0.9988502860069275, "alpha_loss": 0.08519342541694641, "alpha_value": 0.3434025589742303, "duration": 1.5048580169677734, "info_normalized_performance_mean": 0.7358482480049133, "info_normalized_performance_final": 0.8035714030265808, "info_performance_mean": 0.7358482480049133, "info_performance_final": 0.8035714030265808, "step": 804000}
{"episode_reward": 1471.6964285714305, "episode": 8041.0, "batch_reward": 11.676153182983398, "critic_loss": 2602.271484375, "actor_loss": -1627.27490234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5972322821617126, "alpha_loss": -0.07949623465538025, "alpha_value": 0.3448046670295763, "duration": 1.4591083526611328, "info_normalized_performance_mean": 0.3093166649341583, "info_normalized_performance_final": 0.3283333480358124, "info_performance_mean": 0.3093166649341583, "info_performance_final": 0.3283333480358124, "step": 804500}
{"episode_reward": 618.633333333334, "episode": 8046.0, "batch_reward": 12.573379516601562, "critic_loss": 253.77664184570312, "actor_loss": -1738.25732421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0460858345031738, "alpha_loss": 0.13484621047973633, "alpha_value": 0.34587091312296026, "duration": 1.5808265209197998, "info_normalized_performance_mean": 0.8444919586181641, "info_normalized_performance_final": 0.9315508008003235, "info_performance_mean": 0.8444919586181641, "info_performance_final": 0.9315508008003235, "step": 805000}
{"episode_reward": 1688.983957219255, "episode": 8051.0, "batch_reward": 13.107916831970215, "critic_loss": 445.864990234375, "actor_loss": -1752.843994140625, "actor_target_entropy": -3.0, "actor_entropy": 1.1553151607513428, "alpha_loss": -0.022714994847774506, "alpha_value": 0.34678451710888186, "duration": 1.4726743698120117, "info_normalized_performance_mean": 0.44951170682907104, "info_normalized_performance_final": 0.48388671875, "info_performance_mean": 0.44951170682907104, "info_performance_final": 0.48388671875, "step": 805500}
{"episode_reward": 899.0234375, "episode": 8056.0, "batch_reward": 11.65342903137207, "critic_loss": 166.9317626953125, "actor_loss": -1673.2801513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.4246338605880737, "alpha_loss": -0.0009799432009458542, "alpha_value": 0.3473657312898547, "duration": 1.599869728088379, "info_normalized_performance_mean": 0.6639998555183411, "info_normalized_performance_final": 0.7120000123977661, "info_performance_mean": 0.6639998555183411, "info_performance_final": 0.7120000123977661, "step": 806000}
{"episode_reward": 1328.0000000000007, "episode": 8061.0, "batch_reward": 11.983135223388672, "critic_loss": 264.6030578613281, "actor_loss": -1704.2464599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.8335494995117188, "alpha_loss": -0.02561960369348526, "alpha_value": 0.3471958366687535, "duration": 1.4864437580108643, "info_normalized_performance_mean": 0.6451593637466431, "info_normalized_performance_final": 0.6989796161651611, "info_performance_mean": 0.6451593637466431, "info_performance_final": 0.6989796161651611, "step": 806500}
{"episode_reward": 1290.3188775510207, "episode": 8066.0, "batch_reward": 13.363618850708008, "critic_loss": 418.5013427734375, "actor_loss": -1774.295166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.013221263885498, "alpha_loss": 0.0834040567278862, "alpha_value": 0.3485421190904832, "duration": 1.4686853885650635, "info_normalized_performance_mean": 0.6431424021720886, "info_normalized_performance_final": 0.6909722089767456, "info_performance_mean": 0.6431424021720886, "info_performance_final": 0.6909722089767456, "step": 807000}
{"episode_reward": 1286.284722222221, "episode": 8071.0, "batch_reward": 12.123441696166992, "critic_loss": 577.7406005859375, "actor_loss": -1712.21533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.3351221084594727, "alpha_loss": -0.1122625395655632, "alpha_value": 0.34830802205242106, "duration": 1.596867322921753, "info_normalized_performance_mean": 0.6548116207122803, "info_normalized_performance_final": 0.7063491940498352, "info_performance_mean": 0.6548116207122803, "info_performance_final": 0.7063491940498352, "step": 807500}
{"episode_reward": 1309.6230158730148, "episode": 8076.0, "batch_reward": 13.015848159790039, "critic_loss": 97.95794677734375, "actor_loss": -1711.96484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4792253971099854, "alpha_loss": 0.19986967742443085, "alpha_value": 0.3494767644321651, "duration": 1.5961813926696777, "info_normalized_performance_mean": 0.7511599659919739, "info_normalized_performance_final": 0.8069999814033508, "info_performance_mean": 0.7511599659919739, "info_performance_final": 0.8069999814033508, "step": 808000}
{"episode_reward": 1502.3200000000022, "episode": 8081.0, "batch_reward": 12.359515190124512, "critic_loss": 254.54942321777344, "actor_loss": -1684.059326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1146318912506104, "alpha_loss": 0.026545848697423935, "alpha_value": 0.3493240041408076, "duration": 1.5545597076416016, "info_normalized_performance_mean": 0.5974484086036682, "info_normalized_performance_final": 0.6641483306884766, "info_performance_mean": 0.5974484086036682, "info_performance_final": 0.6641483306884766, "step": 808500}
{"episode_reward": 1194.8969780219763, "episode": 8086.0, "batch_reward": 12.204422950744629, "critic_loss": 218.9541015625, "actor_loss": -1718.714599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3165624141693115, "alpha_loss": 0.1654801219701767, "alpha_value": 0.3493668290857546, "duration": 1.642545461654663, "info_normalized_performance_mean": 0.8099735379219055, "info_normalized_performance_final": 0.8789682388305664, "info_performance_mean": 0.8099735379219055, "info_performance_final": 0.8789682388305664, "step": 809000}
{"episode_reward": 1619.9470899470887, "episode": 8091.0, "batch_reward": 12.03447151184082, "critic_loss": 432.99639892578125, "actor_loss": -1709.529052734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8289231061935425, "alpha_loss": -0.18219463527202606, "alpha_value": 0.3521467383880706, "duration": 1.615222454071045, "info_normalized_performance_mean": 0.6982534527778625, "info_normalized_performance_final": 0.7502262592315674, "info_performance_mean": 0.6982534527778625, "info_performance_final": 0.7502262592315674, "step": 809500}
{"episode_reward": 1396.5067873303149, "episode": 8096.0, "batch_reward": 11.733125686645508, "critic_loss": 220.57916259765625, "actor_loss": -1668.73779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.0847322940826416, "alpha_loss": 0.021746665239334106, "alpha_value": 0.35279432987049125, "step": 810000}
{"duration": 18.329261779785156, "info_normalized_performance_mean": 0.6709864735603333, "info_normalized_performance_final": 0.7348416447639465, "info_performance_mean": 0.6709864735603333, "info_performance_final": 0.7348416447639465, "step": 810000}
{"episode_reward": 1341.9728506787308, "episode": 8101.0, "batch_reward": 12.281478881835938, "critic_loss": 538.8780517578125, "actor_loss": -1704.4520263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.5837619304656982, "alpha_loss": 0.027737386524677277, "alpha_value": 0.3540228263417235, "duration": 1.5369112491607666, "info_normalized_performance_mean": 0.7236997485160828, "info_normalized_performance_final": 0.8026556968688965, "info_performance_mean": 0.7236997485160828, "info_performance_final": 0.8026556968688965, "step": 810500}
{"episode_reward": 1447.3992673992661, "episode": 8106.0, "batch_reward": 11.734058380126953, "critic_loss": 252.9347381591797, "actor_loss": -1677.5565185546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4210832118988037, "alpha_loss": -0.044195178896188736, "alpha_value": 0.35326786025056345, "duration": 1.4993236064910889, "info_normalized_performance_mean": 0.7290475368499756, "info_normalized_performance_final": 0.7840136289596558, "info_performance_mean": 0.7290475368499756, "info_performance_final": 0.7840136289596558, "step": 811000}
{"episode_reward": 1458.0952380952392, "episode": 8111.0, "batch_reward": 12.349014282226562, "critic_loss": 203.4921112060547, "actor_loss": -1660.042236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.2722909450531006, "alpha_loss": 0.03757322579622269, "alpha_value": 0.3522593446602628, "duration": 1.5122416019439697, "info_normalized_performance_mean": 0.5652727484703064, "info_normalized_performance_final": 0.6135912537574768, "info_performance_mean": 0.5652727484703064, "info_performance_final": 0.6135912537574768, "step": 811500}
{"episode_reward": 1130.5456349206356, "episode": 8116.0, "batch_reward": 12.225166320800781, "critic_loss": 697.4124755859375, "actor_loss": -1673.558349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1011967658996582, "alpha_loss": -0.13546079397201538, "alpha_value": 0.35190432696005447, "duration": 1.498753309249878, "info_normalized_performance_mean": 0.2543630301952362, "info_normalized_performance_final": 0.2797418534755707, "info_performance_mean": 0.2543630301952362, "info_performance_final": 0.2797418534755707, "step": 812000}
{"episode_reward": 508.7261503928169, "episode": 8121.0, "batch_reward": 12.110391616821289, "critic_loss": 479.3429870605469, "actor_loss": -1700.287353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.169987440109253, "alpha_loss": 0.013267423957586288, "alpha_value": 0.35084739943505755, "duration": 1.5658693313598633, "info_normalized_performance_mean": 0.7630540728569031, "info_normalized_performance_final": 0.8409090638160706, "info_performance_mean": 0.7630540728569031, "info_performance_final": 0.8409090638160706, "step": 812500}
{"episode_reward": 1526.1079545454543, "episode": 8126.0, "batch_reward": 11.824687957763672, "critic_loss": 764.3394775390625, "actor_loss": -1641.360107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.156383752822876, "alpha_loss": 0.11457279324531555, "alpha_value": 0.3490953719608681, "duration": 1.7100141048431396, "info_normalized_performance_mean": 0.34621182084083557, "info_normalized_performance_final": 0.42200854420661926, "info_performance_mean": 0.34621182084083557, "info_performance_final": 0.42200854420661926, "step": 813000}
{"episode_reward": 692.4236874236868, "episode": 8131.0, "batch_reward": 12.222963333129883, "critic_loss": 237.79495239257812, "actor_loss": -1706.985595703125, "actor_target_entropy": -3.0, "actor_entropy": 1.052988052368164, "alpha_loss": -0.014271557331085205, "alpha_value": 0.34974184233167105, "duration": 1.525101900100708, "info_normalized_performance_mean": 0.6377195119857788, "info_normalized_performance_final": 0.6943877339363098, "info_performance_mean": 0.6377195119857788, "info_performance_final": 0.6943877339363098, "step": 813500}
{"episode_reward": 1275.4387755102039, "episode": 8136.0, "batch_reward": 13.22584342956543, "critic_loss": 605.22705078125, "actor_loss": -1751.527099609375, "actor_target_entropy": -3.0, "actor_entropy": 0.9627187252044678, "alpha_loss": -0.028497502207756042, "alpha_value": 0.34685365867435186, "duration": 1.6125330924987793, "info_normalized_performance_mean": 0.4922381341457367, "info_normalized_performance_final": 0.6333333253860474, "info_performance_mean": 0.4922381341457367, "info_performance_final": 0.6333333253860474, "step": 814000}
{"episode_reward": 984.4761904761893, "episode": 8141.0, "batch_reward": 12.028642654418945, "critic_loss": 258.3240966796875, "actor_loss": -1700.5955810546875, "actor_target_entropy": -3.0, "actor_entropy": 1.0091670751571655, "alpha_loss": 0.04421074688434601, "alpha_value": 0.3432537843576617, "duration": 1.5032215118408203, "info_normalized_performance_mean": 0.529410719871521, "info_normalized_performance_final": 0.574999988079071, "info_performance_mean": 0.529410719871521, "info_performance_final": 0.574999988079071, "step": 814500}
{"episode_reward": 1058.8214285714284, "episode": 8146.0, "batch_reward": 12.201481819152832, "critic_loss": 232.0554656982422, "actor_loss": -1706.34521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3787801265716553, "alpha_loss": 0.15649712085723877, "alpha_value": 0.33914893551766584, "duration": 1.4598240852355957, "info_normalized_performance_mean": 0.6668055653572083, "info_normalized_performance_final": 0.7373737096786499, "info_performance_mean": 0.6668055653572083, "info_performance_final": 0.7373737096786499, "step": 815000}
{"episode_reward": 1333.6111111111118, "episode": 8151.0, "batch_reward": 12.389644622802734, "critic_loss": 266.72369384765625, "actor_loss": -1693.9837646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4540668725967407, "alpha_loss": 0.1731235682964325, "alpha_value": 0.3365170795178402, "duration": 1.561058521270752, "info_normalized_performance_mean": 0.7193124294281006, "info_normalized_performance_final": 0.7640625238418579, "info_performance_mean": 0.7193124294281006, "info_performance_final": 0.7640625238418579, "step": 815500}
{"episode_reward": 1438.625, "episode": 8156.0, "batch_reward": 12.303298950195312, "critic_loss": 443.4024963378906, "actor_loss": -1676.897216796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0336685180664062, "alpha_loss": 0.10008974373340607, "alpha_value": 0.33264086773462814, "duration": 1.6141986846923828, "info_normalized_performance_mean": 0.44370102882385254, "info_normalized_performance_final": 0.5072527527809143, "info_performance_mean": 0.44370102882385254, "info_performance_final": 0.5072527527809143, "step": 816000}
{"episode_reward": 887.4021978021993, "episode": 8161.0, "batch_reward": 11.74957275390625, "critic_loss": 739.6541748046875, "actor_loss": -1639.47216796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5478787422180176, "alpha_loss": -0.1756504476070404, "alpha_value": 0.331038387108772, "duration": 1.5967299938201904, "info_normalized_performance_mean": 0.3793089985847473, "info_normalized_performance_final": 0.4356818199157715, "info_performance_mean": 0.3793089985847473, "info_performance_final": 0.4356818199157715, "step": 816500}
{"episode_reward": 758.6181818181822, "episode": 8166.0, "batch_reward": 12.174442291259766, "critic_loss": 658.8179321289062, "actor_loss": -1672.5067138671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9011093378067017, "alpha_loss": 0.11814189702272415, "alpha_value": 0.3280674991841224, "duration": 1.575244665145874, "info_normalized_performance_mean": 0.8569543957710266, "info_normalized_performance_final": 0.9202614426612854, "info_performance_mean": 0.8569543957710266, "info_performance_final": 0.9202614426612854, "step": 817000}
{"episode_reward": 1713.9084967320248, "episode": 8171.0, "batch_reward": 12.409788131713867, "critic_loss": 484.24334716796875, "actor_loss": -1682.123779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.940753161907196, "alpha_loss": -0.011033125221729279, "alpha_value": 0.32503180428880385, "duration": 1.476698398590088, "info_normalized_performance_mean": 0.5017063617706299, "info_normalized_performance_final": 0.5416666865348816, "info_performance_mean": 0.5017063617706299, "info_performance_final": 0.5416666865348816, "step": 817500}
{"episode_reward": 1003.4126984126998, "episode": 8176.0, "batch_reward": 12.15922737121582, "critic_loss": 176.70703125, "actor_loss": -1663.82763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9112212657928467, "alpha_loss": -0.05930439755320549, "alpha_value": 0.32226269269538793, "duration": 1.4810395240783691, "info_normalized_performance_mean": 0.5415816307067871, "info_normalized_performance_final": 0.5808477401733398, "info_performance_mean": 0.5415816307067871, "info_performance_final": 0.5808477401733398, "step": 818000}
{"episode_reward": 1083.163265306125, "episode": 8181.0, "batch_reward": 11.522892951965332, "critic_loss": 279.9261779785156, "actor_loss": -1662.951416015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1151264905929565, "alpha_loss": -0.11834852397441864, "alpha_value": 0.32260334591477574, "duration": 1.6088674068450928, "info_normalized_performance_mean": 0.8045499324798584, "info_normalized_performance_final": 0.8641666769981384, "info_performance_mean": 0.8045499324798584, "info_performance_final": 0.8641666769981384, "step": 818500}
{"episode_reward": 1609.0999999999976, "episode": 8186.0, "batch_reward": 12.300518035888672, "critic_loss": 445.1522216796875, "actor_loss": -1647.906005859375, "actor_target_entropy": -3.0, "actor_entropy": 0.983128547668457, "alpha_loss": -0.1359540969133377, "alpha_value": 0.31832729091582407, "duration": 1.6154325008392334, "info_normalized_performance_mean": 0.6614683270454407, "info_normalized_performance_final": 0.7103174328804016, "info_performance_mean": 0.6614683270454407, "info_performance_final": 0.7103174328804016, "step": 819000}
{"episode_reward": 1322.9365079365054, "episode": 8191.0, "batch_reward": 12.086052894592285, "critic_loss": 138.49710083007812, "actor_loss": -1653.17529296875, "actor_target_entropy": -3.0, "actor_entropy": 1.2931736707687378, "alpha_loss": 0.11504808813333511, "alpha_value": 0.3170204817845154, "duration": 1.5052289962768555, "info_normalized_performance_mean": 0.5071561932563782, "info_normalized_performance_final": 0.559374988079071, "info_performance_mean": 0.5071561932563782, "info_performance_final": 0.559374988079071, "step": 819500}
{"episode_reward": 1014.3125, "episode": 8196.0, "batch_reward": 11.20422077178955, "critic_loss": 259.69488525390625, "actor_loss": -1645.8668212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.5353832244873047, "alpha_loss": -0.01558469608426094, "alpha_value": 0.3156947614285559, "step": 820000}
{"duration": 19.193451404571533, "info_normalized_performance_mean": 0.7340002655982971, "info_normalized_performance_final": 0.7984126806259155, "info_performance_mean": 0.7340002655982971, "info_performance_final": 0.7984126806259155, "step": 820000}
{"episode_reward": 1468.0000000000005, "episode": 8201.0, "batch_reward": 12.196868896484375, "critic_loss": 510.3043518066406, "actor_loss": -1665.4854736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.1702234745025635, "alpha_loss": -0.10757086426019669, "alpha_value": 0.3128261068936126, "duration": 1.6371142864227295, "info_normalized_performance_mean": 0.45324164628982544, "info_normalized_performance_final": 0.503333330154419, "info_performance_mean": 0.45324164628982544, "info_performance_final": 0.503333330154419, "step": 820500}
{"episode_reward": 906.4833333333353, "episode": 8206.0, "batch_reward": 11.856790542602539, "critic_loss": 623.2763061523438, "actor_loss": -1632.6044921875, "actor_target_entropy": -3.0, "actor_entropy": 0.6525912284851074, "alpha_loss": -0.04431888088583946, "alpha_value": 0.31337755035308973, "duration": 1.5346930027008057, "info_normalized_performance_mean": 0.9252456426620483, "info_normalized_performance_final": 0.9955357313156128, "info_performance_mean": 0.9252456426620483, "info_performance_final": 0.9955357313156128, "step": 821000}
{"episode_reward": 1850.4910714285697, "episode": 8211.0, "batch_reward": 12.086297988891602, "critic_loss": 167.4429931640625, "actor_loss": -1673.9677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1219260692596436, "alpha_loss": 0.2716871201992035, "alpha_value": 0.31033902432652155, "duration": 1.5771639347076416, "info_normalized_performance_mean": 0.7604206800460815, "info_normalized_performance_final": 0.84375, "info_performance_mean": 0.7604206800460815, "info_performance_final": 0.84375, "step": 821500}
{"episode_reward": 1520.8413461538462, "episode": 8216.0, "batch_reward": 12.76772689819336, "critic_loss": 170.0186767578125, "actor_loss": -1666.584716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.6102395057678223, "alpha_loss": 0.016508284956216812, "alpha_value": 0.30935775809743127, "duration": 1.5638000965118408, "info_normalized_performance_mean": 0.6943132877349854, "info_normalized_performance_final": 0.7733516693115234, "info_performance_mean": 0.6943132877349854, "info_performance_final": 0.7733516693115234, "step": 822000}
{"episode_reward": 1388.6263736263747, "episode": 8221.0, "batch_reward": 12.571112632751465, "critic_loss": 202.16578674316406, "actor_loss": -1678.095947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0851905345916748, "alpha_loss": -0.03340233117341995, "alpha_value": 0.3078640526897057, "duration": 1.5610730648040771, "info_normalized_performance_mean": 0.8558334112167358, "info_normalized_performance_final": 0.9392361044883728, "info_performance_mean": 0.8558334112167358, "info_performance_final": 0.9392361044883728, "step": 822500}
{"episode_reward": 1711.6666666666636, "episode": 8226.0, "batch_reward": 12.131165504455566, "critic_loss": 261.3171691894531, "actor_loss": -1646.325439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.123591661453247, "alpha_loss": 0.20867589116096497, "alpha_value": 0.30643009347541983, "duration": 1.5543663501739502, "info_normalized_performance_mean": 0.39208853244781494, "info_normalized_performance_final": 0.4305555522441864, "info_performance_mean": 0.39208853244781494, "info_performance_final": 0.4305555522441864, "step": 823000}
{"episode_reward": 784.1769547325089, "episode": 8231.0, "batch_reward": 12.928476333618164, "critic_loss": 275.8326110839844, "actor_loss": -1680.308837890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2441954612731934, "alpha_loss": 0.21545274555683136, "alpha_value": 0.3042164164281329, "duration": 1.6036953926086426, "info_normalized_performance_mean": 0.839647114276886, "info_normalized_performance_final": 0.9176470637321472, "info_performance_mean": 0.839647114276886, "info_performance_final": 0.9176470637321472, "step": 823500}
{"episode_reward": 1679.2941176470563, "episode": 8236.0, "batch_reward": 12.451300621032715, "critic_loss": 127.34974670410156, "actor_loss": -1642.286865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1658660173416138, "alpha_loss": 0.05677327141165733, "alpha_value": 0.3045616086681611, "duration": 1.6099202632904053, "info_normalized_performance_mean": 0.7256667613983154, "info_normalized_performance_final": 0.7785714268684387, "info_performance_mean": 0.7256667613983154, "info_performance_final": 0.7785714268684387, "step": 824000}
{"episode_reward": 1451.3333333333353, "episode": 8241.0, "batch_reward": 12.000545501708984, "critic_loss": 284.64556884765625, "actor_loss": -1650.238525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.928159236907959, "alpha_loss": 0.17928332090377808, "alpha_value": 0.30528586431204113, "duration": 1.5988731384277344, "info_normalized_performance_mean": 0.5122119188308716, "info_normalized_performance_final": 0.5668724179267883, "info_performance_mean": 0.5122119188308716, "info_performance_final": 0.5668724179267883, "step": 824500}
{"episode_reward": 1024.423868312756, "episode": 8246.0, "batch_reward": 12.190536499023438, "critic_loss": 324.6949462890625, "actor_loss": -1657.043701171875, "actor_target_entropy": -3.0, "actor_entropy": 0.9104734063148499, "alpha_loss": -0.08048160374164581, "alpha_value": 0.30481811451962465, "duration": 1.4647438526153564, "info_normalized_performance_mean": 0.4868878126144409, "info_normalized_performance_final": 0.5197703838348389, "info_performance_mean": 0.4868878126144409, "info_performance_final": 0.5197703838348389, "step": 825000}
{"episode_reward": 973.7755102040812, "episode": 8251.0, "batch_reward": 12.527076721191406, "critic_loss": 329.5775146484375, "actor_loss": -1649.16650390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1253353357315063, "alpha_loss": -0.010979373939335346, "alpha_value": 0.3070424604311878, "duration": 1.5851986408233643, "info_normalized_performance_mean": 0.48484671115875244, "info_normalized_performance_final": 0.5332467555999756, "info_performance_mean": 0.48484671115875244, "info_performance_final": 0.5332467555999756, "step": 825500}
{"episode_reward": 969.6935064935084, "episode": 8256.0, "batch_reward": 12.390701293945312, "critic_loss": 195.09649658203125, "actor_loss": -1675.73583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.6213310956954956, "alpha_loss": 0.10589510947465897, "alpha_value": 0.30835149717543553, "duration": 1.433579444885254, "info_normalized_performance_mean": 0.6289583444595337, "info_normalized_performance_final": 0.6770833134651184, "info_performance_mean": 0.6289583444595337, "info_performance_final": 0.6770833134651184, "step": 826000}
{"episode_reward": 1257.9166666666667, "episode": 8261.0, "batch_reward": 12.068817138671875, "critic_loss": 374.2420654296875, "actor_loss": -1655.394775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5346741676330566, "alpha_loss": -0.15061405301094055, "alpha_value": 0.3094777768118827, "duration": 1.5533170700073242, "info_normalized_performance_mean": 0.48207932710647583, "info_normalized_performance_final": 0.5237379670143127, "info_performance_mean": 0.48207932710647583, "info_performance_final": 0.5237379670143127, "step": 826500}
{"episode_reward": 964.1586538461555, "episode": 8266.0, "batch_reward": 11.641940116882324, "critic_loss": 1938.5535888671875, "actor_loss": -1634.7767333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.193238377571106, "alpha_loss": -0.10497497022151947, "alpha_value": 0.31136348838452493, "duration": 1.4874799251556396, "info_normalized_performance_mean": 0.8245517015457153, "info_normalized_performance_final": 0.8920454382896423, "info_performance_mean": 0.8245517015457153, "info_performance_final": 0.8920454382896423, "step": 827000}
{"episode_reward": 1649.1035353535337, "episode": 8271.0, "batch_reward": 12.809569358825684, "critic_loss": 185.6876983642578, "actor_loss": -1711.105712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7459364533424377, "alpha_loss": -0.011010900139808655, "alpha_value": 0.3130313117923294, "duration": 1.5563149452209473, "info_normalized_performance_mean": 0.7267140746116638, "info_normalized_performance_final": 0.7799999713897705, "info_performance_mean": 0.7267140746116638, "info_performance_final": 0.7799999713897705, "step": 827500}
{"episode_reward": 1453.42857142857, "episode": 8276.0, "batch_reward": 11.779123306274414, "critic_loss": 114.48410034179688, "actor_loss": -1654.8409423828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8818676471710205, "alpha_loss": -0.17463672161102295, "alpha_value": 0.3116781817415959, "duration": 1.6205494403839111, "info_normalized_performance_mean": 0.8143271803855896, "info_normalized_performance_final": 0.8745454549789429, "info_performance_mean": 0.8143271803855896, "info_performance_final": 0.8745454549789429, "step": 828000}
{"episode_reward": 1628.654545454546, "episode": 8281.0, "batch_reward": 12.56331729888916, "critic_loss": 166.48422241210938, "actor_loss": -1670.8726806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.465976595878601, "alpha_loss": 0.19442659616470337, "alpha_value": 0.3113801078789512, "duration": 1.5434963703155518, "info_normalized_performance_mean": 0.8649833798408508, "info_normalized_performance_final": 0.9300000071525574, "info_performance_mean": 0.8649833798408508, "info_performance_final": 0.9300000071525574, "step": 828500}
{"episode_reward": 1729.9666666666642, "episode": 8286.0, "batch_reward": 12.708396911621094, "critic_loss": 268.84564208984375, "actor_loss": -1685.56591796875, "actor_target_entropy": -3.0, "actor_entropy": 1.2614290714263916, "alpha_loss": 0.194964200258255, "alpha_value": 0.30826608153836116, "duration": 1.562148094177246, "info_normalized_performance_mean": 0.9031445384025574, "info_normalized_performance_final": 0.970703125, "info_performance_mean": 0.9031445384025574, "info_performance_final": 0.970703125, "step": 829000}
{"episode_reward": 1806.2890625, "episode": 8291.0, "batch_reward": 12.113664627075195, "critic_loss": 706.86279296875, "actor_loss": -1620.139892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.442664384841919, "alpha_loss": -0.1267404556274414, "alpha_value": 0.30539131685454357, "duration": 1.500983715057373, "info_normalized_performance_mean": 0.4810429513454437, "info_normalized_performance_final": 0.5275974273681641, "info_performance_mean": 0.4810429513454437, "info_performance_final": 0.5275974273681641, "step": 829500}
{"episode_reward": 962.0860389610408, "episode": 8296.0, "batch_reward": 12.171590805053711, "critic_loss": 474.2943115234375, "actor_loss": -1650.236328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7700327634811401, "alpha_loss": 0.06153132766485214, "alpha_value": 0.3032829942881618, "step": 830000}
{"duration": 18.870429039001465, "info_normalized_performance_mean": 0.246011883020401, "info_normalized_performance_final": 0.27794313430786133, "info_performance_mean": 0.246011883020401, "info_performance_final": 0.27794313430786133, "step": 830000}
{"episode_reward": 492.02380952380923, "episode": 8301.0, "batch_reward": 11.715768814086914, "critic_loss": 387.3138732910156, "actor_loss": -1591.943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.988616943359375, "alpha_loss": 0.06598423421382904, "alpha_value": 0.30079044630686247, "duration": 1.6380767822265625, "info_normalized_performance_mean": 0.796867311000824, "info_normalized_performance_final": 0.8572530746459961, "info_performance_mean": 0.796867311000824, "info_performance_final": 0.8572530746459961, "step": 830500}
{"episode_reward": 1593.7345679012362, "episode": 8306.0, "batch_reward": 11.981595993041992, "critic_loss": 337.0289306640625, "actor_loss": -1638.557373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1337151527404785, "alpha_loss": 0.04846299812197685, "alpha_value": 0.29761647622311244, "duration": 1.5812833309173584, "info_normalized_performance_mean": 0.6679253578186035, "info_normalized_performance_final": 0.7233560085296631, "info_performance_mean": 0.6679253578186035, "info_performance_final": 0.7233560085296631, "step": 831000}
{"episode_reward": 1335.8503401360526, "episode": 8311.0, "batch_reward": 12.689109802246094, "critic_loss": 375.019287109375, "actor_loss": -1667.445556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0380563735961914, "alpha_loss": 0.2561568021774292, "alpha_value": 0.2952007363556359, "duration": 1.5497772693634033, "info_normalized_performance_mean": 0.401874840259552, "info_normalized_performance_final": 0.44334161281585693, "info_performance_mean": 0.401874840259552, "info_performance_final": 0.44334161281585693, "step": 831500}
{"episode_reward": 803.7496553625593, "episode": 8316.0, "batch_reward": 12.431418418884277, "critic_loss": 180.42596435546875, "actor_loss": -1663.6251220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3272266387939453, "alpha_loss": 0.051080793142318726, "alpha_value": 0.2955507110826241, "duration": 1.4998242855072021, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 832000}
{"episode_reward": 0.0, "episode": 8321.0, "batch_reward": 11.978971481323242, "critic_loss": 765.4808959960938, "actor_loss": -1670.0518798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3092012405395508, "alpha_loss": -0.015781231224536896, "alpha_value": 0.29472658475647884, "duration": 1.770357370376587, "info_normalized_performance_mean": 0.27622103691101074, "info_normalized_performance_final": 0.30757850408554077, "info_performance_mean": 0.27622103691101074, "info_performance_final": 0.30757850408554077, "step": 832500}
{"episode_reward": 552.4419663177058, "episode": 8326.0, "batch_reward": 13.018259048461914, "critic_loss": 432.14813232421875, "actor_loss": -1695.2783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1568305492401123, "alpha_loss": -0.19445253908634186, "alpha_value": 0.2970858534578163, "duration": 1.440777063369751, "info_normalized_performance_mean": 0.17663750052452087, "info_normalized_performance_final": 0.1875, "info_performance_mean": 0.17663750052452087, "info_performance_final": 0.1875, "step": 833000}
{"episode_reward": 353.275, "episode": 8331.0, "batch_reward": 12.746519088745117, "critic_loss": 1578.87255859375, "actor_loss": -1655.7054443359375, "actor_target_entropy": -3.0, "actor_entropy": 1.1331820487976074, "alpha_loss": -0.06600196659564972, "alpha_value": 0.2972831166267175, "duration": 1.6033904552459717, "info_normalized_performance_mean": 0.4539125859737396, "info_normalized_performance_final": 0.5104463696479797, "info_performance_mean": 0.4539125859737396, "info_performance_final": 0.5104463696479797, "step": 833500}
{"episode_reward": 907.8252611585939, "episode": 8336.0, "batch_reward": 11.85888671875, "critic_loss": 155.34640502929688, "actor_loss": -1604.04345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2409372329711914, "alpha_loss": 0.10722006857395172, "alpha_value": 0.29740660910671635, "duration": 1.60672926902771, "info_normalized_performance_mean": 0.6712942719459534, "info_normalized_performance_final": 0.7429864406585693, "info_performance_mean": 0.6712942719459534, "info_performance_final": 0.7429864406585693, "step": 834000}
{"episode_reward": 1342.588235294118, "episode": 8341.0, "batch_reward": 13.080077171325684, "critic_loss": 263.6069030761719, "actor_loss": -1687.491943359375, "actor_target_entropy": -3.0, "actor_entropy": 1.149024486541748, "alpha_loss": 0.029875382781028748, "alpha_value": 0.29879238074293857, "duration": 1.4773201942443848, "info_normalized_performance_mean": 0.6451042294502258, "info_normalized_performance_final": 0.6953125, "info_performance_mean": 0.6451042294502258, "info_performance_final": 0.6953125, "step": 834500}
{"episode_reward": 1290.2083333333333, "episode": 8346.0, "batch_reward": 13.165895462036133, "critic_loss": 303.09234619140625, "actor_loss": -1658.2889404296875, "actor_target_entropy": -3.0, "actor_entropy": 1.545119285583496, "alpha_loss": 0.2476624995470047, "alpha_value": 0.2997917929088853, "duration": 1.4645230770111084, "info_normalized_performance_mean": 0.5236161947250366, "info_normalized_performance_final": 0.5675223469734192, "info_performance_mean": 0.5236161947250366, "info_performance_final": 0.5675223469734192, "step": 835000}
{"episode_reward": 1047.2321428571436, "episode": 8351.0, "batch_reward": 12.994235038757324, "critic_loss": 200.73419189453125, "actor_loss": -1685.5029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.5487861037254333, "alpha_loss": 0.1886676847934723, "alpha_value": 0.2988374080439225, "duration": 1.6821062564849854, "info_normalized_performance_mean": 0.2809058427810669, "info_normalized_performance_final": 0.31452637910842896, "info_performance_mean": 0.2809058427810669, "info_performance_final": 0.31452637910842896, "step": 835500}
{"episode_reward": 561.8118245390972, "episode": 8356.0, "batch_reward": 12.870780944824219, "critic_loss": 667.520751953125, "actor_loss": -1686.942626953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9780923128128052, "alpha_loss": 0.053462915122509, "alpha_value": 0.29695541932982855, "duration": 1.5879178047180176, "info_normalized_performance_mean": 0.6827059388160706, "info_normalized_performance_final": 0.7247058749198914, "info_performance_mean": 0.6827059388160706, "info_performance_final": 0.7247058749198914, "step": 836000}
{"episode_reward": 1365.4117647058827, "episode": 8361.0, "batch_reward": 12.04416275024414, "critic_loss": 231.09913635253906, "actor_loss": -1660.635009765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9485558271408081, "alpha_loss": -0.013738803565502167, "alpha_value": 0.29436503269933845, "duration": 1.632037878036499, "info_normalized_performance_mean": 0.6108729839324951, "info_normalized_performance_final": 0.6633597612380981, "info_performance_mean": 0.6108729839324951, "info_performance_final": 0.6633597612380981, "step": 836500}
{"episode_reward": 1221.7460317460302, "episode": 8366.0, "batch_reward": 12.19729232788086, "critic_loss": 249.8876190185547, "actor_loss": -1606.8331298828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3463609218597412, "alpha_loss": 0.0064350515604019165, "alpha_value": 0.29513715764635445, "duration": 1.7203540802001953, "info_normalized_performance_mean": 0.4927213191986084, "info_normalized_performance_final": 0.5761599540710449, "info_performance_mean": 0.4927213191986084, "info_performance_final": 0.5761599540710449, "step": 837000}
{"episode_reward": 985.4426129426132, "episode": 8371.0, "batch_reward": 12.33538818359375, "critic_loss": 179.78236389160156, "actor_loss": -1638.624755859375, "actor_target_entropy": -3.0, "actor_entropy": 1.0229544639587402, "alpha_loss": 0.07112728804349899, "alpha_value": 0.2934440215703936, "duration": 1.492539882659912, "info_normalized_performance_mean": 0.3696945905685425, "info_normalized_performance_final": 0.39772728085517883, "info_performance_mean": 0.3696945905685425, "info_performance_final": 0.39772728085517883, "step": 837500}
{"episode_reward": 739.3892045454554, "episode": 8376.0, "batch_reward": 13.063982009887695, "critic_loss": 324.78985595703125, "actor_loss": -1702.83251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.316047191619873, "alpha_loss": -0.006398782134056091, "alpha_value": 0.29300530670956276, "duration": 1.468386173248291, "info_normalized_performance_mean": 0.7554733753204346, "info_normalized_performance_final": 0.8118686676025391, "info_performance_mean": 0.7554733753204346, "info_performance_final": 0.8118686676025391, "step": 838000}
{"episode_reward": 1510.9469696969693, "episode": 8381.0, "batch_reward": 12.20424747467041, "critic_loss": 622.875732421875, "actor_loss": -1667.106201171875, "actor_target_entropy": -3.0, "actor_entropy": 0.9806193113327026, "alpha_loss": 0.0023957043886184692, "alpha_value": 0.29169604540692734, "duration": 1.58400297164917, "info_normalized_performance_mean": 0.18175451457500458, "info_normalized_performance_final": 0.19705602526664734, "info_performance_mean": 0.18175451457500458, "info_performance_final": 0.19705602526664734, "step": 838500}
{"episode_reward": 363.5090218423556, "episode": 8386.0, "batch_reward": 13.34847354888916, "critic_loss": 175.7036590576172, "actor_loss": -1683.2830810546875, "actor_target_entropy": -3.0, "actor_entropy": 1.373486876487732, "alpha_loss": 0.15826013684272766, "alpha_value": 0.2928716781749039, "duration": 1.568087100982666, "info_normalized_performance_mean": 0.20281818509101868, "info_normalized_performance_final": 0.2206818163394928, "info_performance_mean": 0.20281818509101868, "info_performance_final": 0.2206818163394928, "step": 839000}
{"episode_reward": 405.6363636363641, "episode": 8391.0, "batch_reward": 12.703407287597656, "critic_loss": 896.1862182617188, "actor_loss": -1651.808837890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0362468957901, "alpha_loss": 0.12701821327209473, "alpha_value": 0.2935570020897726, "duration": 1.5843634605407715, "info_normalized_performance_mean": 0.6104525923728943, "info_normalized_performance_final": 0.6561086177825928, "info_performance_mean": 0.6104525923728943, "info_performance_final": 0.6561086177825928, "step": 839500}
{"episode_reward": 1220.904977375566, "episode": 8396.0, "batch_reward": 12.609169960021973, "critic_loss": 690.2880859375, "actor_loss": -1622.909423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.2181295156478882, "alpha_loss": 0.05290195345878601, "alpha_value": 0.29249519070459284, "step": 840000}
{"duration": 18.56829071044922, "info_normalized_performance_mean": 0.8720858693122864, "info_normalized_performance_final": 0.9357143044471741, "info_performance_mean": 0.8720858693122864, "info_performance_final": 0.9357143044471741, "step": 840000}
{"episode_reward": 1744.17142857143, "episode": 8401.0, "batch_reward": 11.85579776763916, "critic_loss": 202.668212890625, "actor_loss": -1641.476318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2320367097854614, "alpha_loss": -0.08652463555335999, "alpha_value": 0.29154354807283034, "duration": 1.5497324466705322, "info_normalized_performance_mean": 0.22135066986083984, "info_normalized_performance_final": 0.24207791686058044, "info_performance_mean": 0.22135066986083984, "info_performance_final": 0.24207791686058044, "step": 840500}
{"episode_reward": 442.70129870129915, "episode": 8406.0, "batch_reward": 12.40318775177002, "critic_loss": 294.6729431152344, "actor_loss": -1675.4722900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1295708417892456, "alpha_loss": -0.02476951852440834, "alpha_value": 0.2915397251475139, "duration": 1.6348066329956055, "info_normalized_performance_mean": 0.8000952005386353, "info_normalized_performance_final": 0.8698412775993347, "info_performance_mean": 0.8000952005386353, "info_performance_final": 0.8698412775993347, "step": 841000}
{"episode_reward": 1600.190476190474, "episode": 8411.0, "batch_reward": 12.560064315795898, "critic_loss": 253.13238525390625, "actor_loss": -1648.469970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2383594512939453, "alpha_loss": 0.015123514458537102, "alpha_value": 0.29148623288601444, "duration": 1.4896619319915771, "info_normalized_performance_mean": 0.5511472821235657, "info_normalized_performance_final": 0.606249988079071, "info_performance_mean": 0.5511472821235657, "info_performance_final": 0.606249988079071, "step": 841500}
{"episode_reward": 1102.294642857143, "episode": 8416.0, "batch_reward": 12.48582649230957, "critic_loss": 335.60260009765625, "actor_loss": -1641.677490234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2597851753234863, "alpha_loss": -0.004953108727931976, "alpha_value": 0.29125093476213976, "duration": 1.6273229122161865, "info_normalized_performance_mean": 0.6490475535392761, "info_normalized_performance_final": 0.695105791091919, "info_performance_mean": 0.6490475535392761, "info_performance_final": 0.695105791091919, "step": 842000}
{"episode_reward": 1298.0952380952374, "episode": 8421.0, "batch_reward": 12.067952156066895, "critic_loss": 435.5813293457031, "actor_loss": -1589.88525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9969856142997742, "alpha_loss": 0.10612690448760986, "alpha_value": 0.2914907921768589, "duration": 1.3963449001312256, "info_normalized_performance_mean": 0.5841428637504578, "info_normalized_performance_final": 0.6214285492897034, "info_performance_mean": 0.5841428637504578, "info_performance_final": 0.6214285492897034, "step": 842500}
{"episode_reward": 1168.285714285714, "episode": 8426.0, "batch_reward": 11.61728286743164, "critic_loss": 205.0148162841797, "actor_loss": -1601.73974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.8927021622657776, "alpha_loss": 0.11187972873449326, "alpha_value": 0.2904657143991328, "duration": 1.6177968978881836, "info_normalized_performance_mean": 0.7578355669975281, "info_normalized_performance_final": 0.8131313323974609, "info_performance_mean": 0.7578355669975281, "info_performance_final": 0.8131313323974609, "step": 843000}
{"episode_reward": 1515.6709956709963, "episode": 8431.0, "batch_reward": 11.687392234802246, "critic_loss": 214.45541381835938, "actor_loss": -1634.859619140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6523649096488953, "alpha_loss": -0.00953071191906929, "alpha_value": 0.2904628084110168, "duration": 1.458927869796753, "info_normalized_performance_mean": 0.4809672236442566, "info_normalized_performance_final": 0.5208333134651184, "info_performance_mean": 0.4809672236442566, "info_performance_final": 0.5208333134651184, "step": 843500}
{"episode_reward": 961.9345238095225, "episode": 8436.0, "batch_reward": 12.485057830810547, "critic_loss": 210.447265625, "actor_loss": -1623.146728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.060451865196228, "alpha_loss": -0.03267700970172882, "alpha_value": 0.28906211982651114, "duration": 1.454026699066162, "info_normalized_performance_mean": 0.5027679204940796, "info_normalized_performance_final": 0.5401785969734192, "info_performance_mean": 0.5027679204940796, "info_performance_final": 0.5401785969734192, "step": 844000}
{"episode_reward": 1005.5357142857152, "episode": 8441.0, "batch_reward": 12.377705574035645, "critic_loss": 214.51791381835938, "actor_loss": -1591.8851318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.0454204082489014, "alpha_loss": 0.0562988743185997, "alpha_value": 0.2890948610700744, "duration": 1.3973958492279053, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 844500}
{"episode_reward": 0.0, "episode": 8446.0, "batch_reward": 12.255903244018555, "critic_loss": 463.4137268066406, "actor_loss": -1638.042724609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3235161304473877, "alpha_loss": -0.15751802921295166, "alpha_value": 0.28836199069165397, "duration": 1.5461680889129639, "info_normalized_performance_mean": 0.46635517477989197, "info_normalized_performance_final": 0.5051081776618958, "info_performance_mean": 0.46635517477989197, "info_performance_final": 0.5051081776618958, "step": 845000}
{"episode_reward": 932.7103365384609, "episode": 8451.0, "batch_reward": 11.80872917175293, "critic_loss": 354.80859375, "actor_loss": -1620.3017578125, "actor_target_entropy": -3.0, "actor_entropy": 0.93080735206604, "alpha_loss": -0.052288688719272614, "alpha_value": 0.2887978620818989, "duration": 1.4868407249450684, "info_normalized_performance_mean": 0.6455627679824829, "info_normalized_performance_final": 0.7196969985961914, "info_performance_mean": 0.6455627679824829, "info_performance_final": 0.7196969985961914, "step": 845500}
{"episode_reward": 1291.1255411255422, "episode": 8456.0, "batch_reward": 12.433042526245117, "critic_loss": 845.8800048828125, "actor_loss": -1620.25732421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8178855180740356, "alpha_loss": 0.1564268171787262, "alpha_value": 0.28884110740859414, "duration": 1.4509220123291016, "info_normalized_performance_mean": 0.3309175968170166, "info_normalized_performance_final": 0.3616071343421936, "info_performance_mean": 0.3309175968170166, "info_performance_final": 0.3616071343421936, "step": 846000}
{"episode_reward": 661.8353174603168, "episode": 8461.0, "batch_reward": 12.09372329711914, "critic_loss": 430.6632385253906, "actor_loss": -1611.555908203125, "actor_target_entropy": -3.0, "actor_entropy": 0.7608822584152222, "alpha_loss": -0.027400804683566093, "alpha_value": 0.2884322800005602, "duration": 1.4650816917419434, "info_normalized_performance_mean": 0.4910244047641754, "info_normalized_performance_final": 0.5310047268867493, "info_performance_mean": 0.4910244047641754, "info_performance_final": 0.5310047268867493, "step": 846500}
{"episode_reward": 982.0486656200935, "episode": 8466.0, "batch_reward": 12.298885345458984, "critic_loss": 380.30706787109375, "actor_loss": -1630.060302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1332483291625977, "alpha_loss": 0.22384658455848694, "alpha_value": 0.28784669299210547, "duration": 1.4456653594970703, "info_normalized_performance_mean": 0.6035892963409424, "info_normalized_performance_final": 0.6553571224212646, "info_performance_mean": 0.6035892963409424, "info_performance_final": 0.6553571224212646, "step": 847000}
{"episode_reward": 1207.1785714285727, "episode": 8471.0, "batch_reward": 12.251148223876953, "critic_loss": 331.6587829589844, "actor_loss": -1606.4801025390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0959703922271729, "alpha_loss": -0.17122840881347656, "alpha_value": 0.28668497010641675, "duration": 1.4634275436401367, "info_normalized_performance_mean": 0.2977472245693207, "info_normalized_performance_final": 0.3214285671710968, "info_performance_mean": 0.2977472245693207, "info_performance_final": 0.3214285671710968, "step": 847500}
{"episode_reward": 595.4945054945061, "episode": 8476.0, "batch_reward": 12.805950164794922, "critic_loss": 684.6129150390625, "actor_loss": -1638.40185546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7516186237335205, "alpha_loss": -0.027084654197096825, "alpha_value": 0.28630298229804935, "duration": 1.4425058364868164, "info_normalized_performance_mean": 0.688154935836792, "info_normalized_performance_final": 0.738095223903656, "info_performance_mean": 0.688154935836792, "info_performance_final": 0.738095223903656, "step": 848000}
{"episode_reward": 1376.3095238095268, "episode": 8481.0, "batch_reward": 12.800897598266602, "critic_loss": 176.36068725585938, "actor_loss": -1624.08447265625, "actor_target_entropy": -3.0, "actor_entropy": 0.8029983043670654, "alpha_loss": 0.02275143936276436, "alpha_value": 0.2870142309865023, "duration": 1.519972801208496, "info_normalized_performance_mean": 0.6943784952163696, "info_normalized_performance_final": 0.7458255887031555, "info_performance_mean": 0.6943784952163696, "info_performance_final": 0.7458255887031555, "step": 848500}
{"episode_reward": 1388.7569573283838, "episode": 8486.0, "batch_reward": 12.415075302124023, "critic_loss": 407.5757141113281, "actor_loss": -1635.18212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2350008487701416, "alpha_loss": 0.057675786316394806, "alpha_value": 0.2859407851734555, "duration": 1.4980368614196777, "info_normalized_performance_mean": 0.7529038786888123, "info_normalized_performance_final": 0.8214285969734192, "info_performance_mean": 0.7529038786888123, "info_performance_final": 0.8214285969734192, "step": 849000}
{"episode_reward": 1505.8078231292495, "episode": 8491.0, "batch_reward": 12.465778350830078, "critic_loss": 231.1901397705078, "actor_loss": -1652.927001953125, "actor_target_entropy": -3.0, "actor_entropy": 0.5440331101417542, "alpha_loss": -0.13673046231269836, "alpha_value": 0.2849619391454275, "duration": 1.480053186416626, "info_normalized_performance_mean": 0.7604876160621643, "info_normalized_performance_final": 0.8151927590370178, "info_performance_mean": 0.7604876160621643, "info_performance_final": 0.8151927590370178, "step": 849500}
{"episode_reward": 1520.9750566893415, "episode": 8496.0, "batch_reward": 11.912888526916504, "critic_loss": 385.172119140625, "actor_loss": -1597.42578125, "actor_target_entropy": -3.0, "actor_entropy": 0.5353061556816101, "alpha_loss": 0.13533231616020203, "alpha_value": 0.2851177209842313, "step": 850000}
{"duration": 18.81638193130493, "info_normalized_performance_mean": 0.4522870182991028, "info_normalized_performance_final": 0.503337562084198, "info_performance_mean": 0.4522870182991028, "info_performance_final": 0.503337562084198, "step": 850000}
{"episode_reward": 904.574062301333, "episode": 8501.0, "batch_reward": 12.28207778930664, "critic_loss": 161.38088989257812, "actor_loss": -1623.3505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1045868396759033, "alpha_loss": -0.11067977547645569, "alpha_value": 0.28480306054390975, "duration": 1.4654524326324463, "info_normalized_performance_mean": 0.10748659074306488, "info_normalized_performance_final": 0.11785714328289032, "info_performance_mean": 0.10748659074306488, "info_performance_final": 0.11785714328289032, "step": 850500}
{"episode_reward": 214.9732142857145, "episode": 8506.0, "batch_reward": 10.861100196838379, "critic_loss": 261.8812255859375, "actor_loss": -1598.914794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.6982609629631042, "alpha_loss": -0.09648250043392181, "alpha_value": 0.28542657983779307, "duration": 1.6040327548980713, "info_normalized_performance_mean": 0.6858400106430054, "info_normalized_performance_final": 0.7379999756813049, "info_performance_mean": 0.6858400106430054, "info_performance_final": 0.7379999756813049, "step": 851000}
{"episode_reward": 1371.6799999999994, "episode": 8511.0, "batch_reward": 11.731842041015625, "critic_loss": 339.24468994140625, "actor_loss": -1590.908935546875, "actor_target_entropy": -3.0, "actor_entropy": 0.583103597164154, "alpha_loss": 0.023311147466301918, "alpha_value": 0.2844044839293136, "duration": 1.4745469093322754, "info_normalized_performance_mean": 0.6472851634025574, "info_normalized_performance_final": 0.6953125, "info_performance_mean": 0.6472851634025574, "info_performance_final": 0.6953125, "step": 851500}
{"episode_reward": 1294.5703125, "episode": 8516.0, "batch_reward": 11.925743103027344, "critic_loss": 349.8162841796875, "actor_loss": -1580.60986328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0951712131500244, "alpha_loss": -0.22637061774730682, "alpha_value": 0.2837399235847504, "duration": 1.559781551361084, "info_normalized_performance_mean": 0.46738967299461365, "info_normalized_performance_final": 0.5194805264472961, "info_performance_mean": 0.46738967299461365, "info_performance_final": 0.5194805264472961, "step": 852000}
{"episode_reward": 934.7792207792218, "episode": 8521.0, "batch_reward": 12.596016883850098, "critic_loss": 170.18130493164062, "actor_loss": -1609.09521484375, "actor_target_entropy": -3.0, "actor_entropy": 0.8898265361785889, "alpha_loss": 0.31271544098854065, "alpha_value": 0.2837710838094671, "duration": 1.5282549858093262, "info_normalized_performance_mean": 0.4171817898750305, "info_normalized_performance_final": 0.46597403287887573, "info_performance_mean": 0.4171817898750305, "info_performance_final": 0.46597403287887573, "step": 852500}
{"episode_reward": 834.3636363636365, "episode": 8526.0, "batch_reward": 11.880325317382812, "critic_loss": 261.03033447265625, "actor_loss": -1592.05810546875, "actor_target_entropy": -3.0, "actor_entropy": 1.002553939819336, "alpha_loss": 0.03377359360456467, "alpha_value": 0.2819108444133569, "duration": 1.5816552639007568, "info_normalized_performance_mean": 0.4261294901371002, "info_normalized_performance_final": 0.4765909016132355, "info_performance_mean": 0.4261294901371002, "info_performance_final": 0.4765909016132355, "step": 853000}
{"episode_reward": 852.2590909090892, "episode": 8531.0, "batch_reward": 12.652936935424805, "critic_loss": 142.33804321289062, "actor_loss": -1601.53125, "actor_target_entropy": -3.0, "actor_entropy": 0.9051518440246582, "alpha_loss": -0.03146573156118393, "alpha_value": 0.2805710041199843, "duration": 1.4909191131591797, "info_normalized_performance_mean": 0.9271725416183472, "info_normalized_performance_final": 0.9970238208770752, "info_performance_mean": 0.9271725416183472, "info_performance_final": 0.9970238208770752, "step": 853500}
{"episode_reward": 1854.3452380952356, "episode": 8536.0, "batch_reward": 12.268516540527344, "critic_loss": 315.0017395019531, "actor_loss": -1612.50244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7120522260665894, "alpha_loss": 0.020121179521083832, "alpha_value": 0.2785272791674117, "duration": 1.6211161613464355, "info_normalized_performance_mean": 0.5807716250419617, "info_normalized_performance_final": 0.6405507922172546, "info_performance_mean": 0.5807716250419617, "info_performance_final": 0.6405507922172546, "step": 854000}
{"episode_reward": 1161.5432098765407, "episode": 8541.0, "batch_reward": 12.592428207397461, "critic_loss": 372.38165283203125, "actor_loss": -1603.923828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9040498733520508, "alpha_loss": -0.20980632305145264, "alpha_value": 0.2776926920245798, "duration": 1.462280511856079, "info_normalized_performance_mean": 0.46785154938697815, "info_normalized_performance_final": 0.5078125, "info_performance_mean": 0.46785154938697815, "info_performance_final": 0.5078125, "step": 854500}
{"episode_reward": 935.703125, "episode": 8546.0, "batch_reward": 11.715993881225586, "critic_loss": 293.21148681640625, "actor_loss": -1566.6776123046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9168436527252197, "alpha_loss": -0.06899397820234299, "alpha_value": 0.2762640440575685, "duration": 1.4435701370239258, "info_normalized_performance_mean": 0.5748106241226196, "info_normalized_performance_final": 0.6167929172515869, "info_performance_mean": 0.5748106241226196, "info_performance_final": 0.6167929172515869, "step": 855000}
{"episode_reward": 1149.6212121212116, "episode": 8551.0, "batch_reward": 12.721466064453125, "critic_loss": 107.15127563476562, "actor_loss": -1610.46337890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9167650938034058, "alpha_loss": 0.15867261588573456, "alpha_value": 0.27731439731108193, "duration": 1.564683437347412, "info_normalized_performance_mean": 0.5085276961326599, "info_normalized_performance_final": 0.5770609378814697, "info_performance_mean": 0.5085276961326599, "info_performance_final": 0.5770609378814697, "step": 855500}
{"episode_reward": 1017.0554177005804, "episode": 8556.0, "batch_reward": 12.069796562194824, "critic_loss": 578.2618408203125, "actor_loss": -1586.0838623046875, "actor_target_entropy": -3.0, "actor_entropy": 0.7361435890197754, "alpha_loss": -0.1303132027387619, "alpha_value": 0.27650839916772013, "duration": 1.4059741497039795, "info_normalized_performance_mean": 0.0002604166802484542, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0002604166802484542, "info_performance_final": 0.0, "step": 856000}
{"episode_reward": 0.5208333333333333, "episode": 8561.0, "batch_reward": 12.453607559204102, "critic_loss": 232.79498291015625, "actor_loss": -1622.84716796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7664278745651245, "alpha_loss": -0.02465023100376129, "alpha_value": 0.2793898472704365, "duration": 1.5314559936523438, "info_normalized_performance_mean": 0.5796341896057129, "info_normalized_performance_final": 0.6281960010528564, "info_performance_mean": 0.5796341896057129, "info_performance_final": 0.6281960010528564, "step": 856500}
{"episode_reward": 1159.2684659090926, "episode": 8566.0, "batch_reward": 11.528773307800293, "critic_loss": 533.2823486328125, "actor_loss": -1614.5550537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.4519658386707306, "alpha_loss": -0.08725672960281372, "alpha_value": 0.28070562324855897, "duration": 1.6025216579437256, "info_normalized_performance_mean": 0.8481469750404358, "info_normalized_performance_final": 0.9284313917160034, "info_performance_mean": 0.8481469750404358, "info_performance_final": 0.9284313917160034, "step": 857000}
{"episode_reward": 1696.2941176470579, "episode": 8571.0, "batch_reward": 11.524673461914062, "critic_loss": 355.5907287597656, "actor_loss": -1545.4439697265625, "actor_target_entropy": -3.0, "actor_entropy": 0.5543205142021179, "alpha_loss": -0.015300199389457703, "alpha_value": 0.2812549261333447, "duration": 1.5358021259307861, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 857500}
{"episode_reward": 0.0, "episode": 8576.0, "batch_reward": 12.034669876098633, "critic_loss": 200.84336853027344, "actor_loss": -1598.567138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.0244247913360596, "alpha_loss": -0.03539986163377762, "alpha_value": 0.2866225043050336, "duration": 1.6241190433502197, "info_normalized_performance_mean": 0.38626816868782043, "info_normalized_performance_final": 0.49840909242630005, "info_performance_mean": 0.38626816868782043, "info_performance_final": 0.49840909242630005, "step": 858000}
{"episode_reward": 772.5363636363633, "episode": 8581.0, "batch_reward": 12.627670288085938, "critic_loss": 351.86065673828125, "actor_loss": -1616.67333984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8777976036071777, "alpha_loss": -0.06209529563784599, "alpha_value": 0.28918629070043667, "duration": 1.5732367038726807, "info_normalized_performance_mean": 0.0018749999580904841, "info_normalized_performance_final": 0.02130681835114956, "info_performance_mean": 0.0018749999580904841, "info_performance_final": 0.02130681835114956, "step": 858500}
{"episode_reward": 3.7500000000000004, "episode": 8586.0, "batch_reward": 12.24395751953125, "critic_loss": 770.726806640625, "actor_loss": -1557.251708984375, "actor_target_entropy": -3.0, "actor_entropy": 0.6111645698547363, "alpha_loss": 0.028229229152202606, "alpha_value": 0.2919896987174763, "duration": 1.4678456783294678, "info_normalized_performance_mean": 0.42204806208610535, "info_normalized_performance_final": 0.4581473171710968, "info_performance_mean": 0.42204806208610535, "info_performance_final": 0.4581473171710968, "step": 859000}
{"episode_reward": 844.095982142858, "episode": 8591.0, "batch_reward": 11.82033634185791, "critic_loss": 121.73283386230469, "actor_loss": -1561.841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7004750967025757, "alpha_loss": 0.04711347818374634, "alpha_value": 0.2934511117704124, "duration": 1.4790599346160889, "info_normalized_performance_mean": 0.47506943345069885, "info_normalized_performance_final": 0.5101010203361511, "info_performance_mean": 0.47506943345069885, "info_performance_final": 0.5101010203361511, "step": 859500}
{"episode_reward": 950.1388888888894, "episode": 8596.0, "batch_reward": 12.570062637329102, "critic_loss": 333.735107421875, "actor_loss": -1576.447998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5682942867279053, "alpha_loss": -0.0023355986922979355, "alpha_value": 0.2973222644424739, "step": 860000}
{"duration": 18.37320899963379, "info_normalized_performance_mean": 0.625243067741394, "info_normalized_performance_final": 0.6736111044883728, "info_performance_mean": 0.625243067741394, "info_performance_final": 0.6736111044883728, "step": 860000}
{"episode_reward": 1250.4861111111086, "episode": 8601.0, "batch_reward": 12.187861442565918, "critic_loss": 335.70831298828125, "actor_loss": -1565.6275634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.6304852962493896, "alpha_loss": -0.17617806792259216, "alpha_value": 0.30155301577309307, "duration": 1.5198137760162354, "info_normalized_performance_mean": 0.45426541566848755, "info_normalized_performance_final": 0.5018518567085266, "info_performance_mean": 0.45426541566848755, "info_performance_final": 0.5018518567085266, "step": 860500}
{"episode_reward": 908.5308641975328, "episode": 8606.0, "batch_reward": 12.243202209472656, "critic_loss": 592.9573974609375, "actor_loss": -1601.9208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9935063123703003, "alpha_loss": -0.1579868197441101, "alpha_value": 0.3070774548351897, "duration": 1.5808539390563965, "info_normalized_performance_mean": 0.4455074369907379, "info_normalized_performance_final": 0.48899999260902405, "info_performance_mean": 0.4455074369907379, "info_performance_final": 0.48899999260902405, "step": 861000}
{"episode_reward": 891.0149999999983, "episode": 8611.0, "batch_reward": 11.973898887634277, "critic_loss": 229.71304321289062, "actor_loss": -1565.806640625, "actor_target_entropy": -3.0, "actor_entropy": 0.776130199432373, "alpha_loss": 0.06328385323286057, "alpha_value": 0.3170671697444238, "duration": 1.5612928867340088, "info_normalized_performance_mean": 0.8069624304771423, "info_normalized_performance_final": 0.8712499737739563, "info_performance_mean": 0.8069624304771423, "info_performance_final": 0.8712499737739563, "step": 861500}
{"episode_reward": 1613.9249999999975, "episode": 8616.0, "batch_reward": 11.37713623046875, "critic_loss": 226.37242126464844, "actor_loss": -1559.59130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.7188055515289307, "alpha_loss": -0.23193925619125366, "alpha_value": 0.3262145473628014, "duration": 1.396582841873169, "info_normalized_performance_mean": 0.7632187008857727, "info_normalized_performance_final": 0.8187500238418579, "info_performance_mean": 0.7632187008857727, "info_performance_final": 0.8187500238418579, "step": 862000}
{"episode_reward": 1526.4375, "episode": 8621.0, "batch_reward": 11.480489730834961, "critic_loss": 410.17816162109375, "actor_loss": -1588.6103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8313834071159363, "alpha_loss": -0.1058509349822998, "alpha_value": 0.33438497828703806, "duration": 1.5753881931304932, "info_normalized_performance_mean": 0.9153769612312317, "info_normalized_performance_final": 0.9920634627342224, "info_performance_mean": 0.9153769612312317, "info_performance_final": 0.9920634627342224, "step": 862500}
{"episode_reward": 1830.7539682539705, "episode": 8626.0, "batch_reward": 11.271064758300781, "critic_loss": 251.41607666015625, "actor_loss": -1597.78857421875, "actor_target_entropy": -3.0, "actor_entropy": 0.5634504556655884, "alpha_loss": -0.16513340175151825, "alpha_value": 0.3406263070310447, "duration": 1.492865800857544, "info_normalized_performance_mean": 0.5902827382087708, "info_normalized_performance_final": 0.6408730149269104, "info_performance_mean": 0.5902827382087708, "info_performance_final": 0.6408730149269104, "step": 863000}
{"episode_reward": 1180.5654761904768, "episode": 8631.0, "batch_reward": 11.751073837280273, "critic_loss": 214.22540283203125, "actor_loss": -1610.2174072265625, "actor_target_entropy": -3.0, "actor_entropy": 0.6046847701072693, "alpha_loss": -0.16497837007045746, "alpha_value": 0.3481025096068411, "duration": 1.7340757846832275, "info_normalized_performance_mean": 0.5139545202255249, "info_normalized_performance_final": 0.5811966061592102, "info_performance_mean": 0.5139545202255249, "info_performance_final": 0.5811966061592102, "step": 863500}
{"episode_reward": 1027.9090354090365, "episode": 8636.0, "batch_reward": 12.346403121948242, "critic_loss": 589.7452392578125, "actor_loss": -1615.0916748046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8492411375045776, "alpha_loss": 0.15482395887374878, "alpha_value": 0.3535760138799562, "duration": 1.6269111633300781, "info_normalized_performance_mean": 0.7677468657493591, "info_normalized_performance_final": 0.8248456716537476, "info_performance_mean": 0.7677468657493591, "info_performance_final": 0.8248456716537476, "step": 864000}
{"episode_reward": 1535.4938271604924, "episode": 8641.0, "batch_reward": 10.700424194335938, "critic_loss": 342.628173828125, "actor_loss": -1601.047119140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6400085687637329, "alpha_loss": -0.28221213817596436, "alpha_value": 0.356756156459496, "duration": 1.5510752201080322, "info_normalized_performance_mean": 0.825848400592804, "info_normalized_performance_final": 0.8772321343421936, "info_performance_mean": 0.825848400592804, "info_performance_final": 0.8772321343421936, "step": 864500}
{"episode_reward": 1651.6964285714303, "episode": 8646.0, "batch_reward": 12.478960037231445, "critic_loss": 311.4341125488281, "actor_loss": -1657.672119140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8374350666999817, "alpha_loss": -0.002398315817117691, "alpha_value": 0.35947094536193425, "duration": 1.46639084815979, "info_normalized_performance_mean": 0.6127380728721619, "info_normalized_performance_final": 0.6686508059501648, "info_performance_mean": 0.6127380728721619, "info_performance_final": 0.6686508059501648, "step": 865000}
{"episode_reward": 1225.4761904761915, "episode": 8651.0, "batch_reward": 12.814610481262207, "critic_loss": 232.7836456298828, "actor_loss": -1642.381103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9910786747932434, "alpha_loss": 0.15191584825515747, "alpha_value": 0.3599573792934882, "duration": 1.7476205825805664, "info_normalized_performance_mean": 0.4458066523075104, "info_normalized_performance_final": 0.49772968888282776, "info_performance_mean": 0.4458066523075104, "info_performance_final": 0.49772968888282776, "step": 865500}
{"episode_reward": 891.6132478632467, "episode": 8656.0, "batch_reward": 12.294183731079102, "critic_loss": 188.47921752929688, "actor_loss": -1619.135009765625, "actor_target_entropy": -3.0, "actor_entropy": 0.48207682371139526, "alpha_loss": -0.1785823106765747, "alpha_value": 0.35924772266672284, "duration": 1.519777774810791, "info_normalized_performance_mean": 0.3832934498786926, "info_normalized_performance_final": 0.4193548262119293, "info_performance_mean": 0.3832934498786926, "info_performance_final": 0.4193548262119293, "step": 866000}
{"episode_reward": 766.5870171246507, "episode": 8661.0, "batch_reward": 11.630130767822266, "critic_loss": 329.14532470703125, "actor_loss": -1618.4814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.3812762498855591, "alpha_loss": -0.003954920917749405, "alpha_value": 0.35764515528186663, "duration": 1.484844446182251, "info_normalized_performance_mean": 0.742526113986969, "info_normalized_performance_final": 0.8020833134651184, "info_performance_mean": 0.742526113986969, "info_performance_final": 0.8020833134651184, "step": 866500}
{"episode_reward": 1485.0520833333346, "episode": 8666.0, "batch_reward": 12.64533805847168, "critic_loss": 252.10333251953125, "actor_loss": -1639.5003662109375, "actor_target_entropy": -3.0, "actor_entropy": 0.39661383628845215, "alpha_loss": 0.04325183480978012, "alpha_value": 0.3537408938866728, "duration": 1.540121078491211, "info_normalized_performance_mean": 0.5399085283279419, "info_normalized_performance_final": 0.5925925970077515, "info_performance_mean": 0.5399085283279419, "info_performance_final": 0.5925925970077515, "step": 867000}
{"episode_reward": 1079.8168060533653, "episode": 8671.0, "batch_reward": 11.741844177246094, "critic_loss": 176.83448791503906, "actor_loss": -1632.556884765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9294975399971008, "alpha_loss": -0.13607442378997803, "alpha_value": 0.3511800076075598, "duration": 1.554483413696289, "info_normalized_performance_mean": 0.47564125061035156, "info_normalized_performance_final": 0.52734375, "info_performance_mean": 0.47564125061035156, "info_performance_final": 0.52734375, "step": 867500}
{"episode_reward": 951.2825520833334, "episode": 8676.0, "batch_reward": 11.435449600219727, "critic_loss": 209.70181274414062, "actor_loss": -1626.76123046875, "actor_target_entropy": -3.0, "actor_entropy": 0.30549806356430054, "alpha_loss": -0.09102883189916611, "alpha_value": 0.350067842226342, "duration": 1.5034825801849365, "info_normalized_performance_mean": 0.7216722369194031, "info_normalized_performance_final": 0.7749432921409607, "info_performance_mean": 0.7216722369194031, "info_performance_final": 0.7749432921409607, "step": 868000}
{"episode_reward": 1443.3446712018113, "episode": 8681.0, "batch_reward": 11.430924415588379, "critic_loss": 418.24615478515625, "actor_loss": -1604.440673828125, "actor_target_entropy": -3.0, "actor_entropy": 0.4445243775844574, "alpha_loss": 0.07436598837375641, "alpha_value": 0.3475167371808317, "duration": 1.4513769149780273, "info_normalized_performance_mean": 0.5218406915664673, "info_normalized_performance_final": 0.5659340620040894, "info_performance_mean": 0.5218406915664673, "info_performance_final": 0.5659340620040894, "step": 868500}
{"episode_reward": 1043.6813186813201, "episode": 8686.0, "batch_reward": 12.235179901123047, "critic_loss": 327.12738037109375, "actor_loss": -1647.1220703125, "actor_target_entropy": -3.0, "actor_entropy": 0.5956531167030334, "alpha_loss": 0.13102906942367554, "alpha_value": 0.34543927652356266, "duration": 1.5016250610351562, "info_normalized_performance_mean": 0.5544453263282776, "info_normalized_performance_final": 0.600390613079071, "info_performance_mean": 0.5544453263282776, "info_performance_final": 0.600390613079071, "step": 869000}
{"episode_reward": 1108.890625, "episode": 8691.0, "batch_reward": 12.379343032836914, "critic_loss": 233.60272216796875, "actor_loss": -1659.7371826171875, "actor_target_entropy": -3.0, "actor_entropy": 0.47989314794540405, "alpha_loss": 0.03398194536566734, "alpha_value": 0.3448580444168151, "duration": 1.621652364730835, "info_normalized_performance_mean": 0.4513857364654541, "info_normalized_performance_final": 0.5066666603088379, "info_performance_mean": 0.4513857364654541, "info_performance_final": 0.5066666603088379, "step": 869500}
{"episode_reward": 902.771428571428, "episode": 8696.0, "batch_reward": 11.687005043029785, "critic_loss": 244.60906982421875, "actor_loss": -1623.080810546875, "actor_target_entropy": -3.0, "actor_entropy": 0.3194819688796997, "alpha_loss": -0.02668580785393715, "alpha_value": 0.34346213083502924, "step": 870000}
{"duration": 18.49217128753662, "info_normalized_performance_mean": 0.3596561551094055, "info_normalized_performance_final": 0.3812499940395355, "info_performance_mean": 0.3596561551094055, "info_performance_final": 0.3812499940395355, "step": 870000}
{"episode_reward": 719.3125, "episode": 8701.0, "batch_reward": 12.662759780883789, "critic_loss": 260.7074890136719, "actor_loss": -1650.289306640625, "actor_target_entropy": -3.0, "actor_entropy": 0.5883764028549194, "alpha_loss": 0.126613050699234, "alpha_value": 0.3415753347987493, "duration": 1.6129822731018066, "info_normalized_performance_mean": 0.5555675029754639, "info_normalized_performance_final": 0.6037511825561523, "info_performance_mean": 0.5555675029754639, "info_performance_final": 0.6037511825561523, "step": 870500}
{"episode_reward": 1111.1348528015192, "episode": 8706.0, "batch_reward": 11.630704879760742, "critic_loss": 156.67172241210938, "actor_loss": -1606.435546875, "actor_target_entropy": -3.0, "actor_entropy": 0.3590545058250427, "alpha_loss": -0.12119218707084656, "alpha_value": 0.339845233896156, "duration": 1.542952299118042, "info_normalized_performance_mean": 0.5107427835464478, "info_normalized_performance_final": 0.569870114326477, "info_performance_mean": 0.5107427835464478, "info_performance_final": 0.569870114326477, "step": 871000}
{"episode_reward": 1021.485714285713, "episode": 8711.0, "batch_reward": 11.241714477539062, "critic_loss": 241.98291015625, "actor_loss": -1613.47705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.4853370487689972, "alpha_loss": -0.1199992448091507, "alpha_value": 0.33764855555527407, "duration": 1.4292309284210205, "info_normalized_performance_mean": 0.346638947725296, "info_normalized_performance_final": 0.37308672070503235, "info_performance_mean": 0.346638947725296, "info_performance_final": 0.37308672070503235, "step": 871500}
{"episode_reward": 693.2780612244901, "episode": 8716.0, "batch_reward": 12.105012893676758, "critic_loss": 281.2092590332031, "actor_loss": -1617.83056640625, "actor_target_entropy": -3.0, "actor_entropy": 0.4256061613559723, "alpha_loss": 0.09197761118412018, "alpha_value": 0.3341096398794842, "duration": 1.5489094257354736, "info_normalized_performance_mean": 0.8254901766777039, "info_normalized_performance_final": 0.886274516582489, "info_performance_mean": 0.8254901766777039, "info_performance_final": 0.886274516582489, "step": 872000}
{"episode_reward": 1650.9803921568644, "episode": 8721.0, "batch_reward": 11.632909774780273, "critic_loss": 238.26309204101562, "actor_loss": -1628.991455078125, "actor_target_entropy": -3.0, "actor_entropy": 0.48674821853637695, "alpha_loss": 0.05527425929903984, "alpha_value": 0.33000287278716295, "duration": 1.514920711517334, "info_normalized_performance_mean": 0.8176460266113281, "info_normalized_performance_final": 0.8944805264472961, "info_performance_mean": 0.8176460266113281, "info_performance_final": 0.8944805264472961, "step": 872500}
{"episode_reward": 1635.2922077922096, "episode": 8726.0, "batch_reward": 12.616562843322754, "critic_loss": 141.41061401367188, "actor_loss": -1647.132568359375, "actor_target_entropy": -3.0, "actor_entropy": 0.4824894368648529, "alpha_loss": 0.0951729416847229, "alpha_value": 0.32670632077435724, "duration": 1.4814834594726562, "info_normalized_performance_mean": 0.5824694037437439, "info_normalized_performance_final": 0.6326530575752258, "info_performance_mean": 0.5824694037437439, "info_performance_final": 0.6326530575752258, "step": 873000}
{"episode_reward": 1164.9387755102039, "episode": 8731.0, "batch_reward": 11.898239135742188, "critic_loss": 142.43930053710938, "actor_loss": -1604.716064453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5755002498626709, "alpha_loss": 0.26412588357925415, "alpha_value": 0.32207865393984436, "duration": 1.6172537803649902, "info_normalized_performance_mean": 0.8359900712966919, "info_normalized_performance_final": 0.9020000100135803, "info_performance_mean": 0.8359900712966919, "info_performance_final": 0.9020000100135803, "step": 873500}
{"episode_reward": 1671.979999999998, "episode": 8736.0, "batch_reward": 11.502671241760254, "critic_loss": 485.378173828125, "actor_loss": -1579.697021484375, "actor_target_entropy": -3.0, "actor_entropy": 0.4547727704048157, "alpha_loss": 0.03356814384460449, "alpha_value": 0.3188952407877251, "duration": 1.3963711261749268, "info_normalized_performance_mean": 0.23559027910232544, "info_normalized_performance_final": 0.25, "info_performance_mean": 0.23559027910232544, "info_performance_final": 0.25, "step": 874000}
{"episode_reward": 471.18055555555554, "episode": 8741.0, "batch_reward": 11.604178428649902, "critic_loss": 254.21221923828125, "actor_loss": -1606.25, "actor_target_entropy": -3.0, "actor_entropy": 0.2942374646663666, "alpha_loss": -0.08600670844316483, "alpha_value": 0.3176920191346348, "duration": 1.4419174194335938, "info_normalized_performance_mean": 0.43302083015441895, "info_normalized_performance_final": 0.4583333432674408, "info_performance_mean": 0.43302083015441895, "info_performance_final": 0.4583333432674408, "step": 874500}
{"episode_reward": 866.0416666666656, "episode": 8746.0, "batch_reward": 11.348182678222656, "critic_loss": 849.634033203125, "actor_loss": -1568.50927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.1691587269306183, "alpha_loss": 0.10969440639019012, "alpha_value": 0.31590278133161326, "duration": 1.503204345703125, "info_normalized_performance_mean": 0.5324313640594482, "info_normalized_performance_final": 0.5755494236946106, "info_performance_mean": 0.5324313640594482, "info_performance_final": 0.5755494236946106, "step": 875000}
{"episode_reward": 1064.862637362636, "episode": 8751.0, "batch_reward": 12.263788223266602, "critic_loss": 275.2557678222656, "actor_loss": -1644.4683837890625, "actor_target_entropy": -3.0, "actor_entropy": 0.29765164852142334, "alpha_loss": 0.024678215384483337, "alpha_value": 0.3128727279055037, "duration": 1.6045575141906738, "info_normalized_performance_mean": 0.4575033485889435, "info_normalized_performance_final": 0.5059340596199036, "info_performance_mean": 0.4575033485889435, "info_performance_final": 0.5059340596199036, "step": 875500}
{"episode_reward": 915.0065934065921, "episode": 8756.0, "batch_reward": 11.673224449157715, "critic_loss": 219.68714904785156, "actor_loss": -1563.26318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.4556823670864105, "alpha_loss": -0.06390800327062607, "alpha_value": 0.3133701958062935, "duration": 1.4728164672851562, "info_normalized_performance_mean": 0.5861848592758179, "info_normalized_performance_final": 0.6281179189682007, "info_performance_mean": 0.5861848592758179, "info_performance_final": 0.6281179189682007, "step": 876000}
{"episode_reward": 1172.3696145124718, "episode": 8761.0, "batch_reward": 12.36852741241455, "critic_loss": 530.2081298828125, "actor_loss": -1633.0838623046875, "actor_target_entropy": -3.0, "actor_entropy": 0.28388628363609314, "alpha_loss": 0.09165865927934647, "alpha_value": 0.31306550737913363, "duration": 1.5914969444274902, "info_normalized_performance_mean": 0.7043055891990662, "info_normalized_performance_final": 0.7546296119689941, "info_performance_mean": 0.7043055891990662, "info_performance_final": 0.7546296119689941, "step": 876500}
{"episode_reward": 1408.6111111111122, "episode": 8766.0, "batch_reward": 12.469629287719727, "critic_loss": 213.45819091796875, "actor_loss": -1639.3232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.3735394775867462, "alpha_loss": 0.1834096908569336, "alpha_value": 0.31139854252374977, "duration": 1.6196527481079102, "info_normalized_performance_mean": 0.7028001546859741, "info_normalized_performance_final": 0.7709090709686279, "info_performance_mean": 0.7028001546859741, "info_performance_final": 0.7709090709686279, "step": 877000}
{"episode_reward": 1405.6000000000008, "episode": 8771.0, "batch_reward": 11.653257369995117, "critic_loss": 307.70074462890625, "actor_loss": -1630.7294921875, "actor_target_entropy": -3.0, "actor_entropy": 0.1485241949558258, "alpha_loss": -0.07586365193128586, "alpha_value": 0.31051101171440415, "duration": 1.5645408630371094, "info_normalized_performance_mean": 0.4697246253490448, "info_normalized_performance_final": 0.517568826675415, "info_performance_mean": 0.4697246253490448, "info_performance_final": 0.517568826675415, "step": 877500}
{"episode_reward": 939.4491927825251, "episode": 8776.0, "batch_reward": 11.96651840209961, "critic_loss": 206.10983276367188, "actor_loss": -1607.803955078125, "actor_target_entropy": -3.0, "actor_entropy": 0.48833799362182617, "alpha_loss": -1.874566078186035e-05, "alpha_value": 0.311096239868244, "duration": 1.5036442279815674, "info_normalized_performance_mean": 0.7539681792259216, "info_normalized_performance_final": 0.8205128312110901, "info_performance_mean": 0.7539681792259216, "info_performance_final": 0.8205128312110901, "step": 878000}
{"episode_reward": 1507.9365079365043, "episode": 8781.0, "batch_reward": 11.093305587768555, "critic_loss": 728.7556762695312, "actor_loss": -1620.2684326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6286012530326843, "alpha_loss": -0.08962862193584442, "alpha_value": 0.3115955897446173, "duration": 1.5535540580749512, "info_normalized_performance_mean": 0.7939804792404175, "info_normalized_performance_final": 0.8509804010391235, "info_performance_mean": 0.7939804792404175, "info_performance_final": 0.8509804010391235, "step": 878500}
{"episode_reward": 1587.9607843137242, "episode": 8786.0, "batch_reward": 11.91049861907959, "critic_loss": 333.0091552734375, "actor_loss": -1621.4853515625, "actor_target_entropy": -3.0, "actor_entropy": 0.559829592704773, "alpha_loss": -0.07243962585926056, "alpha_value": 0.3150402051153938, "duration": 1.5634796619415283, "info_normalized_performance_mean": 0.8300142884254456, "info_normalized_performance_final": 0.8899999856948853, "info_performance_mean": 0.8300142884254456, "info_performance_final": 0.8899999856948853, "step": 879000}
{"episode_reward": 1660.0285714285687, "episode": 8791.0, "batch_reward": 11.691028594970703, "critic_loss": 195.30715942382812, "actor_loss": -1590.3232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8311933279037476, "alpha_loss": -0.01957528665661812, "alpha_value": 0.32064462465709814, "duration": 1.70723557472229, "info_normalized_performance_mean": 0.39176133275032043, "info_normalized_performance_final": 0.4381868243217468, "info_performance_mean": 0.39176133275032043, "info_performance_final": 0.4381868243217468, "step": 879500}
{"episode_reward": 783.5225885225901, "episode": 8796.0, "batch_reward": 11.074195861816406, "critic_loss": 710.2306518554688, "actor_loss": -1572.593505859375, "actor_target_entropy": -3.0, "actor_entropy": 0.3017547130584717, "alpha_loss": -0.3049028515815735, "alpha_value": 0.3289738691885285, "step": 880000}
{"duration": 18.78994107246399, "info_normalized_performance_mean": 0.4532429575920105, "info_normalized_performance_final": 0.4871428608894348, "info_performance_mean": 0.4532429575920105, "info_performance_final": 0.4871428608894348, "step": 880000}
{"episode_reward": 906.4857142857136, "episode": 8801.0, "batch_reward": 11.580734252929688, "critic_loss": 521.2255859375, "actor_loss": -1571.6544189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5172747373580933, "alpha_loss": -0.2013053148984909, "alpha_value": 0.34034386708979847, "duration": 1.4845764636993408, "info_normalized_performance_mean": 0.5016021728515625, "info_normalized_performance_final": 0.5486111044883728, "info_performance_mean": 0.5016021728515625, "info_performance_final": 0.5486111044883728, "step": 880500}
{"episode_reward": 1003.2043650793629, "episode": 8806.0, "batch_reward": 11.007829666137695, "critic_loss": 332.4579772949219, "actor_loss": -1613.14208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.376309335231781, "alpha_loss": -0.21296721696853638, "alpha_value": 0.35221100366354374, "duration": 1.4838218688964844, "info_normalized_performance_mean": 0.2831810414791107, "info_normalized_performance_final": 0.3243727684020996, "info_performance_mean": 0.2831810414791107, "info_performance_final": 0.3243727684020996, "step": 881000}
{"episode_reward": 566.3620071684576, "episode": 8811.0, "batch_reward": 12.432430267333984, "critic_loss": 212.50326538085938, "actor_loss": -1630.1591796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7757375836372375, "alpha_loss": -0.04357430338859558, "alpha_value": 0.3639064773605233, "duration": 1.7106263637542725, "info_normalized_performance_mean": 0.4220311641693115, "info_normalized_performance_final": 0.4713922441005707, "info_performance_mean": 0.4220311641693115, "info_performance_final": 0.4713922441005707, "step": 881500}
{"episode_reward": 844.0623013350288, "episode": 8816.0, "batch_reward": 12.45168399810791, "critic_loss": 248.61029052734375, "actor_loss": -1643.375244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.9960164427757263, "alpha_loss": -0.04100927338004112, "alpha_value": 0.37335415297988667, "duration": 1.52980637550354, "info_normalized_performance_mean": 0.5701000094413757, "info_normalized_performance_final": 0.6114285588264465, "info_performance_mean": 0.5701000094413757, "info_performance_final": 0.6114285588264465, "step": 882000}
{"episode_reward": 1140.199999999999, "episode": 8821.0, "batch_reward": 12.067499160766602, "critic_loss": 147.97991943359375, "actor_loss": -1629.41796875, "actor_target_entropy": -3.0, "actor_entropy": 0.9670267105102539, "alpha_loss": -0.2997422516345978, "alpha_value": 0.38084776841977913, "duration": 1.4709017276763916, "info_normalized_performance_mean": 0.2565997242927551, "info_normalized_performance_final": 0.3415178656578064, "info_performance_mean": 0.2565997242927551, "info_performance_final": 0.3415178656578064, "step": 882500}
{"episode_reward": 513.1994047619046, "episode": 8826.0, "batch_reward": 11.69810962677002, "critic_loss": 241.29254150390625, "actor_loss": -1621.5543212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6688141226768494, "alpha_loss": -0.3717419505119324, "alpha_value": 0.38822816931029597, "duration": 1.5654304027557373, "info_normalized_performance_mean": 0.8247665166854858, "info_normalized_performance_final": 0.8833333253860474, "info_performance_mean": 0.8247665166854858, "info_performance_final": 0.8833333253860474, "step": 883000}
{"episode_reward": 1649.5333333333351, "episode": 8831.0, "batch_reward": 12.075399398803711, "critic_loss": 183.57421875, "actor_loss": -1659.565673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.1799049377441406, "alpha_loss": -0.22245562076568604, "alpha_value": 0.39540742458549705, "duration": 1.493910551071167, "info_normalized_performance_mean": 0.6782711148262024, "info_normalized_performance_final": 0.7267573475837708, "info_performance_mean": 0.6782711148262024, "info_performance_final": 0.7267573475837708, "step": 883500}
{"episode_reward": 1356.5419501133806, "episode": 8836.0, "batch_reward": 11.08924674987793, "critic_loss": 353.0863037109375, "actor_loss": -1638.974853515625, "actor_target_entropy": -3.0, "actor_entropy": 0.48728081583976746, "alpha_loss": -0.1885528266429901, "alpha_value": 0.39970900719826674, "duration": 1.557034969329834, "info_normalized_performance_mean": 0.9216300845146179, "info_normalized_performance_final": 0.9848739504814148, "info_performance_mean": 0.9216300845146179, "info_performance_final": 0.9848739504814148, "step": 884000}
{"episode_reward": 1843.260504201682, "episode": 8841.0, "batch_reward": 10.621598243713379, "critic_loss": 504.6091003417969, "actor_loss": -1581.48193359375, "actor_target_entropy": -3.0, "actor_entropy": 0.7938616871833801, "alpha_loss": -0.24376872181892395, "alpha_value": 0.4029353769144376, "duration": 1.4778378009796143, "info_normalized_performance_mean": 0.7477041482925415, "info_normalized_performance_final": 0.8112244606018066, "info_performance_mean": 0.7477041482925415, "info_performance_final": 0.8112244606018066, "step": 884500}
{"episode_reward": 1495.4081632653033, "episode": 8846.0, "batch_reward": 11.459787368774414, "critic_loss": 489.61138916015625, "actor_loss": -1618.19677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7997856140136719, "alpha_loss": 0.06739892810583115, "alpha_value": 0.4033094719498131, "duration": 1.5009145736694336, "info_normalized_performance_mean": 0.33466261625289917, "info_normalized_performance_final": 0.37180396914482117, "info_performance_mean": 0.33466261625289917, "info_performance_final": 0.37180396914482117, "step": 885000}
{"episode_reward": 669.3252840909088, "episode": 8851.0, "batch_reward": 11.211554527282715, "critic_loss": 122.7454833984375, "actor_loss": -1600.20458984375, "actor_target_entropy": -3.0, "actor_entropy": 0.49951547384262085, "alpha_loss": -0.030379578471183777, "alpha_value": 0.403905174888532, "duration": 1.6060335636138916, "info_normalized_performance_mean": 0.37851932644844055, "info_normalized_performance_final": 0.4069940447807312, "info_performance_mean": 0.37851932644844055, "info_performance_final": 0.4069940447807312, "step": 885500}
{"episode_reward": 757.0386904761913, "episode": 8856.0, "batch_reward": 11.257131576538086, "critic_loss": 239.3251953125, "actor_loss": -1619.6298828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8790645599365234, "alpha_loss": -0.14324122667312622, "alpha_value": 0.40536464287760865, "duration": 1.6399972438812256, "info_normalized_performance_mean": 0.37507399916648865, "info_normalized_performance_final": 0.41873279213905334, "info_performance_mean": 0.37507399916648865, "info_performance_final": 0.41873279213905334, "step": 886000}
{"episode_reward": 750.1480716253445, "episode": 8861.0, "batch_reward": 11.124526023864746, "critic_loss": 265.7106018066406, "actor_loss": -1632.818115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.9197711944580078, "alpha_loss": -0.21271051466464996, "alpha_value": 0.40837632029305126, "duration": 1.5713813304901123, "info_normalized_performance_mean": 0.5658599734306335, "info_normalized_performance_final": 0.621999979019165, "info_performance_mean": 0.5658599734306335, "info_performance_final": 0.621999979019165, "step": 886500}
{"episode_reward": 1131.7200000000025, "episode": 8866.0, "batch_reward": 11.382366180419922, "critic_loss": 192.6544189453125, "actor_loss": -1615.582763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.7484754323959351, "alpha_loss": 0.1361207365989685, "alpha_value": 0.40894781253323137, "duration": 1.5794332027435303, "info_normalized_performance_mean": 0.8416882157325745, "info_normalized_performance_final": 0.9318181872367859, "info_performance_mean": 0.8416882157325745, "info_performance_final": 0.9318181872367859, "step": 887000}
{"episode_reward": 1683.3766233766255, "episode": 8871.0, "batch_reward": 12.209169387817383, "critic_loss": 201.67466735839844, "actor_loss": -1685.9425048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.4712843894958496, "alpha_loss": 0.05555906891822815, "alpha_value": 0.40987959722720857, "duration": 1.6929931640625, "info_normalized_performance_mean": 0.4015892744064331, "info_normalized_performance_final": 0.4499364197254181, "info_performance_mean": 0.4015892744064331, "info_performance_final": 0.4499364197254181, "step": 887500}
{"episode_reward": 803.178639542277, "episode": 8876.0, "batch_reward": 11.97941780090332, "critic_loss": 270.4525146484375, "actor_loss": -1614.004150390625, "actor_target_entropy": -3.0, "actor_entropy": 0.5847687721252441, "alpha_loss": 0.06583341211080551, "alpha_value": 0.4159350025701893, "duration": 1.5705702304840088, "info_normalized_performance_mean": 0.4604572057723999, "info_normalized_performance_final": 0.5132467746734619, "info_performance_mean": 0.4604572057723999, "info_performance_final": 0.5132467746734619, "step": 888000}
{"episode_reward": 920.9142857142875, "episode": 8881.0, "batch_reward": 11.689128875732422, "critic_loss": 228.0595703125, "actor_loss": -1678.015380859375, "actor_target_entropy": -3.0, "actor_entropy": 0.6011060476303101, "alpha_loss": -0.16235005855560303, "alpha_value": 0.4218339630037751, "duration": 1.645561695098877, "info_normalized_performance_mean": 0.6607012152671814, "info_normalized_performance_final": 0.7169312238693237, "info_performance_mean": 0.6607012152671814, "info_performance_final": 0.7169312238693237, "step": 888500}
{"episode_reward": 1321.4021164021167, "episode": 8886.0, "batch_reward": 12.206652641296387, "critic_loss": 265.4576416015625, "actor_loss": -1643.510009765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9258534908294678, "alpha_loss": -0.046727851033210754, "alpha_value": 0.42868188738543983, "duration": 1.5755794048309326, "info_normalized_performance_mean": 0.8241697549819946, "info_normalized_performance_final": 0.8928104639053345, "info_performance_mean": 0.8241697549819946, "info_performance_final": 0.8928104639053345, "step": 889000}
{"episode_reward": 1648.3398692810442, "episode": 8891.0, "batch_reward": 11.458573341369629, "critic_loss": 298.4332275390625, "actor_loss": -1672.463134765625, "actor_target_entropy": -3.0, "actor_entropy": 0.7175049185752869, "alpha_loss": -0.2735668420791626, "alpha_value": 0.43856625434192387, "duration": 1.5457134246826172, "info_normalized_performance_mean": 0.9245665073394775, "info_normalized_performance_final": 0.9974489808082581, "info_performance_mean": 0.9245665073394775, "info_performance_final": 0.9974489808082581, "step": 889500}
{"episode_reward": 1849.1326530612207, "episode": 8896.0, "batch_reward": 11.741622924804688, "critic_loss": 635.8965454101562, "actor_loss": -1662.6693115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8221781253814697, "alpha_loss": -0.15437500178813934, "alpha_value": 0.4506736339712463, "step": 890000}
{"duration": 18.872416257858276, "info_normalized_performance_mean": 0.618165135383606, "info_normalized_performance_final": 0.6723214387893677, "info_performance_mean": 0.618165135383606, "info_performance_final": 0.6723214387893677, "step": 890000}
{"episode_reward": 1236.3303571428578, "episode": 8901.0, "batch_reward": 11.165821075439453, "critic_loss": 546.6544189453125, "actor_loss": -1635.358154296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7813294529914856, "alpha_loss": -0.05814353749155998, "alpha_value": 0.46075046083095705, "duration": 1.3275868892669678, "info_normalized_performance_mean": 0.32350003719329834, "info_normalized_performance_final": 0.3464285731315613, "info_performance_mean": 0.32350003719329834, "info_performance_final": 0.3464285731315613, "step": 890500}
{"episode_reward": 647.0000000000007, "episode": 8906.0, "batch_reward": 11.000303268432617, "critic_loss": 1147.0633544921875, "actor_loss": -1643.5711669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.5029815435409546, "alpha_loss": -0.2906000018119812, "alpha_value": 0.4684609322057555, "duration": 1.6038804054260254, "info_normalized_performance_mean": 0.7829726338386536, "info_normalized_performance_final": 0.8554545640945435, "info_performance_mean": 0.7829726338386536, "info_performance_final": 0.8554545640945435, "step": 891000}
{"episode_reward": 1565.945454545452, "episode": 8911.0, "batch_reward": 11.560789108276367, "critic_loss": 287.9018249511719, "actor_loss": -1704.9178466796875, "actor_target_entropy": -3.0, "actor_entropy": 0.6553701758384705, "alpha_loss": 0.08703134953975677, "alpha_value": 0.47434897506709306, "duration": 1.4980404376983643, "info_normalized_performance_mean": 0.6722656488418579, "info_normalized_performance_final": 0.728515625, "info_performance_mean": 0.6722656488418579, "info_performance_final": 0.728515625, "step": 891500}
{"episode_reward": 1344.53125, "episode": 8916.0, "batch_reward": 11.039410591125488, "critic_loss": 263.6270751953125, "actor_loss": -1639.95361328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7500753998756409, "alpha_loss": -0.14342857897281647, "alpha_value": 0.4785480592640655, "duration": 1.601686954498291, "info_normalized_performance_mean": 0.7853000164031982, "info_normalized_performance_final": 0.84375, "info_performance_mean": 0.7853000164031982, "info_performance_final": 0.84375, "step": 892000}
{"episode_reward": 1570.6, "episode": 8921.0, "batch_reward": 11.969157218933105, "critic_loss": 432.77398681640625, "actor_loss": -1696.253173828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7671259641647339, "alpha_loss": -0.1517777442932129, "alpha_value": 0.48277680712108384, "duration": 1.5446813106536865, "info_normalized_performance_mean": 0.8506695628166199, "info_normalized_performance_final": 0.913690447807312, "info_performance_mean": 0.8506695628166199, "info_performance_final": 0.913690447807312, "step": 892500}
{"episode_reward": 1701.3392857142896, "episode": 8926.0, "batch_reward": 12.318300247192383, "critic_loss": 264.3297424316406, "actor_loss": -1718.179931640625, "actor_target_entropy": -3.0, "actor_entropy": 0.7687780261039734, "alpha_loss": 0.0607558935880661, "alpha_value": 0.4852663696461399, "duration": 1.6676568984985352, "info_normalized_performance_mean": 0.46429404616355896, "info_normalized_performance_final": 0.5105027556419373, "info_performance_mean": 0.46429404616355896, "info_performance_final": 0.5105027556419373, "step": 893000}
{"episode_reward": 928.588154269972, "episode": 8931.0, "batch_reward": 11.578243255615234, "critic_loss": 234.04904174804688, "actor_loss": -1685.887939453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6301904916763306, "alpha_loss": 0.052688583731651306, "alpha_value": 0.48056116190169584, "duration": 1.5802569389343262, "info_normalized_performance_mean": 0.7767875790596008, "info_normalized_performance_final": 0.8374999761581421, "info_performance_mean": 0.7767875790596008, "info_performance_final": 0.8374999761581421, "step": 893500}
{"episode_reward": 1553.575, "episode": 8936.0, "batch_reward": 12.588688850402832, "critic_loss": 1365.3406982421875, "actor_loss": -1723.64599609375, "actor_target_entropy": -3.0, "actor_entropy": 0.9524636268615723, "alpha_loss": 0.44706183671951294, "alpha_value": 0.4750622138751725, "duration": 1.5709514617919922, "info_normalized_performance_mean": 0.9046273827552795, "info_normalized_performance_final": 0.9555288553237915, "info_performance_mean": 0.9046273827552795, "info_performance_final": 0.9555288553237915, "step": 894000}
{"episode_reward": 1809.2548076923065, "episode": 8941.0, "batch_reward": 11.52035903930664, "critic_loss": 545.8063354492188, "actor_loss": -1704.041259765625, "actor_target_entropy": -3.0, "actor_entropy": 0.5415502190589905, "alpha_loss": -0.09237244725227356, "alpha_value": 0.47185484455328036, "duration": 1.603734016418457, "info_normalized_performance_mean": 0.2952241003513336, "info_normalized_performance_final": 0.32505494356155396, "info_performance_mean": 0.2952241003513336, "info_performance_final": 0.32505494356155396, "step": 894500}
{"episode_reward": 590.4483516483509, "episode": 8946.0, "batch_reward": 11.429556846618652, "critic_loss": 452.10260009765625, "actor_loss": -1710.2296142578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6924890279769897, "alpha_loss": 0.11360670626163483, "alpha_value": 0.46435567746007583, "duration": 1.6274299621582031, "info_normalized_performance_mean": 0.765407919883728, "info_normalized_performance_final": 0.8211805820465088, "info_performance_mean": 0.765407919883728, "info_performance_final": 0.8211805820465088, "step": 895000}
{"episode_reward": 1530.8159722222204, "episode": 8951.0, "batch_reward": 10.959883689880371, "critic_loss": 193.3822784423828, "actor_loss": -1648.637451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.4101479947566986, "alpha_loss": 0.04116173833608627, "alpha_value": 0.4575867328320949, "duration": 1.4176630973815918, "info_normalized_performance_mean": 0.35282984375953674, "info_normalized_performance_final": 0.375, "info_performance_mean": 0.35282984375953674, "info_performance_final": 0.375, "step": 895500}
{"episode_reward": 705.6597222222222, "episode": 8956.0, "batch_reward": 11.803300857543945, "critic_loss": 244.0055694580078, "actor_loss": -1702.25146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7073657512664795, "alpha_loss": -0.13575729727745056, "alpha_value": 0.44911882096691025, "duration": 1.6167433261871338, "info_normalized_performance_mean": 0.7277750968933105, "info_normalized_performance_final": 0.7858333587646484, "info_performance_mean": 0.7277750968933105, "info_performance_final": 0.7858333587646484, "step": 896000}
{"episode_reward": 1455.5500000000022, "episode": 8961.0, "batch_reward": 11.716405868530273, "critic_loss": 524.3267211914062, "actor_loss": -1722.2657470703125, "actor_target_entropy": -3.0, "actor_entropy": 0.4446927607059479, "alpha_loss": -0.0025694873183965683, "alpha_value": 0.44464882969104647, "duration": 1.4592540264129639, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 896500}
{"episode_reward": 0.0, "episode": 8966.0, "batch_reward": 11.786796569824219, "critic_loss": 170.84890747070312, "actor_loss": -1710.068115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.521364152431488, "alpha_loss": 0.13609594106674194, "alpha_value": 0.43833168381644216, "duration": 1.6023595333099365, "info_normalized_performance_mean": 0.4757479727268219, "info_normalized_performance_final": 0.5233333110809326, "info_performance_mean": 0.4757479727268219, "info_performance_final": 0.5233333110809326, "step": 897000}
{"episode_reward": 951.495833333334, "episode": 8971.0, "batch_reward": 12.238057136535645, "critic_loss": 276.11114501953125, "actor_loss": -1698.63623046875, "actor_target_entropy": -3.0, "actor_entropy": 0.5426833033561707, "alpha_loss": 0.08466078341007233, "alpha_value": 0.43056361074571026, "duration": 1.5906906127929688, "info_normalized_performance_mean": 0.4734130799770355, "info_normalized_performance_final": 0.5136317014694214, "info_performance_mean": 0.4734130799770355, "info_performance_final": 0.5136317014694214, "step": 897500}
{"episode_reward": 946.8261316872428, "episode": 8976.0, "batch_reward": 11.741774559020996, "critic_loss": 309.4410095214844, "actor_loss": -1711.234619140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6115124225616455, "alpha_loss": 0.20465677976608276, "alpha_value": 0.42308319021510393, "duration": 1.7791783809661865, "info_normalized_performance_mean": 0.4035332202911377, "info_normalized_performance_final": 0.5145299434661865, "info_performance_mean": 0.4035332202911377, "info_performance_final": 0.5145299434661865, "step": 898000}
{"episode_reward": 807.0664036817881, "episode": 8981.0, "batch_reward": 10.699166297912598, "critic_loss": 279.6908264160156, "actor_loss": -1633.0224609375, "actor_target_entropy": -3.0, "actor_entropy": 0.012217223644256592, "alpha_loss": -0.031827449798583984, "alpha_value": 0.41663713800512736, "duration": 1.5585460662841797, "info_normalized_performance_mean": 0.5088580846786499, "info_normalized_performance_final": 0.5535914897918701, "info_performance_mean": 0.5088580846786499, "info_performance_final": 0.5535914897918701, "step": 898500}
{"episode_reward": 1017.7160493827148, "episode": 8986.0, "batch_reward": 10.744367599487305, "critic_loss": 408.2315673828125, "actor_loss": -1623.0400390625, "actor_target_entropy": -3.0, "actor_entropy": 0.20945730805397034, "alpha_loss": 0.132908895611763, "alpha_value": 0.4116871639284922, "duration": 1.4981484413146973, "info_normalized_performance_mean": 0.5020089149475098, "info_normalized_performance_final": 0.5504464507102966, "info_performance_mean": 0.5020089149475098, "info_performance_final": 0.5504464507102966, "step": 899000}
{"episode_reward": 1004.0178571428562, "episode": 8991.0, "batch_reward": 12.059836387634277, "critic_loss": 230.57861328125, "actor_loss": -1656.41015625, "actor_target_entropy": -3.0, "actor_entropy": 0.42645299434661865, "alpha_loss": 0.18587341904640198, "alpha_value": 0.4047085260415672, "duration": 1.5380399227142334, "info_normalized_performance_mean": 0.3840441107749939, "info_normalized_performance_final": 0.43012985587120056, "info_performance_mean": 0.3840441107749939, "info_performance_final": 0.43012985587120056, "step": 899500}
{"episode_reward": 768.0883116883124, "episode": 8996.0, "batch_reward": 11.981521606445312, "critic_loss": 714.125, "actor_loss": -1649.3843994140625, "actor_target_entropy": -3.0, "actor_entropy": 0.28782421350479126, "alpha_loss": 0.3667687177658081, "alpha_value": 0.3999428911001965, "step": 900000}
{"duration": 19.027376413345337, "info_normalized_performance_mean": 0.7274513840675354, "info_normalized_performance_final": 0.7824675440788269, "info_performance_mean": 0.7274513840675354, "info_performance_final": 0.7824675440788269, "step": 900000}
{"episode_reward": 1454.9025974025972, "episode": 9001.0, "batch_reward": 11.1846284866333, "critic_loss": 439.13751220703125, "actor_loss": -1622.1253662109375, "actor_target_entropy": -3.0, "actor_entropy": 0.4010171592235565, "alpha_loss": -0.10088492184877396, "alpha_value": 0.39609352005900533, "duration": 1.5718131065368652, "info_normalized_performance_mean": 0.7853816747665405, "info_normalized_performance_final": 0.8460648059844971, "info_performance_mean": 0.7853816747665405, "info_performance_final": 0.8460648059844971, "step": 900500}
{"episode_reward": 1570.7638888888894, "episode": 9006.0, "batch_reward": 11.645063400268555, "critic_loss": 863.5575561523438, "actor_loss": -1639.406982421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0752476453781128, "alpha_loss": 0.20382262766361237, "alpha_value": 0.3920333368329665, "duration": 1.6180460453033447, "info_normalized_performance_mean": 0.7455000281333923, "info_normalized_performance_final": 0.8145833611488342, "info_performance_mean": 0.7455000281333923, "info_performance_final": 0.8145833611488342, "step": 901000}
{"episode_reward": 1491.0000000000011, "episode": 9011.0, "batch_reward": 12.217785835266113, "critic_loss": 324.93231201171875, "actor_loss": -1682.233642578125, "actor_target_entropy": -3.0, "actor_entropy": 0.57023686170578, "alpha_loss": 0.14499296247959137, "alpha_value": 0.3883898170446972, "duration": 1.63747239112854, "info_normalized_performance_mean": 0.5543750524520874, "info_normalized_performance_final": 0.6018518805503845, "info_performance_mean": 0.5543750524520874, "info_performance_final": 0.6018518805503845, "step": 901500}
{"episode_reward": 1108.7500000000011, "episode": 9016.0, "batch_reward": 11.330950736999512, "critic_loss": 427.7347717285156, "actor_loss": -1583.3594970703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6266357898712158, "alpha_loss": 0.09962496161460876, "alpha_value": 0.3846914600232464, "duration": 1.5218615531921387, "info_normalized_performance_mean": 0.43597304821014404, "info_normalized_performance_final": 0.4751420319080353, "info_performance_mean": 0.43597304821014404, "info_performance_final": 0.4751420319080353, "step": 902000}
{"episode_reward": 871.9460227272722, "episode": 9021.0, "batch_reward": 11.948911666870117, "critic_loss": 382.53131103515625, "actor_loss": -1645.9163818359375, "actor_target_entropy": -3.0, "actor_entropy": 0.45846450328826904, "alpha_loss": 0.0939486101269722, "alpha_value": 0.37999904338353163, "duration": 1.5430247783660889, "info_normalized_performance_mean": 0.2850100100040436, "info_normalized_performance_final": 0.31474998593330383, "info_performance_mean": 0.2850100100040436, "info_performance_final": 0.31474998593330383, "step": 902500}
{"episode_reward": 570.0200000000002, "episode": 9026.0, "batch_reward": 11.150001525878906, "critic_loss": 1034.82470703125, "actor_loss": -1606.1275634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.09876741468906403, "alpha_loss": 0.0073954276740550995, "alpha_value": 0.37764080032311304, "duration": 1.666504144668579, "info_normalized_performance_mean": 0.4244939386844635, "info_normalized_performance_final": 0.4747883677482605, "info_performance_mean": 0.4244939386844635, "info_performance_final": 0.4747883677482605, "step": 903000}
{"episode_reward": 848.9878542510138, "episode": 9031.0, "batch_reward": 11.36902904510498, "critic_loss": 381.4858093261719, "actor_loss": -1598.079833984375, "actor_target_entropy": -3.0, "actor_entropy": 0.1647873967885971, "alpha_loss": 0.04374704509973526, "alpha_value": 0.374379989700664, "duration": 1.5428524017333984, "info_normalized_performance_mean": 0.8332588076591492, "info_normalized_performance_final": 0.9166666865348816, "info_performance_mean": 0.8332588076591492, "info_performance_final": 0.9166666865348816, "step": 903500}
{"episode_reward": 1666.5178571428553, "episode": 9036.0, "batch_reward": 11.29524040222168, "critic_loss": 485.7530212402344, "actor_loss": -1623.65234375, "actor_target_entropy": -3.0, "actor_entropy": 0.6783310174942017, "alpha_loss": 0.11256949603557587, "alpha_value": 0.3712826307611585, "duration": 1.5434741973876953, "info_normalized_performance_mean": 0.634371280670166, "info_normalized_performance_final": 0.6814285516738892, "info_performance_mean": 0.634371280670166, "info_performance_final": 0.6814285516738892, "step": 904000}
{"episode_reward": 1268.7428571428545, "episode": 9041.0, "batch_reward": 11.616321563720703, "critic_loss": 245.45199584960938, "actor_loss": -1614.1690673828125, "actor_target_entropy": -3.0, "actor_entropy": 0.4559924304485321, "alpha_loss": 0.06132298707962036, "alpha_value": 0.370691392095469, "duration": 1.5387914180755615, "info_normalized_performance_mean": 0.7984166741371155, "info_normalized_performance_final": 0.8583333492279053, "info_performance_mean": 0.7984166741371155, "info_performance_final": 0.8583333492279053, "step": 904500}
{"episode_reward": 1596.8333333333348, "episode": 9046.0, "batch_reward": 12.174493789672852, "critic_loss": 498.0408935546875, "actor_loss": -1678.640380859375, "actor_target_entropy": -3.0, "actor_entropy": 0.25307852029800415, "alpha_loss": 0.02066461741924286, "alpha_value": 0.36681984426763414, "duration": 1.480539321899414, "info_normalized_performance_mean": 0.512057900428772, "info_normalized_performance_final": 0.5556972622871399, "info_performance_mean": 0.512057900428772, "info_performance_final": 0.5556972622871399, "step": 905000}
{"episode_reward": 1024.1156462585043, "episode": 9051.0, "batch_reward": 11.248722076416016, "critic_loss": 502.5238342285156, "actor_loss": -1596.2314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.2341737449169159, "alpha_loss": -0.12999264895915985, "alpha_value": 0.3630867959179444, "duration": 1.5387117862701416, "info_normalized_performance_mean": 0.4222390651702881, "info_normalized_performance_final": 0.4584736227989197, "info_performance_mean": 0.4222390651702881, "info_performance_final": 0.4584736227989197, "step": 905500}
{"episode_reward": 844.4781144781161, "episode": 9056.0, "batch_reward": 11.544387817382812, "critic_loss": 249.67282104492188, "actor_loss": -1632.556884765625, "actor_target_entropy": -3.0, "actor_entropy": 0.017929568886756897, "alpha_loss": -0.06140810623764992, "alpha_value": 0.35932776421227736, "duration": 1.5006115436553955, "info_normalized_performance_mean": 0.3261840045452118, "info_normalized_performance_final": 0.36026936769485474, "info_performance_mean": 0.3261840045452118, "info_performance_final": 0.36026936769485474, "step": 906000}
{"episode_reward": 652.368125701458, "episode": 9061.0, "batch_reward": 11.454483032226562, "critic_loss": 289.3500671386719, "actor_loss": -1629.822509765625, "actor_target_entropy": -3.0, "actor_entropy": 0.5606648325920105, "alpha_loss": -0.017832083627581596, "alpha_value": 0.3578676083041819, "duration": 1.4929313659667969, "info_normalized_performance_mean": 0.6290109157562256, "info_normalized_performance_final": 0.6895604133605957, "info_performance_mean": 0.6290109157562256, "info_performance_final": 0.6895604133605957, "step": 906500}
{"episode_reward": 1258.0219780219786, "episode": 9066.0, "batch_reward": 10.556180953979492, "critic_loss": 285.5050354003906, "actor_loss": -1622.58203125, "actor_target_entropy": -3.0, "actor_entropy": 0.04660278186202049, "alpha_loss": -0.22974169254302979, "alpha_value": 0.357102981843382, "duration": 1.4766547679901123, "info_normalized_performance_mean": 0.7255969047546387, "info_normalized_performance_final": 0.7908163070678711, "info_performance_mean": 0.7255969047546387, "info_performance_final": 0.7908163070678711, "step": 907000}
{"episode_reward": 1451.1938775510228, "episode": 9071.0, "batch_reward": 11.554780960083008, "critic_loss": 322.4979553222656, "actor_loss": -1651.1175537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.44137805700302124, "alpha_loss": 0.04827706888318062, "alpha_value": 0.35845000523025405, "duration": 1.6349854469299316, "info_normalized_performance_mean": 0.810707688331604, "info_normalized_performance_final": 0.8875661492347717, "info_performance_mean": 0.810707688331604, "info_performance_final": 0.8875661492347717, "step": 907500}
{"episode_reward": 1621.4153439153426, "episode": 9076.0, "batch_reward": 11.87022876739502, "critic_loss": 119.17872619628906, "actor_loss": -1633.129150390625, "actor_target_entropy": -3.0, "actor_entropy": 0.3426854610443115, "alpha_loss": 0.1320132613182068, "alpha_value": 0.35926059267805843, "duration": 1.5205621719360352, "info_normalized_performance_mean": 0.8293344378471375, "info_normalized_performance_final": 0.9155844449996948, "info_performance_mean": 0.8293344378471375, "info_performance_final": 0.9155844449996948, "step": 908000}
{"episode_reward": 1658.6688311688329, "episode": 9081.0, "batch_reward": 10.89966869354248, "critic_loss": 476.2743225097656, "actor_loss": -1615.3582763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.7918825149536133, "alpha_loss": -0.03233702480792999, "alpha_value": 0.3604431294577179, "duration": 1.478313684463501, "info_normalized_performance_mean": 0.6138281226158142, "info_normalized_performance_final": 0.6744791865348816, "info_performance_mean": 0.6138281226158142, "info_performance_final": 0.6744791865348816, "step": 908500}
{"episode_reward": 1227.65625, "episode": 9086.0, "batch_reward": 11.22783088684082, "critic_loss": 228.80078125, "actor_loss": -1608.093994140625, "actor_target_entropy": -3.0, "actor_entropy": 0.26428502798080444, "alpha_loss": -0.1207716315984726, "alpha_value": 0.362247757292159, "duration": 1.619166374206543, "info_normalized_performance_mean": 0.8230034708976746, "info_normalized_performance_final": 0.8836805820465088, "info_performance_mean": 0.8230034708976746, "info_performance_final": 0.8836805820465088, "step": 909000}
{"episode_reward": 1646.0069444444425, "episode": 9091.0, "batch_reward": 11.119463920593262, "critic_loss": 467.89263916015625, "actor_loss": -1615.6458740234375, "actor_target_entropy": -3.0, "actor_entropy": 0.2026640921831131, "alpha_loss": -0.05430997908115387, "alpha_value": 0.3643903137847279, "duration": 1.4506056308746338, "info_normalized_performance_mean": 0.7388774156570435, "info_normalized_performance_final": 0.8066893219947815, "info_performance_mean": 0.7388774156570435, "info_performance_final": 0.8066893219947815, "step": 909500}
{"episode_reward": 1477.755102040814, "episode": 9096.0, "batch_reward": 11.233642578125, "critic_loss": 287.636474609375, "actor_loss": -1578.101318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.35981905460357666, "alpha_loss": -0.23807360231876373, "alpha_value": 0.3654748809294843, "step": 910000}
{"duration": 18.4328875541687, "info_normalized_performance_mean": 0.8775402307510376, "info_normalized_performance_final": 0.9390374422073364, "info_performance_mean": 0.8775402307510376, "info_performance_final": 0.9390374422073364, "step": 910000}
{"episode_reward": 1755.0802139037412, "episode": 9101.0, "batch_reward": 11.752141952514648, "critic_loss": 466.8531494140625, "actor_loss": -1589.6953125, "actor_target_entropy": -3.0, "actor_entropy": 0.8103179931640625, "alpha_loss": -0.03417012840509415, "alpha_value": 0.3686628524900484, "duration": 1.5203750133514404, "info_normalized_performance_mean": 0.7888391613960266, "info_normalized_performance_final": 0.8638392686843872, "info_performance_mean": 0.7888391613960266, "info_performance_final": 0.8638392686843872, "step": 910500}
{"episode_reward": 1577.6785714285722, "episode": 9106.0, "batch_reward": 12.32044792175293, "critic_loss": 325.4935302734375, "actor_loss": -1612.00390625, "actor_target_entropy": -3.0, "actor_entropy": 0.6853963136672974, "alpha_loss": 0.17524009943008423, "alpha_value": 0.37208145171714924, "duration": 1.479008674621582, "info_normalized_performance_mean": 0.6526145339012146, "info_normalized_performance_final": 0.718406617641449, "info_performance_mean": 0.6526145339012146, "info_performance_final": 0.718406617641449, "step": 911000}
{"episode_reward": 1305.228937728939, "episode": 9111.0, "batch_reward": 11.710859298706055, "critic_loss": 1056.302734375, "actor_loss": -1607.486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7149806618690491, "alpha_loss": -0.04721017926931381, "alpha_value": 0.3766545026260431, "duration": 1.4493179321289062, "info_normalized_performance_mean": 0.5813323259353638, "info_normalized_performance_final": 0.6309523582458496, "info_performance_mean": 0.5813323259353638, "info_performance_final": 0.6309523582458496, "step": 911500}
{"episode_reward": 1162.6648351648344, "episode": 9116.0, "batch_reward": 10.9024658203125, "critic_loss": 280.2593688964844, "actor_loss": -1595.189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.378907710313797, "alpha_loss": -0.047750070691108704, "alpha_value": 0.380709777774933, "duration": 1.5429799556732178, "info_normalized_performance_mean": 0.8425284028053284, "info_normalized_performance_final": 0.9071428775787354, "info_performance_mean": 0.8425284028053284, "info_performance_final": 0.9071428775787354, "step": 912000}
{"episode_reward": 1685.0571428571411, "episode": 9121.0, "batch_reward": 11.239786148071289, "critic_loss": 278.79705810546875, "actor_loss": -1590.1416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9933420419692993, "alpha_loss": 0.18490050733089447, "alpha_value": 0.3816660594169395, "duration": 1.552128553390503, "info_normalized_performance_mean": 0.8580954074859619, "info_normalized_performance_final": 0.9241071343421936, "info_performance_mean": 0.8580954074859619, "info_performance_final": 0.9241071343421936, "step": 912500}
{"episode_reward": 1716.190476190478, "episode": 9126.0, "batch_reward": 11.409564971923828, "critic_loss": 227.0177001953125, "actor_loss": -1583.573974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.5702757835388184, "alpha_loss": 0.01763042062520981, "alpha_value": 0.3841303150016453, "duration": 1.5435278415679932, "info_normalized_performance_mean": 0.35820984840393066, "info_normalized_performance_final": 0.39403292536735535, "info_performance_mean": 0.35820984840393066, "info_performance_final": 0.39403292536735535, "step": 913000}
{"episode_reward": 716.4197530864183, "episode": 9131.0, "batch_reward": 10.940271377563477, "critic_loss": 288.4786071777344, "actor_loss": -1567.9053955078125, "actor_target_entropy": -3.0, "actor_entropy": 0.6343579292297363, "alpha_loss": -0.05652105435729027, "alpha_value": 0.3866843961948169, "duration": 1.5526866912841797, "info_normalized_performance_mean": 0.7569917440414429, "info_normalized_performance_final": 0.8145604133605957, "info_performance_mean": 0.7569917440414429, "info_performance_final": 0.8145604133605957, "step": 913500}
{"episode_reward": 1513.9835164835183, "episode": 9136.0, "batch_reward": 12.168591499328613, "critic_loss": 388.91632080078125, "actor_loss": -1618.20458984375, "actor_target_entropy": -3.0, "actor_entropy": 0.917999804019928, "alpha_loss": 0.11909699440002441, "alpha_value": 0.3879235328863257, "duration": 1.4694232940673828, "info_normalized_performance_mean": 0.7487325072288513, "info_normalized_performance_final": 0.8188657164573669, "info_performance_mean": 0.7487325072288513, "info_performance_final": 0.8188657164573669, "step": 914000}
{"episode_reward": 1497.465277777776, "episode": 9141.0, "batch_reward": 11.844451904296875, "critic_loss": 670.7843017578125, "actor_loss": -1598.7335205078125, "actor_target_entropy": -3.0, "actor_entropy": 0.30847662687301636, "alpha_loss": -0.01940460503101349, "alpha_value": 0.3891514884490173, "duration": 1.587592601776123, "info_normalized_performance_mean": 0.482217013835907, "info_normalized_performance_final": 0.5329217910766602, "info_performance_mean": 0.482217013835907, "info_performance_final": 0.5329217910766602, "step": 914500}
{"episode_reward": 964.4341563786003, "episode": 9146.0, "batch_reward": 11.670026779174805, "critic_loss": 388.65106201171875, "actor_loss": -1577.208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9384769201278687, "alpha_loss": 0.0549532026052475, "alpha_value": 0.39116641980921274, "duration": 1.4556634426116943, "info_normalized_performance_mean": 0.6541612148284912, "info_normalized_performance_final": 0.7104978561401367, "info_performance_mean": 0.6541612148284912, "info_performance_final": 0.7104978561401367, "step": 915000}
{"episode_reward": 1308.322510822511, "episode": 9151.0, "batch_reward": 10.538911819458008, "critic_loss": 265.8118896484375, "actor_loss": -1536.273681640625, "actor_target_entropy": -3.0, "actor_entropy": 0.6743762493133545, "alpha_loss": -0.07586047053337097, "alpha_value": 0.39004316424005103, "duration": 1.6067655086517334, "info_normalized_performance_mean": 0.7380000352859497, "info_normalized_performance_final": 0.8047618865966797, "info_performance_mean": 0.7380000352859497, "info_performance_final": 0.8047618865966797, "step": 915500}
{"episode_reward": 1475.9999999999984, "episode": 9156.0, "batch_reward": 12.121915817260742, "critic_loss": 313.04083251953125, "actor_loss": -1613.3897705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7952694296836853, "alpha_loss": 0.17542006075382233, "alpha_value": 0.39207308714734224, "duration": 1.6256487369537354, "info_normalized_performance_mean": 0.7783800363540649, "info_normalized_performance_final": 0.8361991047859192, "info_performance_mean": 0.7783800363540649, "info_performance_final": 0.8361991047859192, "step": 916000}
{"episode_reward": 1556.7601809954785, "episode": 9161.0, "batch_reward": 12.314491271972656, "critic_loss": 195.8821563720703, "actor_loss": -1616.5771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.9764713048934937, "alpha_loss": 0.14850011467933655, "alpha_value": 0.390746915160152, "duration": 1.6056303977966309, "info_normalized_performance_mean": 0.7078254818916321, "info_normalized_performance_final": 0.7714285850524902, "info_performance_mean": 0.7078254818916321, "info_performance_final": 0.7714285850524902, "step": 916500}
{"episode_reward": 1415.650793650792, "episode": 9166.0, "batch_reward": 11.140291213989258, "critic_loss": 216.76646423339844, "actor_loss": -1588.3677978515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8550587892532349, "alpha_loss": 0.14406001567840576, "alpha_value": 0.39074476501751243, "duration": 1.5260655879974365, "info_normalized_performance_mean": 0.6480356454849243, "info_normalized_performance_final": 0.7074176073074341, "info_performance_mean": 0.6480356454849243, "info_performance_final": 0.7074176073074341, "step": 917000}
{"episode_reward": 1296.0714285714307, "episode": 9171.0, "batch_reward": 11.411433219909668, "critic_loss": 319.0751953125, "actor_loss": -1598.845458984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8800553679466248, "alpha_loss": -0.02691454067826271, "alpha_value": 0.3901228595912795, "duration": 1.5419731140136719, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 917500}
{"episode_reward": 0.0, "episode": 9176.0, "batch_reward": 11.905086517333984, "critic_loss": 374.71392822265625, "actor_loss": -1616.8179931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1123924255371094, "alpha_loss": 0.13923881947994232, "alpha_value": 0.38969103090503543, "duration": 1.5282542705535889, "info_normalized_performance_mean": 0.7375169992446899, "info_normalized_performance_final": 0.8048469424247742, "info_performance_mean": 0.7375169992446899, "info_performance_final": 0.8048469424247742, "step": 918000}
{"episode_reward": 1475.0340136054408, "episode": 9181.0, "batch_reward": 11.376871109008789, "critic_loss": 960.6373901367188, "actor_loss": -1600.4493408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.6730600595474243, "alpha_loss": -0.003755703568458557, "alpha_value": 0.39382387737490515, "duration": 1.445556640625, "info_normalized_performance_mean": 0.536354124546051, "info_normalized_performance_final": 0.5833333134651184, "info_performance_mean": 0.536354124546051, "info_performance_final": 0.5833333134651184, "step": 918500}
{"episode_reward": 1072.7083333333323, "episode": 9186.0, "batch_reward": 10.762521743774414, "critic_loss": 546.173095703125, "actor_loss": -1601.9306640625, "actor_target_entropy": -3.0, "actor_entropy": 0.6193087697029114, "alpha_loss": -0.3045787811279297, "alpha_value": 0.39483178038664585, "duration": 1.5917003154754639, "info_normalized_performance_mean": 0.5020943284034729, "info_normalized_performance_final": 0.5595604181289673, "info_performance_mean": 0.5020943284034729, "info_performance_final": 0.5595604181289673, "step": 919000}
{"episode_reward": 1004.1890109890087, "episode": 9191.0, "batch_reward": 11.794886589050293, "critic_loss": 213.82113647460938, "actor_loss": -1604.297607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.5960725545883179, "alpha_loss": -0.14120790362358093, "alpha_value": 0.3963776727054562, "duration": 1.4624176025390625, "info_normalized_performance_mean": 0.8004821538925171, "info_normalized_performance_final": 0.8852258920669556, "info_performance_mean": 0.8004821538925171, "info_performance_final": 0.8852258920669556, "step": 919500}
{"episode_reward": 1600.9645909645897, "episode": 9196.0, "batch_reward": 12.207372665405273, "critic_loss": 353.660888671875, "actor_loss": -1625.234619140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6864897012710571, "alpha_loss": 0.2342594861984253, "alpha_value": 0.3987960045979545, "step": 920000}
{"duration": 18.989850759506226, "info_normalized_performance_mean": 0.5124460458755493, "info_normalized_performance_final": 0.5648351907730103, "info_performance_mean": 0.5124460458755493, "info_performance_final": 0.5648351907730103, "step": 920000}
{"episode_reward": 1024.8923076923077, "episode": 9201.0, "batch_reward": 10.929574966430664, "critic_loss": 320.1125793457031, "actor_loss": -1619.67724609375, "actor_target_entropy": -3.0, "actor_entropy": 0.5907601118087769, "alpha_loss": -0.3998507857322693, "alpha_value": 0.39775726011560636, "duration": 1.5950860977172852, "info_normalized_performance_mean": 0.5181689262390137, "info_normalized_performance_final": 0.579285740852356, "info_performance_mean": 0.5181689262390137, "info_performance_final": 0.579285740852356, "step": 920500}
{"episode_reward": 1036.3380952380953, "episode": 9206.0, "batch_reward": 10.936433792114258, "critic_loss": 276.67901611328125, "actor_loss": -1549.914794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.6232728362083435, "alpha_loss": -0.17287030816078186, "alpha_value": 0.4019470716155665, "duration": 1.5212328433990479, "info_normalized_performance_mean": 0.5155877470970154, "info_normalized_performance_final": 0.5677419304847717, "info_performance_mean": 0.5155877470970154, "info_performance_final": 0.5677419304847717, "step": 921000}
{"episode_reward": 1031.1756272401444, "episode": 9211.0, "batch_reward": 12.156241416931152, "critic_loss": 501.0248718261719, "actor_loss": -1623.11376953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9244237542152405, "alpha_loss": 0.06289742887020111, "alpha_value": 0.40620070439065986, "duration": 1.5496177673339844, "info_normalized_performance_mean": 0.2995416522026062, "info_normalized_performance_final": 0.3229166567325592, "info_performance_mean": 0.2995416522026062, "info_performance_final": 0.3229166567325592, "step": 921500}
{"episode_reward": 599.0833333333333, "episode": 9216.0, "batch_reward": 11.551071166992188, "critic_loss": 122.14462280273438, "actor_loss": -1568.149658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.2840156555175781, "alpha_loss": -0.09428298473358154, "alpha_value": 0.4120457070717485, "duration": 1.6131901741027832, "info_normalized_performance_mean": 0.7616440653800964, "info_normalized_performance_final": 0.8151927590370178, "info_performance_mean": 0.7616440653800964, "info_performance_final": 0.8151927590370178, "step": 922000}
{"episode_reward": 1523.2879818594095, "episode": 9221.0, "batch_reward": 11.740276336669922, "critic_loss": 283.4554138183594, "actor_loss": -1635.320068359375, "actor_target_entropy": -3.0, "actor_entropy": 0.600033164024353, "alpha_loss": -0.003466309979557991, "alpha_value": 0.41674638373950856, "duration": 1.3515441417694092, "info_normalized_performance_mean": 0.6335546970367432, "info_normalized_performance_final": 0.6796875, "info_performance_mean": 0.6335546970367432, "info_performance_final": 0.6796875, "step": 922500}
{"episode_reward": 1267.109375, "episode": 9226.0, "batch_reward": 11.184053421020508, "critic_loss": 284.1824951171875, "actor_loss": -1613.255615234375, "actor_target_entropy": -3.0, "actor_entropy": 0.6347354650497437, "alpha_loss": -0.09969323873519897, "alpha_value": 0.4196116538449954, "duration": 1.4744939804077148, "info_normalized_performance_mean": 0.8307342529296875, "info_normalized_performance_final": 0.8948412537574768, "info_performance_mean": 0.8307342529296875, "info_performance_final": 0.8948412537574768, "step": 923000}
{"episode_reward": 1661.4682539682517, "episode": 9231.0, "batch_reward": 11.04205322265625, "critic_loss": 236.93157958984375, "actor_loss": -1606.019775390625, "actor_target_entropy": -3.0, "actor_entropy": 0.841126561164856, "alpha_loss": -0.06206705421209335, "alpha_value": 0.42540707632558156, "duration": 1.5610315799713135, "info_normalized_performance_mean": 0.4782099425792694, "info_normalized_performance_final": 0.5264999866485596, "info_performance_mean": 0.4782099425792694, "info_performance_final": 0.5264999866485596, "step": 923500}
{"episode_reward": 956.4199999999983, "episode": 9236.0, "batch_reward": 11.83057975769043, "critic_loss": 227.48866271972656, "actor_loss": -1608.70849609375, "actor_target_entropy": -3.0, "actor_entropy": 0.6974502801895142, "alpha_loss": 0.18493962287902832, "alpha_value": 0.431110306309973, "duration": 1.5396692752838135, "info_normalized_performance_mean": 0.1529500037431717, "info_normalized_performance_final": 0.1641666740179062, "info_performance_mean": 0.1529500037431717, "info_performance_final": 0.1641666740179062, "step": 924000}
{"episode_reward": 305.90000000000026, "episode": 9241.0, "batch_reward": 11.532255172729492, "critic_loss": 383.3129577636719, "actor_loss": -1625.49755859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1065179109573364, "alpha_loss": -0.23123551905155182, "alpha_value": 0.43325209792596886, "duration": 1.718134880065918, "info_normalized_performance_mean": 0.3853616714477539, "info_normalized_performance_final": 0.46643519401550293, "info_performance_mean": 0.3853616714477539, "info_performance_final": 0.46643519401550293, "step": 924500}
{"episode_reward": 770.7233796296288, "episode": 9246.0, "batch_reward": 11.459157943725586, "critic_loss": 288.73101806640625, "actor_loss": -1647.083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.5904794335365295, "alpha_loss": -0.03324997425079346, "alpha_value": 0.43661516594468697, "duration": 1.6412465572357178, "info_normalized_performance_mean": 0.5819510817527771, "info_normalized_performance_final": 0.6335979104042053, "info_performance_mean": 0.5819510817527771, "info_performance_final": 0.6335979104042053, "step": 925000}
{"episode_reward": 1163.9021164021165, "episode": 9251.0, "batch_reward": 11.666887283325195, "critic_loss": 458.75592041015625, "actor_loss": -1651.51708984375, "actor_target_entropy": -3.0, "actor_entropy": 1.000538945198059, "alpha_loss": 0.06832615286111832, "alpha_value": 0.4406070250964489, "duration": 1.4683990478515625, "info_normalized_performance_mean": 0.3077978491783142, "info_normalized_performance_final": 0.33203125, "info_performance_mean": 0.3077978491783142, "info_performance_final": 0.33203125, "step": 925500}
{"episode_reward": 615.595703125, "episode": 9256.0, "batch_reward": 11.617269515991211, "critic_loss": 888.4365844726562, "actor_loss": -1644.6510009765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9746428728103638, "alpha_loss": 0.07388100028038025, "alpha_value": 0.44569367056733156, "duration": 1.6063213348388672, "info_normalized_performance_mean": 0.8879749774932861, "info_normalized_performance_final": 0.9441666603088379, "info_performance_mean": 0.8879749774932861, "info_performance_final": 0.9441666603088379, "step": 926000}
{"episode_reward": 1775.950000000004, "episode": 9261.0, "batch_reward": 11.315213203430176, "critic_loss": 684.0787353515625, "actor_loss": -1613.1158447265625, "actor_target_entropy": -3.0, "actor_entropy": 0.49691522121429443, "alpha_loss": 0.12286748737096786, "alpha_value": 0.4499477756453303, "duration": 1.5249674320220947, "info_normalized_performance_mean": 0.8474777340888977, "info_normalized_performance_final": 0.9129464030265808, "info_performance_mean": 0.8474777340888977, "info_performance_final": 0.9129464030265808, "step": 926500}
{"episode_reward": 1694.95535714286, "episode": 9266.0, "batch_reward": 10.664840698242188, "critic_loss": 282.3641662597656, "actor_loss": -1569.904541015625, "actor_target_entropy": -3.0, "actor_entropy": 0.8131942749023438, "alpha_loss": -0.20067375898361206, "alpha_value": 0.4531857139727096, "duration": 1.5138969421386719, "info_normalized_performance_mean": 0.7950891256332397, "info_normalized_performance_final": 0.8589285612106323, "info_performance_mean": 0.7950891256332397, "info_performance_final": 0.8589285612106323, "step": 927000}
{"episode_reward": 1590.1785714285688, "episode": 9271.0, "batch_reward": 10.671967506408691, "critic_loss": 637.1685791015625, "actor_loss": -1596.923583984375, "actor_target_entropy": -3.0, "actor_entropy": 0.6931207180023193, "alpha_loss": -0.2947632372379303, "alpha_value": 0.4531222841569243, "duration": 1.517124891281128, "info_normalized_performance_mean": 0.5777806639671326, "info_normalized_performance_final": 0.6275510191917419, "info_performance_mean": 0.5777806639671326, "info_performance_final": 0.6275510191917419, "step": 927500}
{"episode_reward": 1155.5612244897961, "episode": 9276.0, "batch_reward": 11.358577728271484, "critic_loss": 538.2308349609375, "actor_loss": -1657.8978271484375, "actor_target_entropy": -3.0, "actor_entropy": 0.35934847593307495, "alpha_loss": -0.1358463615179062, "alpha_value": 0.454021090906908, "duration": 1.432551622390747, "info_normalized_performance_mean": 0.6186309456825256, "info_normalized_performance_final": 0.663690447807312, "info_performance_mean": 0.6186309456825256, "info_performance_final": 0.663690447807312, "step": 928000}
{"episode_reward": 1237.2619047619062, "episode": 9281.0, "batch_reward": 10.449808120727539, "critic_loss": 684.2334594726562, "actor_loss": -1622.3858642578125, "actor_target_entropy": -3.0, "actor_entropy": 0.4200654923915863, "alpha_loss": -0.09014204144477844, "alpha_value": 0.45794977759918337, "duration": 1.5277776718139648, "info_normalized_performance_mean": 0.847725510597229, "info_normalized_performance_final": 0.9117646813392639, "info_performance_mean": 0.847725510597229, "info_performance_final": 0.9117646813392639, "step": 928500}
{"episode_reward": 1695.4509803921578, "episode": 9286.0, "batch_reward": 10.530765533447266, "critic_loss": 441.96923828125, "actor_loss": -1628.506591796875, "actor_target_entropy": -3.0, "actor_entropy": 0.4659738540649414, "alpha_loss": -0.20207479596138, "alpha_value": 0.46755992214159253, "duration": 1.610274314880371, "info_normalized_performance_mean": 0.7259232997894287, "info_normalized_performance_final": 0.7784993052482605, "info_performance_mean": 0.7259232997894287, "info_performance_final": 0.7784993052482605, "step": 929000}
{"episode_reward": 1451.847041847043, "episode": 9291.0, "batch_reward": 11.211484909057617, "critic_loss": 213.45416259765625, "actor_loss": -1682.5343017578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6160877346992493, "alpha_loss": -0.1747266948223114, "alpha_value": 0.4829570366087301, "duration": 1.6461551189422607, "info_normalized_performance_mean": 0.5834673047065735, "info_normalized_performance_final": 0.6346726417541504, "info_performance_mean": 0.5834673047065735, "info_performance_final": 0.6346726417541504, "step": 929500}
{"episode_reward": 1166.9345238095243, "episode": 9296.0, "batch_reward": 10.407196044921875, "critic_loss": 789.2066650390625, "actor_loss": -1674.022705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.5857594609260559, "alpha_loss": -0.39408692717552185, "alpha_value": 0.5036598885801671, "step": 930000}
{"duration": 18.567039012908936, "info_normalized_performance_mean": 0.8373568654060364, "info_normalized_performance_final": 0.9192708134651184, "info_performance_mean": 0.8373568654060364, "info_performance_final": 0.9192708134651184, "step": 930000}
{"episode_reward": 1674.7135416666686, "episode": 9301.0, "batch_reward": 12.012947082519531, "critic_loss": 1028.826171875, "actor_loss": -1741.86767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.3745386600494385, "alpha_loss": -0.39942312240600586, "alpha_value": 0.525062838183444, "duration": 1.5565402507781982, "info_normalized_performance_mean": 0.7830988168716431, "info_normalized_performance_final": 0.8346354365348816, "info_performance_mean": 0.7830988168716431, "info_performance_final": 0.8346354365348816, "step": 930500}
{"episode_reward": 1566.1979166666652, "episode": 9306.0, "batch_reward": 10.523761749267578, "critic_loss": 425.65753173828125, "actor_loss": -1686.90087890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7644262313842773, "alpha_loss": -0.6553544998168945, "alpha_value": 0.5431063967708752, "duration": 1.6016039848327637, "info_normalized_performance_mean": 0.7661024332046509, "info_normalized_performance_final": 0.8227513432502747, "info_performance_mean": 0.7661024332046509, "info_performance_final": 0.8227513432502747, "step": 931000}
{"episode_reward": 1532.2045855379167, "episode": 9311.0, "batch_reward": 11.249712944030762, "critic_loss": 357.62799072265625, "actor_loss": -1720.335205078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0144627094268799, "alpha_loss": -0.72488933801651, "alpha_value": 0.5632833571329227, "duration": 1.5493676662445068, "info_normalized_performance_mean": 0.9276041984558105, "info_normalized_performance_final": 0.9973958134651184, "info_performance_mean": 0.9276041984558105, "info_performance_final": 0.9973958134651184, "step": 931500}
{"episode_reward": 1855.2083333333358, "episode": 9316.0, "batch_reward": 11.706315040588379, "critic_loss": 309.6836242675781, "actor_loss": -1823.190673828125, "actor_target_entropy": -3.0, "actor_entropy": 0.749756932258606, "alpha_loss": -0.6969853639602661, "alpha_value": 0.5838665345467067, "duration": 1.6091961860656738, "info_normalized_performance_mean": 0.6487170457839966, "info_normalized_performance_final": 0.7037037014961243, "info_performance_mean": 0.6487170457839966, "info_performance_final": 0.7037037014961243, "step": 932000}
{"episode_reward": 1297.4338624338616, "episode": 9321.0, "batch_reward": 10.936863899230957, "critic_loss": 338.45367431640625, "actor_loss": -1766.839111328125, "actor_target_entropy": -3.0, "actor_entropy": 1.15338933467865, "alpha_loss": -0.6745067238807678, "alpha_value": 0.6056755211051081, "duration": 1.495124340057373, "info_normalized_performance_mean": 0.637091875076294, "info_normalized_performance_final": 0.6843112111091614, "info_performance_mean": 0.637091875076294, "info_performance_final": 0.6843112111091614, "step": 932500}
{"episode_reward": 1274.1836734693868, "episode": 9326.0, "batch_reward": 11.23966121673584, "critic_loss": 584.249267578125, "actor_loss": -1836.7657470703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9978468418121338, "alpha_loss": -0.7291990518569946, "alpha_value": 0.6249891167240944, "duration": 1.6003906726837158, "info_normalized_performance_mean": 0.7344357371330261, "info_normalized_performance_final": 0.7899305820465088, "info_performance_mean": 0.7344357371330261, "info_performance_final": 0.7899305820465088, "step": 933000}
{"episode_reward": 1468.871527777776, "episode": 9331.0, "batch_reward": 10.86729621887207, "critic_loss": 740.136474609375, "actor_loss": -1848.732177734375, "actor_target_entropy": -3.0, "actor_entropy": 0.768360435962677, "alpha_loss": -1.1051039695739746, "alpha_value": 0.6455152718287068, "duration": 1.4461424350738525, "info_normalized_performance_mean": 0.4334940016269684, "info_normalized_performance_final": 0.46964284777641296, "info_performance_mean": 0.4334940016269684, "info_performance_final": 0.46964284777641296, "step": 933500}
{"episode_reward": 866.9880952380946, "episode": 9336.0, "batch_reward": 10.780681610107422, "critic_loss": 711.636474609375, "actor_loss": -1844.6256103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0597305297851562, "alpha_loss": -0.853088915348053, "alpha_value": 0.6655278967855548, "duration": 1.5955321788787842, "info_normalized_performance_mean": 0.795203685760498, "info_normalized_performance_final": 0.8542986512184143, "info_performance_mean": 0.795203685760498, "info_performance_final": 0.8542986512184143, "step": 934000}
{"episode_reward": 1590.407239819004, "episode": 9341.0, "batch_reward": 11.421031951904297, "critic_loss": 753.4090576171875, "actor_loss": -1932.19287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1431875228881836, "alpha_loss": -1.2830626964569092, "alpha_value": 0.6832817926285867, "duration": 1.5747127532958984, "info_normalized_performance_mean": 0.13481192290782928, "info_normalized_performance_final": 0.18119047582149506, "info_performance_mean": 0.13481192290782928, "info_performance_final": 0.18119047582149506, "step": 934500}
{"episode_reward": 269.62380952380926, "episode": 9346.0, "batch_reward": 11.859474182128906, "critic_loss": 309.9769287109375, "actor_loss": -1960.82421875, "actor_target_entropy": -3.0, "actor_entropy": 1.2970468997955322, "alpha_loss": -0.5849497318267822, "alpha_value": 0.6990293242628418, "duration": 1.616431474685669, "info_normalized_performance_mean": 0.5724149346351624, "info_normalized_performance_final": 0.6224489808082581, "info_performance_mean": 0.5724149346351624, "info_performance_final": 0.6224489808082581, "step": 935000}
{"episode_reward": 1144.829931972789, "episode": 9351.0, "batch_reward": 10.927927017211914, "critic_loss": 822.8875732421875, "actor_loss": -1947.3736572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2562601566314697, "alpha_loss": -0.8095221519470215, "alpha_value": 0.7138043910102826, "duration": 1.5068538188934326, "info_normalized_performance_mean": 0.7018994688987732, "info_normalized_performance_final": 0.7554945349693298, "info_performance_mean": 0.7018994688987732, "info_performance_final": 0.7554945349693298, "step": 935500}
{"episode_reward": 1403.7990580847718, "episode": 9356.0, "batch_reward": 11.488567352294922, "critic_loss": 1264.28369140625, "actor_loss": -1971.6923828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9397269487380981, "alpha_loss": -0.28418922424316406, "alpha_value": 0.7246519834969694, "duration": 1.558741569519043, "info_normalized_performance_mean": 0.8055893182754517, "info_normalized_performance_final": 0.8785714507102966, "info_performance_mean": 0.8055893182754517, "info_performance_final": 0.8785714507102966, "step": 936000}
{"episode_reward": 1611.1785714285738, "episode": 9361.0, "batch_reward": 12.08715534210205, "critic_loss": 420.6400451660156, "actor_loss": -2013.518798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3043891191482544, "alpha_loss": -0.3120709955692291, "alpha_value": 0.7341835687359908, "duration": 1.544433355331421, "info_normalized_performance_mean": 0.4867522418498993, "info_normalized_performance_final": 0.5334987640380859, "info_performance_mean": 0.4867522418498993, "info_performance_final": 0.5334987640380859, "step": 936500}
{"episode_reward": 973.5042735042748, "episode": 9366.0, "batch_reward": 11.192033767700195, "critic_loss": 1309.381591796875, "actor_loss": -1986.11328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0335806608200073, "alpha_loss": 0.09659057855606079, "alpha_value": 0.7411529191043716, "duration": 1.3613636493682861, "info_normalized_performance_mean": 0.14540816843509674, "info_normalized_performance_final": 0.16287283599376678, "info_performance_mean": 0.14540816843509674, "info_performance_final": 0.16287283599376678, "step": 937000}
{"episode_reward": 290.81632653061234, "episode": 9371.0, "batch_reward": 11.825010299682617, "critic_loss": 833.62939453125, "actor_loss": -2038.773681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1045728921890259, "alpha_loss": -0.03515740856528282, "alpha_value": 0.7471333134960013, "duration": 1.5289618968963623, "info_normalized_performance_mean": 0.6145285367965698, "info_normalized_performance_final": 0.6600000262260437, "info_performance_mean": 0.6145285367965698, "info_performance_final": 0.6600000262260437, "step": 937500}
{"episode_reward": 1229.057142857145, "episode": 9376.0, "batch_reward": 11.941320419311523, "critic_loss": 772.4000854492188, "actor_loss": -2069.939453125, "actor_target_entropy": -3.0, "actor_entropy": 1.1177417039871216, "alpha_loss": 0.047297149896621704, "alpha_value": 0.7542630186440124, "duration": 1.523080587387085, "info_normalized_performance_mean": 0.5734999775886536, "info_normalized_performance_final": 0.6236607432365417, "info_performance_mean": 0.5734999775886536, "info_performance_final": 0.6236607432365417, "step": 938000}
{"episode_reward": 1147.0000000000011, "episode": 9381.0, "batch_reward": 11.692924499511719, "critic_loss": 552.3561401367188, "actor_loss": -2085.652099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1748212575912476, "alpha_loss": 0.18363109230995178, "alpha_value": 0.7603832767404192, "duration": 1.5261588096618652, "info_normalized_performance_mean": 0.2874993085861206, "info_normalized_performance_final": 0.3189964294433594, "info_performance_mean": 0.2874993085861206, "info_performance_final": 0.3189964294433594, "step": 938500}
{"episode_reward": 574.9986214502349, "episode": 9386.0, "batch_reward": 11.627717018127441, "critic_loss": 1094.04833984375, "actor_loss": -2045.67333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.121545672416687, "alpha_loss": 0.3943277597427368, "alpha_value": 0.7577019675709504, "duration": 1.5794427394866943, "info_normalized_performance_mean": 0.7457999587059021, "info_normalized_performance_final": 0.801111102104187, "info_performance_mean": 0.7457999587059021, "info_performance_final": 0.801111102104187, "step": 939000}
{"episode_reward": 1491.5999999999979, "episode": 9391.0, "batch_reward": 11.019944190979004, "critic_loss": 480.3165283203125, "actor_loss": -2048.377685546875, "actor_target_entropy": -3.0, "actor_entropy": 0.884613573551178, "alpha_loss": 0.2974373996257782, "alpha_value": 0.75183630601359, "duration": 1.5775327682495117, "info_normalized_performance_mean": 0.5700777769088745, "info_normalized_performance_final": 0.605555534362793, "info_performance_mean": 0.5700777769088745, "info_performance_final": 0.605555534362793, "step": 939500}
{"episode_reward": 1140.1555555555537, "episode": 9396.0, "batch_reward": 10.293750762939453, "critic_loss": 498.42010498046875, "actor_loss": -2047.0565185546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7881706953048706, "alpha_loss": 0.14971502125263214, "alpha_value": 0.7449522991852655, "step": 940000}
{"duration": 18.614675998687744, "info_normalized_performance_mean": 0.46417099237442017, "info_normalized_performance_final": 0.5190972089767456, "info_performance_mean": 0.46417099237442017, "info_performance_final": 0.5190972089767456, "step": 940000}
{"episode_reward": 928.3420138888898, "episode": 9401.0, "batch_reward": 11.337900161743164, "critic_loss": 587.307861328125, "actor_loss": -1998.96484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7903714179992676, "alpha_loss": 0.2862789034843445, "alpha_value": 0.7344689401132656, "duration": 1.4846694469451904, "info_normalized_performance_mean": 0.8614106774330139, "info_normalized_performance_final": 0.9267857074737549, "info_performance_mean": 0.8614106774330139, "info_performance_final": 0.9267857074737549, "step": 940500}
{"episode_reward": 1722.8214285714264, "episode": 9406.0, "batch_reward": 11.158517837524414, "critic_loss": 270.42266845703125, "actor_loss": -2028.3502197265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2279949188232422, "alpha_loss": 0.22424741089344025, "alpha_value": 0.7242717406260563, "duration": 1.5756149291992188, "info_normalized_performance_mean": 0.42685970664024353, "info_normalized_performance_final": 0.47394540905952454, "info_performance_mean": 0.42685970664024353, "info_performance_final": 0.47394540905952454, "step": 941000}
{"episode_reward": 853.7193272677135, "episode": 9411.0, "batch_reward": 10.493772506713867, "critic_loss": 1729.718505859375, "actor_loss": -2025.556396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0612473487854004, "alpha_loss": -0.0018738210201263428, "alpha_value": 0.7161639554972483, "duration": 1.5229551792144775, "info_normalized_performance_mean": 0.4982706308364868, "info_normalized_performance_final": 0.5514914989471436, "info_performance_mean": 0.4982706308364868, "info_performance_final": 0.5514914989471436, "step": 941500}
{"episode_reward": 996.5411931818169, "episode": 9416.0, "batch_reward": 11.809564590454102, "critic_loss": 1180.329345703125, "actor_loss": -2071.069580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0704121589660645, "alpha_loss": 0.44238123297691345, "alpha_value": 0.7076515855439252, "duration": 1.536961555480957, "info_normalized_performance_mean": 0.7966468930244446, "info_normalized_performance_final": 0.863095223903656, "info_performance_mean": 0.7966468930244446, "info_performance_final": 0.863095223903656, "step": 942000}
{"episode_reward": 1593.293650793654, "episode": 9421.0, "batch_reward": 11.408929824829102, "critic_loss": 1080.6434326171875, "actor_loss": -2024.7352294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.0676623582839966, "alpha_loss": 0.24248534440994263, "alpha_value": 0.6957220375025782, "duration": 1.5138108730316162, "info_normalized_performance_mean": 0.33836430311203003, "info_normalized_performance_final": 0.37536656856536865, "info_performance_mean": 0.33836430311203003, "info_performance_final": 0.37536656856536865, "step": 942500}
{"episode_reward": 676.7285760834143, "episode": 9426.0, "batch_reward": 12.079829216003418, "critic_loss": 382.1245422363281, "actor_loss": -2074.89208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.0072869062423706, "alpha_loss": 0.1440143585205078, "alpha_value": 0.6877579669724945, "duration": 1.5048627853393555, "info_normalized_performance_mean": 0.5010972619056702, "info_normalized_performance_final": 0.5383522510528564, "info_performance_mean": 0.5010972619056702, "info_performance_final": 0.5383522510528564, "step": 943000}
{"episode_reward": 1002.1946022727286, "episode": 9431.0, "batch_reward": 11.868441581726074, "critic_loss": 495.9070129394531, "actor_loss": -2101.7958984375, "actor_target_entropy": -3.0, "actor_entropy": 0.918363094329834, "alpha_loss": 0.19268085062503815, "alpha_value": 0.6804087625526901, "duration": 1.4711816310882568, "info_normalized_performance_mean": 0.582123875617981, "info_normalized_performance_final": 0.6493055820465088, "info_performance_mean": 0.582123875617981, "info_performance_final": 0.6493055820465088, "step": 943500}
{"episode_reward": 1164.2476851851836, "episode": 9436.0, "batch_reward": 11.589269638061523, "critic_loss": 557.1000366210938, "actor_loss": -2058.326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.0904266834259033, "alpha_loss": 0.5154417157173157, "alpha_value": 0.6720872670225361, "duration": 1.5626671314239502, "info_normalized_performance_mean": 0.612606406211853, "info_normalized_performance_final": 0.6840659379959106, "info_performance_mean": 0.612606406211853, "info_performance_final": 0.6840659379959106, "step": 944000}
{"episode_reward": 1225.2129120879122, "episode": 9441.0, "batch_reward": 10.198554992675781, "critic_loss": 509.0935974121094, "actor_loss": -1965.2509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0322767496109009, "alpha_loss": -0.04095115885138512, "alpha_value": 0.6624134646095174, "duration": 1.5885896682739258, "info_normalized_performance_mean": 0.5598015785217285, "info_normalized_performance_final": 0.6539682745933533, "info_performance_mean": 0.5598015785217285, "info_performance_final": 0.6539682745933533, "step": 944500}
{"episode_reward": 1119.6031746031733, "episode": 9446.0, "batch_reward": 11.673828125, "critic_loss": 690.900146484375, "actor_loss": -2053.67431640625, "actor_target_entropy": -3.0, "actor_entropy": 1.4079644680023193, "alpha_loss": 0.15848985314369202, "alpha_value": 0.6547021783279998, "duration": 1.5343267917633057, "info_normalized_performance_mean": 0.6068620085716248, "info_normalized_performance_final": 0.6618923544883728, "info_performance_mean": 0.6068620085716248, "info_performance_final": 0.6618923544883728, "step": 945000}
{"episode_reward": 1213.723958333331, "episode": 9451.0, "batch_reward": 11.375907897949219, "critic_loss": 606.4885864257812, "actor_loss": -2018.251953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7853713035583496, "alpha_loss": 0.21522408723831177, "alpha_value": 0.6461340577052723, "duration": 1.5312628746032715, "info_normalized_performance_mean": 0.8213528394699097, "info_normalized_performance_final": 0.8882352709770203, "info_performance_mean": 0.8213528394699097, "info_performance_final": 0.8882352709770203, "step": 945500}
{"episode_reward": 1642.70588235294, "episode": 9456.0, "batch_reward": 11.489218711853027, "critic_loss": 1229.615234375, "actor_loss": -2068.414794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8700089454650879, "alpha_loss": 0.33183610439300537, "alpha_value": 0.6442041791707414, "duration": 1.563387393951416, "info_normalized_performance_mean": 0.4134952425956726, "info_normalized_performance_final": 0.46047618985176086, "info_performance_mean": 0.4134952425956726, "info_performance_final": 0.46047618985176086, "step": 946000}
{"episode_reward": 826.9904761904772, "episode": 9461.0, "batch_reward": 11.747928619384766, "critic_loss": 880.2443237304688, "actor_loss": -2068.599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2784812450408936, "alpha_loss": 0.22301344573497772, "alpha_value": 0.6384325015568828, "duration": 1.7093782424926758, "info_normalized_performance_mean": 0.47888123989105225, "info_normalized_performance_final": 0.596764326095581, "info_performance_mean": 0.47888123989105225, "info_performance_final": 0.596764326095581, "step": 946500}
{"episode_reward": 957.762515262516, "episode": 9466.0, "batch_reward": 11.503400802612305, "critic_loss": 880.2356567382812, "actor_loss": -2003.476318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.0825204849243164, "alpha_loss": 0.22754178941249847, "alpha_value": 0.6318993017815985, "duration": 1.4605257511138916, "info_normalized_performance_mean": 0.529171884059906, "info_normalized_performance_final": 0.5625, "info_performance_mean": 0.529171884059906, "info_performance_final": 0.5625, "step": 947000}
{"episode_reward": 1058.34375, "episode": 9471.0, "batch_reward": 11.544142723083496, "critic_loss": 186.69931030273438, "actor_loss": -2070.2353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1100654602050781, "alpha_loss": 0.30378803610801697, "alpha_value": 0.6255201032688232, "duration": 1.6014184951782227, "info_normalized_performance_mean": 0.7221400737762451, "info_normalized_performance_final": 0.7900000214576721, "info_performance_mean": 0.7221400737762451, "info_performance_final": 0.7900000214576721, "step": 947500}
{"episode_reward": 1444.2799999999977, "episode": 9476.0, "batch_reward": 10.957868576049805, "critic_loss": 390.0084228515625, "actor_loss": -1986.0606689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0646103620529175, "alpha_loss": 0.052769362926483154, "alpha_value": 0.6232604335699752, "duration": 1.5014402866363525, "info_normalized_performance_mean": 0.7520198225975037, "info_normalized_performance_final": 0.8119999766349792, "info_performance_mean": 0.7520198225975037, "info_performance_final": 0.8119999766349792, "step": 948000}
{"episode_reward": 1504.0400000000006, "episode": 9481.0, "batch_reward": 11.3504638671875, "critic_loss": 1503.795166015625, "actor_loss": -2080.7568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.0392050743103027, "alpha_loss": 0.18543468415737152, "alpha_value": 0.6187916036899044, "duration": 1.5735669136047363, "info_normalized_performance_mean": 0.5683007836341858, "info_normalized_performance_final": 0.6259765625, "info_performance_mean": 0.5683007836341858, "info_performance_final": 0.6259765625, "step": 948500}
{"episode_reward": 1136.6015625, "episode": 9486.0, "batch_reward": 11.752650260925293, "critic_loss": 951.6099243164062, "actor_loss": -2048.01513671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9688284993171692, "alpha_loss": 0.0089578777551651, "alpha_value": 0.616520505523964, "duration": 1.59199857711792, "info_normalized_performance_mean": 0.4150524139404297, "info_normalized_performance_final": 0.4650000035762787, "info_performance_mean": 0.4150524139404297, "info_performance_final": 0.4650000035762787, "step": 949000}
{"episode_reward": 830.1047619047608, "episode": 9491.0, "batch_reward": 10.530903816223145, "critic_loss": 579.1644287109375, "actor_loss": -1998.52490234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8187507390975952, "alpha_loss": 0.12228789180517197, "alpha_value": 0.6145047048840859, "duration": 1.5170066356658936, "info_normalized_performance_mean": 0.9250781536102295, "info_normalized_performance_final": 0.9973958134651184, "info_performance_mean": 0.9250781536102295, "info_performance_final": 0.9973958134651184, "step": 949500}
{"episode_reward": 1850.1562500000023, "episode": 9496.0, "batch_reward": 11.778120040893555, "critic_loss": 308.562744140625, "actor_loss": -2074.1962890625, "actor_target_entropy": -3.0, "actor_entropy": 1.1218348741531372, "alpha_loss": -0.05508645623922348, "alpha_value": 0.6107051268264543, "step": 950000}
{"duration": 19.191589832305908, "info_normalized_performance_mean": 0.3684374988079071, "info_normalized_performance_final": 0.4040798544883728, "info_performance_mean": 0.3684374988079071, "info_performance_final": 0.4040798544883728, "step": 950000}
{"episode_reward": 736.874999999999, "episode": 9501.0, "batch_reward": 12.083878517150879, "critic_loss": 531.8780517578125, "actor_loss": -2042.6224365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.223803997039795, "alpha_loss": 0.503292441368103, "alpha_value": 0.6038353825071585, "duration": 1.5583207607269287, "info_normalized_performance_mean": 0.7108822464942932, "info_normalized_performance_final": 0.7617647051811218, "info_performance_mean": 0.7108822464942932, "info_performance_final": 0.7617647051811218, "step": 950500}
{"episode_reward": 1421.764705882354, "episode": 9506.0, "batch_reward": 11.457880973815918, "critic_loss": 722.9405517578125, "actor_loss": -2049.17626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.009206771850586, "alpha_loss": -0.11842245608568192, "alpha_value": 0.5990004895079426, "duration": 1.5731494426727295, "info_normalized_performance_mean": 0.37720513343811035, "info_normalized_performance_final": 0.42571428418159485, "info_performance_mean": 0.37720513343811035, "info_performance_final": 0.42571428418159485, "step": 951000}
{"episode_reward": 754.4103896103906, "episode": 9511.0, "batch_reward": 11.20553207397461, "critic_loss": 593.1502075195312, "actor_loss": -1993.371826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.0725226402282715, "alpha_loss": -0.00481608510017395, "alpha_value": 0.5948690534673035, "duration": 1.598996877670288, "info_normalized_performance_mean": 0.7321630716323853, "info_normalized_performance_final": 0.7855203747749329, "info_performance_mean": 0.7321630716323853, "info_performance_final": 0.7855203747749329, "step": 951500}
{"episode_reward": 1464.3257918552035, "episode": 9516.0, "batch_reward": 11.580713272094727, "critic_loss": 430.94244384765625, "actor_loss": -2017.9149169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.9854681491851807, "alpha_loss": 0.11438670009374619, "alpha_value": 0.588425799952078, "duration": 1.528663158416748, "info_normalized_performance_mean": 0.6210121512413025, "info_normalized_performance_final": 0.6669034361839294, "info_performance_mean": 0.6210121512413025, "info_performance_final": 0.6669034361839294, "step": 952000}
{"episode_reward": 1242.0241477272718, "episode": 9521.0, "batch_reward": 11.729955673217773, "critic_loss": 826.3609008789062, "actor_loss": -2007.08251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1110155582427979, "alpha_loss": 0.27250802516937256, "alpha_value": 0.5806936382385561, "duration": 1.54783296585083, "info_normalized_performance_mean": 0.9264286756515503, "info_normalized_performance_final": 0.9980158805847168, "info_performance_mean": 0.9264286756515503, "info_performance_final": 0.9980158805847168, "step": 952500}
{"episode_reward": 1852.8571428571388, "episode": 9526.0, "batch_reward": 11.640790939331055, "critic_loss": 247.13844299316406, "actor_loss": -2029.5673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.24366295337677, "alpha_loss": 0.09382933378219604, "alpha_value": 0.5725134065315562, "duration": 1.5667634010314941, "info_normalized_performance_mean": 0.8817317485809326, "info_normalized_performance_final": 0.9401041865348816, "info_performance_mean": 0.8817317485809326, "info_performance_final": 0.9401041865348816, "step": 953000}
{"episode_reward": 1763.4635416666645, "episode": 9531.0, "batch_reward": 11.636627197265625, "critic_loss": 553.9580078125, "actor_loss": -1995.01416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.6999205946922302, "alpha_loss": 0.18780484795570374, "alpha_value": 0.5663296791559019, "duration": 1.5819270610809326, "info_normalized_performance_mean": 0.5422917008399963, "info_normalized_performance_final": 0.5799999833106995, "info_performance_mean": 0.5422917008399963, "info_performance_final": 0.5799999833106995, "step": 953500}
{"episode_reward": 1084.5833333333342, "episode": 9536.0, "batch_reward": 11.728338241577148, "critic_loss": 991.9302978515625, "actor_loss": -1995.362060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.1343542337417603, "alpha_loss": 0.11722466349601746, "alpha_value": 0.5600949319429079, "duration": 1.4491550922393799, "info_normalized_performance_mean": 0.7740739583969116, "info_normalized_performance_final": 0.8431712985038757, "info_performance_mean": 0.7740739583969116, "info_performance_final": 0.8431712985038757, "step": 954000}
{"episode_reward": 1548.1481481481444, "episode": 9541.0, "batch_reward": 11.883008003234863, "critic_loss": 268.05328369140625, "actor_loss": -2017.220458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3718985319137573, "alpha_loss": -0.14760062098503113, "alpha_value": 0.5553519243215961, "duration": 1.475175142288208, "info_normalized_performance_mean": 0.4915638864040375, "info_normalized_performance_final": 0.5254328846931458, "info_performance_mean": 0.4915638864040375, "info_performance_final": 0.5254328846931458, "step": 954500}
{"episode_reward": 983.1277056277063, "episode": 9546.0, "batch_reward": 10.90342903137207, "critic_loss": 292.8624572753906, "actor_loss": -1940.12646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1150882244110107, "alpha_loss": 0.1283056139945984, "alpha_value": 0.5503158703960592, "duration": 1.5727334022521973, "info_normalized_performance_mean": 0.5704687237739563, "info_normalized_performance_final": 0.625, "info_performance_mean": 0.5704687237739563, "info_performance_final": 0.625, "step": 955000}
{"episode_reward": 1140.9375, "episode": 9551.0, "batch_reward": 11.243902206420898, "critic_loss": 831.55419921875, "actor_loss": -1976.892333984375, "actor_target_entropy": -3.0, "actor_entropy": 0.23830635845661163, "alpha_loss": -0.05920351296663284, "alpha_value": 0.5382353806634307, "duration": 1.5561151504516602, "info_normalized_performance_mean": 0.7334570288658142, "info_normalized_performance_final": 0.8042857050895691, "info_performance_mean": 0.7334570288658142, "info_performance_final": 0.8042857050895691, "step": 955500}
{"episode_reward": 1466.9142857142829, "episode": 9556.0, "batch_reward": 10.789693832397461, "critic_loss": 587.6781005859375, "actor_loss": -1915.75732421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0593632459640503, "alpha_loss": 0.043098334223032, "alpha_value": 0.5291905051828528, "duration": 1.4917755126953125, "info_normalized_performance_mean": 0.5123177170753479, "info_normalized_performance_final": 0.5564236044883728, "info_performance_mean": 0.5123177170753479, "info_performance_final": 0.5564236044883728, "step": 956000}
{"episode_reward": 1024.6354166666647, "episode": 9561.0, "batch_reward": 11.407360076904297, "critic_loss": 240.116455078125, "actor_loss": -1973.510498046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9226816296577454, "alpha_loss": -0.23105601966381073, "alpha_value": 0.5211496921595606, "duration": 1.5958130359649658, "info_normalized_performance_mean": 0.819431483745575, "info_normalized_performance_final": 0.8803921341896057, "info_performance_mean": 0.819431483745575, "info_performance_final": 0.8803921341896057, "step": 956500}
{"episode_reward": 1638.8627450980366, "episode": 9566.0, "batch_reward": 11.771681785583496, "critic_loss": 705.813232421875, "actor_loss": -1967.7432861328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7789936661720276, "alpha_loss": -0.05160636454820633, "alpha_value": 0.5134131320838857, "duration": 1.44105863571167, "info_normalized_performance_mean": 0.6116471290588379, "info_normalized_performance_final": 0.6682353019714355, "info_performance_mean": 0.6116471290588379, "info_performance_final": 0.6682353019714355, "step": 957000}
{"episode_reward": 1223.2941176470579, "episode": 9571.0, "batch_reward": 11.26087474822998, "critic_loss": 339.9852600097656, "actor_loss": -1917.604248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.073930263519287, "alpha_loss": 0.08734080195426941, "alpha_value": 0.5042771659943999, "duration": 1.5367205142974854, "info_normalized_performance_mean": 0.8582305312156677, "info_normalized_performance_final": 0.9123376607894897, "info_performance_mean": 0.8582305312156677, "info_performance_final": 0.9123376607894897, "step": 957500}
{"episode_reward": 1716.4610389610405, "episode": 9576.0, "batch_reward": 11.083467483520508, "critic_loss": 819.50634765625, "actor_loss": -1891.0655517578125, "actor_target_entropy": -3.0, "actor_entropy": 0.9149539470672607, "alpha_loss": 0.0889904797077179, "alpha_value": 0.4929795053132726, "duration": 1.5623390674591064, "info_normalized_performance_mean": 0.4849117696285248, "info_normalized_performance_final": 0.5394805073738098, "info_performance_mean": 0.4849117696285248, "info_performance_final": 0.5394805073738098, "step": 958000}
{"episode_reward": 969.8233766233776, "episode": 9581.0, "batch_reward": 11.620322227478027, "critic_loss": 226.83865356445312, "actor_loss": -1911.253662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3744521141052246, "alpha_loss": 0.062128689140081406, "alpha_value": 0.48458209857586854, "duration": 1.480393886566162, "info_normalized_performance_mean": 0.48795047402381897, "info_normalized_performance_final": 0.5385552048683167, "info_performance_mean": 0.48795047402381897, "info_performance_final": 0.5385552048683167, "step": 958500}
{"episode_reward": 975.900974025975, "episode": 9586.0, "batch_reward": 11.636285781860352, "critic_loss": 713.3837890625, "actor_loss": -1920.6400146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.8017145395278931, "alpha_loss": 0.20958594977855682, "alpha_value": 0.4753992717402573, "duration": 1.4865515232086182, "info_normalized_performance_mean": 0.6041733622550964, "info_normalized_performance_final": 0.656632661819458, "info_performance_mean": 0.6041733622550964, "info_performance_final": 0.656632661819458, "step": 959000}
{"episode_reward": 1208.3469387755108, "episode": 9591.0, "batch_reward": 11.982181549072266, "critic_loss": 527.0382080078125, "actor_loss": -1907.5986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8712408542633057, "alpha_loss": 0.21256756782531738, "alpha_value": 0.4667274409775664, "duration": 1.578392505645752, "info_normalized_performance_mean": 0.43518292903900146, "info_normalized_performance_final": 0.47958216071128845, "info_performance_mean": 0.43518292903900146, "info_performance_final": 0.47958216071128845, "step": 959500}
{"episode_reward": 870.3656220322874, "episode": 9596.0, "batch_reward": 11.810144424438477, "critic_loss": 289.7723083496094, "actor_loss": -1900.08056640625, "actor_target_entropy": -3.0, "actor_entropy": 0.9476907253265381, "alpha_loss": 0.09924964606761932, "alpha_value": 0.4575322942412838, "step": 960000}
{"duration": 19.474980115890503, "info_normalized_performance_mean": 0.6488521099090576, "info_normalized_performance_final": 0.6957908272743225, "info_performance_mean": 0.6488521099090576, "info_performance_final": 0.6957908272743225, "step": 960000}
{"episode_reward": 1297.7040816326523, "episode": 9601.0, "batch_reward": 11.099496841430664, "critic_loss": 376.8218994140625, "actor_loss": -1858.2203369140625, "actor_target_entropy": -3.0, "actor_entropy": 1.22832453250885, "alpha_loss": 0.25376027822494507, "alpha_value": 0.4500258060725715, "duration": 1.6360199451446533, "info_normalized_performance_mean": 0.8255941867828369, "info_normalized_performance_final": 0.8865740895271301, "info_performance_mean": 0.8255941867828369, "info_performance_final": 0.8865740895271301, "step": 960500}
{"episode_reward": 1651.1882716049406, "episode": 9606.0, "batch_reward": 11.621291160583496, "critic_loss": 502.4571228027344, "actor_loss": -1886.314208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.5524194240570068, "alpha_loss": 0.0521845668554306, "alpha_value": 0.44058239276757366, "duration": 1.4303321838378906, "info_normalized_performance_mean": 0.38649001717567444, "info_normalized_performance_final": 0.4196428656578064, "info_performance_mean": 0.38649001717567444, "info_performance_final": 0.4196428656578064, "step": 961000}
{"episode_reward": 772.9799107142853, "episode": 9611.0, "batch_reward": 11.03831672668457, "critic_loss": 1438.671142578125, "actor_loss": -1833.57373046875, "actor_target_entropy": -3.0, "actor_entropy": 0.35533735156059265, "alpha_loss": -0.1427580863237381, "alpha_value": 0.43351187122063833, "duration": 1.624079942703247, "info_normalized_performance_mean": 0.3581699728965759, "info_normalized_performance_final": 0.45524999499320984, "info_performance_mean": 0.3581699728965759, "info_performance_final": 0.45524999499320984, "step": 961500}
{"episode_reward": 716.3400000000008, "episode": 9616.0, "batch_reward": 11.852254867553711, "critic_loss": 785.5494995117188, "actor_loss": -1847.604248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.0298316478729248, "alpha_loss": 0.2570784091949463, "alpha_value": 0.42585401757856217, "duration": 1.5671980381011963, "info_normalized_performance_mean": 0.8487800359725952, "info_normalized_performance_final": 0.9120000004768372, "info_performance_mean": 0.8487800359725952, "info_performance_final": 0.9120000004768372, "step": 962000}
{"episode_reward": 1697.5600000000006, "episode": 9621.0, "batch_reward": 11.487510681152344, "critic_loss": 272.51507568359375, "actor_loss": -1832.560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.0432831048965454, "alpha_loss": 0.18470269441604614, "alpha_value": 0.4182350335573565, "duration": 1.4734342098236084, "info_normalized_performance_mean": 0.6083099842071533, "info_normalized_performance_final": 0.6600765585899353, "info_performance_mean": 0.6083099842071533, "info_performance_final": 0.6600765585899353, "step": 962500}
{"episode_reward": 1216.6198979591838, "episode": 9626.0, "batch_reward": 11.554909706115723, "critic_loss": 431.3033447265625, "actor_loss": -1859.142822265625, "actor_target_entropy": -3.0, "actor_entropy": 0.8467852473258972, "alpha_loss": 0.2711160182952881, "alpha_value": 0.4105996702555841, "duration": 1.4688944816589355, "info_normalized_performance_mean": 0.6467632055282593, "info_normalized_performance_final": 0.6941964030265808, "info_performance_mean": 0.6467632055282593, "info_performance_final": 0.6941964030265808, "step": 963000}
{"episode_reward": 1293.526785714287, "episode": 9631.0, "batch_reward": 11.35901927947998, "critic_loss": 140.52044677734375, "actor_loss": -1860.363037109375, "actor_target_entropy": -3.0, "actor_entropy": 0.5379763245582581, "alpha_loss": 0.2563185393810272, "alpha_value": 0.4021961036406641, "duration": 1.612252950668335, "info_normalized_performance_mean": 0.7078230977058411, "info_normalized_performance_final": 0.7562358379364014, "info_performance_mean": 0.7078230977058411, "info_performance_final": 0.7562358379364014, "step": 963500}
{"episode_reward": 1415.6462585033992, "episode": 9636.0, "batch_reward": 11.009475708007812, "critic_loss": 293.71954345703125, "actor_loss": -1814.2886962890625, "actor_target_entropy": -3.0, "actor_entropy": 0.977817714214325, "alpha_loss": 0.0628078430891037, "alpha_value": 0.3957237065218809, "duration": 1.5879948139190674, "info_normalized_performance_mean": 0.8099875450134277, "info_normalized_performance_final": 0.8700000047683716, "info_performance_mean": 0.8099875450134277, "info_performance_final": 0.8700000047683716, "step": 964000}
{"episode_reward": 1619.9750000000022, "episode": 9641.0, "batch_reward": 11.04863166809082, "critic_loss": 509.488037109375, "actor_loss": -1818.76611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.48251497745513916, "alpha_loss": -0.33540627360343933, "alpha_value": 0.39145960610770586, "duration": 1.4746975898742676, "info_normalized_performance_mean": 0.6354138851165771, "info_normalized_performance_final": 0.6797052025794983, "info_performance_mean": 0.6354138851165771, "info_performance_final": 0.6797052025794983, "step": 964500}
{"episode_reward": 1270.8276643990937, "episode": 9646.0, "batch_reward": 11.609067916870117, "critic_loss": 886.0737915039062, "actor_loss": -1806.8160400390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8793396949768066, "alpha_loss": 0.03716682270169258, "alpha_value": 0.38676476895067513, "duration": 1.4874341487884521, "info_normalized_performance_mean": 0.778367280960083, "info_normalized_performance_final": 0.8418367505073547, "info_performance_mean": 0.778367280960083, "info_performance_final": 0.8418367505073547, "step": 965000}
{"episode_reward": 1556.7346938775531, "episode": 9651.0, "batch_reward": 11.889293670654297, "critic_loss": 323.39129638671875, "actor_loss": -1824.7371826171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8456063270568848, "alpha_loss": -0.065497025847435, "alpha_value": 0.3812384175650041, "duration": 1.4818792343139648, "info_normalized_performance_mean": 0.3682508170604706, "info_normalized_performance_final": 0.4017857015132904, "info_performance_mean": 0.3682508170604706, "info_performance_final": 0.4017857015132904, "step": 965500}
{"episode_reward": 736.5016233766244, "episode": 9656.0, "batch_reward": 11.184295654296875, "critic_loss": 1044.3785400390625, "actor_loss": -1769.785888671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8549864888191223, "alpha_loss": 0.20731715857982635, "alpha_value": 0.3771502458101563, "duration": 1.5741009712219238, "info_normalized_performance_mean": 0.45407921075820923, "info_normalized_performance_final": 0.49176955223083496, "info_performance_mean": 0.45407921075820923, "info_performance_final": 0.49176955223083496, "step": 966000}
{"episode_reward": 908.1584362139896, "episode": 9661.0, "batch_reward": 11.697053909301758, "critic_loss": 1054.678955078125, "actor_loss": -1767.774658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.17513108253479, "alpha_loss": 0.2620830833911896, "alpha_value": 0.3719686288009436, "duration": 1.6097807884216309, "info_normalized_performance_mean": 0.8317501544952393, "info_normalized_performance_final": 0.8970000147819519, "info_performance_mean": 0.8317501544952393, "info_performance_final": 0.8970000147819519, "step": 966500}
{"episode_reward": 1663.5000000000034, "episode": 9666.0, "batch_reward": 11.785869598388672, "critic_loss": 384.3873596191406, "actor_loss": -1796.4775390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8556972742080688, "alpha_loss": -0.13024643063545227, "alpha_value": 0.3683363186703109, "duration": 1.647130012512207, "info_normalized_performance_mean": 0.4156869649887085, "info_normalized_performance_final": 0.457988977432251, "info_performance_mean": 0.4156869649887085, "info_performance_final": 0.457988977432251, "step": 967000}
{"episode_reward": 831.3739669421499, "episode": 9671.0, "batch_reward": 11.814762115478516, "critic_loss": 198.4244842529297, "actor_loss": -1814.661865234375, "actor_target_entropy": -3.0, "actor_entropy": 0.81840980052948, "alpha_loss": 0.1464463323354721, "alpha_value": 0.364410349759345, "duration": 1.5336668491363525, "info_normalized_performance_mean": 0.927152693271637, "info_normalized_performance_final": 0.9982638955116272, "info_performance_mean": 0.927152693271637, "info_performance_final": 0.9982638955116272, "step": 967500}
{"episode_reward": 1854.3055555555588, "episode": 9676.0, "batch_reward": 11.301982879638672, "critic_loss": 640.8685913085938, "actor_loss": -1829.7342529296875, "actor_target_entropy": -3.0, "actor_entropy": 1.1637362241744995, "alpha_loss": -0.06290844082832336, "alpha_value": 0.3582286763773577, "duration": 1.4939074516296387, "info_normalized_performance_mean": 0.6432044506072998, "info_normalized_performance_final": 0.6889880895614624, "info_performance_mean": 0.6432044506072998, "info_performance_final": 0.6889880895614624, "step": 968000}
{"episode_reward": 1286.4087301587315, "episode": 9681.0, "batch_reward": 11.205307006835938, "critic_loss": 312.36993408203125, "actor_loss": -1770.94580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.9740735292434692, "alpha_loss": -0.0817885473370552, "alpha_value": 0.3527758668526134, "duration": 1.5812652111053467, "info_normalized_performance_mean": 0.2961779832839966, "info_normalized_performance_final": 0.32879120111465454, "info_performance_mean": 0.2961779832839966, "info_performance_final": 0.32879120111465454, "step": 968500}
{"episode_reward": 592.3560439560435, "episode": 9686.0, "batch_reward": 11.216596603393555, "critic_loss": 493.72674560546875, "actor_loss": -1706.3485107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0882999897003174, "alpha_loss": 0.1277206987142563, "alpha_value": 0.34655273969583594, "duration": 1.5063846111297607, "info_normalized_performance_mean": 0.556947648525238, "info_normalized_performance_final": 0.6049107313156128, "info_performance_mean": 0.556947648525238, "info_performance_final": 0.6049107313156128, "step": 969000}
{"episode_reward": 1113.8950892857156, "episode": 9691.0, "batch_reward": 11.518904685974121, "critic_loss": 450.10614013671875, "actor_loss": -1784.7374267578125, "actor_target_entropy": -3.0, "actor_entropy": 0.4833061993122101, "alpha_loss": 0.09405755996704102, "alpha_value": 0.34169028146715374, "duration": 1.413621425628662, "info_normalized_performance_mean": 0.2223828136920929, "info_normalized_performance_final": 0.23828125, "info_performance_mean": 0.2223828136920929, "info_performance_final": 0.23828125, "step": 969500}
{"episode_reward": 444.765625, "episode": 9696.0, "batch_reward": 12.22181224822998, "critic_loss": 600.8150634765625, "actor_loss": -1780.0997314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0158288478851318, "alpha_loss": 0.2577889859676361, "alpha_value": 0.3366770455609389, "step": 970000}
{"duration": 18.75603723526001, "info_normalized_performance_mean": 0.532910168170929, "info_normalized_performance_final": 0.572265625, "info_performance_mean": 0.532910168170929, "info_performance_final": 0.572265625, "step": 970000}
{"episode_reward": 1065.8203125, "episode": 9701.0, "batch_reward": 11.627920150756836, "critic_loss": 690.2659912109375, "actor_loss": -1749.63720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.5477827787399292, "alpha_loss": 0.09399544447660446, "alpha_value": 0.3314342568629347, "duration": 1.6245849132537842, "info_normalized_performance_mean": 0.777717113494873, "info_normalized_performance_final": 0.8333333134651184, "info_performance_mean": 0.777717113494873, "info_performance_final": 0.8333333134651184, "step": 970500}
{"episode_reward": 1555.4340277777792, "episode": 9706.0, "batch_reward": 11.492225646972656, "critic_loss": 436.57208251953125, "actor_loss": -1748.52197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.4026182293891907, "alpha_loss": 0.15703026950359344, "alpha_value": 0.3253872872690682, "duration": 1.3821625709533691, "info_normalized_performance_mean": 0.5541517734527588, "info_normalized_performance_final": 0.59375, "info_performance_mean": 0.5541517734527588, "info_performance_final": 0.59375, "step": 971000}
{"episode_reward": 1108.3035714285713, "episode": 9711.0, "batch_reward": 12.927865028381348, "critic_loss": 171.7982177734375, "actor_loss": -1837.74267578125, "actor_target_entropy": -3.0, "actor_entropy": 0.7701033353805542, "alpha_loss": 0.058702562004327774, "alpha_value": 0.3209932523118796, "duration": 1.5771734714508057, "info_normalized_performance_mean": 0.7049999237060547, "info_normalized_performance_final": 0.751764714717865, "info_performance_mean": 0.7049999237060547, "info_performance_final": 0.751764714717865, "step": 971500}
{"episode_reward": 1409.9999999999986, "episode": 9716.0, "batch_reward": 11.598762512207031, "critic_loss": 323.5122985839844, "actor_loss": -1752.86767578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6502792239189148, "alpha_loss": 0.12698085606098175, "alpha_value": 0.31787441677550626, "duration": 1.4793386459350586, "info_normalized_performance_mean": 0.5553365349769592, "info_normalized_performance_final": 0.6009615659713745, "info_performance_mean": 0.5553365349769592, "info_performance_final": 0.6009615659713745, "step": 972000}
{"episode_reward": 1110.6730769230746, "episode": 9721.0, "batch_reward": 11.030195236206055, "critic_loss": 218.883544921875, "actor_loss": -1684.62548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9867591857910156, "alpha_loss": -0.08596259355545044, "alpha_value": 0.31582739390001424, "duration": 1.4587955474853516, "info_normalized_performance_mean": 0.5746427774429321, "info_normalized_performance_final": 0.6168367266654968, "info_performance_mean": 0.5746427774429321, "info_performance_final": 0.6168367266654968, "step": 972500}
{"episode_reward": 1149.2857142857158, "episode": 9726.0, "batch_reward": 12.419995307922363, "critic_loss": 702.04736328125, "actor_loss": -1787.2078857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0008684396743774, "alpha_loss": -0.06944966316223145, "alpha_value": 0.31283415177254886, "duration": 1.60654878616333, "info_normalized_performance_mean": 0.751792311668396, "info_normalized_performance_final": 0.8384615182876587, "info_performance_mean": 0.751792311668396, "info_performance_final": 0.8384615182876587, "step": 973000}
{"episode_reward": 1503.5846153846123, "episode": 9731.0, "batch_reward": 11.838285446166992, "critic_loss": 349.6436462402344, "actor_loss": -1714.262939453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7137616276741028, "alpha_loss": 0.18491306900978088, "alpha_value": 0.31079351263694793, "duration": 1.641167163848877, "info_normalized_performance_mean": 0.40758442878723145, "info_normalized_performance_final": 0.4474862217903137, "info_performance_mean": 0.40758442878723145, "info_performance_final": 0.4474862217903137, "step": 973500}
{"episode_reward": 815.1687327823706, "episode": 9736.0, "batch_reward": 12.437297821044922, "critic_loss": 618.777587890625, "actor_loss": -1750.9046630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.0254377126693726, "alpha_loss": 0.13147005438804626, "alpha_value": 0.31068251995750806, "duration": 1.7963407039642334, "info_normalized_performance_mean": 0.4564155340194702, "info_normalized_performance_final": 0.5406236052513123, "info_performance_mean": 0.4564155340194702, "info_performance_final": 0.5406236052513123, "step": 974000}
{"episode_reward": 912.8311333636786, "episode": 9741.0, "batch_reward": 12.36237621307373, "critic_loss": 194.40243530273438, "actor_loss": -1713.303955078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0009429454803467, "alpha_loss": -0.027112189680337906, "alpha_value": 0.31107380409162494, "duration": 1.5981342792510986, "info_normalized_performance_mean": 0.6988167762756348, "info_normalized_performance_final": 0.7842712998390198, "info_performance_mean": 0.6988167762756348, "info_performance_final": 0.7842712998390198, "step": 974500}
{"episode_reward": 1397.6334776334797, "episode": 9746.0, "batch_reward": 11.866418838500977, "critic_loss": 338.5400390625, "actor_loss": -1675.5240478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.5386272668838501, "alpha_loss": 0.03502752631902695, "alpha_value": 0.3094789726822777, "duration": 1.4730746746063232, "info_normalized_performance_mean": 0.5682161450386047, "info_normalized_performance_final": 0.6176215410232544, "info_performance_mean": 0.5682161450386047, "info_performance_final": 0.6176215410232544, "step": 975000}
{"episode_reward": 1136.4322916666667, "episode": 9751.0, "batch_reward": 11.468904495239258, "critic_loss": 394.7283020019531, "actor_loss": -1707.702392578125, "actor_target_entropy": -3.0, "actor_entropy": 0.49616172909736633, "alpha_loss": -0.0655832439661026, "alpha_value": 0.3075313692183148, "duration": 1.6292297840118408, "info_normalized_performance_mean": 0.45377853512763977, "info_normalized_performance_final": 0.5052381157875061, "info_performance_mean": 0.45377853512763977, "info_performance_final": 0.5052381157875061, "step": 975500}
{"episode_reward": 907.5571428571413, "episode": 9756.0, "batch_reward": 11.38530158996582, "critic_loss": 526.6249389648438, "actor_loss": -1736.7232666015625, "actor_target_entropy": -3.0, "actor_entropy": 0.5668179988861084, "alpha_loss": -0.08136672526597977, "alpha_value": 0.3060574887807735, "duration": 1.5151417255401611, "info_normalized_performance_mean": 0.8345882892608643, "info_normalized_performance_final": 0.8941176533699036, "info_performance_mean": 0.8345882892608643, "info_performance_final": 0.8941176533699036, "step": 976000}
{"episode_reward": 1669.176470588239, "episode": 9761.0, "batch_reward": 11.666608810424805, "critic_loss": 280.24273681640625, "actor_loss": -1670.89501953125, "actor_target_entropy": -3.0, "actor_entropy": 1.3816454410552979, "alpha_loss": 0.008181188255548477, "alpha_value": 0.30548612874981523, "duration": 1.406670331954956, "info_normalized_performance_mean": 0.9300000071525574, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9300000071525574, "info_performance_final": 1.0, "step": 976500}
{"episode_reward": 1860.0, "episode": 9766.0, "batch_reward": 11.57065200805664, "critic_loss": 295.57904052734375, "actor_loss": -1671.506103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.5910893082618713, "alpha_loss": -0.09302221238613129, "alpha_value": 0.30644118746065935, "duration": 1.405827283859253, "info_normalized_performance_mean": 0.5960317850112915, "info_normalized_performance_final": 0.6388888955116272, "info_performance_mean": 0.5960317850112915, "info_performance_final": 0.6388888955116272, "step": 977000}
{"episode_reward": 1192.0634920634946, "episode": 9771.0, "batch_reward": 11.978553771972656, "critic_loss": 217.61886596679688, "actor_loss": -1694.1915283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1872477531433105, "alpha_loss": 0.09443231672048569, "alpha_value": 0.3088053225950161, "duration": 1.604740858078003, "info_normalized_performance_mean": 0.4794294834136963, "info_normalized_performance_final": 0.5284090638160706, "info_performance_mean": 0.4794294834136963, "info_performance_final": 0.5284090638160706, "step": 977500}
{"episode_reward": 958.859090909093, "episode": 9776.0, "batch_reward": 12.679203033447266, "critic_loss": 312.1729431152344, "actor_loss": -1747.381591796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0720391273498535, "alpha_loss": 0.04941125959157944, "alpha_value": 0.3091646357158121, "duration": 1.5821599960327148, "info_normalized_performance_mean": 0.8409000635147095, "info_normalized_performance_final": 0.9083333611488342, "info_performance_mean": 0.8409000635147095, "info_performance_final": 0.9083333611488342, "step": 978000}
{"episode_reward": 1681.800000000002, "episode": 9781.0, "batch_reward": 11.518895149230957, "critic_loss": 624.66162109375, "actor_loss": -1644.73681640625, "actor_target_entropy": -3.0, "actor_entropy": 0.624446451663971, "alpha_loss": 0.21308381855487823, "alpha_value": 0.3090554800132394, "duration": 1.4919190406799316, "info_normalized_performance_mean": 0.7832132577896118, "info_normalized_performance_final": 0.8415403962135315, "info_performance_mean": 0.7832132577896118, "info_performance_final": 0.8415403962135315, "step": 978500}
{"episode_reward": 1566.426767676768, "episode": 9786.0, "batch_reward": 11.355918884277344, "critic_loss": 199.00344848632812, "actor_loss": -1653.756103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1039924621582031, "alpha_loss": -0.04600677639245987, "alpha_value": 0.31081953402236595, "duration": 1.6140763759613037, "info_normalized_performance_mean": 0.7342063188552856, "info_normalized_performance_final": 0.8152958154678345, "info_performance_mean": 0.7342063188552856, "info_performance_final": 0.8152958154678345, "step": 979000}
{"episode_reward": 1468.412698412698, "episode": 9791.0, "batch_reward": 11.61056137084961, "critic_loss": 286.09423828125, "actor_loss": -1678.300048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9952346086502075, "alpha_loss": -0.07077912241220474, "alpha_value": 0.31571296892730594, "duration": 1.5096828937530518, "info_normalized_performance_mean": 0.6345088481903076, "info_normalized_performance_final": 0.6884920597076416, "info_performance_mean": 0.6345088481903076, "info_performance_final": 0.6884920597076416, "step": 979500}
{"episode_reward": 1269.0178571428578, "episode": 9796.0, "batch_reward": 12.33224868774414, "critic_loss": 286.2351989746094, "actor_loss": -1693.8072509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0540995597839355, "alpha_loss": 0.08504049479961395, "alpha_value": 0.320074889610831, "step": 980000}
{"duration": 18.789876222610474, "info_normalized_performance_mean": 0.5495088696479797, "info_normalized_performance_final": 0.5907738208770752, "info_performance_mean": 0.5495088696479797, "info_performance_final": 0.5907738208770752, "step": 980000}
{"episode_reward": 1099.0178571428555, "episode": 9801.0, "batch_reward": 11.763293266296387, "critic_loss": 487.48046875, "actor_loss": -1672.112060546875, "actor_target_entropy": -3.0, "actor_entropy": 0.4775465726852417, "alpha_loss": -0.27493783831596375, "alpha_value": 0.3255672634673065, "duration": 1.7085671424865723, "info_normalized_performance_mean": 0.4225350618362427, "info_normalized_performance_final": 0.4888583719730377, "info_performance_mean": 0.4225350618362427, "info_performance_final": 0.4888583719730377, "step": 980500}
{"episode_reward": 845.0702075702058, "episode": 9806.0, "batch_reward": 11.667686462402344, "critic_loss": 244.98333740234375, "actor_loss": -1655.45068359375, "actor_target_entropy": -3.0, "actor_entropy": 0.7534294128417969, "alpha_loss": -0.10801293700933456, "alpha_value": 0.3318940118188324, "duration": 1.5652475357055664, "info_normalized_performance_mean": 0.584453284740448, "info_normalized_performance_final": 0.6439732313156128, "info_performance_mean": 0.584453284740448, "info_performance_final": 0.6439732313156128, "step": 981000}
{"episode_reward": 1168.906250000001, "episode": 9811.0, "batch_reward": 11.300863265991211, "critic_loss": 363.89898681640625, "actor_loss": -1712.4342041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.6275738477706909, "alpha_loss": -0.11796722561120987, "alpha_value": 0.33660087360914837, "duration": 1.8032236099243164, "info_normalized_performance_mean": 0.25365149974823, "info_normalized_performance_final": 0.2879684269428253, "info_performance_mean": 0.25365149974823, "info_performance_final": 0.2879684269428253, "step": 981500}
{"episode_reward": 507.3030900723208, "episode": 9816.0, "batch_reward": 11.814872741699219, "critic_loss": 613.34375, "actor_loss": -1673.2879638671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9759047627449036, "alpha_loss": -0.29353299736976624, "alpha_value": 0.33817155015002603, "duration": 1.6331110000610352, "info_normalized_performance_mean": 0.664821445941925, "info_normalized_performance_final": 0.7222222089767456, "info_performance_mean": 0.664821445941925, "info_performance_final": 0.7222222089767456, "step": 982000}
{"episode_reward": 1329.6428571428557, "episode": 9821.0, "batch_reward": 11.27840518951416, "critic_loss": 222.28936767578125, "actor_loss": -1619.3101806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.00552237033844, "alpha_loss": 0.059767503291368484, "alpha_value": 0.34135316582074077, "duration": 1.5113587379455566, "info_normalized_performance_mean": 0.6329563856124878, "info_normalized_performance_final": 0.6870039701461792, "info_performance_mean": 0.6329563856124878, "info_performance_final": 0.6870039701461792, "step": 982500}
{"episode_reward": 1265.9126984126976, "episode": 9826.0, "batch_reward": 12.53012466430664, "critic_loss": 440.1975402832031, "actor_loss": -1691.280029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.6804506778717041, "alpha_loss": -0.010022934526205063, "alpha_value": 0.3456958990973235, "duration": 1.523406744003296, "info_normalized_performance_mean": 0.32396748661994934, "info_normalized_performance_final": 0.35475000739097595, "info_performance_mean": 0.32396748661994934, "info_performance_final": 0.35475000739097595, "step": 983000}
{"episode_reward": 647.9350000000014, "episode": 9831.0, "batch_reward": 11.815889358520508, "critic_loss": 614.7884521484375, "actor_loss": -1663.8408203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1141266822814941, "alpha_loss": -0.13381649553775787, "alpha_value": 0.3488226180887215, "duration": 1.3889658451080322, "info_normalized_performance_mean": 0.14265625178813934, "info_normalized_performance_final": 0.1510416716337204, "info_performance_mean": 0.14265625178813934, "info_performance_final": 0.1510416716337204, "step": 983500}
{"episode_reward": 285.31250000000017, "episode": 9836.0, "batch_reward": 11.472267150878906, "critic_loss": 332.91729736328125, "actor_loss": -1657.1002197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.6298314332962036, "alpha_loss": -0.04040900990366936, "alpha_value": 0.35200378538404364, "duration": 1.565429449081421, "info_normalized_performance_mean": 0.7897527813911438, "info_normalized_performance_final": 0.8667582273483276, "info_performance_mean": 0.7897527813911438, "info_performance_final": 0.8667582273483276, "step": 984000}
{"episode_reward": 1579.5054945054917, "episode": 9841.0, "batch_reward": 11.264358520507812, "critic_loss": 411.6258239746094, "actor_loss": -1648.970947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0046402215957642, "alpha_loss": 0.004499301314353943, "alpha_value": 0.35262564240478445, "duration": 1.4815747737884521, "info_normalized_performance_mean": 0.7897863984107971, "info_normalized_performance_final": 0.846764326095581, "info_performance_mean": 0.7897863984107971, "info_performance_final": 0.846764326095581, "step": 984500}
{"episode_reward": 1579.5726495726512, "episode": 9846.0, "batch_reward": 11.662548065185547, "critic_loss": 191.7293701171875, "actor_loss": -1649.3505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1631653308868408, "alpha_loss": 0.2310587465763092, "alpha_value": 0.35012163084026127, "duration": 1.5837593078613281, "info_normalized_performance_mean": 0.45530641078948975, "info_normalized_performance_final": 0.5072727203369141, "info_performance_mean": 0.45530641078948975, "info_performance_final": 0.5072727203369141, "step": 985000}
{"episode_reward": 910.612987012986, "episode": 9851.0, "batch_reward": 12.708471298217773, "critic_loss": 454.10009765625, "actor_loss": -1705.4677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9503113031387329, "alpha_loss": 0.02664019539952278, "alpha_value": 0.3467579864258822, "duration": 1.4908950328826904, "info_normalized_performance_mean": 0.42397841811180115, "info_normalized_performance_final": 0.4651533365249634, "info_performance_mean": 0.42397841811180115, "info_performance_final": 0.4651533365249634, "step": 985500}
{"episode_reward": 847.9569892473123, "episode": 9856.0, "batch_reward": 11.982315063476562, "critic_loss": 1083.180908203125, "actor_loss": -1671.7362060546875, "actor_target_entropy": -3.0, "actor_entropy": 0.5593681931495667, "alpha_loss": 0.00026131048798561096, "alpha_value": 0.3441133747481194, "duration": 1.5272419452667236, "info_normalized_performance_mean": 0.710099458694458, "info_normalized_performance_final": 0.7642045617103577, "info_performance_mean": 0.710099458694458, "info_performance_final": 0.7642045617103577, "step": 986000}
{"episode_reward": 1420.198863636365, "episode": 9861.0, "batch_reward": 11.645454406738281, "critic_loss": 177.3905029296875, "actor_loss": -1667.951416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.6125898361206055, "alpha_loss": -0.1564229130744934, "alpha_value": 0.3414476936654958, "duration": 1.6413698196411133, "info_normalized_performance_mean": 0.7076770067214966, "info_normalized_performance_final": 0.7769230604171753, "info_performance_mean": 0.7076770067214966, "info_performance_final": 0.7769230604171753, "step": 986500}
{"episode_reward": 1415.353846153844, "episode": 9866.0, "batch_reward": 12.454130172729492, "critic_loss": 418.5992736816406, "actor_loss": -1684.594482421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8027036190032959, "alpha_loss": 0.14435142278671265, "alpha_value": 0.34125001582468323, "duration": 1.4799561500549316, "info_normalized_performance_mean": 0.5477083325386047, "info_normalized_performance_final": 0.5885416865348816, "info_performance_mean": 0.5477083325386047, "info_performance_final": 0.5885416865348816, "step": 987000}
{"episode_reward": 1095.4166666666674, "episode": 9871.0, "batch_reward": 12.012582778930664, "critic_loss": 653.3292236328125, "actor_loss": -1672.5933837890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7400504350662231, "alpha_loss": 0.06457031518220901, "alpha_value": 0.34034784189983996, "duration": 1.365739107131958, "info_normalized_performance_mean": 0.6713570356369019, "info_normalized_performance_final": 0.7214285731315613, "info_performance_mean": 0.6713570356369019, "info_performance_final": 0.7214285731315613, "step": 987500}
{"episode_reward": 1342.7142857142842, "episode": 9876.0, "batch_reward": 11.885049819946289, "critic_loss": 304.2126770019531, "actor_loss": -1647.6337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0109670162200928, "alpha_loss": -0.09184841066598892, "alpha_value": 0.33786707157512147, "duration": 1.4797465801239014, "info_normalized_performance_mean": 0.8758261203765869, "info_normalized_performance_final": 0.9553571343421936, "info_performance_mean": 0.8758261203765869, "info_performance_final": 0.9553571343421936, "step": 988000}
{"episode_reward": 1751.6517857142874, "episode": 9881.0, "batch_reward": 12.074922561645508, "critic_loss": 430.2628479003906, "actor_loss": -1710.9637451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6286765336990356, "alpha_loss": 0.028674036264419556, "alpha_value": 0.33665886363863134, "duration": 1.599670171737671, "info_normalized_performance_mean": 0.6055422425270081, "info_normalized_performance_final": 0.6607142686843872, "info_performance_mean": 0.6055422425270081, "info_performance_final": 0.6607142686843872, "step": 988500}
{"episode_reward": 1211.0846560846553, "episode": 9886.0, "batch_reward": 12.337543487548828, "critic_loss": 447.9403991699219, "actor_loss": -1669.022216796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8506431579589844, "alpha_loss": 0.18463507294654846, "alpha_value": 0.3327486403742046, "duration": 1.5176937580108643, "info_normalized_performance_mean": 0.6337717175483704, "info_normalized_performance_final": 0.6938775777816772, "info_performance_mean": 0.6337717175483704, "info_performance_final": 0.6938775777816772, "step": 989000}
{"episode_reward": 1267.5431711146016, "episode": 9891.0, "batch_reward": 12.219354629516602, "critic_loss": 915.0557861328125, "actor_loss": -1657.084716796875, "actor_target_entropy": -3.0, "actor_entropy": 0.5144677758216858, "alpha_loss": 0.14294934272766113, "alpha_value": 0.33084318720478856, "duration": 1.6573011875152588, "info_normalized_performance_mean": 0.47832831740379333, "info_normalized_performance_final": 0.5324943661689758, "info_performance_mean": 0.47832831740379333, "info_performance_final": 0.5324943661689758, "step": 989500}
{"episode_reward": 956.6566491359899, "episode": 9896.0, "batch_reward": 12.212942123413086, "critic_loss": 358.6068115234375, "actor_loss": -1679.02099609375, "actor_target_entropy": -3.0, "actor_entropy": 0.7129825353622437, "alpha_loss": -0.11840230226516724, "alpha_value": 0.32846046357727604, "step": 990000}
{"duration": 18.625167846679688, "info_normalized_performance_mean": 0.7957438826560974, "info_normalized_performance_final": 0.8541666865348816, "info_performance_mean": 0.7957438826560974, "info_performance_final": 0.8541666865348816, "step": 990000}
{"episode_reward": 1591.4880952380936, "episode": 9901.0, "batch_reward": 12.458057403564453, "critic_loss": 461.9832458496094, "actor_loss": -1655.8621826171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7981982827186584, "alpha_loss": 0.20710013806819916, "alpha_value": 0.32567952705340847, "duration": 1.677025318145752, "info_normalized_performance_mean": 0.3987063467502594, "info_normalized_performance_final": 0.4570883810520172, "info_performance_mean": 0.3987063467502594, "info_performance_final": 0.4570883810520172, "step": 990500}
{"episode_reward": 797.4125874125887, "episode": 9906.0, "batch_reward": 11.296089172363281, "critic_loss": 221.13140869140625, "actor_loss": -1598.2762451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6914253234863281, "alpha_loss": -0.12482577562332153, "alpha_value": 0.32414612049167574, "duration": 1.5728483200073242, "info_normalized_performance_mean": 0.8723333477973938, "info_normalized_performance_final": 0.9372549057006836, "info_performance_mean": 0.8723333477973938, "info_performance_final": 0.9372549057006836, "step": 991000}
{"episode_reward": 1744.666666666667, "episode": 9911.0, "batch_reward": 11.193352699279785, "critic_loss": 266.72406005859375, "actor_loss": -1575.731689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.1625913381576538, "alpha_loss": 0.10469353944063187, "alpha_value": 0.3221743506838005, "duration": 1.356774091720581, "info_normalized_performance_mean": 0.7549643516540527, "info_normalized_performance_final": 0.8107143044471741, "info_performance_mean": 0.7549643516540527, "info_performance_final": 0.8107143044471741, "step": 991500}
{"episode_reward": 1509.928571428572, "episode": 9916.0, "batch_reward": 11.848018646240234, "critic_loss": 214.10198974609375, "actor_loss": -1666.8870849609375, "actor_target_entropy": -3.0, "actor_entropy": 0.8866318464279175, "alpha_loss": -0.1672946810722351, "alpha_value": 0.32031152274428193, "duration": 1.6405010223388672, "info_normalized_performance_mean": 0.49781256914138794, "info_normalized_performance_final": 0.5475000143051147, "info_performance_mean": 0.49781256914138794, "info_performance_final": 0.5475000143051147, "step": 992000}
{"episode_reward": 995.6250000000017, "episode": 9921.0, "batch_reward": 11.940555572509766, "critic_loss": 305.98358154296875, "actor_loss": -1615.494140625, "actor_target_entropy": -3.0, "actor_entropy": 1.0698634386062622, "alpha_loss": 0.07282514870166779, "alpha_value": 0.31796563285869506, "duration": 1.5283093452453613, "info_normalized_performance_mean": 0.26670610904693604, "info_normalized_performance_final": 0.29318997263908386, "info_performance_mean": 0.26670610904693604, "info_performance_final": 0.29318997263908386, "step": 992500}
{"episode_reward": 533.412186379927, "episode": 9926.0, "batch_reward": 12.145989418029785, "critic_loss": 256.7884216308594, "actor_loss": -1620.7362060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.0280622243881226, "alpha_loss": -0.10266552120447159, "alpha_value": 0.31586871524209137, "duration": 1.5635604858398438, "info_normalized_performance_mean": 0.7865798473358154, "info_normalized_performance_final": 0.8653846383094788, "info_performance_mean": 0.7865798473358154, "info_performance_final": 0.8653846383094788, "step": 993000}
{"episode_reward": 1573.1593406593418, "episode": 9931.0, "batch_reward": 11.168909072875977, "critic_loss": 373.700927734375, "actor_loss": -1629.14599609375, "actor_target_entropy": -3.0, "actor_entropy": 0.6689834594726562, "alpha_loss": -0.2334267944097519, "alpha_value": 0.31429967173668366, "duration": 1.6056203842163086, "info_normalized_performance_mean": 0.8567602038383484, "info_normalized_performance_final": 0.9429864287376404, "info_performance_mean": 0.8567602038383484, "info_performance_final": 0.9429864287376404, "step": 993500}
{"episode_reward": 1713.520361990952, "episode": 9936.0, "batch_reward": 11.644886016845703, "critic_loss": 215.869384765625, "actor_loss": -1583.779541015625, "actor_target_entropy": -3.0, "actor_entropy": 0.7084755301475525, "alpha_loss": -0.012030864134430885, "alpha_value": 0.31395044819991225, "duration": 1.464355230331421, "info_normalized_performance_mean": 0.5577702522277832, "info_normalized_performance_final": 0.5970696210861206, "info_performance_mean": 0.5577702522277832, "info_performance_final": 0.5970696210861206, "step": 994000}
{"episode_reward": 1115.5402930402902, "episode": 9941.0, "batch_reward": 12.256545066833496, "critic_loss": 217.54978942871094, "actor_loss": -1647.576416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.5916078686714172, "alpha_loss": 0.08498068898916245, "alpha_value": 0.3112145460971585, "duration": 1.5398948192596436, "info_normalized_performance_mean": 0.5485156774520874, "info_normalized_performance_final": 0.5877403616905212, "info_performance_mean": 0.5485156774520874, "info_performance_final": 0.5877403616905212, "step": 994500}
{"episode_reward": 1097.031250000001, "episode": 9946.0, "batch_reward": 12.345867156982422, "critic_loss": 511.0828857421875, "actor_loss": -1642.3868408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.7873309850692749, "alpha_loss": -0.1453540325164795, "alpha_value": 0.30941353100546887, "duration": 1.4524056911468506, "info_normalized_performance_mean": 0.6218979358673096, "info_normalized_performance_final": 0.7132652997970581, "info_performance_mean": 0.6218979358673096, "info_performance_final": 0.7132652997970581, "step": 995000}
{"episode_reward": 1243.7959183673468, "episode": 9951.0, "batch_reward": 12.693665504455566, "critic_loss": 292.6590270996094, "actor_loss": -1648.568115234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2808551788330078, "alpha_loss": 0.16704635322093964, "alpha_value": 0.3075021761421456, "duration": 1.4505298137664795, "info_normalized_performance_mean": 0.6749414205551147, "info_normalized_performance_final": 0.724609375, "info_performance_mean": 0.6749414205551147, "info_performance_final": 0.724609375, "step": 995500}
{"episode_reward": 1349.8828125, "episode": 9956.0, "batch_reward": 12.360027313232422, "critic_loss": 486.84075927734375, "actor_loss": -1640.9185791015625, "actor_target_entropy": -3.0, "actor_entropy": 0.7271944284439087, "alpha_loss": 0.16123536229133606, "alpha_value": 0.3053780116261646, "duration": 1.5572006702423096, "info_normalized_performance_mean": 0.2377704232931137, "info_normalized_performance_final": 0.2622727155685425, "info_performance_mean": 0.2377704232931137, "info_performance_final": 0.2622727155685425, "step": 996000}
{"episode_reward": 475.5409090909094, "episode": 9961.0, "batch_reward": 12.75533390045166, "critic_loss": 147.8743896484375, "actor_loss": -1618.998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9262242913246155, "alpha_loss": 0.17952698469161987, "alpha_value": 0.3004759845511362, "duration": 1.5215096473693848, "info_normalized_performance_mean": 0.3788502514362335, "info_normalized_performance_final": 0.41825199127197266, "info_performance_mean": 0.3788502514362335, "info_performance_final": 0.41825199127197266, "step": 996500}
{"episode_reward": 757.7005789909005, "episode": 9966.0, "batch_reward": 11.669803619384766, "critic_loss": 149.12451171875, "actor_loss": -1584.309814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7673889398574829, "alpha_loss": -0.11836770176887512, "alpha_value": 0.29716211631489947, "duration": 1.4731793403625488, "info_normalized_performance_mean": 0.8200260996818542, "info_normalized_performance_final": 0.8958333134651184, "info_performance_mean": 0.8200260996818542, "info_performance_final": 0.8958333134651184, "step": 997000}
{"episode_reward": 1640.052083333335, "episode": 9971.0, "batch_reward": 11.643289566040039, "critic_loss": 684.3693237304688, "actor_loss": -1575.8887939453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9181057214736938, "alpha_loss": 0.1543440818786621, "alpha_value": 0.2917939328232416, "duration": 1.4514193534851074, "info_normalized_performance_mean": 0.5408072471618652, "info_normalized_performance_final": 0.59375, "info_performance_mean": 0.5408072471618652, "info_performance_final": 0.59375, "step": 997500}
{"episode_reward": 1081.6145833333333, "episode": 9976.0, "batch_reward": 11.433341979980469, "critic_loss": 203.35682678222656, "actor_loss": -1566.6409912109375, "actor_target_entropy": -3.0, "actor_entropy": 0.5290873050689697, "alpha_loss": -0.0061329323798418045, "alpha_value": 0.2874916728426752, "duration": 1.507188320159912, "info_normalized_performance_mean": 0.6789157390594482, "info_normalized_performance_final": 0.7402210831642151, "info_performance_mean": 0.6789157390594482, "info_performance_final": 0.7402210831642151, "step": 998000}
{"episode_reward": 1357.8316326530603, "episode": 9981.0, "batch_reward": 11.88790512084961, "critic_loss": 645.2677001953125, "actor_loss": -1600.1964111328125, "actor_target_entropy": -3.0, "actor_entropy": 0.24380534887313843, "alpha_loss": 0.14465317130088806, "alpha_value": 0.2821758380710735, "duration": 1.7464542388916016, "info_normalized_performance_mean": 0.47307175397872925, "info_normalized_performance_final": 0.5925049185752869, "info_performance_mean": 0.47307175397872925, "info_performance_final": 0.5925049185752869, "step": 998500}
{"episode_reward": 946.1433267587119, "episode": 9986.0, "batch_reward": 12.545341491699219, "critic_loss": 366.015625, "actor_loss": -1617.184326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8483556509017944, "alpha_loss": -0.09447408467531204, "alpha_value": 0.2763580887127447, "duration": 1.560835599899292, "info_normalized_performance_mean": 0.8275529742240906, "info_normalized_performance_final": 0.9082353115081787, "info_performance_mean": 0.8275529742240906, "info_performance_final": 0.9082353115081787, "step": 999000}
{"episode_reward": 1655.1058823529431, "episode": 9991.0, "batch_reward": 11.926488876342773, "critic_loss": 397.08251953125, "actor_loss": -1578.3936767578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6063984036445618, "alpha_loss": -0.01923546753823757, "alpha_value": 0.27454111564178874, "duration": 1.4154548645019531, "info_normalized_performance_mean": 0.7313520908355713, "info_normalized_performance_final": 0.7984693646430969, "info_performance_mean": 0.7313520908355713, "info_performance_final": 0.7984693646430969, "step": 999500}
{"episode_reward": 1462.7040816326505, "episode": 9996.0, "batch_reward": 11.945630073547363, "critic_loss": 583.5135498046875, "actor_loss": -1616.8074951171875, "actor_target_entropy": -3.0, "actor_entropy": 0.2960525155067444, "alpha_loss": -0.17926329374313354, "alpha_value": 0.27410692530713526, "step": 1000000}
{"duration": 19.200111150741577, "info_normalized_performance_mean": 0.3984813988208771, "info_normalized_performance_final": 0.4526861906051636, "info_performance_mean": 0.3984813988208771, "info_performance_final": 0.4526861906051636, "step": 1000000}
{"episode_reward": 796.96275946276, "episode": 10001.0, "batch_reward": 12.868705749511719, "critic_loss": 199.00482177734375, "actor_loss": -1608.408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.47059565782546997, "alpha_loss": 0.12419251352548599, "alpha_value": 0.27219844908790364, "duration": 1.6114377975463867, "info_normalized_performance_mean": 0.5121166706085205, "info_normalized_performance_final": 0.5723809599876404, "info_performance_mean": 0.5121166706085205, "info_performance_final": 0.5723809599876404, "step": 1000500}
{"episode_reward": 1024.2333333333324, "episode": 10006.0, "batch_reward": 11.601278305053711, "critic_loss": 502.41448974609375, "actor_loss": -1604.2237548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.5709888339042664, "alpha_loss": 0.03211411088705063, "alpha_value": 0.269962407968367, "duration": 1.5264360904693604, "info_normalized_performance_mean": 0.605843722820282, "info_normalized_performance_final": 0.658984363079071, "info_performance_mean": 0.605843722820282, "info_performance_final": 0.658984363079071, "step": 1001000}
{"episode_reward": 1211.6875, "episode": 10011.0, "batch_reward": 12.077808380126953, "critic_loss": 680.0936279296875, "actor_loss": -1556.5330810546875, "actor_target_entropy": -3.0, "actor_entropy": 0.4297959804534912, "alpha_loss": -0.05972641706466675, "alpha_value": 0.26641927822107253, "duration": 1.5221996307373047, "info_normalized_performance_mean": 0.3886606991291046, "info_normalized_performance_final": 0.4289434552192688, "info_performance_mean": 0.3886606991291046, "info_performance_final": 0.4289434552192688, "step": 1001500}
{"episode_reward": 777.3214285714279, "episode": 10016.0, "batch_reward": 12.102437973022461, "critic_loss": 283.62420654296875, "actor_loss": -1580.05126953125, "actor_target_entropy": -3.0, "actor_entropy": 0.37287747859954834, "alpha_loss": 0.04376199468970299, "alpha_value": 0.26460384456104213, "duration": 1.4472780227661133, "info_normalized_performance_mean": 0.690420925617218, "info_normalized_performance_final": 0.7423469424247742, "info_performance_mean": 0.690420925617218, "info_performance_final": 0.7423469424247742, "step": 1002000}
{"episode_reward": 1380.8418367346928, "episode": 10021.0, "batch_reward": 11.706377983093262, "critic_loss": 837.8382568359375, "actor_loss": -1549.211669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.5203499794006348, "alpha_loss": 0.08928517997264862, "alpha_value": 0.26080066485289427, "duration": 1.6630873680114746, "info_normalized_performance_mean": 0.3868520259857178, "info_normalized_performance_final": 0.6405502557754517, "info_performance_mean": 0.3868520259857178, "info_performance_final": 0.6405502557754517, "step": 1002500}
{"episode_reward": 773.7041467304628, "episode": 10026.0, "batch_reward": 12.948619842529297, "critic_loss": 419.3544006347656, "actor_loss": -1591.90478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.36342325806617737, "alpha_loss": 0.0735083669424057, "alpha_value": 0.2577564884861681, "duration": 1.5647144317626953, "info_normalized_performance_mean": 0.39506760239601135, "info_normalized_performance_final": 0.4345000088214874, "info_performance_mean": 0.39506760239601135, "info_performance_final": 0.4345000088214874, "step": 1003000}
{"episode_reward": 790.1350000000017, "episode": 10031.0, "batch_reward": 11.970701217651367, "critic_loss": 291.5364685058594, "actor_loss": -1534.485107421875, "actor_target_entropy": -3.0, "actor_entropy": 0.6705001592636108, "alpha_loss": 0.004230855032801628, "alpha_value": 0.25598768967296043, "duration": 1.6170310974121094, "info_normalized_performance_mean": 0.8340489268302917, "info_normalized_performance_final": 0.9107843041419983, "info_performance_mean": 0.8340489268302917, "info_performance_final": 0.9107843041419983, "step": 1003500}
{"episode_reward": 1668.0980392156878, "episode": 10036.0, "batch_reward": 12.252716064453125, "critic_loss": 308.1964111328125, "actor_loss": -1559.467041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.3893461525440216, "alpha_loss": 0.007567133754491806, "alpha_value": 0.25478218609557257, "duration": 1.4960718154907227, "info_normalized_performance_mean": 0.5940042734146118, "info_normalized_performance_final": 0.6461039185523987, "info_performance_mean": 0.5940042734146118, "info_performance_final": 0.6461039185523987, "step": 1004000}
{"episode_reward": 1188.0086580086597, "episode": 10041.0, "batch_reward": 12.96268367767334, "critic_loss": 194.88705444335938, "actor_loss": -1577.0225830078125, "actor_target_entropy": -3.0, "actor_entropy": 0.6528194546699524, "alpha_loss": 0.06127757579088211, "alpha_value": 0.2537254086423231, "duration": 1.5134193897247314, "info_normalized_performance_mean": 0.5929598212242126, "info_normalized_performance_final": 0.6459821462631226, "info_performance_mean": 0.5929598212242126, "info_performance_final": 0.6459821462631226, "step": 1004500}
{"episode_reward": 1185.919642857144, "episode": 10046.0, "batch_reward": 11.529338836669922, "critic_loss": 228.53248596191406, "actor_loss": -1545.0262451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.4971660375595093, "alpha_loss": -0.04107120633125305, "alpha_value": 0.25320932366882365, "duration": 1.6240930557250977, "info_normalized_performance_mean": 0.4491318464279175, "info_normalized_performance_final": 0.5008791089057922, "info_performance_mean": 0.4491318464279175, "info_performance_final": 0.5008791089057922, "step": 1005000}
{"episode_reward": 898.2637362637345, "episode": 10051.0, "batch_reward": 11.999387741088867, "critic_loss": 212.08377075195312, "actor_loss": -1571.2706298828125, "actor_target_entropy": -3.0, "actor_entropy": 0.49778029322624207, "alpha_loss": -0.02899068593978882, "alpha_value": 0.2530344195461822, "duration": 1.5343728065490723, "info_normalized_performance_mean": 0.6439204216003418, "info_normalized_performance_final": 0.703125, "info_performance_mean": 0.6439204216003418, "info_performance_final": 0.703125, "step": 1005500}
{"episode_reward": 1287.840909090909, "episode": 10056.0, "batch_reward": 12.307559967041016, "critic_loss": 209.64019775390625, "actor_loss": -1563.07470703125, "actor_target_entropy": -3.0, "actor_entropy": 0.7638654112815857, "alpha_loss": 0.05007847025990486, "alpha_value": 0.25450815991618364, "duration": 1.5505895614624023, "info_normalized_performance_mean": 0.5348072648048401, "info_normalized_performance_final": 0.5748299360275269, "info_performance_mean": 0.5348072648048401, "info_performance_final": 0.5748299360275269, "step": 1006000}
{"episode_reward": 1069.6145124716552, "episode": 10061.0, "batch_reward": 12.038585662841797, "critic_loss": 466.06109619140625, "actor_loss": -1514.9178466796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7628504037857056, "alpha_loss": 0.09396690875291824, "alpha_value": 0.2573416132672277, "duration": 1.5550246238708496, "info_normalized_performance_mean": 0.7199832797050476, "info_normalized_performance_final": 0.7733333110809326, "info_performance_mean": 0.7199832797050476, "info_performance_final": 0.7733333110809326, "step": 1006500}
{"episode_reward": 1439.966666666668, "episode": 10066.0, "batch_reward": 12.082745552062988, "critic_loss": 304.30450439453125, "actor_loss": -1531.26611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.4100577235221863, "alpha_loss": 0.045575663447380066, "alpha_value": 0.2578351192971578, "duration": 1.5174839496612549, "info_normalized_performance_mean": 0.8087695240974426, "info_normalized_performance_final": 0.876953125, "info_performance_mean": 0.8087695240974426, "info_performance_final": 0.876953125, "step": 1007000}
{"episode_reward": 1617.5390625, "episode": 10071.0, "batch_reward": 12.675653457641602, "critic_loss": 393.6143798828125, "actor_loss": -1554.2584228515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7940749526023865, "alpha_loss": 0.06910593807697296, "alpha_value": 0.25886306528664765, "duration": 1.6212081909179688, "info_normalized_performance_mean": 0.2906736433506012, "info_normalized_performance_final": 0.3201389014720917, "info_performance_mean": 0.2906736433506012, "info_performance_final": 0.3201389014720917, "step": 1007500}
{"episode_reward": 581.3472222222223, "episode": 10076.0, "batch_reward": 12.570694923400879, "critic_loss": 176.205322265625, "actor_loss": -1543.345947265625, "actor_target_entropy": -3.0, "actor_entropy": 0.744836688041687, "alpha_loss": 0.002705186605453491, "alpha_value": 0.2604589975759109, "duration": 1.5569679737091064, "info_normalized_performance_mean": 0.7145957350730896, "info_normalized_performance_final": 0.7813971638679504, "info_performance_mean": 0.7145957350730896, "info_performance_final": 0.7813971638679504, "step": 1008000}
{"episode_reward": 1429.1915227629488, "episode": 10081.0, "batch_reward": 11.582572937011719, "critic_loss": 188.11239624023438, "actor_loss": -1507.1192626953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7327103614807129, "alpha_loss": -0.055994339287281036, "alpha_value": 0.2635055892028204, "duration": 1.5819816589355469, "info_normalized_performance_mean": 0.7738691568374634, "info_normalized_performance_final": 0.8333333134651184, "info_performance_mean": 0.7738691568374634, "info_performance_final": 0.8333333134651184, "step": 1008500}
{"episode_reward": 1547.7380952380968, "episode": 10086.0, "batch_reward": 12.018260955810547, "critic_loss": 458.1012878417969, "actor_loss": -1539.94189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5378130674362183, "alpha_loss": -0.0828809142112732, "alpha_value": 0.26488943955756344, "duration": 1.7341527938842773, "info_normalized_performance_mean": 0.34186965227127075, "info_normalized_performance_final": 0.38635149598121643, "info_performance_mean": 0.34186965227127075, "info_performance_final": 0.38635149598121643, "step": 1009000}
{"episode_reward": 683.7393162393151, "episode": 10091.0, "batch_reward": 12.303916931152344, "critic_loss": 214.26324462890625, "actor_loss": -1529.349365234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5301716327667236, "alpha_loss": 0.05334312841296196, "alpha_value": 0.26574765363916825, "duration": 1.5748333930969238, "info_normalized_performance_mean": 0.8690984845161438, "info_normalized_performance_final": 0.9350961446762085, "info_performance_mean": 0.8690984845161438, "info_performance_final": 0.9350961446762085, "step": 1009500}
{"episode_reward": 1738.1971153846166, "episode": 10096.0, "batch_reward": 12.326033592224121, "critic_loss": 108.05964660644531, "actor_loss": -1527.02001953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7461060285568237, "alpha_loss": 0.1302306205034256, "alpha_value": 0.2640417624737436, "step": 1010000}
{"duration": 18.933281898498535, "info_normalized_performance_mean": 0.6685280799865723, "info_normalized_performance_final": 0.7174254059791565, "info_performance_mean": 0.6685280799865723, "info_performance_final": 0.7174254059791565, "step": 1010000}
{"episode_reward": 1337.0565149136573, "episode": 10101.0, "batch_reward": 12.35207748413086, "critic_loss": 313.790771484375, "actor_loss": -1599.943603515625, "actor_target_entropy": -3.0, "actor_entropy": 0.5616449117660522, "alpha_loss": -0.01341307908296585, "alpha_value": 0.2625670412145209, "duration": 1.5249834060668945, "info_normalized_performance_mean": 0.8320761322975159, "info_normalized_performance_final": 0.8928571343421936, "info_performance_mean": 0.8320761322975159, "info_performance_final": 0.8928571343421936, "step": 1010500}
{"episode_reward": 1664.1517857142874, "episode": 10106.0, "batch_reward": 12.108092308044434, "critic_loss": 413.55194091796875, "actor_loss": -1558.38232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.3045094311237335, "alpha_loss": -0.18024872243404388, "alpha_value": 0.26240130180268756, "duration": 1.5610520839691162, "info_normalized_performance_mean": 0.8738908171653748, "info_normalized_performance_final": 0.940625011920929, "info_performance_mean": 0.8738908171653748, "info_performance_final": 0.940625011920929, "step": 1011000}
{"episode_reward": 1747.78125, "episode": 10111.0, "batch_reward": 11.91384220123291, "critic_loss": 188.16812133789062, "actor_loss": -1493.3603515625, "actor_target_entropy": -3.0, "actor_entropy": 0.4935973882675171, "alpha_loss": -0.12197081744670868, "alpha_value": 0.2603872939929553, "duration": 1.6164863109588623, "info_normalized_performance_mean": 0.6007993817329407, "info_normalized_performance_final": 0.6445578336715698, "info_performance_mean": 0.6007993817329407, "info_performance_final": 0.6445578336715698, "step": 1011500}
{"episode_reward": 1201.598639455784, "episode": 10116.0, "batch_reward": 11.33580207824707, "critic_loss": 481.38006591796875, "actor_loss": -1484.957275390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9899051189422607, "alpha_loss": -0.018140830099582672, "alpha_value": 0.2567637395484033, "duration": 1.4625663757324219, "info_normalized_performance_mean": 0.7418373227119446, "info_normalized_performance_final": 0.8011363744735718, "info_performance_mean": 0.7418373227119446, "info_performance_final": 0.8011363744735718, "step": 1012000}
{"episode_reward": 1483.674242424241, "episode": 10121.0, "batch_reward": 11.381006240844727, "critic_loss": 202.10110473632812, "actor_loss": -1486.352294921875, "actor_target_entropy": -3.0, "actor_entropy": 0.6680777072906494, "alpha_loss": 0.051651738584041595, "alpha_value": 0.25442510167071525, "duration": 1.5066354274749756, "info_normalized_performance_mean": 0.8569011092185974, "info_normalized_performance_final": 0.921875, "info_performance_mean": 0.8569011092185974, "info_performance_final": 0.921875, "step": 1012500}
{"episode_reward": 1713.8020833333335, "episode": 10126.0, "batch_reward": 12.76160717010498, "critic_loss": 461.37493896484375, "actor_loss": -1539.2615966796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7741063833236694, "alpha_loss": 0.012931426987051964, "alpha_value": 0.25208764182817706, "duration": 1.7453994750976562, "info_normalized_performance_mean": 0.32909858226776123, "info_normalized_performance_final": 0.36818909645080566, "info_performance_mean": 0.32909858226776123, "info_performance_final": 0.36818909645080566, "step": 1013000}
{"episode_reward": 658.1971153846159, "episode": 10131.0, "batch_reward": 12.155927658081055, "critic_loss": 447.8822021484375, "actor_loss": -1543.8502197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.7674380540847778, "alpha_loss": -0.06856659799814224, "alpha_value": 0.25030302930880194, "duration": 1.6386103630065918, "info_normalized_performance_mean": 0.7968757748603821, "info_normalized_performance_final": 0.8672438859939575, "info_performance_mean": 0.7968757748603821, "info_performance_final": 0.8672438859939575, "step": 1013500}
{"episode_reward": 1593.7518037518055, "episode": 10136.0, "batch_reward": 11.560345649719238, "critic_loss": 201.331298828125, "actor_loss": -1491.25, "actor_target_entropy": -3.0, "actor_entropy": 0.7095281481742859, "alpha_loss": 0.0032247714698314667, "alpha_value": 0.2512390902440347, "duration": 1.6003444194793701, "info_normalized_performance_mean": 0.4128401279449463, "info_normalized_performance_final": 0.4555000066757202, "info_performance_mean": 0.4128401279449463, "info_performance_final": 0.4555000066757202, "step": 1014000}
{"episode_reward": 825.680000000001, "episode": 10141.0, "batch_reward": 12.184922218322754, "critic_loss": 1015.71533203125, "actor_loss": -1530.150634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.5768599510192871, "alpha_loss": -0.04833853244781494, "alpha_value": 0.24882626665456978, "duration": 1.4662830829620361, "info_normalized_performance_mean": 0.5855357646942139, "info_normalized_performance_final": 0.6288265585899353, "info_performance_mean": 0.5855357646942139, "info_performance_final": 0.6288265585899353, "step": 1014500}
{"episode_reward": 1171.0714285714291, "episode": 10146.0, "batch_reward": 12.786588668823242, "critic_loss": 444.501220703125, "actor_loss": -1568.231201171875, "actor_target_entropy": -3.0, "actor_entropy": 0.4618018865585327, "alpha_loss": -0.007218055427074432, "alpha_value": 0.248759725360855, "duration": 1.6030182838439941, "info_normalized_performance_mean": 0.7638351917266846, "info_normalized_performance_final": 0.822352945804596, "info_performance_mean": 0.7638351917266846, "info_performance_final": 0.822352945804596, "step": 1015000}
{"episode_reward": 1527.670588235297, "episode": 10151.0, "batch_reward": 12.737945556640625, "critic_loss": 639.7728881835938, "actor_loss": -1536.787109375, "actor_target_entropy": -3.0, "actor_entropy": 0.6062253713607788, "alpha_loss": -0.00921282172203064, "alpha_value": 0.24752251861677754, "duration": 1.5516314506530762, "info_normalized_performance_mean": 0.5897476673126221, "info_normalized_performance_final": 0.631911039352417, "info_performance_mean": 0.5897476673126221, "info_performance_final": 0.631911039352417, "step": 1015500}
{"episode_reward": 1179.4951923076937, "episode": 10156.0, "batch_reward": 11.74254322052002, "critic_loss": 249.8087158203125, "actor_loss": -1526.24365234375, "actor_target_entropy": -3.0, "actor_entropy": 0.6242771744728088, "alpha_loss": -0.022527800872921944, "alpha_value": 0.24662026238875634, "duration": 1.6140902042388916, "info_normalized_performance_mean": 0.3523064851760864, "info_normalized_performance_final": 0.3859879672527313, "info_performance_mean": 0.3523064851760864, "info_performance_final": 0.3859879672527313, "step": 1016000}
{"episode_reward": 704.6130728775365, "episode": 10161.0, "batch_reward": 12.991508483886719, "critic_loss": 210.84085083007812, "actor_loss": -1510.85546875, "actor_target_entropy": -3.0, "actor_entropy": 1.0558767318725586, "alpha_loss": 0.0901772677898407, "alpha_value": 0.246746007857734, "duration": 1.4135630130767822, "info_normalized_performance_mean": 0.5422353148460388, "info_normalized_performance_final": 0.5843137502670288, "info_performance_mean": 0.5422353148460388, "info_performance_final": 0.5843137502670288, "step": 1016500}
{"episode_reward": 1084.4705882352969, "episode": 10166.0, "batch_reward": 11.32258415222168, "critic_loss": 1160.5908203125, "actor_loss": -1493.2025146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.2120656669139862, "alpha_loss": -0.17842867970466614, "alpha_value": 0.2474482892620348, "duration": 1.5959835052490234, "info_normalized_performance_mean": 0.8576666116714478, "info_normalized_performance_final": 0.9392156600952148, "info_performance_mean": 0.8576666116714478, "info_performance_final": 0.9392156600952148, "step": 1017000}
{"episode_reward": 1715.3333333333317, "episode": 10171.0, "batch_reward": 11.960484504699707, "critic_loss": 141.09939575195312, "actor_loss": -1495.263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.6163668036460876, "alpha_loss": -0.10248343646526337, "alpha_value": 0.2511626520207423, "duration": 1.485156774520874, "info_normalized_performance_mean": 0.7377038598060608, "info_normalized_performance_final": 0.7936508059501648, "info_performance_mean": 0.7377038598060608, "info_performance_final": 0.7936508059501648, "step": 1017500}
{"episode_reward": 1475.4081632653074, "episode": 10176.0, "batch_reward": 11.5416259765625, "critic_loss": 722.9561767578125, "actor_loss": -1467.632080078125, "actor_target_entropy": -3.0, "actor_entropy": 0.31306368112564087, "alpha_loss": -0.16756385564804077, "alpha_value": 0.25474792611488534, "duration": 1.5010709762573242, "info_normalized_performance_mean": 0.4470135569572449, "info_normalized_performance_final": 0.4865056872367859, "info_performance_mean": 0.4470135569572449, "info_performance_final": 0.4865056872367859, "step": 1018000}
{"episode_reward": 894.026988636363, "episode": 10181.0, "batch_reward": 11.94379711151123, "critic_loss": 170.80288696289062, "actor_loss": -1472.3609619140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6760916709899902, "alpha_loss": 0.04917328059673309, "alpha_value": 0.25736215092884, "duration": 1.4932098388671875, "info_normalized_performance_mean": 0.7941573858261108, "info_normalized_performance_final": 0.8534798622131348, "info_performance_mean": 0.7941573858261108, "info_performance_final": 0.8534798622131348, "step": 1018500}
{"episode_reward": 1588.3150183150153, "episode": 10186.0, "batch_reward": 12.396326065063477, "critic_loss": 523.6030883789062, "actor_loss": -1472.7998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8314579129219055, "alpha_loss": 0.020128225907683372, "alpha_value": 0.2617604526250162, "duration": 1.5360243320465088, "info_normalized_performance_mean": 0.9090747237205505, "info_normalized_performance_final": 0.9837662577629089, "info_performance_mean": 0.9090747237205505, "info_performance_final": 0.9837662577629089, "step": 1019000}
{"episode_reward": 1818.1493506493484, "episode": 10191.0, "batch_reward": 10.936483383178711, "critic_loss": 322.763671875, "actor_loss": -1499.895751953125, "actor_target_entropy": -3.0, "actor_entropy": 0.46098899841308594, "alpha_loss": -0.12502890825271606, "alpha_value": 0.26482751774755503, "duration": 1.5887737274169922, "info_normalized_performance_mean": 0.9118750095367432, "info_normalized_performance_final": 0.9819711446762085, "info_performance_mean": 0.9118750095367432, "info_performance_final": 0.9819711446762085, "step": 1019500}
{"episode_reward": 1823.7500000000011, "episode": 10196.0, "batch_reward": 11.998414039611816, "critic_loss": 140.69564819335938, "actor_loss": -1488.7890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6108846664428711, "alpha_loss": 0.06327271461486816, "alpha_value": 0.269604438120081, "step": 1020000}
{"duration": 19.17898654937744, "info_normalized_performance_mean": 0.39192143082618713, "info_normalized_performance_final": 0.43634259700775146, "info_performance_mean": 0.39192143082618713, "info_performance_final": 0.43634259700775146, "step": 1020000}
{"episode_reward": 783.8425925925923, "episode": 10201.0, "batch_reward": 11.72144603729248, "critic_loss": 226.0497589111328, "actor_loss": -1465.16357421875, "actor_target_entropy": -3.0, "actor_entropy": 1.019968032836914, "alpha_loss": -0.017304040491580963, "alpha_value": 0.2753385784665387, "duration": 1.5239098072052002, "info_normalized_performance_mean": 0.8654101490974426, "info_normalized_performance_final": 0.9296875, "info_performance_mean": 0.8654101490974426, "info_performance_final": 0.9296875, "step": 1020500}
{"episode_reward": 1730.8203125, "episode": 10206.0, "batch_reward": 12.106948852539062, "critic_loss": 143.06185913085938, "actor_loss": -1498.2264404296875, "actor_target_entropy": -3.0, "actor_entropy": 0.5898136496543884, "alpha_loss": -0.0921681672334671, "alpha_value": 0.28253084708449105, "duration": 1.452488660812378, "info_normalized_performance_mean": 0.8275312781333923, "info_normalized_performance_final": 0.8843749761581421, "info_performance_mean": 0.8275312781333923, "info_performance_final": 0.8843749761581421, "step": 1021000}
{"episode_reward": 1655.0625, "episode": 10211.0, "batch_reward": 11.783088684082031, "critic_loss": 875.43701171875, "actor_loss": -1530.9271240234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5402480363845825, "alpha_loss": -0.1491849720478058, "alpha_value": 0.28917488140933495, "duration": 1.396313190460205, "info_normalized_performance_mean": 0.6880627274513245, "info_normalized_performance_final": 0.737500011920929, "info_performance_mean": 0.6880627274513245, "info_performance_final": 0.737500011920929, "step": 1021500}
{"episode_reward": 1376.125, "episode": 10216.0, "batch_reward": 11.926765441894531, "critic_loss": 363.4896545410156, "actor_loss": -1516.681640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8521448373794556, "alpha_loss": -0.15652799606323242, "alpha_value": 0.29572746693832536, "duration": 1.4311878681182861, "info_normalized_performance_mean": 0.45310065150260925, "info_normalized_performance_final": 0.48971861600875854, "info_performance_mean": 0.45310065150260925, "info_performance_final": 0.48971861600875854, "step": 1022000}
{"episode_reward": 906.2012987013009, "episode": 10221.0, "batch_reward": 12.62945556640625, "critic_loss": 354.38818359375, "actor_loss": -1553.583251953125, "actor_target_entropy": -3.0, "actor_entropy": 0.6206084489822388, "alpha_loss": -0.0028640441596508026, "alpha_value": 0.3026246362294911, "duration": 1.4640679359436035, "info_normalized_performance_mean": 0.4065190851688385, "info_normalized_performance_final": 0.4366319477558136, "info_performance_mean": 0.4065190851688385, "info_performance_final": 0.4366319477558136, "step": 1022500}
{"episode_reward": 813.0381944444459, "episode": 10226.0, "batch_reward": 11.158642768859863, "critic_loss": 521.2637939453125, "actor_loss": -1476.49169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7551690340042114, "alpha_loss": -0.39279401302337646, "alpha_value": 0.3122637252624154, "duration": 1.6319403648376465, "info_normalized_performance_mean": 0.8151127696037292, "info_normalized_performance_final": 0.8810763955116272, "info_performance_mean": 0.8151127696037292, "info_performance_final": 0.8810763955116272, "step": 1023000}
{"episode_reward": 1630.2256944444475, "episode": 10231.0, "batch_reward": 12.577280044555664, "critic_loss": 182.13973999023438, "actor_loss": -1574.4508056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0946563482284546, "alpha_loss": -0.23044568300247192, "alpha_value": 0.32347042904839635, "duration": 1.5488531589508057, "info_normalized_performance_mean": 0.5673387050628662, "info_normalized_performance_final": 0.6342719793319702, "info_performance_mean": 0.5673387050628662, "info_performance_final": 0.6342719793319702, "step": 1023500}
{"episode_reward": 1134.6771978021986, "episode": 10236.0, "batch_reward": 11.384842872619629, "critic_loss": 393.9515380859375, "actor_loss": -1492.0924072265625, "actor_target_entropy": -3.0, "actor_entropy": 0.7674669027328491, "alpha_loss": -0.25821542739868164, "alpha_value": 0.3345399263820353, "duration": 1.7141742706298828, "info_normalized_performance_mean": 0.31609660387039185, "info_normalized_performance_final": 0.3537326455116272, "info_performance_mean": 0.31609660387039185, "info_performance_final": 0.3537326455116272, "step": 1024000}
{"episode_reward": 632.1932870370375, "episode": 10241.0, "batch_reward": 12.231328010559082, "critic_loss": 554.472412109375, "actor_loss": -1516.94873046875, "actor_target_entropy": -3.0, "actor_entropy": 0.6323752403259277, "alpha_loss": -0.3017890751361847, "alpha_value": 0.34534194908766674, "duration": 1.4114489555358887, "info_normalized_performance_mean": 0.7855358719825745, "info_normalized_performance_final": 0.8428571224212646, "info_performance_mean": 0.7855358719825745, "info_performance_final": 0.8428571224212646, "step": 1024500}
{"episode_reward": 1571.0714285714303, "episode": 10246.0, "batch_reward": 12.052391052246094, "critic_loss": 536.962158203125, "actor_loss": -1534.298095703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6511225700378418, "alpha_loss": -0.2135411500930786, "alpha_value": 0.35538208900957463, "duration": 1.5894570350646973, "info_normalized_performance_mean": 0.8926702737808228, "info_normalized_performance_final": 0.9701704382896423, "info_performance_mean": 0.8926702737808228, "info_performance_final": 0.9701704382896423, "step": 1025000}
{"episode_reward": 1785.340909090907, "episode": 10251.0, "batch_reward": 11.842220306396484, "critic_loss": 287.8832092285156, "actor_loss": -1505.3212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.8537558317184448, "alpha_loss": -0.45837247371673584, "alpha_value": 0.3640234880213234, "duration": 1.4887022972106934, "info_normalized_performance_mean": 0.6994388103485107, "info_normalized_performance_final": 0.75, "info_performance_mean": 0.6994388103485107, "info_performance_final": 0.75, "step": 1025500}
{"episode_reward": 1398.8775510204082, "episode": 10256.0, "batch_reward": 12.326577186584473, "critic_loss": 179.17715454101562, "actor_loss": -1576.57177734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8489302396774292, "alpha_loss": -0.21572166681289673, "alpha_value": 0.3723561228373601, "duration": 1.4510469436645508, "info_normalized_performance_mean": 0.573475182056427, "info_normalized_performance_final": 0.6140109896659851, "info_performance_mean": 0.573475182056427, "info_performance_final": 0.6140109896659851, "step": 1026000}
{"episode_reward": 1146.9505494505506, "episode": 10261.0, "batch_reward": 12.43452262878418, "critic_loss": 486.9659423828125, "actor_loss": -1609.456298828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8181194067001343, "alpha_loss": -0.10668717324733734, "alpha_value": 0.3796397440904589, "duration": 1.5331883430480957, "info_normalized_performance_mean": 0.9259921908378601, "info_normalized_performance_final": 0.9980158805847168, "info_performance_mean": 0.9259921908378601, "info_performance_final": 0.9980158805847168, "step": 1026500}
{"episode_reward": 1851.9841269841231, "episode": 10266.0, "batch_reward": 12.14577579498291, "critic_loss": 188.01568603515625, "actor_loss": -1562.0537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.149466633796692, "alpha_loss": -0.035383790731430054, "alpha_value": 0.38731221315371495, "duration": 1.5604875087738037, "info_normalized_performance_mean": 0.3601571023464203, "info_normalized_performance_final": 0.40226081013679504, "info_performance_mean": 0.3601571023464203, "info_performance_final": 0.40226081013679504, "step": 1027000}
{"episode_reward": 720.3143093465669, "episode": 10271.0, "batch_reward": 12.076681137084961, "critic_loss": 373.91876220703125, "actor_loss": -1651.976318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.7983556389808655, "alpha_loss": -0.28647276759147644, "alpha_value": 0.3950622957630674, "duration": 1.467078685760498, "info_normalized_performance_mean": 0.5508010983467102, "info_normalized_performance_final": 0.5913265347480774, "info_performance_mean": 0.5508010983467102, "info_performance_final": 0.5913265347480774, "step": 1027500}
{"episode_reward": 1101.6020408163274, "episode": 10276.0, "batch_reward": 11.949197769165039, "critic_loss": 350.25640869140625, "actor_loss": -1537.544677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.2101109027862549, "alpha_loss": -0.36960622668266296, "alpha_value": 0.40251850805973044, "duration": 1.5369534492492676, "info_normalized_performance_mean": 0.8629106879234314, "info_normalized_performance_final": 0.9303571581840515, "info_performance_mean": 0.8629106879234314, "info_performance_final": 0.9303571581840515, "step": 1028000}
{"episode_reward": 1725.8214285714303, "episode": 10281.0, "batch_reward": 13.638816833496094, "critic_loss": 308.5429992675781, "actor_loss": -1717.646240234375, "actor_target_entropy": -3.0, "actor_entropy": 0.9161520004272461, "alpha_loss": -0.11391045153141022, "alpha_value": 0.4111189471746393, "duration": 1.5558125972747803, "info_normalized_performance_mean": 0.6285244226455688, "info_normalized_performance_final": 0.6872056722640991, "info_performance_mean": 0.6285244226455688, "info_performance_final": 0.6872056722640991, "step": 1028500}
{"episode_reward": 1257.0486656200933, "episode": 10286.0, "batch_reward": 11.854079246520996, "critic_loss": 160.1082763671875, "actor_loss": -1586.91796875, "actor_target_entropy": -3.0, "actor_entropy": 0.896928608417511, "alpha_loss": -0.34066683053970337, "alpha_value": 0.421680448076451, "duration": 1.5836687088012695, "info_normalized_performance_mean": 0.445372998714447, "info_normalized_performance_final": 0.4761904776096344, "info_performance_mean": 0.445372998714447, "info_performance_final": 0.4761904776096344, "step": 1029000}
{"episode_reward": 890.7460317460313, "episode": 10291.0, "batch_reward": 11.766508102416992, "critic_loss": 453.361083984375, "actor_loss": -1582.90576171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6283840537071228, "alpha_loss": -0.650136411190033, "alpha_value": 0.4315058682194896, "duration": 1.5262925624847412, "info_normalized_performance_mean": 0.9275001287460327, "info_normalized_performance_final": 0.9974489808082581, "info_performance_mean": 0.9275001287460327, "info_performance_final": 0.9974489808082581, "step": 1029500}
{"episode_reward": 1854.9999999999961, "episode": 10296.0, "batch_reward": 11.858294486999512, "critic_loss": 410.000244140625, "actor_loss": -1603.9576416015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9024580717086792, "alpha_loss": -0.5873904228210449, "alpha_value": 0.44228453732999506, "step": 1030000}
{"duration": 19.31969928741455, "info_normalized_performance_mean": 0.4242957830429077, "info_normalized_performance_final": 0.46043771505355835, "info_performance_mean": 0.4242957830429077, "info_performance_final": 0.46043771505355835, "step": 1030000}
{"episode_reward": 848.5914702581354, "episode": 10301.0, "batch_reward": 12.748090744018555, "critic_loss": 296.01556396484375, "actor_loss": -1650.831298828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3101818561553955, "alpha_loss": -0.028600364923477173, "alpha_value": 0.45269751508353573, "duration": 1.509355068206787, "info_normalized_performance_mean": 0.7946556210517883, "info_normalized_performance_final": 0.8545918464660645, "info_performance_mean": 0.7946556210517883, "info_performance_final": 0.8545918464660645, "step": 1030500}
{"episode_reward": 1589.3112244897982, "episode": 10306.0, "batch_reward": 11.815016746520996, "critic_loss": 315.59857177734375, "actor_loss": -1653.1007080078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8409844040870667, "alpha_loss": -0.12628205120563507, "alpha_value": 0.46037879110078245, "duration": 1.5889627933502197, "info_normalized_performance_mean": 0.8804262280464172, "info_normalized_performance_final": 0.9573863744735718, "info_performance_mean": 0.8804262280464172, "info_performance_final": 0.9573863744735718, "step": 1031000}
{"episode_reward": 1760.8522727272712, "episode": 10311.0, "batch_reward": 12.09111213684082, "critic_loss": 596.2432861328125, "actor_loss": -1594.44921875, "actor_target_entropy": -3.0, "actor_entropy": 1.1394667625427246, "alpha_loss": 0.07293285429477692, "alpha_value": 0.46581814820821504, "duration": 1.4663898944854736, "info_normalized_performance_mean": 0.5670849680900574, "info_normalized_performance_final": 0.61572265625, "info_performance_mean": 0.5670849680900574, "info_performance_final": 0.61572265625, "step": 1031500}
{"episode_reward": 1134.169921875, "episode": 10316.0, "batch_reward": 11.921558380126953, "critic_loss": 492.4493103027344, "actor_loss": -1612.27001953125, "actor_target_entropy": -3.0, "actor_entropy": 1.0357861518859863, "alpha_loss": -0.2894483208656311, "alpha_value": 0.47350561810154274, "duration": 1.604907512664795, "info_normalized_performance_mean": 0.7199399471282959, "info_normalized_performance_final": 0.777999997138977, "info_performance_mean": 0.7199399471282959, "info_performance_final": 0.777999997138977, "step": 1032000}
{"episode_reward": 1439.879999999997, "episode": 10321.0, "batch_reward": 11.929705619812012, "critic_loss": 300.3284606933594, "actor_loss": -1618.4437255859375, "actor_target_entropy": -3.0, "actor_entropy": 0.8941121101379395, "alpha_loss": -0.11924707889556885, "alpha_value": 0.47797516503030174, "duration": 1.6103615760803223, "info_normalized_performance_mean": 0.8213809132575989, "info_normalized_performance_final": 0.882539689540863, "info_performance_mean": 0.8213809132575989, "info_performance_final": 0.882539689540863, "step": 1032500}
{"episode_reward": 1642.7619047619069, "episode": 10326.0, "batch_reward": 11.957194328308105, "critic_loss": 292.52703857421875, "actor_loss": -1633.6298828125, "actor_target_entropy": -3.0, "actor_entropy": 1.068627953529358, "alpha_loss": -0.07820598781108856, "alpha_value": 0.4784834633856432, "duration": 1.5566174983978271, "info_normalized_performance_mean": 0.7952772378921509, "info_normalized_performance_final": 0.8554621934890747, "info_performance_mean": 0.7952772378921509, "info_performance_final": 0.8554621934890747, "step": 1033000}
{"episode_reward": 1590.554621848742, "episode": 10331.0, "batch_reward": 11.801399230957031, "critic_loss": 288.1687316894531, "actor_loss": -1605.458251953125, "actor_target_entropy": -3.0, "actor_entropy": 0.5746382474899292, "alpha_loss": 0.13169831037521362, "alpha_value": 0.4785346222525643, "duration": 1.6043057441711426, "info_normalized_performance_mean": 0.41642993688583374, "info_normalized_performance_final": 0.4582499861717224, "info_performance_mean": 0.41642993688583374, "info_performance_final": 0.4582499861717224, "step": 1033500}
{"episode_reward": 832.8599999999991, "episode": 10336.0, "batch_reward": 12.383188247680664, "critic_loss": 558.1112670898438, "actor_loss": -1681.450927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9519522786140442, "alpha_loss": 0.07480673491954803, "alpha_value": 0.47611148899018546, "duration": 1.562631368637085, "info_normalized_performance_mean": 0.9225780963897705, "info_normalized_performance_final": 0.99609375, "info_performance_mean": 0.9225780963897705, "info_performance_final": 0.99609375, "step": 1034000}
{"episode_reward": 1845.15625, "episode": 10341.0, "batch_reward": 11.474620819091797, "critic_loss": 132.2259521484375, "actor_loss": -1584.3138427734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9770220518112183, "alpha_loss": 0.28764480352401733, "alpha_value": 0.4732445870221487, "duration": 1.5799505710601807, "info_normalized_performance_mean": 0.867275059223175, "info_normalized_performance_final": 0.9325000047683716, "info_performance_mean": 0.867275059223175, "info_performance_final": 0.9325000047683716, "step": 1034500}
{"episode_reward": 1734.5500000000027, "episode": 10346.0, "batch_reward": 11.99740219116211, "critic_loss": 568.948974609375, "actor_loss": -1663.779541015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9327642917633057, "alpha_loss": -0.011030890047550201, "alpha_value": 0.4676083495255576, "duration": 1.4735794067382812, "info_normalized_performance_mean": 0.6727267503738403, "info_normalized_performance_final": 0.7222222089767456, "info_performance_mean": 0.6727267503738403, "info_performance_final": 0.7222222089767456, "step": 1035000}
{"episode_reward": 1345.4535147392276, "episode": 10351.0, "batch_reward": 12.929039001464844, "critic_loss": 301.841064453125, "actor_loss": -1671.0, "actor_target_entropy": -3.0, "actor_entropy": 0.8142907619476318, "alpha_loss": 0.13016536831855774, "alpha_value": 0.46296676226850053, "duration": 1.462874412536621, "info_normalized_performance_mean": 0.6719127893447876, "info_normalized_performance_final": 0.7297979593276978, "info_performance_mean": 0.6719127893447876, "info_performance_final": 0.7297979593276978, "step": 1035500}
{"episode_reward": 1343.8257575757568, "episode": 10356.0, "batch_reward": 11.222885131835938, "critic_loss": 355.4629821777344, "actor_loss": -1588.332763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8080763816833496, "alpha_loss": -0.2785354256629944, "alpha_value": 0.4579980228843151, "duration": 1.4459993839263916, "info_normalized_performance_mean": 0.8970715403556824, "info_normalized_performance_final": 0.9642857313156128, "info_performance_mean": 0.8970715403556824, "info_performance_final": 0.9642857313156128, "step": 1036000}
{"episode_reward": 1794.1428571428557, "episode": 10361.0, "batch_reward": 13.033048629760742, "critic_loss": 260.1033020019531, "actor_loss": -1705.35791015625, "actor_target_entropy": -3.0, "actor_entropy": 0.8752742409706116, "alpha_loss": 0.19207657873630524, "alpha_value": 0.4518191553760305, "duration": 1.5188655853271484, "info_normalized_performance_mean": 0.5565097332000732, "info_normalized_performance_final": 0.6116071343421936, "info_performance_mean": 0.5565097332000732, "info_performance_final": 0.6116071343421936, "step": 1036500}
{"episode_reward": 1113.0194805194817, "episode": 10366.0, "batch_reward": 12.14046859741211, "critic_loss": 209.36245727539062, "actor_loss": -1676.93408203125, "actor_target_entropy": -3.0, "actor_entropy": 1.0031921863555908, "alpha_loss": 0.14698883891105652, "alpha_value": 0.44562420858880447, "duration": 1.5765447616577148, "info_normalized_performance_mean": 0.8708202838897705, "info_normalized_performance_final": 0.9361979365348816, "info_performance_mean": 0.8708202838897705, "info_performance_final": 0.9361979365348816, "step": 1037000}
{"episode_reward": 1741.640624999998, "episode": 10371.0, "batch_reward": 12.945220947265625, "critic_loss": 146.5452423095703, "actor_loss": -1681.05224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.219689130783081, "alpha_loss": 0.28729313611984253, "alpha_value": 0.43988637360716515, "duration": 1.5933637619018555, "info_normalized_performance_mean": 0.7335295081138611, "info_normalized_performance_final": 0.7882353067398071, "info_performance_mean": 0.7335295081138611, "info_performance_final": 0.7882353067398071, "step": 1037500}
{"episode_reward": 1467.0588235294108, "episode": 10376.0, "batch_reward": 12.086103439331055, "critic_loss": 664.8182983398438, "actor_loss": -1654.1986083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.880389928817749, "alpha_loss": 0.011750884354114532, "alpha_value": 0.4325989576788666, "duration": 1.640376091003418, "info_normalized_performance_mean": 0.7367515563964844, "info_normalized_performance_final": 0.8047839403152466, "info_performance_mean": 0.7367515563964844, "info_performance_final": 0.8047839403152466, "step": 1038000}
{"episode_reward": 1473.5030864197556, "episode": 10381.0, "batch_reward": 12.423603057861328, "critic_loss": 519.7572631835938, "actor_loss": -1652.496826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.0670602321624756, "alpha_loss": 0.411348819732666, "alpha_value": 0.42360050093747104, "duration": 1.4280495643615723, "info_normalized_performance_mean": 0.42604178190231323, "info_normalized_performance_final": 0.46260684728622437, "info_performance_mean": 0.42604178190231323, "info_performance_final": 0.46260684728622437, "step": 1038500}
{"episode_reward": 852.0833333333329, "episode": 10386.0, "batch_reward": 12.095794677734375, "critic_loss": 415.50750732421875, "actor_loss": -1656.32275390625, "actor_target_entropy": -3.0, "actor_entropy": 0.4885401129722595, "alpha_loss": 0.030444085597991943, "alpha_value": 0.41384926562011815, "duration": 1.511247158050537, "info_normalized_performance_mean": 0.6018261909484863, "info_normalized_performance_final": 0.6615259647369385, "info_performance_mean": 0.6018261909484863, "info_performance_final": 0.6615259647369385, "step": 1039000}
{"episode_reward": 1203.6525974025951, "episode": 10391.0, "batch_reward": 11.913776397705078, "critic_loss": 278.31451416015625, "actor_loss": -1673.23681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1747990846633911, "alpha_loss": 0.1445237100124359, "alpha_value": 0.40685194217637743, "duration": 1.529158592224121, "info_normalized_performance_mean": 0.8129608035087585, "info_normalized_performance_final": 0.8725489974021912, "info_performance_mean": 0.8129608035087585, "info_performance_final": 0.8725489974021912, "step": 1039500}
{"episode_reward": 1625.9215686274536, "episode": 10396.0, "batch_reward": 12.494451522827148, "critic_loss": 266.55975341796875, "actor_loss": -1686.19873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.019658088684082, "alpha_loss": 0.3052408993244171, "alpha_value": 0.399862613682615, "step": 1040000}
{"duration": 18.815804719924927, "info_normalized_performance_mean": 0.6565160155296326, "info_normalized_performance_final": 0.7054398059844971, "info_performance_mean": 0.6565160155296326, "info_performance_final": 0.7054398059844971, "step": 1040000}
{"episode_reward": 1313.032407407408, "episode": 10401.0, "batch_reward": 13.001774787902832, "critic_loss": 368.67596435546875, "actor_loss": -1678.3802490234375, "actor_target_entropy": -3.0, "actor_entropy": 0.4696541428565979, "alpha_loss": 0.05778404325246811, "alpha_value": 0.39569038794831285, "duration": 1.662677526473999, "info_normalized_performance_mean": 0.7050860524177551, "info_normalized_performance_final": 0.7671957612037659, "info_performance_mean": 0.7050860524177551, "info_performance_final": 0.7671957612037659, "step": 1040500}
{"episode_reward": 1410.1719576719577, "episode": 10406.0, "batch_reward": 12.102814674377441, "critic_loss": 528.5482788085938, "actor_loss": -1642.172607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8157339692115784, "alpha_loss": -0.018502872437238693, "alpha_value": 0.3905778956981361, "duration": 1.5151634216308594, "info_normalized_performance_mean": 0.5355398058891296, "info_normalized_performance_final": 0.5965750813484192, "info_performance_mean": 0.5355398058891296, "info_performance_final": 0.5965750813484192, "step": 1041000}
{"episode_reward": 1071.0792512943033, "episode": 10411.0, "batch_reward": 12.379100799560547, "critic_loss": 327.91302490234375, "actor_loss": -1664.669677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8763818144798279, "alpha_loss": 0.19958025217056274, "alpha_value": 0.38671356602972007, "duration": 1.5210363864898682, "info_normalized_performance_mean": 0.7507508993148804, "info_normalized_performance_final": 0.8141025900840759, "info_performance_mean": 0.7507508993148804, "info_performance_final": 0.8141025900840759, "step": 1041500}
{"episode_reward": 1501.5018315018306, "episode": 10416.0, "batch_reward": 12.810352325439453, "critic_loss": 158.253173828125, "actor_loss": -1682.4049072265625, "actor_target_entropy": -3.0, "actor_entropy": 0.770449161529541, "alpha_loss": 0.06194571405649185, "alpha_value": 0.3834247191897523, "duration": 1.68416428565979, "info_normalized_performance_mean": 0.31305718421936035, "info_normalized_performance_final": 0.3695436418056488, "info_performance_mean": 0.31305718421936035, "info_performance_final": 0.3695436418056488, "step": 1042000}
{"episode_reward": 626.1144179894181, "episode": 10421.0, "batch_reward": 11.639093399047852, "critic_loss": 300.2750244140625, "actor_loss": -1637.5640869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7819522619247437, "alpha_loss": -0.09492453187704086, "alpha_value": 0.37826340094391486, "duration": 1.5100865364074707, "info_normalized_performance_mean": 0.7290537357330322, "info_normalized_performance_final": 0.7832722663879395, "info_performance_mean": 0.7290537357330322, "info_performance_final": 0.7832722663879395, "step": 1042500}
{"episode_reward": 1458.1074481074497, "episode": 10426.0, "batch_reward": 11.78740119934082, "critic_loss": 217.9468536376953, "actor_loss": -1639.81494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.48900485038757324, "alpha_loss": 0.11892315000295639, "alpha_value": 0.374074690687502, "duration": 1.48521089553833, "info_normalized_performance_mean": 0.7440403699874878, "info_normalized_performance_final": 0.8147321343421936, "info_performance_mean": 0.7440403699874878, "info_performance_final": 0.8147321343421936, "step": 1043000}
{"episode_reward": 1488.0803571428587, "episode": 10431.0, "batch_reward": 12.991765975952148, "critic_loss": 401.0549011230469, "actor_loss": -1694.3865966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1289321184158325, "alpha_loss": 0.26429951190948486, "alpha_value": 0.3708949771165722, "duration": 1.6151893138885498, "info_normalized_performance_mean": 0.6579985022544861, "info_normalized_performance_final": 0.7157738208770752, "info_performance_mean": 0.6579985022544861, "info_performance_final": 0.7157738208770752, "step": 1043500}
{"episode_reward": 1315.9970238095218, "episode": 10436.0, "batch_reward": 12.24024772644043, "critic_loss": 334.7429504394531, "actor_loss": -1673.7822265625, "actor_target_entropy": -3.0, "actor_entropy": 0.797501802444458, "alpha_loss": 0.06411807984113693, "alpha_value": 0.36606474742831996, "duration": 1.5452427864074707, "info_normalized_performance_mean": 0.8067999482154846, "info_normalized_performance_final": 0.8658823370933533, "info_performance_mean": 0.8067999482154846, "info_performance_final": 0.8658823370933533, "step": 1044000}
{"episode_reward": 1613.5999999999992, "episode": 10441.0, "batch_reward": 12.890514373779297, "critic_loss": 363.3008117675781, "actor_loss": -1704.2392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.22426176071167, "alpha_loss": 0.05081358551979065, "alpha_value": 0.36217695395258337, "duration": 1.6271107196807861, "info_normalized_performance_mean": 0.6085880398750305, "info_normalized_performance_final": 0.6728395223617554, "info_performance_mean": 0.6085880398750305, "info_performance_final": 0.6728395223617554, "step": 1044500}
{"episode_reward": 1217.1759259259275, "episode": 10446.0, "batch_reward": 12.692571640014648, "critic_loss": 137.58692932128906, "actor_loss": -1679.427001953125, "actor_target_entropy": -3.0, "actor_entropy": 0.6503815650939941, "alpha_loss": 0.09703098982572556, "alpha_value": 0.357065692162156, "duration": 1.4168457984924316, "info_normalized_performance_mean": 0.9300000071525574, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9300000071525574, "info_performance_final": 1.0, "step": 1045000}
{"episode_reward": 1860.0, "episode": 10451.0, "batch_reward": 12.729124069213867, "critic_loss": 359.94622802734375, "actor_loss": -1667.04541015625, "actor_target_entropy": -3.0, "actor_entropy": 0.4995351731777191, "alpha_loss": -0.06366554647684097, "alpha_value": 0.3533472887492536, "duration": 1.534797191619873, "info_normalized_performance_mean": 0.5863789916038513, "info_normalized_performance_final": 0.6363281011581421, "info_performance_mean": 0.5863789916038513, "info_performance_final": 0.6363281011581421, "step": 1045500}
{"episode_reward": 1172.7578125, "episode": 10456.0, "batch_reward": 12.388318061828613, "critic_loss": 217.43194580078125, "actor_loss": -1657.4495849609375, "actor_target_entropy": -3.0, "actor_entropy": 0.9383382797241211, "alpha_loss": 0.15456993877887726, "alpha_value": 0.34827589634588985, "duration": 1.5593280792236328, "info_normalized_performance_mean": 0.9023376703262329, "info_normalized_performance_final": 0.9918830990791321, "info_performance_mean": 0.9023376703262329, "info_performance_final": 0.9918830990791321, "step": 1046000}
{"episode_reward": 1804.6753246753235, "episode": 10461.0, "batch_reward": 12.805012702941895, "critic_loss": 179.3639678955078, "actor_loss": -1687.6474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.7976694107055664, "alpha_loss": 0.08658207952976227, "alpha_value": 0.34546463236378955, "duration": 1.653057336807251, "info_normalized_performance_mean": 0.42007410526275635, "info_normalized_performance_final": 0.4624655544757843, "info_performance_mean": 0.42007410526275635, "info_performance_final": 0.4624655544757843, "step": 1046500}
{"episode_reward": 840.1480716253428, "episode": 10466.0, "batch_reward": 12.09707260131836, "critic_loss": 248.732177734375, "actor_loss": -1686.976318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.6239825487136841, "alpha_loss": -0.1671440601348877, "alpha_value": 0.34329084047628206, "duration": 1.5891828536987305, "info_normalized_performance_mean": 0.9277384877204895, "info_normalized_performance_final": 0.9973856210708618, "info_performance_mean": 0.9277384877204895, "info_performance_final": 0.9973856210708618, "step": 1047000}
{"episode_reward": 1855.4771241830044, "episode": 10471.0, "batch_reward": 13.191049575805664, "critic_loss": 970.4827880859375, "actor_loss": -1695.5018310546875, "actor_target_entropy": -3.0, "actor_entropy": 0.5341304540634155, "alpha_loss": 0.0022964030504226685, "alpha_value": 0.34253004164874873, "duration": 1.4679152965545654, "info_normalized_performance_mean": 0.5948789119720459, "info_normalized_performance_final": 0.6383928656578064, "info_performance_mean": 0.5948789119720459, "info_performance_final": 0.6383928656578064, "step": 1047500}
{"episode_reward": 1189.7576530612232, "episode": 10476.0, "batch_reward": 12.444770812988281, "critic_loss": 270.70709228515625, "actor_loss": -1657.7601318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.45489057898521423, "alpha_loss": 0.05385810509324074, "alpha_value": 0.3428189693662196, "duration": 1.5405364036560059, "info_normalized_performance_mean": 0.7275393605232239, "info_normalized_performance_final": 0.7986656427383423, "info_performance_mean": 0.7275393605232239, "info_performance_final": 0.7986656427383423, "step": 1048000}
{"episode_reward": 1455.078492935634, "episode": 10481.0, "batch_reward": 12.234500885009766, "critic_loss": 721.458740234375, "actor_loss": -1671.830322265625, "actor_target_entropy": -3.0, "actor_entropy": 0.42381736636161804, "alpha_loss": -0.036252837628126144, "alpha_value": 0.34046853130295945, "duration": 1.549393653869629, "info_normalized_performance_mean": 0.6207452416419983, "info_normalized_performance_final": 0.6658653616905212, "info_performance_mean": 0.6207452416419983, "info_performance_final": 0.6658653616905212, "step": 1048500}
{"episode_reward": 1241.4903846153848, "episode": 10486.0, "batch_reward": 12.072145462036133, "critic_loss": 298.3958740234375, "actor_loss": -1700.8389892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6696642637252808, "alpha_loss": -0.19925449788570404, "alpha_value": 0.338296757592264, "duration": 1.6406011581420898, "info_normalized_performance_mean": 0.6695371866226196, "info_normalized_performance_final": 0.7189153432846069, "info_performance_mean": 0.6695371866226196, "info_performance_final": 0.7189153432846069, "step": 1049000}
{"episode_reward": 1339.0740740740716, "episode": 10491.0, "batch_reward": 12.468427658081055, "critic_loss": 470.8030090332031, "actor_loss": -1654.925048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9413067102432251, "alpha_loss": 0.00025020167231559753, "alpha_value": 0.3374480949711594, "duration": 1.6135594844818115, "info_normalized_performance_mean": 0.4678332805633545, "info_normalized_performance_final": 0.5214285850524902, "info_performance_mean": 0.4678332805633545, "info_performance_final": 0.5214285850524902, "step": 1049500}
{"episode_reward": 935.6666666666675, "episode": 10496.0, "batch_reward": 13.41840934753418, "critic_loss": 367.11602783203125, "actor_loss": -1693.24560546875, "actor_target_entropy": -3.0, "actor_entropy": 0.2905026972293854, "alpha_loss": 0.09882806241512299, "alpha_value": 0.33583960589182843, "step": 1050000}
{"duration": 19.57666778564453, "info_normalized_performance_mean": 0.7026786804199219, "info_normalized_performance_final": 0.7490079402923584, "info_performance_mean": 0.7026786804199219, "info_performance_final": 0.7490079402923584, "step": 1050000}
{"episode_reward": 1405.3571428571427, "episode": 10501.0, "batch_reward": 13.346717834472656, "critic_loss": 137.75779724121094, "actor_loss": -1709.1376953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7106633186340332, "alpha_loss": 0.08599776029586792, "alpha_value": 0.33643623793089233, "duration": 1.4442405700683594, "info_normalized_performance_mean": 0.774678647518158, "info_normalized_performance_final": 0.8321428298950195, "info_performance_mean": 0.774678647518158, "info_performance_final": 0.8321428298950195, "step": 1050500}
{"episode_reward": 1549.3571428571413, "episode": 10506.0, "batch_reward": 11.790882110595703, "critic_loss": 373.5183410644531, "actor_loss": -1649.003173828125, "actor_target_entropy": -3.0, "actor_entropy": 0.6526681184768677, "alpha_loss": -0.043629974126815796, "alpha_value": 0.33581459836520566, "duration": 1.6033716201782227, "info_normalized_performance_mean": 0.889113187789917, "info_normalized_performance_final": 0.955656111240387, "info_performance_mean": 0.889113187789917, "info_performance_final": 0.955656111240387, "step": 1051000}
{"episode_reward": 1778.2262443438897, "episode": 10511.0, "batch_reward": 12.39271354675293, "critic_loss": 264.468017578125, "actor_loss": -1656.835205078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8759781122207642, "alpha_loss": 0.24705182015895844, "alpha_value": 0.3346134154621948, "duration": 1.6302862167358398, "info_normalized_performance_mean": 0.8509295582771301, "info_normalized_performance_final": 0.9164705872535706, "info_performance_mean": 0.8509295582771301, "info_performance_final": 0.9164705872535706, "step": 1051500}
{"episode_reward": 1701.85882352941, "episode": 10516.0, "batch_reward": 12.560976028442383, "critic_loss": 251.60084533691406, "actor_loss": -1624.330810546875, "actor_target_entropy": -3.0, "actor_entropy": 0.5278418064117432, "alpha_loss": -0.000914156436920166, "alpha_value": 0.3341004577727612, "duration": 1.5691196918487549, "info_normalized_performance_mean": 0.7803844213485718, "info_normalized_performance_final": 0.8571428656578064, "info_performance_mean": 0.7803844213485718, "info_performance_final": 0.8571428656578064, "step": 1052000}
{"episode_reward": 1560.7692307692291, "episode": 10521.0, "batch_reward": 13.381239891052246, "critic_loss": 191.61807250976562, "actor_loss": -1749.8984375, "actor_target_entropy": -3.0, "actor_entropy": 0.5537303686141968, "alpha_loss": 0.155003160238266, "alpha_value": 0.3322311619240402, "duration": 1.5323359966278076, "info_normalized_performance_mean": 0.595781147480011, "info_normalized_performance_final": 0.6488281488418579, "info_performance_mean": 0.595781147480011, "info_performance_final": 0.6488281488418579, "step": 1052500}
{"episode_reward": 1191.5625, "episode": 10526.0, "batch_reward": 13.013057708740234, "critic_loss": 168.70755004882812, "actor_loss": -1694.845458984375, "actor_target_entropy": -3.0, "actor_entropy": 0.7555303573608398, "alpha_loss": 0.010444104671478271, "alpha_value": 0.3300972933223354, "duration": 1.609957218170166, "info_normalized_performance_mean": 0.6080808043479919, "info_normalized_performance_final": 0.6507936716079712, "info_performance_mean": 0.6080808043479919, "info_performance_final": 0.6507936716079712, "step": 1053000}
{"episode_reward": 1216.161616161616, "episode": 10531.0, "batch_reward": 13.043756484985352, "critic_loss": 336.09246826171875, "actor_loss": -1692.024169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.4974404573440552, "alpha_loss": 0.03380797430872917, "alpha_value": 0.32850903817170873, "duration": 1.6457421779632568, "info_normalized_performance_mean": 0.8298197984695435, "info_normalized_performance_final": 0.9184704422950745, "info_performance_mean": 0.8298197984695435, "info_performance_final": 0.9184704422950745, "step": 1053500}
{"episode_reward": 1659.6392496392482, "episode": 10536.0, "batch_reward": 12.277687072753906, "critic_loss": 387.733642578125, "actor_loss": -1637.403564453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5635315179824829, "alpha_loss": -0.02514297142624855, "alpha_value": 0.32871066133796156, "duration": 1.5680019855499268, "info_normalized_performance_mean": 0.8604168891906738, "info_normalized_performance_final": 0.925000011920929, "info_performance_mean": 0.8604168891906738, "info_performance_final": 0.925000011920929, "step": 1054000}
{"episode_reward": 1720.8333333333335, "episode": 10541.0, "batch_reward": 13.204345703125, "critic_loss": 140.4906768798828, "actor_loss": -1729.372314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6974470615386963, "alpha_loss": -0.15308621525764465, "alpha_value": 0.3284229676981454, "duration": 1.5224456787109375, "info_normalized_performance_mean": 0.8550670146942139, "info_normalized_performance_final": 0.921875, "info_performance_mean": 0.8550670146942139, "info_performance_final": 0.921875, "step": 1054500}
{"episode_reward": 1710.1339285714284, "episode": 10546.0, "batch_reward": 12.41476058959961, "critic_loss": 681.665771484375, "actor_loss": -1691.879638671875, "actor_target_entropy": -3.0, "actor_entropy": 1.013900637626648, "alpha_loss": -0.009920548647642136, "alpha_value": 0.32909138371875946, "duration": 1.57631516456604, "info_normalized_performance_mean": 0.5480313897132874, "info_normalized_performance_final": 0.6112489700317383, "info_performance_mean": 0.5480313897132874, "info_performance_final": 0.6112489700317383, "step": 1055000}
{"episode_reward": 1096.0628618693129, "episode": 10551.0, "batch_reward": 12.611431121826172, "critic_loss": 228.83602905273438, "actor_loss": -1718.066162109375, "actor_target_entropy": -3.0, "actor_entropy": 0.5989158153533936, "alpha_loss": -0.14675858616828918, "alpha_value": 0.32885870096523895, "duration": 1.561800241470337, "info_normalized_performance_mean": 0.43932098150253296, "info_normalized_performance_final": 0.48288440704345703, "info_performance_mean": 0.43932098150253296, "info_performance_final": 0.48288440704345703, "step": 1055500}
{"episode_reward": 878.6419753086429, "episode": 10556.0, "batch_reward": 12.832459449768066, "critic_loss": 178.52987670898438, "actor_loss": -1691.899658203125, "actor_target_entropy": -3.0, "actor_entropy": 0.7080574631690979, "alpha_loss": 0.0950811505317688, "alpha_value": 0.3258192335222694, "duration": 1.48317551612854, "info_normalized_performance_mean": 0.6249558925628662, "info_normalized_performance_final": 0.6786616444587708, "info_performance_mean": 0.6249558925628662, "info_performance_final": 0.6786616444587708, "step": 1056000}
{"episode_reward": 1249.9116161616168, "episode": 10561.0, "batch_reward": 12.724048614501953, "critic_loss": 196.98037719726562, "actor_loss": -1679.421875, "actor_target_entropy": -3.0, "actor_entropy": 0.46183234453201294, "alpha_loss": 0.11399619281291962, "alpha_value": 0.32507704276217536, "duration": 1.5018606185913086, "info_normalized_performance_mean": 0.554030179977417, "info_normalized_performance_final": 0.6093189716339111, "info_performance_mean": 0.554030179977417, "info_performance_final": 0.6093189716339111, "step": 1056500}
{"episode_reward": 1108.060533651932, "episode": 10566.0, "batch_reward": 12.285024642944336, "critic_loss": 335.9718017578125, "actor_loss": -1692.588623046875, "actor_target_entropy": -3.0, "actor_entropy": 0.48808056116104126, "alpha_loss": -0.04081141948699951, "alpha_value": 0.3240672948762435, "duration": 1.522627353668213, "info_normalized_performance_mean": 0.7679999470710754, "info_normalized_performance_final": 0.8214285969734192, "info_performance_mean": 0.7679999470710754, "info_performance_final": 0.8214285969734192, "step": 1057000}
{"episode_reward": 1535.9999999999977, "episode": 10571.0, "batch_reward": 11.939650535583496, "critic_loss": 289.1142272949219, "actor_loss": -1669.1287841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.4307329058647156, "alpha_loss": -0.13822248578071594, "alpha_value": 0.32392061839604014, "duration": 1.4614782333374023, "info_normalized_performance_mean": 0.9277142882347107, "info_normalized_performance_final": 0.9964285492897034, "info_performance_mean": 0.9277142882347107, "info_performance_final": 0.9964285492897034, "step": 1057500}
{"episode_reward": 1855.4285714285681, "episode": 10576.0, "batch_reward": 12.34358024597168, "critic_loss": 399.22406005859375, "actor_loss": -1660.59326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6119364500045776, "alpha_loss": 0.045319199562072754, "alpha_value": 0.32278749025831216, "duration": 1.6238081455230713, "info_normalized_performance_mean": 0.6538360714912415, "info_normalized_performance_final": 0.7096560597419739, "info_performance_mean": 0.6538360714912415, "info_performance_final": 0.7096560597419739, "step": 1058000}
{"episode_reward": 1307.6719576719568, "episode": 10581.0, "batch_reward": 11.63845157623291, "critic_loss": 296.4443664550781, "actor_loss": -1594.32958984375, "actor_target_entropy": -3.0, "actor_entropy": 0.6656703352928162, "alpha_loss": -0.04015697166323662, "alpha_value": 0.3226950333373108, "duration": 1.5588080883026123, "info_normalized_performance_mean": 0.7883681654930115, "info_normalized_performance_final": 0.8611111044883728, "info_performance_mean": 0.7883681654930115, "info_performance_final": 0.8611111044883728, "step": 1058500}
{"episode_reward": 1576.7361111111081, "episode": 10586.0, "batch_reward": 12.016606330871582, "critic_loss": 606.140869140625, "actor_loss": -1622.798095703125, "actor_target_entropy": -3.0, "actor_entropy": 0.31234532594680786, "alpha_loss": -0.049633704125881195, "alpha_value": 0.3213110362865806, "duration": 1.494152307510376, "info_normalized_performance_mean": 0.6152334809303284, "info_normalized_performance_final": 0.6602563858032227, "info_performance_mean": 0.6152334809303284, "info_performance_final": 0.6602563858032227, "step": 1059000}
{"episode_reward": 1230.467032967031, "episode": 10591.0, "batch_reward": 12.199995040893555, "critic_loss": 319.53955078125, "actor_loss": -1633.049560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.0214040279388428, "alpha_loss": -0.16501998901367188, "alpha_value": 0.32153144605182166, "duration": 1.5328178405761719, "info_normalized_performance_mean": 0.7120312452316284, "info_normalized_performance_final": 0.77734375, "info_performance_mean": 0.7120312452316284, "info_performance_final": 0.77734375, "step": 1059500}
{"episode_reward": 1424.0625, "episode": 10596.0, "batch_reward": 12.606820106506348, "critic_loss": 215.32138061523438, "actor_loss": -1673.659423828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8042458295822144, "alpha_loss": -0.14692477881908417, "alpha_value": 0.32183661033267813, "step": 1060000}
{"duration": 18.806894063949585, "info_normalized_performance_mean": 0.5093359351158142, "info_normalized_performance_final": 0.5537109375, "info_performance_mean": 0.5093359351158142, "info_performance_final": 0.5537109375, "step": 1060000}
{"episode_reward": 1018.671875, "episode": 10601.0, "batch_reward": 13.144648551940918, "critic_loss": 166.05361938476562, "actor_loss": -1677.3018798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.5437472462654114, "alpha_loss": 0.10804511606693268, "alpha_value": 0.3217197544555434, "duration": 1.5246601104736328, "info_normalized_performance_mean": 0.8058931231498718, "info_normalized_performance_final": 0.8772321343421936, "info_performance_mean": 0.8058931231498718, "info_performance_final": 0.8772321343421936, "step": 1060500}
{"episode_reward": 1611.785714285716, "episode": 10606.0, "batch_reward": 12.750463485717773, "critic_loss": 329.51922607421875, "actor_loss": -1663.8369140625, "actor_target_entropy": -3.0, "actor_entropy": 0.5116353631019592, "alpha_loss": 0.17206749320030212, "alpha_value": 0.319188359859094, "duration": 1.3896121978759766, "info_normalized_performance_mean": 0.257687509059906, "info_normalized_performance_final": 0.2750000059604645, "info_performance_mean": 0.257687509059906, "info_performance_final": 0.2750000059604645, "step": 1061000}
{"episode_reward": 515.375, "episode": 10611.0, "batch_reward": 13.099602699279785, "critic_loss": 380.7348327636719, "actor_loss": -1713.7945556640625, "actor_target_entropy": -3.0, "actor_entropy": 0.3657531142234802, "alpha_loss": -0.06038577854633331, "alpha_value": 0.31929329829591824, "duration": 1.5582094192504883, "info_normalized_performance_mean": 0.8768215775489807, "info_normalized_performance_final": 0.9589285850524902, "info_performance_mean": 0.8768215775489807, "info_performance_final": 0.9589285850524902, "step": 1061500}
{"episode_reward": 1753.6428571428542, "episode": 10616.0, "batch_reward": 12.048065185546875, "critic_loss": 198.2821044921875, "actor_loss": -1638.6025390625, "actor_target_entropy": -3.0, "actor_entropy": 0.3887602388858795, "alpha_loss": -0.16110242903232574, "alpha_value": 0.3189758578679521, "duration": 1.577409029006958, "info_normalized_performance_mean": 0.8568041324615479, "info_normalized_performance_final": 0.9204545617103577, "info_performance_mean": 0.8568041324615479, "info_performance_final": 0.9204545617103577, "step": 1062000}
{"episode_reward": 1713.6079545454563, "episode": 10621.0, "batch_reward": 12.499582290649414, "critic_loss": 172.9354705810547, "actor_loss": -1678.557373046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8580785989761353, "alpha_loss": -0.09461724758148193, "alpha_value": 0.318327312328725, "duration": 1.4521160125732422, "info_normalized_performance_mean": 0.8261308073997498, "info_normalized_performance_final": 0.886904776096344, "info_performance_mean": 0.8261308073997498, "info_performance_final": 0.886904776096344, "step": 1062500}
{"episode_reward": 1652.2619047619014, "episode": 10626.0, "batch_reward": 13.410331726074219, "critic_loss": 276.0845947265625, "actor_loss": -1709.511474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.7577182054519653, "alpha_loss": -0.01883631944656372, "alpha_value": 0.3184692039391781, "duration": 1.5806684494018555, "info_normalized_performance_mean": 0.7967939972877502, "info_normalized_performance_final": 0.8661764860153198, "info_performance_mean": 0.7967939972877502, "info_performance_final": 0.8661764860153198, "step": 1063000}
{"episode_reward": 1593.5882352941167, "episode": 10631.0, "batch_reward": 12.23297119140625, "critic_loss": 229.5963592529297, "actor_loss": -1680.964111328125, "actor_target_entropy": -3.0, "actor_entropy": 0.6143299341201782, "alpha_loss": 0.17371517419815063, "alpha_value": 0.3179528961159563, "duration": 1.5667061805725098, "info_normalized_performance_mean": 0.8833724856376648, "info_normalized_performance_final": 0.9490196108818054, "info_performance_mean": 0.8833724856376648, "info_performance_final": 0.9490196108818054, "step": 1063500}
{"episode_reward": 1766.745098039217, "episode": 10636.0, "batch_reward": 12.722731590270996, "critic_loss": 183.08970642089844, "actor_loss": -1650.351318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.5975937247276306, "alpha_loss": 0.11525881290435791, "alpha_value": 0.316126390950744, "duration": 1.5629124641418457, "info_normalized_performance_mean": 0.6711847186088562, "info_normalized_performance_final": 0.7213541865348816, "info_performance_mean": 0.6711847186088562, "info_performance_final": 0.7213541865348816, "step": 1064000}
{"episode_reward": 1342.369791666666, "episode": 10641.0, "batch_reward": 12.679691314697266, "critic_loss": 192.43646240234375, "actor_loss": -1699.041259765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0928435325622559, "alpha_loss": 0.1785120666027069, "alpha_value": 0.3126926470074447, "duration": 1.4365999698638916, "info_normalized_performance_mean": 0.5656632781028748, "info_normalized_performance_final": 0.6071428656578064, "info_performance_mean": 0.5656632781028748, "info_performance_final": 0.6071428656578064, "step": 1064500}
{"episode_reward": 1131.3265306122437, "episode": 10646.0, "batch_reward": 12.847940444946289, "critic_loss": 202.13414001464844, "actor_loss": -1699.7303466796875, "actor_target_entropy": -3.0, "actor_entropy": 0.6531646251678467, "alpha_loss": 0.08457475900650024, "alpha_value": 0.31241681887108297, "duration": 1.5048272609710693, "info_normalized_performance_mean": 0.7101737260818481, "info_normalized_performance_final": 0.776289701461792, "info_performance_mean": 0.7101737260818481, "info_performance_final": 0.776289701461792, "step": 1065000}
{"episode_reward": 1420.3472222222233, "episode": 10651.0, "batch_reward": 11.986146926879883, "critic_loss": 619.4959716796875, "actor_loss": -1684.66162109375, "actor_target_entropy": -3.0, "actor_entropy": 0.3974207043647766, "alpha_loss": 0.007347621023654938, "alpha_value": 0.31408885760298016, "duration": 1.471729040145874, "info_normalized_performance_mean": 0.6109933257102966, "info_normalized_performance_final": 0.6640625, "info_performance_mean": 0.6109933257102966, "info_performance_final": 0.6640625, "step": 1065500}
{"episode_reward": 1221.986607142857, "episode": 10656.0, "batch_reward": 12.217595100402832, "critic_loss": 494.7439270019531, "actor_loss": -1694.1767578125, "actor_target_entropy": -3.0, "actor_entropy": 0.1115778386592865, "alpha_loss": -0.0873803049325943, "alpha_value": 0.314116780972736, "duration": 1.7429530620574951, "info_normalized_performance_mean": 0.5371077060699463, "info_normalized_performance_final": 0.6633089184761047, "info_performance_mean": 0.5371077060699463, "info_performance_final": 0.6633089184761047, "step": 1066000}
{"episode_reward": 1074.2155067155063, "episode": 10661.0, "batch_reward": 12.938867568969727, "critic_loss": 237.48184204101562, "actor_loss": -1738.2650146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.6190921664237976, "alpha_loss": -0.031866539269685745, "alpha_value": 0.3140161987289534, "duration": 1.5521914958953857, "info_normalized_performance_mean": 0.6083399057388306, "info_normalized_performance_final": 0.6627604365348816, "info_performance_mean": 0.6083399057388306, "info_performance_final": 0.6627604365348816, "step": 1066500}
{"episode_reward": 1216.6796875, "episode": 10666.0, "batch_reward": 13.243664741516113, "critic_loss": 404.70538330078125, "actor_loss": -1713.11767578125, "actor_target_entropy": -3.0, "actor_entropy": -0.027832042425870895, "alpha_loss": 0.018713057041168213, "alpha_value": 0.31393123700931097, "duration": 1.6019537448883057, "info_normalized_performance_mean": 0.8777255415916443, "info_normalized_performance_final": 0.9431372284889221, "info_performance_mean": 0.8777255415916443, "info_performance_final": 0.9431372284889221, "step": 1067000}
{"episode_reward": 1755.4509803921535, "episode": 10671.0, "batch_reward": 12.634994506835938, "critic_loss": 479.0068054199219, "actor_loss": -1711.745849609375, "actor_target_entropy": -3.0, "actor_entropy": 0.4015963077545166, "alpha_loss": -0.09475460648536682, "alpha_value": 0.3126678608825971, "duration": 1.5011110305786133, "info_normalized_performance_mean": 0.28009113669395447, "info_normalized_performance_final": 0.3151041567325592, "info_performance_mean": 0.28009113669395447, "info_performance_final": 0.3151041567325592, "step": 1067500}
{"episode_reward": 560.1822916666667, "episode": 10676.0, "batch_reward": 13.001957893371582, "critic_loss": 351.84033203125, "actor_loss": -1741.4384765625, "actor_target_entropy": -3.0, "actor_entropy": 0.35995376110076904, "alpha_loss": 0.08182372152805328, "alpha_value": 0.3147387776369514, "duration": 1.7033183574676514, "info_normalized_performance_mean": 0.2707218825817108, "info_normalized_performance_final": 0.33180707693099976, "info_performance_mean": 0.2707218825817108, "info_performance_final": 0.33180707693099976, "step": 1068000}
{"episode_reward": 541.4438339438337, "episode": 10681.0, "batch_reward": 13.214591026306152, "critic_loss": 264.4055480957031, "actor_loss": -1725.507080078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8075408935546875, "alpha_loss": 0.00320613756775856, "alpha_value": 0.3145778699050442, "duration": 1.5495657920837402, "info_normalized_performance_mean": 0.5075098276138306, "info_normalized_performance_final": 0.5514323115348816, "info_performance_mean": 0.5075098276138306, "info_performance_final": 0.5514323115348816, "step": 1068500}
{"episode_reward": 1015.0195312500014, "episode": 10686.0, "batch_reward": 12.567880630493164, "critic_loss": 144.89601135253906, "actor_loss": -1684.466552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0404125452041626, "alpha_loss": 0.0380258783698082, "alpha_value": 0.31626799324689875, "duration": 1.4921808242797852, "info_normalized_performance_mean": 0.7186607122421265, "info_normalized_performance_final": 0.7714285850524902, "info_performance_mean": 0.7186607122421265, "info_performance_final": 0.7714285850524902, "step": 1069000}
{"episode_reward": 1437.3214285714266, "episode": 10691.0, "batch_reward": 12.37520980834961, "critic_loss": 160.27911376953125, "actor_loss": -1687.906494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8096773624420166, "alpha_loss": -0.10753320157527924, "alpha_value": 0.31897191988992823, "duration": 1.568162202835083, "info_normalized_performance_mean": 0.5702646374702454, "info_normalized_performance_final": 0.6084656119346619, "info_performance_mean": 0.5702646374702454, "info_performance_final": 0.6084656119346619, "step": 1069500}
{"episode_reward": 1140.5291005291022, "episode": 10696.0, "batch_reward": 12.57598876953125, "critic_loss": 294.66839599609375, "actor_loss": -1683.522705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.264032244682312, "alpha_loss": 0.15717895328998566, "alpha_value": 0.3207887530693008, "step": 1070000}
{"duration": 18.889078378677368, "info_normalized_performance_mean": 0.5312630534172058, "info_normalized_performance_final": 0.578125, "info_performance_mean": 0.5312630534172058, "info_performance_final": 0.578125, "step": 1070000}
{"episode_reward": 1062.5260416666665, "episode": 10701.0, "batch_reward": 12.763750076293945, "critic_loss": 318.45501708984375, "actor_loss": -1726.724609375, "actor_target_entropy": -3.0, "actor_entropy": 0.5398147702217102, "alpha_loss": -0.05537916719913483, "alpha_value": 0.3222310296151037, "duration": 1.5482151508331299, "info_normalized_performance_mean": 0.8515200614929199, "info_normalized_performance_final": 0.9160000085830688, "info_performance_mean": 0.8515200614929199, "info_performance_final": 0.9160000085830688, "step": 1070500}
{"episode_reward": 1703.0399999999988, "episode": 10706.0, "batch_reward": 12.649467468261719, "critic_loss": 278.2395935058594, "actor_loss": -1709.19091796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8907075524330139, "alpha_loss": -0.026889726519584656, "alpha_value": 0.32365822047168913, "duration": 1.578636884689331, "info_normalized_performance_mean": 0.6747392416000366, "info_normalized_performance_final": 0.7324262857437134, "info_performance_mean": 0.6747392416000366, "info_performance_final": 0.7324262857437134, "step": 1071000}
{"episode_reward": 1349.4784580498876, "episode": 10711.0, "batch_reward": 12.379703521728516, "critic_loss": 410.35125732421875, "actor_loss": -1666.748779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7454020977020264, "alpha_loss": -0.06628253310918808, "alpha_value": 0.3279517344441641, "duration": 1.624955177307129, "info_normalized_performance_mean": 0.7728751301765442, "info_normalized_performance_final": 0.8305555582046509, "info_performance_mean": 0.7728751301765442, "info_performance_final": 0.8305555582046509, "step": 1071500}
{"episode_reward": 1545.7499999999982, "episode": 10716.0, "batch_reward": 12.005163192749023, "critic_loss": 187.95870971679688, "actor_loss": -1677.944091796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8665319085121155, "alpha_loss": -0.11722692847251892, "alpha_value": 0.3308746191378059, "duration": 1.6296422481536865, "info_normalized_performance_mean": 0.7573032379150391, "info_normalized_performance_final": 0.8135746717453003, "info_performance_mean": 0.7573032379150391, "info_performance_final": 0.8135746717453003, "step": 1072000}
{"episode_reward": 1514.6063348416278, "episode": 10721.0, "batch_reward": 12.238946914672852, "critic_loss": 327.9471740722656, "actor_loss": -1668.43310546875, "actor_target_entropy": -3.0, "actor_entropy": 1.0086358785629272, "alpha_loss": -0.14569760859012604, "alpha_value": 0.3311906908563407, "duration": 1.5723998546600342, "info_normalized_performance_mean": 0.8070393204689026, "info_normalized_performance_final": 0.8686274290084839, "info_performance_mean": 0.8070393204689026, "info_performance_final": 0.8686274290084839, "step": 1072500}
{"episode_reward": 1614.078431372553, "episode": 10726.0, "batch_reward": 12.403787612915039, "critic_loss": 131.7326202392578, "actor_loss": -1680.5369873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.0127660036087036, "alpha_loss": -0.10598174482584, "alpha_value": 0.33269236061917046, "duration": 1.7131502628326416, "info_normalized_performance_mean": 0.5284416675567627, "info_normalized_performance_final": 0.6355311274528503, "info_performance_mean": 0.5284416675567627, "info_performance_final": 0.6355311274528503, "step": 1073000}
{"episode_reward": 1056.8833943833945, "episode": 10731.0, "batch_reward": 13.49995231628418, "critic_loss": 256.20843505859375, "actor_loss": -1739.352783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1917721033096313, "alpha_loss": 0.08711988478899002, "alpha_value": 0.3320635928816736, "duration": 1.6072921752929688, "info_normalized_performance_mean": 0.8398397564888, "info_normalized_performance_final": 0.9049999713897705, "info_performance_mean": 0.8398397564888, "info_performance_final": 0.9049999713897705, "step": 1073500}
{"episode_reward": 1679.6799999999976, "episode": 10736.0, "batch_reward": 12.92181396484375, "critic_loss": 214.28709411621094, "actor_loss": -1728.337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2862958908081055, "alpha_loss": -0.021882720291614532, "alpha_value": 0.33215872218445774, "duration": 1.64705228805542, "info_normalized_performance_mean": 0.6518610119819641, "info_normalized_performance_final": 0.7097222208976746, "info_performance_mean": 0.6518610119819641, "info_performance_final": 0.7097222208976746, "step": 1074000}
{"episode_reward": 1303.722222222221, "episode": 10741.0, "batch_reward": 12.47478199005127, "critic_loss": 277.68438720703125, "actor_loss": -1690.9864501953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9678667187690735, "alpha_loss": -0.017424235120415688, "alpha_value": 0.33032702241892997, "duration": 1.5828235149383545, "info_normalized_performance_mean": 0.4841584265232086, "info_normalized_performance_final": 0.5371428728103638, "info_performance_mean": 0.4841584265232086, "info_performance_final": 0.5371428728103638, "step": 1074500}
{"episode_reward": 968.3168831168824, "episode": 10746.0, "batch_reward": 12.090010643005371, "critic_loss": 278.569580078125, "actor_loss": -1684.9041748046875, "actor_target_entropy": -3.0, "actor_entropy": 0.3735874891281128, "alpha_loss": 0.02227834239602089, "alpha_value": 0.32883949964773607, "duration": 1.6042208671569824, "info_normalized_performance_mean": 0.7173177599906921, "info_normalized_performance_final": 0.7690972089767456, "info_performance_mean": 0.7173177599906921, "info_performance_final": 0.7690972089767456, "step": 1075000}
{"episode_reward": 1434.6354166666647, "episode": 10751.0, "batch_reward": 12.5282621383667, "critic_loss": 294.4160461425781, "actor_loss": -1709.2169189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6812077164649963, "alpha_loss": 0.10546958446502686, "alpha_value": 0.32593721220905114, "duration": 1.518552303314209, "info_normalized_performance_mean": 0.520969569683075, "info_normalized_performance_final": 0.5667613744735718, "info_performance_mean": 0.520969569683075, "info_performance_final": 0.5667613744735718, "step": 1075500}
{"episode_reward": 1041.9389204545441, "episode": 10756.0, "batch_reward": 12.25035285949707, "critic_loss": 216.93373107910156, "actor_loss": -1668.474365234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8184049725532532, "alpha_loss": 0.22887173295021057, "alpha_value": 0.3267511151163918, "duration": 1.6402206420898438, "info_normalized_performance_mean": 0.8320347666740417, "info_normalized_performance_final": 0.893217921257019, "info_performance_mean": 0.8320347666740417, "info_performance_final": 0.893217921257019, "step": 1076000}
{"episode_reward": 1664.0692640692616, "episode": 10761.0, "batch_reward": 13.430492401123047, "critic_loss": 138.39898681640625, "actor_loss": -1712.00732421875, "actor_target_entropy": -3.0, "actor_entropy": 0.7363094091415405, "alpha_loss": 0.2890213429927826, "alpha_value": 0.32565786501244887, "duration": 1.4484899044036865, "info_normalized_performance_mean": 0.6553571820259094, "info_normalized_performance_final": 0.6964285969734192, "info_performance_mean": 0.6553571820259094, "info_performance_final": 0.6964285969734192, "step": 1076500}
{"episode_reward": 1310.7142857142844, "episode": 10766.0, "batch_reward": 12.279011726379395, "critic_loss": 302.8221130371094, "actor_loss": -1705.80029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.5098278522491455, "alpha_loss": 0.01727570965886116, "alpha_value": 0.3245646324981916, "duration": 1.5544607639312744, "info_normalized_performance_mean": 0.3561111390590668, "info_normalized_performance_final": 0.38029101490974426, "info_performance_mean": 0.3561111390590668, "info_performance_final": 0.38029101490974426, "step": 1077000}
{"episode_reward": 712.2222222222233, "episode": 10771.0, "batch_reward": 12.731148719787598, "critic_loss": 665.9190673828125, "actor_loss": -1698.0419921875, "actor_target_entropy": -3.0, "actor_entropy": 0.611682653427124, "alpha_loss": 0.06438669562339783, "alpha_value": 0.32453204694007226, "duration": 1.5081024169921875, "info_normalized_performance_mean": 0.6252560615539551, "info_normalized_performance_final": 0.6783854365348816, "info_performance_mean": 0.6252560615539551, "info_performance_final": 0.6783854365348816, "step": 1077500}
{"episode_reward": 1250.5121527777776, "episode": 10776.0, "batch_reward": 12.772443771362305, "critic_loss": 504.6329345703125, "actor_loss": -1698.0498046875, "actor_target_entropy": -3.0, "actor_entropy": 0.33435946702957153, "alpha_loss": -0.16520248353481293, "alpha_value": 0.3239119140222897, "duration": 1.5082921981811523, "info_normalized_performance_mean": 0.7837399840354919, "info_normalized_performance_final": 0.8497023582458496, "info_performance_mean": 0.7837399840354919, "info_performance_final": 0.8497023582458496, "step": 1078000}
{"episode_reward": 1567.4801587301602, "episode": 10781.0, "batch_reward": 13.080728530883789, "critic_loss": 315.3382873535156, "actor_loss": -1738.9078369140625, "actor_target_entropy": -3.0, "actor_entropy": 0.3526683449745178, "alpha_loss": -0.051924750208854675, "alpha_value": 0.3258200210977588, "duration": 1.6251349449157715, "info_normalized_performance_mean": 0.7434446215629578, "info_normalized_performance_final": 0.7986111044883728, "info_performance_mean": 0.7434446215629578, "info_performance_final": 0.7986111044883728, "step": 1078500}
{"episode_reward": 1486.888888888886, "episode": 10786.0, "batch_reward": 12.505836486816406, "critic_loss": 164.54727172851562, "actor_loss": -1694.366455078125, "actor_target_entropy": -3.0, "actor_entropy": 0.5110140442848206, "alpha_loss": 0.07528368383646011, "alpha_value": 0.3276668129129333, "duration": 1.6242434978485107, "info_normalized_performance_mean": 0.5304854512214661, "info_normalized_performance_final": 0.5829166769981384, "info_performance_mean": 0.5304854512214661, "info_performance_final": 0.5829166769981384, "step": 1079000}
{"episode_reward": 1060.9708333333324, "episode": 10791.0, "batch_reward": 12.500360488891602, "critic_loss": 182.61614990234375, "actor_loss": -1690.787841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.5721485614776611, "alpha_loss": 0.024796754121780396, "alpha_value": 0.32987675800057104, "duration": 1.534794807434082, "info_normalized_performance_mean": 0.9213799238204956, "info_normalized_performance_final": 0.9983766078948975, "info_performance_mean": 0.9213799238204956, "info_performance_final": 0.9983766078948975, "step": 1079500}
{"episode_reward": 1842.75974025974, "episode": 10796.0, "batch_reward": 13.185951232910156, "critic_loss": 243.7765350341797, "actor_loss": -1716.1875, "actor_target_entropy": -3.0, "actor_entropy": 0.5022955536842346, "alpha_loss": 0.05978638306260109, "alpha_value": 0.3323892731704904, "step": 1080000}
{"duration": 19.115877628326416, "info_normalized_performance_mean": 0.817474901676178, "info_normalized_performance_final": 0.8799999952316284, "info_performance_mean": 0.817474901676178, "info_performance_final": 0.8799999952316284, "step": 1080000}
{"episode_reward": 1634.9499999999978, "episode": 10801.0, "batch_reward": 12.72227954864502, "critic_loss": 240.1952362060547, "actor_loss": -1732.511962890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7232498526573181, "alpha_loss": -0.13392889499664307, "alpha_value": 0.3350028704754278, "duration": 1.4747188091278076, "info_normalized_performance_mean": 0.4819234609603882, "info_normalized_performance_final": 0.5255101919174194, "info_performance_mean": 0.4819234609603882, "info_performance_final": 0.5255101919174194, "step": 1080500}
{"episode_reward": 963.84693877551, "episode": 10806.0, "batch_reward": 12.697807312011719, "critic_loss": 146.0292205810547, "actor_loss": -1706.9708251953125, "actor_target_entropy": -3.0, "actor_entropy": 0.4997851252555847, "alpha_loss": -0.0658072829246521, "alpha_value": 0.33524592701835326, "duration": 1.6398298740386963, "info_normalized_performance_mean": 0.7256150841712952, "info_normalized_performance_final": 0.8009259104728699, "info_performance_mean": 0.7256150841712952, "info_performance_final": 0.8009259104728699, "step": 1081000}
{"episode_reward": 1451.2301587301567, "episode": 10811.0, "batch_reward": 12.52467155456543, "critic_loss": 835.0745849609375, "actor_loss": -1715.374267578125, "actor_target_entropy": -3.0, "actor_entropy": 0.759164571762085, "alpha_loss": -0.05597664788365364, "alpha_value": 0.3376481398852899, "duration": 1.4289138317108154, "info_normalized_performance_mean": 0.3118891417980194, "info_normalized_performance_final": 0.3423295319080353, "info_performance_mean": 0.3118891417980194, "info_performance_final": 0.3423295319080353, "step": 1081500}
{"episode_reward": 623.7784090909095, "episode": 10816.0, "batch_reward": 13.515748977661133, "critic_loss": 332.5701599121094, "actor_loss": -1768.705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0583622455596924, "alpha_loss": 0.011298149824142456, "alpha_value": 0.3401792259198914, "duration": 1.7040283679962158, "info_normalized_performance_mean": 0.30112841725349426, "info_normalized_performance_final": 0.33260995149612427, "info_performance_mean": 0.30112841725349426, "info_performance_final": 0.33260995149612427, "step": 1082000}
{"episode_reward": 602.2569444444439, "episode": 10821.0, "batch_reward": 12.493732452392578, "critic_loss": 538.8056640625, "actor_loss": -1679.4930419921875, "actor_target_entropy": -3.0, "actor_entropy": 0.812471866607666, "alpha_loss": -0.08594056963920593, "alpha_value": 0.3415918413972105, "duration": 1.501772403717041, "info_normalized_performance_mean": 0.6619021892547607, "info_normalized_performance_final": 0.717578113079071, "info_performance_mean": 0.6619021892547607, "info_performance_final": 0.717578113079071, "step": 1082500}
{"episode_reward": 1323.8046875, "episode": 10826.0, "batch_reward": 12.694219589233398, "critic_loss": 320.8915100097656, "actor_loss": -1716.2943115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.6055773496627808, "alpha_loss": -0.025207823142409325, "alpha_value": 0.3433331359084219, "duration": 1.5530633926391602, "info_normalized_performance_mean": 0.3545762598514557, "info_normalized_performance_final": 0.38860830664634705, "info_performance_mean": 0.3545762598514557, "info_performance_final": 0.38860830664634705, "step": 1083000}
{"episode_reward": 709.1526374859701, "episode": 10831.0, "batch_reward": 12.047382354736328, "critic_loss": 168.35330200195312, "actor_loss": -1686.133056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2983298301696777, "alpha_loss": -0.21140509843826294, "alpha_value": 0.3421759686556221, "duration": 1.3521158695220947, "info_normalized_performance_mean": 0.49459823966026306, "info_normalized_performance_final": 0.53125, "info_performance_mean": 0.49459823966026306, "info_performance_final": 0.53125, "step": 1083500}
{"episode_reward": 989.1964285714286, "episode": 10836.0, "batch_reward": 13.13603401184082, "critic_loss": 700.6139526367188, "actor_loss": -1731.642822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.1472662687301636, "alpha_loss": 0.3237508535385132, "alpha_value": 0.3382200986968225, "duration": 1.5117461681365967, "info_normalized_performance_mean": 0.6286812424659729, "info_normalized_performance_final": 0.6950549483299255, "info_performance_mean": 0.6286812424659729, "info_performance_final": 0.6950549483299255, "step": 1084000}
{"episode_reward": 1257.3626373626375, "episode": 10841.0, "batch_reward": 12.287262916564941, "critic_loss": 325.2415771484375, "actor_loss": -1703.8817138671875, "actor_target_entropy": -3.0, "actor_entropy": 0.6682434678077698, "alpha_loss": 0.10028889775276184, "alpha_value": 0.33519581575551205, "duration": 1.6406903266906738, "info_normalized_performance_mean": 0.710256814956665, "info_normalized_performance_final": 0.7652778029441833, "info_performance_mean": 0.710256814956665, "info_performance_final": 0.7652778029441833, "step": 1084500}
{"episode_reward": 1420.5138888888907, "episode": 10846.0, "batch_reward": 12.770317077636719, "critic_loss": 285.4685974121094, "actor_loss": -1725.083740234375, "actor_target_entropy": -3.0, "actor_entropy": 0.9978853464126587, "alpha_loss": 0.15885254740715027, "alpha_value": 0.33200397811518445, "duration": 1.6249425411224365, "info_normalized_performance_mean": 0.8302244544029236, "info_normalized_performance_final": 0.8919786214828491, "info_performance_mean": 0.8302244544029236, "info_performance_final": 0.8919786214828491, "step": 1085000}
{"episode_reward": 1660.4491978609603, "episode": 10851.0, "batch_reward": 12.85670280456543, "critic_loss": 231.66552734375, "actor_loss": -1754.3336181640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8617215156555176, "alpha_loss": 0.1027664840221405, "alpha_value": 0.32814873696976166, "duration": 1.5984551906585693, "info_normalized_performance_mean": 0.6520636081695557, "info_normalized_performance_final": 0.7083333134651184, "info_performance_mean": 0.6520636081695557, "info_performance_final": 0.7083333134651184, "step": 1085500}
{"episode_reward": 1304.1269841269846, "episode": 10856.0, "batch_reward": 12.216496467590332, "critic_loss": 219.21218872070312, "actor_loss": -1715.113037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1684125661849976, "alpha_loss": -0.060510843992233276, "alpha_value": 0.3247091142565748, "duration": 1.5301647186279297, "info_normalized_performance_mean": 0.4736398756504059, "info_normalized_performance_final": 0.5248579382896423, "info_performance_mean": 0.4736398756504059, "info_performance_final": 0.5248579382896423, "step": 1086000}
{"episode_reward": 947.2798295454553, "episode": 10861.0, "batch_reward": 12.5944242477417, "critic_loss": 112.48133087158203, "actor_loss": -1682.5592041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.6488537788391113, "alpha_loss": 0.15122003853321075, "alpha_value": 0.3220065255064202, "duration": 1.596961259841919, "info_normalized_performance_mean": 0.7356059551239014, "info_normalized_performance_final": 0.798701286315918, "info_performance_mean": 0.7356059551239014, "info_performance_final": 0.798701286315918, "step": 1086500}
{"episode_reward": 1471.2121212121224, "episode": 10866.0, "batch_reward": 13.585153579711914, "critic_loss": 286.1121520996094, "actor_loss": -1752.0467529296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9742310047149658, "alpha_loss": 0.018284335732460022, "alpha_value": 0.31936367328157395, "duration": 1.6864702701568604, "info_normalized_performance_mean": 0.3959812819957733, "info_normalized_performance_final": 0.4452075660228729, "info_performance_mean": 0.3959812819957733, "info_performance_final": 0.4452075660228729, "step": 1087000}
{"episode_reward": 791.9627594627597, "episode": 10871.0, "batch_reward": 12.002950668334961, "critic_loss": 423.50775146484375, "actor_loss": -1719.5372314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.3400862216949463, "alpha_loss": -0.10312049835920334, "alpha_value": 0.3185884047579818, "duration": 1.4904670715332031, "info_normalized_performance_mean": 0.6860774159431458, "info_normalized_performance_final": 0.7452380657196045, "info_performance_mean": 0.6860774159431458, "info_performance_final": 0.7452380657196045, "step": 1087500}
{"episode_reward": 1372.1547619047633, "episode": 10876.0, "batch_reward": 12.581293106079102, "critic_loss": 389.20751953125, "actor_loss": -1737.750244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8369240760803223, "alpha_loss": 0.10153980553150177, "alpha_value": 0.31574815004463536, "duration": 1.614307165145874, "info_normalized_performance_mean": 0.8856860399246216, "info_normalized_performance_final": 0.9519608020782471, "info_performance_mean": 0.8856860399246216, "info_performance_final": 0.9519608020782471, "step": 1088000}
{"episode_reward": 1771.3725490196057, "episode": 10881.0, "batch_reward": 12.189140319824219, "critic_loss": 174.44818115234375, "actor_loss": -1685.707763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.5488165020942688, "alpha_loss": -0.046387121081352234, "alpha_value": 0.31429373287924467, "duration": 1.6227684020996094, "info_normalized_performance_mean": 0.8220966458320618, "info_normalized_performance_final": 0.8921957612037659, "info_performance_mean": 0.8220966458320618, "info_performance_final": 0.8921957612037659, "step": 1088500}
{"episode_reward": 1644.1931216931216, "episode": 10886.0, "batch_reward": 11.94041633605957, "critic_loss": 598.6593017578125, "actor_loss": -1655.703125, "actor_target_entropy": -3.0, "actor_entropy": 0.927973210811615, "alpha_loss": 0.018868938088417053, "alpha_value": 0.3101429108691813, "duration": 1.4927051067352295, "info_normalized_performance_mean": 0.8001370429992676, "info_normalized_performance_final": 0.8702380657196045, "info_performance_mean": 0.8001370429992676, "info_performance_final": 0.8702380657196045, "step": 1089000}
{"episode_reward": 1600.273809523811, "episode": 10891.0, "batch_reward": 12.841963768005371, "critic_loss": 532.6346435546875, "actor_loss": -1791.6025390625, "actor_target_entropy": -3.0, "actor_entropy": 0.38091224431991577, "alpha_loss": -0.060675665736198425, "alpha_value": 0.30796422279661284, "duration": 1.6330671310424805, "info_normalized_performance_mean": 0.7682846188545227, "info_normalized_performance_final": 0.8277778029441833, "info_performance_mean": 0.7682846188545227, "info_performance_final": 0.8277778029441833, "step": 1089500}
{"episode_reward": 1536.5694444444468, "episode": 10896.0, "batch_reward": 12.630998611450195, "critic_loss": 713.0296630859375, "actor_loss": -1751.7518310546875, "actor_target_entropy": -3.0, "actor_entropy": 0.70084547996521, "alpha_loss": -0.07024993002414703, "alpha_value": 0.3041096491150444, "step": 1090000}
{"duration": 18.985044240951538, "info_normalized_performance_mean": 0.44752922654151917, "info_normalized_performance_final": 0.49242424964904785, "info_performance_mean": 0.44752922654151917, "info_performance_final": 0.49242424964904785, "step": 1090000}
{"episode_reward": 895.0585399449051, "episode": 10901.0, "batch_reward": 12.930612564086914, "critic_loss": 205.0773162841797, "actor_loss": -1726.305908203125, "actor_target_entropy": -3.0, "actor_entropy": 0.8399947881698608, "alpha_loss": 0.20780423283576965, "alpha_value": 0.29740024967825757, "duration": 1.587536096572876, "info_normalized_performance_mean": 0.8325750827789307, "info_normalized_performance_final": 0.8987500071525574, "info_performance_mean": 0.8325750827789307, "info_performance_final": 0.8987500071525574, "step": 1090500}
{"episode_reward": 1665.1499999999976, "episode": 10906.0, "batch_reward": 12.449591636657715, "critic_loss": 422.1825866699219, "actor_loss": -1678.430419921875, "actor_target_entropy": -3.0, "actor_entropy": 0.616141676902771, "alpha_loss": 0.05836419761180878, "alpha_value": 0.2917672164500901, "duration": 1.5627853870391846, "info_normalized_performance_mean": 0.8102374076843262, "info_normalized_performance_final": 0.8712499737739563, "info_performance_mean": 0.8102374076843262, "info_performance_final": 0.8712499737739563, "step": 1091000}
{"episode_reward": 1620.4749999999974, "episode": 10911.0, "batch_reward": 12.322896957397461, "critic_loss": 432.77044677734375, "actor_loss": -1678.175537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.07507511973381042, "alpha_loss": 0.13559840619564056, "alpha_value": 0.28610193693845004, "duration": 1.4729835987091064, "info_normalized_performance_mean": 0.535714328289032, "info_normalized_performance_final": 0.5753968358039856, "info_performance_mean": 0.535714328289032, "info_performance_final": 0.5753968358039856, "step": 1091500}
{"episode_reward": 1071.428571428571, "episode": 10916.0, "batch_reward": 12.941991806030273, "critic_loss": 222.8861846923828, "actor_loss": -1702.02880859375, "actor_target_entropy": -3.0, "actor_entropy": 0.7756208181381226, "alpha_loss": 0.124318428337574, "alpha_value": 0.2810802438660685, "duration": 1.4977912902832031, "info_normalized_performance_mean": 0.4595111012458801, "info_normalized_performance_final": 0.4919217824935913, "info_performance_mean": 0.4595111012458801, "info_performance_final": 0.4919217824935913, "step": 1092000}
{"episode_reward": 919.0221088435362, "episode": 10921.0, "batch_reward": 13.026074409484863, "critic_loss": 387.194580078125, "actor_loss": -1691.4739990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4081790447235107, "alpha_loss": 0.14136254787445068, "alpha_value": 0.2762360593321992, "duration": 1.401531457901001, "info_normalized_performance_mean": 0.7454687356948853, "info_normalized_performance_final": 0.80078125, "info_performance_mean": 0.7454687356948853, "info_performance_final": 0.80078125, "step": 1092500}
{"episode_reward": 1490.9375, "episode": 10926.0, "batch_reward": 12.984253883361816, "critic_loss": 1016.9290161132812, "actor_loss": -1699.231689453125, "actor_target_entropy": -3.0, "actor_entropy": 0.790377140045166, "alpha_loss": 0.1812656968832016, "alpha_value": 0.27250635909691784, "duration": 1.6385724544525146, "info_normalized_performance_mean": 0.7885475158691406, "info_normalized_performance_final": 0.858730137348175, "info_performance_mean": 0.7885475158691406, "info_performance_final": 0.858730137348175, "step": 1093000}
{"episode_reward": 1577.0952380952358, "episode": 10931.0, "batch_reward": 13.093900680541992, "critic_loss": 215.95260620117188, "actor_loss": -1661.4005126953125, "actor_target_entropy": -3.0, "actor_entropy": 0.8050180673599243, "alpha_loss": -0.04054773226380348, "alpha_value": 0.26884973057308903, "duration": 1.5418763160705566, "info_normalized_performance_mean": 0.5407865047454834, "info_normalized_performance_final": 0.6050823926925659, "info_performance_mean": 0.5407865047454834, "info_performance_final": 0.6050823926925659, "step": 1093500}
{"episode_reward": 1081.5728021978016, "episode": 10936.0, "batch_reward": 12.636384963989258, "critic_loss": 468.55059814453125, "actor_loss": -1700.83447265625, "actor_target_entropy": -3.0, "actor_entropy": 0.7492778897285461, "alpha_loss": -0.005590155720710754, "alpha_value": 0.2678405467532665, "duration": 1.660060167312622, "info_normalized_performance_mean": 0.3094993531703949, "info_normalized_performance_final": 0.3758741319179535, "info_performance_mean": 0.3094993531703949, "info_performance_final": 0.3758741319179535, "step": 1094000}
{"episode_reward": 618.9987285441831, "episode": 10941.0, "batch_reward": 12.929985046386719, "critic_loss": 420.3725280761719, "actor_loss": -1690.6868896484375, "actor_target_entropy": -3.0, "actor_entropy": 0.5394620895385742, "alpha_loss": 0.07771266251802444, "alpha_value": 0.264466313412589, "duration": 1.4951817989349365, "info_normalized_performance_mean": 0.7091772556304932, "info_normalized_performance_final": 0.7640306353569031, "info_performance_mean": 0.7091772556304932, "info_performance_final": 0.7640306353569031, "step": 1094500}
{"episode_reward": 1418.354591836737, "episode": 10946.0, "batch_reward": 12.66000747680664, "critic_loss": 193.72137451171875, "actor_loss": -1673.004150390625, "actor_target_entropy": -3.0, "actor_entropy": 0.39119523763656616, "alpha_loss": 0.04089716076850891, "alpha_value": 0.26444904622544907, "duration": 1.5769081115722656, "info_normalized_performance_mean": 0.5000447034835815, "info_normalized_performance_final": 0.6674107313156128, "info_performance_mean": 0.5000447034835815, "info_performance_final": 0.6674107313156128, "step": 1095000}
{"episode_reward": 1000.0892857142866, "episode": 10951.0, "batch_reward": 12.091835975646973, "critic_loss": 271.9193115234375, "actor_loss": -1674.822998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.6337076425552368, "alpha_loss": -0.007198077626526356, "alpha_value": 0.2626816321994486, "duration": 1.6943552494049072, "info_normalized_performance_mean": 0.31586533784866333, "info_normalized_performance_final": 0.35470086336135864, "info_performance_mean": 0.31586533784866333, "info_performance_final": 0.35470086336135864, "step": 1095500}
{"episode_reward": 631.730769230769, "episode": 10956.0, "batch_reward": 12.706232070922852, "critic_loss": 172.2492218017578, "actor_loss": -1675.2938232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.7632805109024048, "alpha_loss": 0.08073623478412628, "alpha_value": 0.2622985208979488, "duration": 1.4149868488311768, "info_normalized_performance_mean": 0.9178572297096252, "info_normalized_performance_final": 0.9857142567634583, "info_performance_mean": 0.9178572297096252, "info_performance_final": 0.9857142567634583, "step": 1096000}
{"episode_reward": 1835.7142857142874, "episode": 10961.0, "batch_reward": 12.517032623291016, "critic_loss": 227.98626708984375, "actor_loss": -1643.268798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.559441328048706, "alpha_loss": -0.0030203573405742645, "alpha_value": 0.26010375188216395, "duration": 1.4990005493164062, "info_normalized_performance_mean": 0.4185866415500641, "info_normalized_performance_final": 0.4634232819080353, "info_performance_mean": 0.4185866415500641, "info_performance_final": 0.4634232819080353, "step": 1096500}
{"episode_reward": 837.173295454545, "episode": 10966.0, "batch_reward": 12.481424331665039, "critic_loss": 283.4920654296875, "actor_loss": -1607.486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.5187804698944092, "alpha_loss": 0.0358235165476799, "alpha_value": 0.2590425786276932, "duration": 1.539668321609497, "info_normalized_performance_mean": 0.8951785564422607, "info_normalized_performance_final": 0.9620535969734192, "info_performance_mean": 0.8951785564422607, "info_performance_final": 0.9620535969734192, "step": 1097000}
{"episode_reward": 1790.3571428571395, "episode": 10971.0, "batch_reward": 13.483905792236328, "critic_loss": 108.87653350830078, "actor_loss": -1629.2669677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8650144338607788, "alpha_loss": 0.23575875163078308, "alpha_value": 0.25780507917858775, "duration": 1.5728240013122559, "info_normalized_performance_mean": 0.8323922753334045, "info_normalized_performance_final": 0.8941176533699036, "info_performance_mean": 0.8323922753334045, "info_performance_final": 0.8941176533699036, "step": 1097500}
{"episode_reward": 1664.7843137254938, "episode": 10976.0, "batch_reward": 12.281761169433594, "critic_loss": 278.42333984375, "actor_loss": -1638.808837890625, "actor_target_entropy": -3.0, "actor_entropy": 0.486272931098938, "alpha_loss": -0.0534537099301815, "alpha_value": 0.25605812318712223, "duration": 1.5977931022644043, "info_normalized_performance_mean": 0.28134778141975403, "info_normalized_performance_final": 0.3584090769290924, "info_performance_mean": 0.28134778141975403, "info_performance_final": 0.3584090769290924, "step": 1098000}
{"episode_reward": 562.6954545454543, "episode": 10981.0, "batch_reward": 12.978353500366211, "critic_loss": 173.56216430664062, "actor_loss": -1639.4488525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.9380666017532349, "alpha_loss": 0.14835917949676514, "alpha_value": 0.2541682074566504, "duration": 1.526489496231079, "info_normalized_performance_mean": 0.7276853919029236, "info_normalized_performance_final": 0.7968460321426392, "info_performance_mean": 0.7276853919029236, "info_performance_final": 0.7968460321426392, "step": 1098500}
{"episode_reward": 1455.3710575139119, "episode": 10986.0, "batch_reward": 12.274764060974121, "critic_loss": 385.6267395019531, "actor_loss": -1581.3740234375, "actor_target_entropy": -3.0, "actor_entropy": 0.6250585913658142, "alpha_loss": -0.04095575958490372, "alpha_value": 0.25251390925785777, "duration": 1.4996540546417236, "info_normalized_performance_mean": 0.6648572683334351, "info_normalized_performance_final": 0.7142857313156128, "info_performance_mean": 0.6648572683334351, "info_performance_final": 0.7142857313156128, "step": 1099000}
{"episode_reward": 1329.714285714286, "episode": 10991.0, "batch_reward": 13.025362014770508, "critic_loss": 172.1874237060547, "actor_loss": -1646.15869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6489440202713013, "alpha_loss": -0.08925880491733551, "alpha_value": 0.24973503869401575, "duration": 1.4845430850982666, "info_normalized_performance_mean": 0.5762646198272705, "info_normalized_performance_final": 0.62646484375, "info_performance_mean": 0.5762646198272705, "info_performance_final": 0.62646484375, "step": 1099500}
{"episode_reward": 1152.529296875, "episode": 10996.0, "batch_reward": 13.561758041381836, "critic_loss": 138.50628662109375, "actor_loss": -1676.6192626953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9932321310043335, "alpha_loss": 0.03078855201601982, "alpha_value": 0.2504336010038275, "step": 1100000}
{"duration": 18.765246868133545, "info_normalized_performance_mean": 0.493404358625412, "info_normalized_performance_final": 0.5447530746459961, "info_performance_mean": 0.493404358625412, "info_performance_final": 0.5447530746459961, "step": 1100000}
{"episode_reward": 986.8086419753068, "episode": 11001.0, "batch_reward": 12.92612075805664, "critic_loss": 556.5186767578125, "actor_loss": -1657.8118896484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7567926049232483, "alpha_loss": 0.045181140303611755, "alpha_value": 0.2500295207282044, "duration": 1.6257994174957275, "info_normalized_performance_mean": 0.8118613958358765, "info_normalized_performance_final": 0.8708513975143433, "info_performance_mean": 0.8118613958358765, "info_performance_final": 0.8708513975143433, "step": 1100500}
{"episode_reward": 1623.722943722942, "episode": 11006.0, "batch_reward": 12.367374420166016, "critic_loss": 810.97021484375, "actor_loss": -1629.393798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.18599314987659454, "alpha_loss": -0.10326547920703888, "alpha_value": 0.25052591902288085, "duration": 1.5618083477020264, "info_normalized_performance_mean": 0.7405155897140503, "info_normalized_performance_final": 0.796875, "info_performance_mean": 0.7405155897140503, "info_performance_final": 0.796875, "step": 1101000}
{"episode_reward": 1481.03125, "episode": 11011.0, "batch_reward": 13.021158218383789, "critic_loss": 395.672607421875, "actor_loss": -1630.768310546875, "actor_target_entropy": -3.0, "actor_entropy": 0.6959085464477539, "alpha_loss": 0.09327758848667145, "alpha_value": 0.24878487388405618, "duration": 1.5090022087097168, "info_normalized_performance_mean": 0.6848978400230408, "info_normalized_performance_final": 0.7476809024810791, "info_performance_mean": 0.6848978400230408, "info_performance_final": 0.7476809024810791, "step": 1101500}
{"episode_reward": 1369.7959183673481, "episode": 11016.0, "batch_reward": 12.839567184448242, "critic_loss": 386.5367126464844, "actor_loss": -1640.78369140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8168159127235413, "alpha_loss": 0.037972722202539444, "alpha_value": 0.24801572624091078, "duration": 1.5653347969055176, "info_normalized_performance_mean": 0.8530441522598267, "info_normalized_performance_final": 0.9161764979362488, "info_performance_mean": 0.8530441522598267, "info_performance_final": 0.9161764979362488, "step": 1102000}
{"episode_reward": 1706.0882352941162, "episode": 11021.0, "batch_reward": 12.409133911132812, "critic_loss": 152.41921997070312, "actor_loss": -1589.054931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0514777898788452, "alpha_loss": 0.04374738782644272, "alpha_value": 0.24506163901173242, "duration": 1.5304880142211914, "info_normalized_performance_mean": 0.5757551789283752, "info_normalized_performance_final": 0.6263020634651184, "info_performance_mean": 0.5757551789283752, "info_performance_final": 0.6263020634651184, "step": 1102500}
{"episode_reward": 1151.5104166666663, "episode": 11026.0, "batch_reward": 13.019659042358398, "critic_loss": 249.2825469970703, "actor_loss": -1620.3316650390625, "actor_target_entropy": -3.0, "actor_entropy": 0.6222988367080688, "alpha_loss": 0.022703833878040314, "alpha_value": 0.24474354559846595, "duration": 1.3766961097717285, "info_normalized_performance_mean": 0.25804686546325684, "info_normalized_performance_final": 0.27734375, "info_performance_mean": 0.25804686546325684, "info_performance_final": 0.27734375, "step": 1103000}
{"episode_reward": 516.09375, "episode": 11031.0, "batch_reward": 11.913558959960938, "critic_loss": 320.93115234375, "actor_loss": -1574.804443359375, "actor_target_entropy": -3.0, "actor_entropy": 0.965682864189148, "alpha_loss": -0.1358492374420166, "alpha_value": 0.24377443852851163, "duration": 1.5119411945343018, "info_normalized_performance_mean": 0.6025283932685852, "info_normalized_performance_final": 0.6619318127632141, "info_performance_mean": 0.6025283932685852, "info_performance_final": 0.6619318127632141, "step": 1103500}
{"episode_reward": 1205.0568181818173, "episode": 11036.0, "batch_reward": 12.915094375610352, "critic_loss": 244.14071655273438, "actor_loss": -1660.948974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.84630286693573, "alpha_loss": -0.023864826187491417, "alpha_value": 0.24457588454089502, "duration": 1.4298603534698486, "info_normalized_performance_mean": 0.33893752098083496, "info_normalized_performance_final": 0.36406248807907104, "info_performance_mean": 0.33893752098083496, "info_performance_final": 0.36406248807907104, "step": 1104000}
{"episode_reward": 677.875, "episode": 11041.0, "batch_reward": 12.017011642456055, "critic_loss": 280.53375244140625, "actor_loss": -1617.820068359375, "actor_target_entropy": -3.0, "actor_entropy": 0.802205502986908, "alpha_loss": -0.05367397889494896, "alpha_value": 0.2444346305810782, "duration": 1.6237308979034424, "info_normalized_performance_mean": 0.8294571042060852, "info_normalized_performance_final": 0.8914027214050293, "info_performance_mean": 0.8294571042060852, "info_performance_final": 0.8914027214050293, "step": 1104500}
{"episode_reward": 1658.914027149318, "episode": 11046.0, "batch_reward": 12.412603378295898, "critic_loss": 407.7965393066406, "actor_loss": -1583.843505859375, "actor_target_entropy": -3.0, "actor_entropy": 0.5497137308120728, "alpha_loss": -0.008344607427716255, "alpha_value": 0.24210293320135215, "duration": 1.4738061428070068, "info_normalized_performance_mean": 0.7595604658126831, "info_normalized_performance_final": 0.8290598392486572, "info_performance_mean": 0.7595604658126831, "info_performance_final": 0.8290598392486572, "step": 1105000}
{"episode_reward": 1519.1208791208767, "episode": 11051.0, "batch_reward": 12.745603561401367, "critic_loss": 224.74569702148438, "actor_loss": -1633.002197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.4597833752632141, "alpha_loss": -0.03529374301433563, "alpha_value": 0.2417591488836649, "duration": 1.433061122894287, "info_normalized_performance_mean": 0.19170306622982025, "info_normalized_performance_final": 0.20624999701976776, "info_performance_mean": 0.19170306622982025, "info_performance_final": 0.20624999701976776, "step": 1105500}
{"episode_reward": 383.40625, "episode": 11056.0, "batch_reward": 13.400629043579102, "critic_loss": 377.73248291015625, "actor_loss": -1634.88623046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8476406335830688, "alpha_loss": 0.08548766374588013, "alpha_value": 0.24317514153154876, "duration": 1.4380419254302979, "info_normalized_performance_mean": 0.716330885887146, "info_normalized_performance_final": 0.7777777910232544, "info_performance_mean": 0.716330885887146, "info_performance_final": 0.7777777910232544, "step": 1106000}
{"episode_reward": 1432.6617826617846, "episode": 11061.0, "batch_reward": 12.591777801513672, "critic_loss": 322.725830078125, "actor_loss": -1616.001708984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9151690006256104, "alpha_loss": -0.055653706192970276, "alpha_value": 0.24614200585368395, "duration": 1.531831979751587, "info_normalized_performance_mean": 0.6374005079269409, "info_normalized_performance_final": 0.6889204382896423, "info_performance_mean": 0.6374005079269409, "info_performance_final": 0.6889204382896423, "step": 1106500}
{"episode_reward": 1274.8011363636356, "episode": 11066.0, "batch_reward": 12.742703437805176, "critic_loss": 327.65875244140625, "actor_loss": -1603.10302734375, "actor_target_entropy": -3.0, "actor_entropy": 0.821330189704895, "alpha_loss": -0.0038885194808244705, "alpha_value": 0.249789242191321, "duration": 1.5648407936096191, "info_normalized_performance_mean": 0.7335938811302185, "info_normalized_performance_final": 0.7942708134651184, "info_performance_mean": 0.7335938811302185, "info_performance_final": 0.7942708134651184, "step": 1107000}
{"episode_reward": 1467.1875000000011, "episode": 11071.0, "batch_reward": 13.113992691040039, "critic_loss": 187.408447265625, "actor_loss": -1620.9937744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.5747089982032776, "alpha_loss": 0.09241713583469391, "alpha_value": 0.2538383723560067, "duration": 1.5642621517181396, "info_normalized_performance_mean": 0.670950174331665, "info_normalized_performance_final": 0.7212499976158142, "info_performance_mean": 0.670950174331665, "info_performance_final": 0.7212499976158142, "step": 1107500}
{"episode_reward": 1341.8999999999978, "episode": 11076.0, "batch_reward": 12.565048217773438, "critic_loss": 548.360107421875, "actor_loss": -1583.557373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.322798252105713, "alpha_loss": -0.03541254997253418, "alpha_value": 0.2541375445116547, "duration": 1.4198837280273438, "info_normalized_performance_mean": 0.34578123688697815, "info_normalized_performance_final": 0.3705357015132904, "info_performance_mean": 0.34578123688697815, "info_performance_final": 0.3705357015132904, "step": 1108000}
{"episode_reward": 691.5625000000008, "episode": 11081.0, "batch_reward": 13.11864948272705, "critic_loss": 236.5926513671875, "actor_loss": -1626.565185546875, "actor_target_entropy": -3.0, "actor_entropy": 0.8719710111618042, "alpha_loss": 0.17626087367534637, "alpha_value": 0.25316696085091395, "duration": 1.622326135635376, "info_normalized_performance_mean": 0.48882725834846497, "info_normalized_performance_final": 0.5370454788208008, "info_performance_mean": 0.48882725834846497, "info_performance_final": 0.5370454788208008, "step": 1108500}
{"episode_reward": 977.654545454546, "episode": 11086.0, "batch_reward": 12.730184555053711, "critic_loss": 134.008056640625, "actor_loss": -1588.311279296875, "actor_target_entropy": -3.0, "actor_entropy": 0.5646478533744812, "alpha_loss": 0.07828131318092346, "alpha_value": 0.25308541289846104, "duration": 1.6500427722930908, "info_normalized_performance_mean": 0.731818675994873, "info_normalized_performance_final": 0.8009259104728699, "info_performance_mean": 0.731818675994873, "info_performance_final": 0.8009259104728699, "step": 1109000}
{"episode_reward": 1463.6375661375641, "episode": 11091.0, "batch_reward": 12.78524112701416, "critic_loss": 238.06248474121094, "actor_loss": -1584.8309326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1997624635696411, "alpha_loss": 0.025776926428079605, "alpha_value": 0.25232078131007435, "duration": 1.3583941459655762, "info_normalized_performance_mean": 0.5589062571525574, "info_normalized_performance_final": 0.596875011920929, "info_performance_mean": 0.5589062571525574, "info_performance_final": 0.596875011920929, "step": 1109500}
{"episode_reward": 1117.8125, "episode": 11096.0, "batch_reward": 12.894478797912598, "critic_loss": 324.193603515625, "actor_loss": -1583.5577392578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6152846813201904, "alpha_loss": -0.20426906645298004, "alpha_value": 0.25501696021106773, "step": 1110000}
{"duration": 18.555847883224487, "info_normalized_performance_mean": 0.907559335231781, "info_normalized_performance_final": 0.9821428656578064, "info_performance_mean": 0.907559335231781, "info_performance_final": 0.9821428656578064, "step": 1110000}
{"episode_reward": 1815.119047619046, "episode": 11101.0, "batch_reward": 13.19282054901123, "critic_loss": 1216.5830078125, "actor_loss": -1612.0386962890625, "actor_target_entropy": -3.0, "actor_entropy": 0.5937447547912598, "alpha_loss": 0.040196582674980164, "alpha_value": 0.25811895174452426, "duration": 1.5378029346466064, "info_normalized_performance_mean": 0.6447135210037231, "info_normalized_performance_final": 0.7096354365348816, "info_performance_mean": 0.6447135210037231, "info_performance_final": 0.7096354365348816, "step": 1110500}
{"episode_reward": 1289.427083333333, "episode": 11106.0, "batch_reward": 12.164043426513672, "critic_loss": 619.3458251953125, "actor_loss": -1601.894775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0986838340759277, "alpha_loss": -0.12722575664520264, "alpha_value": 0.25867625263004834, "duration": 1.4710988998413086, "info_normalized_performance_mean": 0.7731729745864868, "info_normalized_performance_final": 0.8493589758872986, "info_performance_mean": 0.7731729745864868, "info_performance_final": 0.8493589758872986, "step": 1111000}
{"episode_reward": 1546.3461538461515, "episode": 11111.0, "batch_reward": 12.926016807556152, "critic_loss": 272.94921875, "actor_loss": -1598.514892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.879888117313385, "alpha_loss": 0.0963466465473175, "alpha_value": 0.25893907244563574, "duration": 1.5676085948944092, "info_normalized_performance_mean": 0.7794641852378845, "info_normalized_performance_final": 0.8557692170143127, "info_performance_mean": 0.7794641852378845, "info_performance_final": 0.8557692170143127, "step": 1111500}
{"episode_reward": 1558.9285714285697, "episode": 11116.0, "batch_reward": 12.342723846435547, "critic_loss": 222.72923278808594, "actor_loss": -1576.033203125, "actor_target_entropy": -3.0, "actor_entropy": 0.962374210357666, "alpha_loss": -0.05478442460298538, "alpha_value": 0.2580948166992099, "duration": 1.6124944686889648, "info_normalized_performance_mean": 0.8061334490776062, "info_normalized_performance_final": 0.8858333230018616, "info_performance_mean": 0.8061334490776062, "info_performance_final": 0.8858333230018616, "step": 1112000}
{"episode_reward": 1612.266666666669, "episode": 11121.0, "batch_reward": 12.801248550415039, "critic_loss": 321.37054443359375, "actor_loss": -1599.5992431640625, "actor_target_entropy": -3.0, "actor_entropy": 0.7395893335342407, "alpha_loss": 0.031113306060433388, "alpha_value": 0.2562972981340904, "duration": 1.7811129093170166, "info_normalized_performance_mean": 0.47115379571914673, "info_normalized_performance_final": 0.5837339758872986, "info_performance_mean": 0.47115379571914673, "info_performance_final": 0.5837339758872986, "step": 1112500}
{"episode_reward": 942.307692307691, "episode": 11126.0, "batch_reward": 12.388701438903809, "critic_loss": 263.96844482421875, "actor_loss": -1618.360107421875, "actor_target_entropy": -3.0, "actor_entropy": 0.6424561738967896, "alpha_loss": 0.02308223955333233, "alpha_value": 0.2561627696468974, "duration": 1.6447734832763672, "info_normalized_performance_mean": 0.47031670808792114, "info_normalized_performance_final": 0.5243750214576721, "info_performance_mean": 0.47031670808792114, "info_performance_final": 0.5243750214576721, "step": 1113000}
{"episode_reward": 940.6333333333318, "episode": 11131.0, "batch_reward": 13.372931480407715, "critic_loss": 503.7396240234375, "actor_loss": -1619.8194580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.868506908416748, "alpha_loss": 0.018763363361358643, "alpha_value": 0.25556325868928903, "duration": 1.5871896743774414, "info_normalized_performance_mean": 0.8885509967803955, "info_normalized_performance_final": 0.9545454382896423, "info_performance_mean": 0.8885509967803955, "info_performance_final": 0.9545454382896423, "step": 1113500}
{"episode_reward": 1777.1022727272707, "episode": 11136.0, "batch_reward": 12.896829605102539, "critic_loss": 178.83447265625, "actor_loss": -1623.004638671875, "actor_target_entropy": -3.0, "actor_entropy": 0.5958265066146851, "alpha_loss": 0.09453507512807846, "alpha_value": 0.25606925748811965, "duration": 1.6081979274749756, "info_normalized_performance_mean": 0.506531834602356, "info_normalized_performance_final": 0.6103296875953674, "info_performance_mean": 0.506531834602356, "info_performance_final": 0.6103296875953674, "step": 1114000}
{"episode_reward": 1013.0637362637343, "episode": 11141.0, "batch_reward": 11.851339340209961, "critic_loss": 580.6568603515625, "actor_loss": -1550.5118408203125, "actor_target_entropy": -3.0, "actor_entropy": 0.3908146619796753, "alpha_loss": -0.15537764132022858, "alpha_value": 0.2568950321391064, "duration": 1.5815844535827637, "info_normalized_performance_mean": 0.39390480518341064, "info_normalized_performance_final": 0.46619048714637756, "info_performance_mean": 0.39390480518341064, "info_performance_final": 0.46619048714637756, "step": 1114500}
{"episode_reward": 787.8095238095224, "episode": 11146.0, "batch_reward": 12.96610164642334, "critic_loss": 585.138427734375, "actor_loss": -1587.50390625, "actor_target_entropy": -3.0, "actor_entropy": 0.47668519616127014, "alpha_loss": 0.11967295408248901, "alpha_value": 0.2587372559880882, "duration": 1.6170799732208252, "info_normalized_performance_mean": 0.8101040720939636, "info_normalized_performance_final": 0.8697916865348816, "info_performance_mean": 0.8101040720939636, "info_performance_final": 0.8697916865348816, "step": 1115000}
{"episode_reward": 1620.2083333333317, "episode": 11151.0, "batch_reward": 13.346284866333008, "critic_loss": 570.2713012695312, "actor_loss": -1624.5394287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2341368198394775, "alpha_loss": 0.018278837203979492, "alpha_value": 0.2617578553704197, "duration": 1.5306060314178467, "info_normalized_performance_mean": 0.8362353444099426, "info_normalized_performance_final": 0.8980392217636108, "info_performance_mean": 0.8362353444099426, "info_performance_final": 0.8980392217636108, "step": 1115500}
{"episode_reward": 1672.4705882352962, "episode": 11156.0, "batch_reward": 13.238750457763672, "critic_loss": 423.4176025390625, "actor_loss": -1598.312255859375, "actor_target_entropy": -3.0, "actor_entropy": 0.5608233213424683, "alpha_loss": 0.03471268713474274, "alpha_value": 0.2624966230560836, "duration": 1.5017569065093994, "info_normalized_performance_mean": 0.2134314924478531, "info_normalized_performance_final": 0.23497596383094788, "info_performance_mean": 0.2134314924478531, "info_performance_final": 0.23497596383094788, "step": 1116000}
{"episode_reward": 426.86298076923043, "episode": 11161.0, "batch_reward": 13.022909164428711, "critic_loss": 252.0970916748047, "actor_loss": -1623.393310546875, "actor_target_entropy": -3.0, "actor_entropy": 0.4398355484008789, "alpha_loss": 0.015172518789768219, "alpha_value": 0.2651996964708178, "duration": 1.5599606037139893, "info_normalized_performance_mean": 0.8139804601669312, "info_normalized_performance_final": 0.8725489974021912, "info_performance_mean": 0.8139804601669312, "info_performance_final": 0.8725489974021912, "step": 1116500}
{"episode_reward": 1627.960784313728, "episode": 11166.0, "batch_reward": 13.099388122558594, "critic_loss": 497.7027893066406, "actor_loss": -1600.7607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.3702540695667267, "alpha_loss": -0.06073925644159317, "alpha_value": 0.26666231791275724, "duration": 1.6226296424865723, "info_normalized_performance_mean": 0.809133768081665, "info_normalized_performance_final": 0.8812834024429321, "info_performance_mean": 0.809133768081665, "info_performance_final": 0.8812834024429321, "step": 1117000}
{"episode_reward": 1618.2673796791405, "episode": 11171.0, "batch_reward": 11.746073722839355, "critic_loss": 661.7093505859375, "actor_loss": -1533.244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.4548683762550354, "alpha_loss": -0.00987187772989273, "alpha_value": 0.266633975227566, "duration": 1.3964662551879883, "info_normalized_performance_mean": 0.8870001435279846, "info_normalized_performance_final": 0.9535714387893677, "info_performance_mean": 0.8870001435279846, "info_performance_final": 0.9535714387893677, "step": 1117500}
{"episode_reward": 1774.0000000000034, "episode": 11176.0, "batch_reward": 12.453121185302734, "critic_loss": 407.6999816894531, "actor_loss": -1569.715576171875, "actor_target_entropy": -3.0, "actor_entropy": 0.6630170941352844, "alpha_loss": 0.12461208552122116, "alpha_value": 0.26753580386567155, "duration": 1.3917064666748047, "info_normalized_performance_mean": 0.9300000071525574, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9300000071525574, "info_performance_final": 1.0, "step": 1118000}
{"episode_reward": 1860.0, "episode": 11181.0, "batch_reward": 12.431854248046875, "critic_loss": 597.992431640625, "actor_loss": -1586.2034912109375, "actor_target_entropy": -3.0, "actor_entropy": 0.6665385961532593, "alpha_loss": -0.07526765763759613, "alpha_value": 0.26514265521654157, "duration": 1.4447879791259766, "info_normalized_performance_mean": 0.5207204222679138, "info_normalized_performance_final": 0.5616605877876282, "info_performance_mean": 0.5207204222679138, "info_performance_final": 0.5616605877876282, "step": 1118500}
{"episode_reward": 1041.4407814407823, "episode": 11186.0, "batch_reward": 13.32193374633789, "critic_loss": 303.2140197753906, "actor_loss": -1622.970703125, "actor_target_entropy": -3.0, "actor_entropy": 0.5967321991920471, "alpha_loss": 0.15543776750564575, "alpha_value": 0.261610132286403, "duration": 1.5982980728149414, "info_normalized_performance_mean": 0.8057998418807983, "info_normalized_performance_final": 0.8682352900505066, "info_performance_mean": 0.8057998418807983, "info_performance_final": 0.8682352900505066, "step": 1119000}
{"episode_reward": 1611.599999999997, "episode": 11191.0, "batch_reward": 12.888689041137695, "critic_loss": 133.9141387939453, "actor_loss": -1574.119384765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8676323890686035, "alpha_loss": 0.13003253936767578, "alpha_value": 0.25801821364869, "duration": 1.6018471717834473, "info_normalized_performance_mean": 0.45567184686660767, "info_normalized_performance_final": 0.5023741722106934, "info_performance_mean": 0.45567184686660767, "info_performance_final": 0.5023741722106934, "step": 1119500}
{"episode_reward": 911.3437796771149, "episode": 11196.0, "batch_reward": 12.230879783630371, "critic_loss": 384.63104248046875, "actor_loss": -1596.3369140625, "actor_target_entropy": -3.0, "actor_entropy": 0.5353452563285828, "alpha_loss": -0.03576566278934479, "alpha_value": 0.25636813393753305, "step": 1120000}
{"duration": 18.842697143554688, "info_normalized_performance_mean": 0.9278572201728821, "info_normalized_performance_final": 0.9980158805847168, "info_performance_mean": 0.9278572201728821, "info_performance_final": 0.9980158805847168, "step": 1120000}
{"episode_reward": 1855.7142857142817, "episode": 11201.0, "batch_reward": 12.581809043884277, "critic_loss": 262.9610290527344, "actor_loss": -1543.1815185546875, "actor_target_entropy": -3.0, "actor_entropy": 0.6620926856994629, "alpha_loss": 0.09819278120994568, "alpha_value": 0.25314516634724277, "duration": 1.5546948909759521, "info_normalized_performance_mean": 0.47282761335372925, "info_normalized_performance_final": 0.522536039352417, "info_performance_mean": 0.47282761335372925, "info_performance_final": 0.522536039352417, "step": 1120500}
{"episode_reward": 945.6550480769241, "episode": 11206.0, "batch_reward": 12.859773635864258, "critic_loss": 214.83245849609375, "actor_loss": -1575.27294921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7141780853271484, "alpha_loss": 0.025147542357444763, "alpha_value": 0.25197498932982804, "duration": 1.6553800106048584, "info_normalized_performance_mean": 0.3172139525413513, "info_normalized_performance_final": 0.4416719675064087, "info_performance_mean": 0.3172139525413513, "info_performance_final": 0.4416719675064087, "step": 1121000}
{"episode_reward": 634.4278448823903, "episode": 11211.0, "batch_reward": 12.629844665527344, "critic_loss": 170.8931121826172, "actor_loss": -1542.499267578125, "actor_target_entropy": -3.0, "actor_entropy": 0.8061326742172241, "alpha_loss": 0.04883286729454994, "alpha_value": 0.2525952425668304, "duration": 1.4792613983154297, "info_normalized_performance_mean": 0.7194047570228577, "info_normalized_performance_final": 0.7833333611488342, "info_performance_mean": 0.7194047570228577, "info_performance_final": 0.7833333611488342, "step": 1121500}
{"episode_reward": 1438.8095238095248, "episode": 11216.0, "batch_reward": 12.707828521728516, "critic_loss": 1377.7197265625, "actor_loss": -1573.34423828125, "actor_target_entropy": -3.0, "actor_entropy": 0.24367722868919373, "alpha_loss": -0.05729106068611145, "alpha_value": 0.2537252554923064, "duration": 1.561800241470337, "info_normalized_performance_mean": 0.8600752353668213, "info_normalized_performance_final": 0.925000011920929, "info_performance_mean": 0.8600752353668213, "info_performance_final": 0.925000011920929, "step": 1122000}
{"episode_reward": 1720.15, "episode": 11221.0, "batch_reward": 13.202980041503906, "critic_loss": 276.3718566894531, "actor_loss": -1574.658203125, "actor_target_entropy": -3.0, "actor_entropy": 0.8112558722496033, "alpha_loss": 0.03222321718931198, "alpha_value": 0.25423012515508586, "duration": 1.4428801536560059, "info_normalized_performance_mean": 0.4765104055404663, "info_normalized_performance_final": 0.5121527910232544, "info_performance_mean": 0.4765104055404663, "info_performance_final": 0.5121527910232544, "step": 1122500}
{"episode_reward": 953.0208333333323, "episode": 11226.0, "batch_reward": 12.748525619506836, "critic_loss": 239.533935546875, "actor_loss": -1560.9488525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.5951974987983704, "alpha_loss": 0.0382123738527298, "alpha_value": 0.25476939060170906, "duration": 1.4466533660888672, "info_normalized_performance_mean": 0.35943886637687683, "info_normalized_performance_final": 0.3877550959587097, "info_performance_mean": 0.35943886637687683, "info_performance_final": 0.3877550959587097, "step": 1123000}
{"episode_reward": 718.8775510204096, "episode": 11231.0, "batch_reward": 13.060806274414062, "critic_loss": 589.2998657226562, "actor_loss": -1611.316650390625, "actor_target_entropy": -3.0, "actor_entropy": 0.23886428773403168, "alpha_loss": -0.20312750339508057, "alpha_value": 0.25674899977184423, "duration": 1.4933438301086426, "info_normalized_performance_mean": 0.7329224944114685, "info_normalized_performance_final": 0.7952380776405334, "info_performance_mean": 0.7329224944114685, "info_performance_final": 0.7952380776405334, "step": 1123500}
{"episode_reward": 1465.8452380952397, "episode": 11236.0, "batch_reward": 12.703240394592285, "critic_loss": 201.53134155273438, "actor_loss": -1557.760009765625, "actor_target_entropy": -3.0, "actor_entropy": 1.1479839086532593, "alpha_loss": 0.005622856318950653, "alpha_value": 0.26042408519961463, "duration": 1.6516475677490234, "info_normalized_performance_mean": 0.8375470042228699, "info_normalized_performance_final": 0.9170274138450623, "info_performance_mean": 0.8375470042228699, "info_performance_final": 0.9170274138450623, "step": 1124000}
{"episode_reward": 1675.093795093797, "episode": 11241.0, "batch_reward": 12.5366792678833, "critic_loss": 408.8497314453125, "actor_loss": -1620.9302978515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8612638711929321, "alpha_loss": 0.025080054998397827, "alpha_value": 0.26375635331061736, "duration": 1.552476167678833, "info_normalized_performance_mean": 0.4135184586048126, "info_normalized_performance_final": 0.46322017908096313, "info_performance_mean": 0.4135184586048126, "info_performance_final": 0.46322017908096313, "step": 1124500}
{"episode_reward": 827.0370370370374, "episode": 11246.0, "batch_reward": 12.73257827758789, "critic_loss": 321.0455322265625, "actor_loss": -1572.188720703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0044797658920288, "alpha_loss": -0.008905167691409588, "alpha_value": 0.26648865135804756, "duration": 1.6206026077270508, "info_normalized_performance_mean": 0.43617722392082214, "info_normalized_performance_final": 0.47999998927116394, "info_performance_mean": 0.43617722392082214, "info_performance_final": 0.47999998927116394, "step": 1125000}
{"episode_reward": 872.3545454545468, "episode": 11251.0, "batch_reward": 12.750195503234863, "critic_loss": 249.2090606689453, "actor_loss": -1516.116455078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8289132118225098, "alpha_loss": 0.002451140433549881, "alpha_value": 0.2686620346776019, "duration": 1.5824453830718994, "info_normalized_performance_mean": 0.7349750399589539, "info_normalized_performance_final": 0.7900000214576721, "info_performance_mean": 0.7349750399589539, "info_performance_final": 0.7900000214576721, "step": 1125500}
{"episode_reward": 1469.9499999999975, "episode": 11256.0, "batch_reward": 12.782186508178711, "critic_loss": 586.2006225585938, "actor_loss": -1585.9560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.2990821599960327, "alpha_loss": 0.024568898603320122, "alpha_value": 0.270767422885498, "duration": 1.6430573463439941, "info_normalized_performance_mean": 0.8130093216896057, "info_normalized_performance_final": 0.8822751045227051, "info_performance_mean": 0.8130093216896057, "info_performance_final": 0.8822751045227051, "step": 1126000}
{"episode_reward": 1626.018518518517, "episode": 11261.0, "batch_reward": 12.549860000610352, "critic_loss": 278.9610595703125, "actor_loss": -1560.7066650390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8722690343856812, "alpha_loss": 0.008329487405717373, "alpha_value": 0.27239145153447036, "duration": 1.6696734428405762, "info_normalized_performance_mean": 0.6877222657203674, "info_normalized_performance_final": 0.7388888597488403, "info_performance_mean": 0.6877222657203674, "info_performance_final": 0.7388888597488403, "step": 1126500}
{"episode_reward": 1375.444444444447, "episode": 11266.0, "batch_reward": 12.226483345031738, "critic_loss": 298.9854736328125, "actor_loss": -1598.3907470703125, "actor_target_entropy": -3.0, "actor_entropy": 0.7061138153076172, "alpha_loss": -0.15054622292518616, "alpha_value": 0.2733236226531937, "duration": 1.6300857067108154, "info_normalized_performance_mean": 0.7926911115646362, "info_normalized_performance_final": 0.850649356842041, "info_performance_mean": 0.7926911115646362, "info_performance_final": 0.850649356842041, "step": 1127000}
{"episode_reward": 1585.3823953823928, "episode": 11271.0, "batch_reward": 13.009986877441406, "critic_loss": 417.9962463378906, "actor_loss": -1575.0531005859375, "actor_target_entropy": -3.0, "actor_entropy": 0.8149914741516113, "alpha_loss": 0.050486594438552856, "alpha_value": 0.27313900714850714, "duration": 1.5745775699615479, "info_normalized_performance_mean": 0.7800347208976746, "info_normalized_performance_final": 0.8368055820465088, "info_performance_mean": 0.7800347208976746, "info_performance_final": 0.8368055820465088, "step": 1127500}
{"episode_reward": 1560.0694444444425, "episode": 11276.0, "batch_reward": 13.08831787109375, "critic_loss": 631.9976806640625, "actor_loss": -1647.83203125, "actor_target_entropy": -3.0, "actor_entropy": 0.7718862295150757, "alpha_loss": 0.08284521847963333, "alpha_value": 0.2722298360339016, "duration": 1.6100170612335205, "info_normalized_performance_mean": 0.38983336091041565, "info_normalized_performance_final": 0.42750000953674316, "info_performance_mean": 0.38983336091041565, "info_performance_final": 0.42750000953674316, "step": 1128000}
{"episode_reward": 779.6666666666657, "episode": 11281.0, "batch_reward": 13.655060768127441, "critic_loss": 191.22457885742188, "actor_loss": -1588.109130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.8742367029190063, "alpha_loss": 0.1059323251247406, "alpha_value": 0.2702234728496697, "duration": 1.470320463180542, "info_normalized_performance_mean": 0.620261549949646, "info_normalized_performance_final": 0.6664540767669678, "info_performance_mean": 0.620261549949646, "info_performance_final": 0.6664540767669678, "step": 1128500}
{"episode_reward": 1240.5229591836712, "episode": 11286.0, "batch_reward": 13.363594055175781, "critic_loss": 285.35345458984375, "actor_loss": -1598.2919921875, "actor_target_entropy": -3.0, "actor_entropy": 0.9087730646133423, "alpha_loss": 0.0808504968881607, "alpha_value": 0.2685233529737204, "duration": 1.5205633640289307, "info_normalized_performance_mean": 0.4517311453819275, "info_normalized_performance_final": 0.49607181549072266, "info_performance_mean": 0.4517311453819275, "info_performance_final": 0.49607181549072266, "step": 1129000}
{"episode_reward": 903.4624017957339, "episode": 11291.0, "batch_reward": 12.119577407836914, "critic_loss": 136.12986755371094, "actor_loss": -1571.255859375, "actor_target_entropy": -3.0, "actor_entropy": 0.9815919399261475, "alpha_loss": -0.05596574395895004, "alpha_value": 0.27027591747730356, "duration": 1.5225985050201416, "info_normalized_performance_mean": 0.5836718678474426, "info_normalized_performance_final": 0.6345486044883728, "info_performance_mean": 0.5836718678474426, "info_performance_final": 0.6345486044883728, "step": 1129500}
{"episode_reward": 1167.3437499999977, "episode": 11296.0, "batch_reward": 12.992213249206543, "critic_loss": 295.4854431152344, "actor_loss": -1584.3543701171875, "actor_target_entropy": -3.0, "actor_entropy": 0.9964224100112915, "alpha_loss": 0.14856982231140137, "alpha_value": 0.26888650503540823, "step": 1130000}
{"duration": 18.677922248840332, "info_normalized_performance_mean": 0.5696309208869934, "info_normalized_performance_final": 0.6196428537368774, "info_performance_mean": 0.5696309208869934, "info_performance_final": 0.6196428537368774, "step": 1130000}
{"episode_reward": 1139.2619047619037, "episode": 11301.0, "batch_reward": 11.946554183959961, "critic_loss": 313.56195068359375, "actor_loss": -1586.9337158203125, "actor_target_entropy": -3.0, "actor_entropy": 0.6444256901741028, "alpha_loss": -0.03448895364999771, "alpha_value": 0.26664668506409317, "duration": 1.4181652069091797, "info_normalized_performance_mean": 0.928428590297699, "info_normalized_performance_final": 0.9964285492897034, "info_performance_mean": 0.928428590297699, "info_performance_final": 0.9964285492897034, "step": 1130500}
{"episode_reward": 1856.8571428571395, "episode": 11306.0, "batch_reward": 12.648879051208496, "critic_loss": 183.28121948242188, "actor_loss": -1618.0662841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.26266026496887207, "alpha_loss": 0.11319327354431152, "alpha_value": 0.2652486189131985, "duration": 1.5967111587524414, "info_normalized_performance_mean": 0.8506736755371094, "info_normalized_performance_final": 0.9304812550544739, "info_performance_mean": 0.8506736755371094, "info_performance_final": 0.9304812550544739, "step": 1131000}
{"episode_reward": 1701.3475935828847, "episode": 11311.0, "batch_reward": 12.286447525024414, "critic_loss": 346.7149353027344, "actor_loss": -1577.81982421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8394894599914551, "alpha_loss": -0.011010454036295414, "alpha_value": 0.26118045818254243, "duration": 1.4764597415924072, "info_normalized_performance_mean": 0.6058680415153503, "info_normalized_performance_final": 0.6582341194152832, "info_performance_mean": 0.6058680415153503, "info_performance_final": 0.6582341194152832, "step": 1131500}
{"episode_reward": 1211.736111111112, "episode": 11316.0, "batch_reward": 13.020038604736328, "critic_loss": 369.41021728515625, "actor_loss": -1574.1890869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6011511087417603, "alpha_loss": 0.08519712090492249, "alpha_value": 0.25982420153419417, "duration": 1.555206298828125, "info_normalized_performance_mean": 0.402831107378006, "info_normalized_performance_final": 0.4561038911342621, "info_performance_mean": 0.402831107378006, "info_performance_final": 0.4561038911342621, "step": 1132000}
{"episode_reward": 805.6623376623374, "episode": 11321.0, "batch_reward": 12.604090690612793, "critic_loss": 129.50901794433594, "actor_loss": -1597.0772705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.162372350692749, "alpha_loss": 0.20671598613262177, "alpha_value": 0.25653743130272555, "duration": 1.6144235134124756, "info_normalized_performance_mean": 0.8206747174263, "info_normalized_performance_final": 0.894444465637207, "info_performance_mean": 0.8206747174263, "info_performance_final": 0.894444465637207, "step": 1132500}
{"episode_reward": 1641.349206349208, "episode": 11326.0, "batch_reward": 12.611773490905762, "critic_loss": 244.92471313476562, "actor_loss": -1609.5450439453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9076014757156372, "alpha_loss": 0.07265088707208633, "alpha_value": 0.25457200301863103, "duration": 1.54976487159729, "info_normalized_performance_mean": 0.8394832611083984, "info_normalized_performance_final": 0.9016666412353516, "info_performance_mean": 0.8394832611083984, "info_performance_final": 0.9016666412353516, "step": 1133000}
{"episode_reward": 1678.9666666666644, "episode": 11331.0, "batch_reward": 12.60767936706543, "critic_loss": 253.68377685546875, "actor_loss": -1568.3140869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8800969123840332, "alpha_loss": -0.05360735207796097, "alpha_value": 0.25343719604064086, "duration": 1.590801477432251, "info_normalized_performance_mean": 0.2885231077671051, "info_normalized_performance_final": 0.32043954730033875, "info_performance_mean": 0.2885231077671051, "info_performance_final": 0.32043954730033875, "step": 1133500}
{"episode_reward": 577.0461538461541, "episode": 11336.0, "batch_reward": 12.174049377441406, "critic_loss": 366.8191833496094, "actor_loss": -1562.47412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9263694882392883, "alpha_loss": -0.09631916880607605, "alpha_value": 0.25553527238846413, "duration": 1.5160212516784668, "info_normalized_performance_mean": 0.7293164134025574, "info_normalized_performance_final": 0.783203125, "info_performance_mean": 0.7293164134025574, "info_performance_final": 0.783203125, "step": 1134000}
{"episode_reward": 1458.6328125, "episode": 11341.0, "batch_reward": 12.643411636352539, "critic_loss": 450.3458251953125, "actor_loss": -1601.7322998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.80096834897995, "alpha_loss": -0.18950586020946503, "alpha_value": 0.2603415663573225, "duration": 1.560645580291748, "info_normalized_performance_mean": 0.5192749500274658, "info_normalized_performance_final": 0.5722500085830688, "info_performance_mean": 0.5192749500274658, "info_performance_final": 0.5722500085830688, "step": 1134500}
{"episode_reward": 1038.550000000002, "episode": 11346.0, "batch_reward": 13.01963996887207, "critic_loss": 236.4463653564453, "actor_loss": -1575.444580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.1478028297424316, "alpha_loss": 0.0854458212852478, "alpha_value": 0.2656285001160608, "duration": 1.495234727859497, "info_normalized_performance_mean": 0.5255761742591858, "info_normalized_performance_final": 0.57177734375, "info_performance_mean": 0.5255761742591858, "info_performance_final": 0.57177734375, "step": 1135000}
{"episode_reward": 1051.15234375, "episode": 11351.0, "batch_reward": 12.527654647827148, "critic_loss": 270.0089111328125, "actor_loss": -1570.7308349609375, "actor_target_entropy": -3.0, "actor_entropy": 0.8335028290748596, "alpha_loss": -0.2470056712627411, "alpha_value": 0.2721804174391225, "duration": 1.5471813678741455, "info_normalized_performance_mean": 0.8128872513771057, "info_normalized_performance_final": 0.8737499713897705, "info_performance_mean": 0.8128872513771057, "info_performance_final": 0.8737499713897705, "step": 1135500}
{"episode_reward": 1625.7749999999978, "episode": 11356.0, "batch_reward": 12.762181282043457, "critic_loss": 383.45965576171875, "actor_loss": -1671.93701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.377249002456665, "alpha_loss": -0.37854352593421936, "alpha_value": 0.2804719063611806, "duration": 1.5375256538391113, "info_normalized_performance_mean": 0.8856786489486694, "info_normalized_performance_final": 0.9571428298950195, "info_performance_mean": 0.8856786489486694, "info_performance_final": 0.9571428298950195, "step": 1136000}
{"episode_reward": 1771.357142857141, "episode": 11361.0, "batch_reward": 12.815088272094727, "critic_loss": 373.8135986328125, "actor_loss": -1603.6337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.3572227954864502, "alpha_loss": -0.1562134474515915, "alpha_value": 0.2869227056680068, "duration": 1.5333266258239746, "info_normalized_performance_mean": 0.32971426844596863, "info_normalized_performance_final": 0.36181819438934326, "info_performance_mean": 0.32971426844596863, "info_performance_final": 0.36181819438934326, "step": 1136500}
{"episode_reward": 659.4285714285722, "episode": 11366.0, "batch_reward": 12.946252822875977, "critic_loss": 546.0194091796875, "actor_loss": -1638.18408203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1494526863098145, "alpha_loss": -0.2197638303041458, "alpha_value": 0.29473034645876584, "duration": 1.500607967376709, "info_normalized_performance_mean": 0.7279512286186218, "info_normalized_performance_final": 0.7760416865348816, "info_performance_mean": 0.7279512286186218, "info_performance_final": 0.7760416865348816, "step": 1137000}
{"episode_reward": 1455.9027777777767, "episode": 11371.0, "batch_reward": 12.59194564819336, "critic_loss": 363.8043212890625, "actor_loss": -1645.2744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.6040977835655212, "alpha_loss": -0.3125607669353485, "alpha_value": 0.299724146392668, "duration": 1.4471919536590576, "info_normalized_performance_mean": 0.2860000729560852, "info_normalized_performance_final": 0.32499998807907104, "info_performance_mean": 0.2860000729560852, "info_performance_final": 0.32499998807907104, "step": 1137500}
{"episode_reward": 572.0, "episode": 11376.0, "batch_reward": 13.399904251098633, "critic_loss": 598.6543579101562, "actor_loss": -1660.6214599609375, "actor_target_entropy": -3.0, "actor_entropy": 0.6224638223648071, "alpha_loss": -0.018227875232696533, "alpha_value": 0.30487689006275087, "duration": 1.5678608417510986, "info_normalized_performance_mean": 0.6411223411560059, "info_normalized_performance_final": 0.695555567741394, "info_performance_mean": 0.6411223411560059, "info_performance_final": 0.695555567741394, "step": 1138000}
{"episode_reward": 1282.2444444444443, "episode": 11381.0, "batch_reward": 13.078327178955078, "critic_loss": 639.681396484375, "actor_loss": -1677.853515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9463600516319275, "alpha_loss": -0.2542908787727356, "alpha_value": 0.30955094758850654, "duration": 1.5109870433807373, "info_normalized_performance_mean": 0.6870112419128418, "info_normalized_performance_final": 0.7491496801376343, "info_performance_mean": 0.6870112419128418, "info_performance_final": 0.7491496801376343, "step": 1138500}
{"episode_reward": 1374.022108843535, "episode": 11386.0, "batch_reward": 13.563943862915039, "critic_loss": 372.986083984375, "actor_loss": -1687.6622314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0485649108886719, "alpha_loss": -0.06935161352157593, "alpha_value": 0.3151027534583233, "duration": 1.6001064777374268, "info_normalized_performance_mean": 0.8235617280006409, "info_normalized_performance_final": 0.8978174328804016, "info_performance_mean": 0.8235617280006409, "info_performance_final": 0.8978174328804016, "step": 1139000}
{"episode_reward": 1647.1230158730132, "episode": 11391.0, "batch_reward": 13.201240539550781, "critic_loss": 652.5126953125, "actor_loss": -1654.5986328125, "actor_target_entropy": -3.0, "actor_entropy": 1.2508411407470703, "alpha_loss": 0.028543785214424133, "alpha_value": 0.3188463504162036, "duration": 1.4883246421813965, "info_normalized_performance_mean": 0.6407652497291565, "info_normalized_performance_final": 0.6979591846466064, "info_performance_mean": 0.6407652497291565, "info_performance_final": 0.6979591846466064, "step": 1139500}
{"episode_reward": 1281.5306122448985, "episode": 11396.0, "batch_reward": 12.86589241027832, "critic_loss": 568.3777465820312, "actor_loss": -1673.177734375, "actor_target_entropy": -3.0, "actor_entropy": 1.080220341682434, "alpha_loss": -0.11374282836914062, "alpha_value": 0.3253724852649788, "step": 1140000}
{"duration": 18.90328884124756, "info_normalized_performance_mean": 0.4921669661998749, "info_normalized_performance_final": 0.5472842454910278, "info_performance_mean": 0.4921669661998749, "info_performance_final": 0.5472842454910278, "step": 1140000}
{"episode_reward": 984.3341604631939, "episode": 11401.0, "batch_reward": 12.471206665039062, "critic_loss": 696.8825073242188, "actor_loss": -1680.891845703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9272245168685913, "alpha_loss": -0.054903946816921234, "alpha_value": 0.3306031983265277, "duration": 1.538132667541504, "info_normalized_performance_mean": 0.7364902496337891, "info_normalized_performance_final": 0.7901960611343384, "info_performance_mean": 0.7364902496337891, "info_performance_final": 0.7901960611343384, "step": 1140500}
{"episode_reward": 1472.98039215686, "episode": 11406.0, "batch_reward": 12.927604675292969, "critic_loss": 319.485595703125, "actor_loss": -1723.9671630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1367926597595215, "alpha_loss": 0.07986769825220108, "alpha_value": 0.33730700624210674, "duration": 1.466369867324829, "info_normalized_performance_mean": 0.6125594973564148, "info_normalized_performance_final": 0.675595223903656, "info_performance_mean": 0.6125594973564148, "info_performance_final": 0.675595223903656, "step": 1141000}
{"episode_reward": 1225.1190476190504, "episode": 11411.0, "batch_reward": 12.881182670593262, "critic_loss": 304.7509765625, "actor_loss": -1670.673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.7531293630599976, "alpha_loss": 0.02192596346139908, "alpha_value": 0.34208802763120305, "duration": 1.5898826122283936, "info_normalized_performance_mean": 0.8200321197509766, "info_normalized_performance_final": 0.8973262310028076, "info_performance_mean": 0.8200321197509766, "info_performance_final": 0.8973262310028076, "step": 1141500}
{"episode_reward": 1640.0641711229975, "episode": 11416.0, "batch_reward": 12.558998107910156, "critic_loss": 389.90899658203125, "actor_loss": -1702.4256591796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1825525760650635, "alpha_loss": -0.02836768329143524, "alpha_value": 0.346497950215569, "duration": 1.5006484985351562, "info_normalized_performance_mean": 0.6873437762260437, "info_normalized_performance_final": 0.7421875, "info_performance_mean": 0.6873437762260437, "info_performance_final": 0.7421875, "step": 1142000}
{"episode_reward": 1374.6875, "episode": 11421.0, "batch_reward": 13.052486419677734, "critic_loss": 511.06256103515625, "actor_loss": -1726.762939453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5521377325057983, "alpha_loss": -0.26744332909584045, "alpha_value": 0.3515595807228102, "duration": 1.5458781719207764, "info_normalized_performance_mean": 0.790578305721283, "info_normalized_performance_final": 0.862500011920929, "info_performance_mean": 0.790578305721283, "info_performance_final": 0.862500011920929, "step": 1142500}
{"episode_reward": 1581.15625, "episode": 11426.0, "batch_reward": 12.98340892791748, "critic_loss": 441.49462890625, "actor_loss": -1685.954833984375, "actor_target_entropy": -3.0, "actor_entropy": 1.2340443134307861, "alpha_loss": 0.23193448781967163, "alpha_value": 0.35477129441005234, "duration": 1.4740831851959229, "info_normalized_performance_mean": 0.6039683222770691, "info_normalized_performance_final": 0.6557539701461792, "info_performance_mean": 0.6039683222770691, "info_performance_final": 0.6557539701461792, "step": 1143000}
{"episode_reward": 1207.9365079365075, "episode": 11431.0, "batch_reward": 12.168966293334961, "critic_loss": 230.0649871826172, "actor_loss": -1651.513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.580364465713501, "alpha_loss": -0.07797756791114807, "alpha_value": 0.35996522458959856, "duration": 1.504753828048706, "info_normalized_performance_mean": 0.534532904624939, "info_normalized_performance_final": 0.5865384340286255, "info_performance_mean": 0.534532904624939, "info_performance_final": 0.5865384340286255, "step": 1143500}
{"episode_reward": 1069.0659340659363, "episode": 11436.0, "batch_reward": 12.35097885131836, "critic_loss": 1361.597412109375, "actor_loss": -1706.097900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.2840747833251953, "alpha_loss": -0.27285996079444885, "alpha_value": 0.36487345840985913, "duration": 1.5338294506072998, "info_normalized_performance_mean": 0.46007493138313293, "info_normalized_performance_final": 0.5122189521789551, "info_performance_mean": 0.46007493138313293, "info_performance_final": 0.5122189521789551, "step": 1144000}
{"episode_reward": 920.1498859563379, "episode": 11441.0, "batch_reward": 12.284046173095703, "critic_loss": 579.5866088867188, "actor_loss": -1711.05029296875, "actor_target_entropy": -3.0, "actor_entropy": 1.1272480487823486, "alpha_loss": -0.13080763816833496, "alpha_value": 0.3679041928450005, "duration": 1.5959501266479492, "info_normalized_performance_mean": 0.43864983320236206, "info_normalized_performance_final": 0.48456791043281555, "info_performance_mean": 0.43864983320236206, "info_performance_final": 0.48456791043281555, "step": 1144500}
{"episode_reward": 877.2993827160484, "episode": 11446.0, "batch_reward": 11.963415145874023, "critic_loss": 538.4193115234375, "actor_loss": -1689.3045654296875, "actor_target_entropy": -3.0, "actor_entropy": 1.2528066635131836, "alpha_loss": 0.04132253676652908, "alpha_value": 0.3709505454320264, "duration": 1.5943548679351807, "info_normalized_performance_mean": 0.727611243724823, "info_normalized_performance_final": 0.7811111211776733, "info_performance_mean": 0.727611243724823, "info_performance_final": 0.7811111211776733, "step": 1145000}
{"episode_reward": 1455.2222222222244, "episode": 11451.0, "batch_reward": 12.549968719482422, "critic_loss": 314.55322265625, "actor_loss": -1679.155517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.535861611366272, "alpha_loss": -0.20301668345928192, "alpha_value": 0.3765455720782081, "duration": 1.6186110973358154, "info_normalized_performance_mean": 0.6537153124809265, "info_normalized_performance_final": 0.7022569179534912, "info_performance_mean": 0.6537153124809265, "info_performance_final": 0.7022569179534912, "step": 1145500}
{"episode_reward": 1307.4305555555572, "episode": 11456.0, "batch_reward": 13.294740676879883, "critic_loss": 256.76361083984375, "actor_loss": -1719.663818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3932065963745117, "alpha_loss": -0.22640898823738098, "alpha_value": 0.3825768507430367, "duration": 1.5800364017486572, "info_normalized_performance_mean": 0.8052850365638733, "info_normalized_performance_final": 0.8977375626564026, "info_performance_mean": 0.8052850365638733, "info_performance_final": 0.8977375626564026, "step": 1146000}
{"episode_reward": 1610.5701357466055, "episode": 11461.0, "batch_reward": 13.882957458496094, "critic_loss": 208.8524169921875, "actor_loss": -1736.8148193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.4637882709503174, "alpha_loss": 0.14611127972602844, "alpha_value": 0.3865618823428538, "duration": 1.4930732250213623, "info_normalized_performance_mean": 0.7669833898544312, "info_normalized_performance_final": 0.8333333134651184, "info_performance_mean": 0.7669833898544312, "info_performance_final": 0.8333333134651184, "step": 1146500}
{"episode_reward": 1533.966666666668, "episode": 11466.0, "batch_reward": 12.217767715454102, "critic_loss": 245.6861114501953, "actor_loss": -1664.5972900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.4236000776290894, "alpha_loss": -0.06640911847352982, "alpha_value": 0.3867832893072086, "duration": 1.566204309463501, "info_normalized_performance_mean": 0.7816029191017151, "info_normalized_performance_final": 0.8397058844566345, "info_performance_mean": 0.7816029191017151, "info_performance_final": 0.8397058844566345, "step": 1147000}
{"episode_reward": 1563.205882352939, "episode": 11471.0, "batch_reward": 12.279718399047852, "critic_loss": 619.4937744140625, "actor_loss": -1685.59716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3356764316558838, "alpha_loss": -0.24563288688659668, "alpha_value": 0.388133003590042, "duration": 1.6603095531463623, "info_normalized_performance_mean": 0.35452955961227417, "info_normalized_performance_final": 0.4120813310146332, "info_performance_mean": 0.35452955961227417, "info_performance_final": 0.4120813310146332, "step": 1147500}
{"episode_reward": 709.0590111642757, "episode": 11476.0, "batch_reward": 12.179471015930176, "critic_loss": 368.6531677246094, "actor_loss": -1750.06005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1232014894485474, "alpha_loss": -0.133144810795784, "alpha_value": 0.38937358163714947, "duration": 1.6359398365020752, "info_normalized_performance_mean": 0.872245192527771, "info_normalized_performance_final": 0.9372549057006836, "info_performance_mean": 0.872245192527771, "info_performance_final": 0.9372549057006836, "step": 1148000}
{"episode_reward": 1744.4901960784316, "episode": 11481.0, "batch_reward": 13.294134140014648, "critic_loss": 224.2059783935547, "actor_loss": -1679.427978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.4685289859771729, "alpha_loss": 0.05654887109994888, "alpha_value": 0.39052548329337294, "duration": 1.52720046043396, "info_normalized_performance_mean": 0.5973516702651978, "info_normalized_performance_final": 0.6567104458808899, "info_performance_mean": 0.5973516702651978, "info_performance_final": 0.6567104458808899, "step": 1148500}
{"episode_reward": 1194.7033054559934, "episode": 11486.0, "batch_reward": 12.611964225769043, "critic_loss": 435.2519836425781, "actor_loss": -1750.974853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.190158724784851, "alpha_loss": -0.11266832053661346, "alpha_value": 0.3939873823821926, "duration": 1.5344288349151611, "info_normalized_performance_mean": 0.39569342136383057, "info_normalized_performance_final": 0.43534600734710693, "info_performance_mean": 0.39569342136383057, "info_performance_final": 0.43534600734710693, "step": 1149000}
{"episode_reward": 791.3868210642408, "episode": 11491.0, "batch_reward": 12.37105655670166, "critic_loss": 431.70306396484375, "actor_loss": -1705.1312255859375, "actor_target_entropy": -3.0, "actor_entropy": 1.056417465209961, "alpha_loss": 0.10108038783073425, "alpha_value": 0.40059851836506516, "duration": 1.537794589996338, "info_normalized_performance_mean": 0.3377993702888489, "info_normalized_performance_final": 0.37839505076408386, "info_performance_mean": 0.3377993702888489, "info_performance_final": 0.37839505076408386, "step": 1149500}
{"episode_reward": 675.5987654320986, "episode": 11496.0, "batch_reward": 12.581247329711914, "critic_loss": 334.95758056640625, "actor_loss": -1718.6630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.338378667831421, "alpha_loss": 0.09157726168632507, "alpha_value": 0.41011311118455585, "step": 1150000}
{"duration": 18.631067514419556, "info_normalized_performance_mean": 0.6786657571792603, "info_normalized_performance_final": 0.7371031641960144, "info_performance_mean": 0.6786657571792603, "info_performance_final": 0.7371031641960144, "step": 1150000}
{"episode_reward": 1357.3313492063517, "episode": 11501.0, "batch_reward": 12.446968078613281, "critic_loss": 428.3929443359375, "actor_loss": -1726.1195068359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2771220207214355, "alpha_loss": 0.06174411624670029, "alpha_value": 0.4150898862446626, "duration": 1.4617106914520264, "info_normalized_performance_mean": 0.5118204355239868, "info_normalized_performance_final": 0.555059552192688, "info_performance_mean": 0.5118204355239868, "info_performance_final": 0.555059552192688, "step": 1150500}
{"episode_reward": 1023.6408730158735, "episode": 11506.0, "batch_reward": 12.108696937561035, "critic_loss": 531.8554077148438, "actor_loss": -1665.71484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3327910900115967, "alpha_loss": -0.2606204152107239, "alpha_value": 0.42023109979283185, "duration": 1.5807652473449707, "info_normalized_performance_mean": 0.6634142994880676, "info_normalized_performance_final": 0.7171428799629211, "info_performance_mean": 0.6634142994880676, "info_performance_final": 0.7171428799629211, "step": 1151000}
{"episode_reward": 1326.8285714285723, "episode": 11511.0, "batch_reward": 12.083590507507324, "critic_loss": 361.4880065917969, "actor_loss": -1740.2861328125, "actor_target_entropy": -3.0, "actor_entropy": 1.186971664428711, "alpha_loss": -0.07879499346017838, "alpha_value": 0.4230863051632096, "duration": 1.5237689018249512, "info_normalized_performance_mean": 0.8850001692771912, "info_normalized_performance_final": 0.9535714387893677, "info_performance_mean": 0.8850001692771912, "info_performance_final": 0.9535714387893677, "step": 1151500}
{"episode_reward": 1770.0000000000034, "episode": 11516.0, "batch_reward": 11.998804092407227, "critic_loss": 794.728271484375, "actor_loss": -1671.613525390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1791218519210815, "alpha_loss": -0.17460604012012482, "alpha_value": 0.4249386335614181, "duration": 1.5238807201385498, "info_normalized_performance_mean": 0.4201588034629822, "info_normalized_performance_final": 0.4512471556663513, "info_performance_mean": 0.4201588034629822, "info_performance_final": 0.4512471556663513, "step": 1152000}
{"episode_reward": 840.3174603174599, "episode": 11521.0, "batch_reward": 12.661235809326172, "critic_loss": 391.2191162109375, "actor_loss": -1668.891845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6107555627822876, "alpha_loss": 0.06662319600582123, "alpha_value": 0.4263652308087563, "duration": 1.6036505699157715, "info_normalized_performance_mean": 0.44224369525909424, "info_normalized_performance_final": 0.49857550859451294, "info_performance_mean": 0.44224369525909424, "info_performance_final": 0.49857550859451294, "step": 1152500}
{"episode_reward": 884.4871794871784, "episode": 11526.0, "batch_reward": 13.295831680297852, "critic_loss": 536.4734497070312, "actor_loss": -1712.38330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2835007905960083, "alpha_loss": 0.14133557677268982, "alpha_value": 0.4271014591511464, "duration": 1.4846477508544922, "info_normalized_performance_mean": 0.11046876758337021, "info_normalized_performance_final": 0.1205357164144516, "info_performance_mean": 0.11046876758337021, "info_performance_final": 0.1205357164144516, "step": 1153000}
{"episode_reward": 220.93749999999983, "episode": 11531.0, "batch_reward": 12.607231140136719, "critic_loss": 778.2714233398438, "actor_loss": -1710.8597412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9714856743812561, "alpha_loss": 0.00707615539431572, "alpha_value": 0.4248514589658222, "duration": 1.4267067909240723, "info_normalized_performance_mean": 0.6848514080047607, "info_normalized_performance_final": 0.7435516119003296, "info_performance_mean": 0.6848514080047607, "info_performance_final": 0.7435516119003296, "step": 1153500}
{"episode_reward": 1369.7023809523841, "episode": 11536.0, "batch_reward": 13.173713684082031, "critic_loss": 498.6305236816406, "actor_loss": -1687.157470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2518099546432495, "alpha_loss": 0.1350899338722229, "alpha_value": 0.42552232709544596, "duration": 1.4532628059387207, "info_normalized_performance_mean": 0.5129464864730835, "info_normalized_performance_final": 0.5565476417541504, "info_performance_mean": 0.5129464864730835, "info_performance_final": 0.5565476417541504, "step": 1154000}
{"episode_reward": 1025.892857142859, "episode": 11541.0, "batch_reward": 12.900626182556152, "critic_loss": 281.47979736328125, "actor_loss": -1701.43017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2087788581848145, "alpha_loss": 0.12188152968883514, "alpha_value": 0.42384236106224293, "duration": 1.5381927490234375, "info_normalized_performance_mean": 0.8367063999176025, "info_normalized_performance_final": 0.9265872836112976, "info_performance_mean": 0.8367063999176025, "info_performance_final": 0.9265872836112976, "step": 1154500}
{"episode_reward": 1673.4126984126979, "episode": 11546.0, "batch_reward": 11.787969589233398, "critic_loss": 301.38916015625, "actor_loss": -1664.002197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.9913344383239746, "alpha_loss": -0.030764471739530563, "alpha_value": 0.4234199017535427, "duration": 1.7306578159332275, "info_normalized_performance_mean": 0.3201541602611542, "info_normalized_performance_final": 0.39926740527153015, "info_performance_mean": 0.3201541602611542, "info_performance_final": 0.39926740527153015, "step": 1155000}
{"episode_reward": 640.3083028083021, "episode": 11551.0, "batch_reward": 12.762138366699219, "critic_loss": 619.84326171875, "actor_loss": -1677.5367431640625, "actor_target_entropy": -3.0, "actor_entropy": 1.518873691558838, "alpha_loss": 0.054832134395837784, "alpha_value": 0.42582635534990176, "duration": 1.4386756420135498, "info_normalized_performance_mean": 0.5158928632736206, "info_normalized_performance_final": 0.5555555820465088, "info_performance_mean": 0.5158928632736206, "info_performance_final": 0.5555555820465088, "step": 1155500}
{"episode_reward": 1031.7857142857126, "episode": 11556.0, "batch_reward": 12.529901504516602, "critic_loss": 295.7843322753906, "actor_loss": -1673.098876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.539578914642334, "alpha_loss": -0.08278931677341461, "alpha_value": 0.42779346319552136, "duration": 1.4380462169647217, "info_normalized_performance_mean": 0.2029687464237213, "info_normalized_performance_final": 0.21875, "info_performance_mean": 0.2029687464237213, "info_performance_final": 0.21875, "step": 1156000}
{"episode_reward": 405.9375, "episode": 11561.0, "batch_reward": 12.932761192321777, "critic_loss": 398.3256530761719, "actor_loss": -1729.7073974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.7678145170211792, "alpha_loss": 0.17199298739433289, "alpha_value": 0.42968883015619813, "duration": 1.5413856506347656, "info_normalized_performance_mean": 0.3715743124485016, "info_normalized_performance_final": 0.439757376909256, "info_performance_mean": 0.3715743124485016, "info_performance_final": 0.439757376909256, "step": 1156500}
{"episode_reward": 743.1486076647375, "episode": 11566.0, "batch_reward": 12.384504318237305, "critic_loss": 305.3392333984375, "actor_loss": -1698.989990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.533437728881836, "alpha_loss": -0.07120723277330399, "alpha_value": 0.43065880556353686, "duration": 1.4726216793060303, "info_normalized_performance_mean": 0.4870288074016571, "info_normalized_performance_final": 0.5272817611694336, "info_performance_mean": 0.4870288074016571, "info_performance_final": 0.5272817611694336, "step": 1157000}
{"episode_reward": 974.0575396825408, "episode": 11571.0, "batch_reward": 12.763978958129883, "critic_loss": 285.1929016113281, "actor_loss": -1708.407470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.570168137550354, "alpha_loss": -0.06841397285461426, "alpha_value": 0.43086352816215717, "duration": 1.5640676021575928, "info_normalized_performance_mean": 0.4320175051689148, "info_normalized_performance_final": 0.47475001215934753, "info_performance_mean": 0.4320175051689148, "info_performance_final": 0.47475001215934753, "step": 1157500}
{"episode_reward": 864.0350000000003, "episode": 11576.0, "batch_reward": 11.807988166809082, "critic_loss": 349.77789306640625, "actor_loss": -1651.093505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.350067377090454, "alpha_loss": 0.07193619012832642, "alpha_value": 0.4290536728163108, "duration": 1.5313799381256104, "info_normalized_performance_mean": 0.5712401866912842, "info_normalized_performance_final": 0.6275985836982727, "info_performance_mean": 0.5712401866912842, "info_performance_final": 0.6275985836982727, "step": 1158000}
{"episode_reward": 1142.4802867383532, "episode": 11581.0, "batch_reward": 12.565895080566406, "critic_loss": 278.5692138671875, "actor_loss": -1680.099853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.4095975160598755, "alpha_loss": 0.300468385219574, "alpha_value": 0.4276689138459337, "duration": 1.4880266189575195, "info_normalized_performance_mean": 0.6217063069343567, "info_normalized_performance_final": 0.6860119104385376, "info_performance_mean": 0.6217063069343567, "info_performance_final": 0.6860119104385376, "step": 1158500}
{"episode_reward": 1243.412698412697, "episode": 11586.0, "batch_reward": 11.944767951965332, "critic_loss": 279.8990478515625, "actor_loss": -1693.69873046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8566694855690002, "alpha_loss": 0.044656965881586075, "alpha_value": 0.42515445127689416, "duration": 1.6267356872558594, "info_normalized_performance_mean": 0.811108410358429, "info_normalized_performance_final": 0.8891666531562805, "info_performance_mean": 0.811108410358429, "info_performance_final": 0.8891666531562805, "step": 1159000}
{"episode_reward": 1622.2166666666644, "episode": 11591.0, "batch_reward": 12.385934829711914, "critic_loss": 416.5618896484375, "actor_loss": -1687.92626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.2266271114349365, "alpha_loss": -0.01952427253127098, "alpha_value": 0.4239865723471724, "duration": 1.631044864654541, "info_normalized_performance_mean": 0.7632899284362793, "info_normalized_performance_final": 0.8168402910232544, "info_performance_mean": 0.7632899284362793, "info_performance_final": 0.8168402910232544, "step": 1159500}
{"episode_reward": 1526.5798611111136, "episode": 11596.0, "batch_reward": 13.414341926574707, "critic_loss": 187.04022216796875, "actor_loss": -1721.4765625, "actor_target_entropy": -3.0, "actor_entropy": 1.1010429859161377, "alpha_loss": 0.21386444568634033, "alpha_value": 0.42386642214264225, "step": 1160000}
{"duration": 18.72026777267456, "info_normalized_performance_mean": 0.8016785383224487, "info_normalized_performance_final": 0.8678571581840515, "info_performance_mean": 0.8016785383224487, "info_performance_final": 0.8678571581840515, "step": 1160000}
{"episode_reward": 1603.3571428571445, "episode": 11601.0, "batch_reward": 11.79638957977295, "critic_loss": 295.71527099609375, "actor_loss": -1699.517578125, "actor_target_entropy": -3.0, "actor_entropy": 0.5823964476585388, "alpha_loss": -0.044353872537612915, "alpha_value": 0.4236842213076621, "duration": 1.5237679481506348, "info_normalized_performance_mean": 0.5136023163795471, "info_normalized_performance_final": 0.5700549483299255, "info_performance_mean": 0.5136023163795471, "info_performance_final": 0.5700549483299255, "step": 1160500}
{"episode_reward": 1027.204670329669, "episode": 11606.0, "batch_reward": 12.103306770324707, "critic_loss": 286.20989990234375, "actor_loss": -1693.0885009765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8595831394195557, "alpha_loss": 0.04944774881005287, "alpha_value": 0.42152053353132934, "duration": 1.4797217845916748, "info_normalized_performance_mean": 0.7338215112686157, "info_normalized_performance_final": 0.8015305995941162, "info_performance_mean": 0.7338215112686157, "info_performance_final": 0.8015305995941162, "step": 1161000}
{"episode_reward": 1467.6428571428596, "episode": 11611.0, "batch_reward": 12.584768295288086, "critic_loss": 266.2005920410156, "actor_loss": -1720.559326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.567652940750122, "alpha_loss": 0.15243108570575714, "alpha_value": 0.4155357931535023, "duration": 1.396479845046997, "info_normalized_performance_mean": 0.46235713362693787, "info_normalized_performance_final": 0.5, "info_performance_mean": 0.46235713362693787, "info_performance_final": 0.5, "step": 1161500}
{"episode_reward": 924.7142857142858, "episode": 11616.0, "batch_reward": 12.238105773925781, "critic_loss": 393.6452331542969, "actor_loss": -1734.388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.096213459968567, "alpha_loss": -0.34112948179244995, "alpha_value": 0.4143500266530191, "duration": 1.5839776992797852, "info_normalized_performance_mean": 0.35733845829963684, "info_normalized_performance_final": 0.40789473056793213, "info_performance_mean": 0.35733845829963684, "info_performance_final": 0.40789473056793213, "step": 1162000}
{"episode_reward": 714.6770334928217, "episode": 11621.0, "batch_reward": 11.49337100982666, "critic_loss": 241.62417602539062, "actor_loss": -1651.69384765625, "actor_target_entropy": -3.0, "actor_entropy": 1.1149238348007202, "alpha_loss": -0.11656282842159271, "alpha_value": 0.41552101701759214, "duration": 1.6522459983825684, "info_normalized_performance_mean": 0.800443172454834, "info_normalized_performance_final": 0.8756613731384277, "info_performance_mean": 0.800443172454834, "info_performance_final": 0.8756613731384277, "step": 1162500}
{"episode_reward": 1600.8862433862453, "episode": 11626.0, "batch_reward": 12.402369499206543, "critic_loss": 307.46868896484375, "actor_loss": -1699.84765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8164083361625671, "alpha_loss": -0.15559616684913635, "alpha_value": 0.4166803806491781, "duration": 1.6035561561584473, "info_normalized_performance_mean": 0.5981097221374512, "info_normalized_performance_final": 0.6500721573829651, "info_performance_mean": 0.5981097221374512, "info_performance_final": 0.6500721573829651, "step": 1163000}
{"episode_reward": 1196.2193362193375, "episode": 11631.0, "batch_reward": 12.730812072753906, "critic_loss": 205.60568237304688, "actor_loss": -1708.873779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.375658392906189, "alpha_loss": 0.033376265317201614, "alpha_value": 0.4183689696136387, "duration": 1.5785069465637207, "info_normalized_performance_mean": 0.8122485876083374, "info_normalized_performance_final": 0.8809523582458496, "info_performance_mean": 0.8122485876083374, "info_performance_final": 0.8809523582458496, "step": 1163500}
{"episode_reward": 1624.4973544973564, "episode": 11636.0, "batch_reward": 11.995102882385254, "critic_loss": 284.15899658203125, "actor_loss": -1691.3671875, "actor_target_entropy": -3.0, "actor_entropy": 1.4528999328613281, "alpha_loss": -0.053573623299598694, "alpha_value": 0.4229289635093299, "duration": 1.508429765701294, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1164000}
{"episode_reward": 0.0, "episode": 11641.0, "batch_reward": 11.650508880615234, "critic_loss": 266.18768310546875, "actor_loss": -1674.71435546875, "actor_target_entropy": -3.0, "actor_entropy": 1.0949913263320923, "alpha_loss": -0.3265993595123291, "alpha_value": 0.43077373493684634, "duration": 1.5099294185638428, "info_normalized_performance_mean": 0.3171999752521515, "info_normalized_performance_final": 0.3477500081062317, "info_performance_mean": 0.3171999752521515, "info_performance_final": 0.3477500081062317, "step": 1164500}
{"episode_reward": 634.4000000000003, "episode": 11646.0, "batch_reward": 12.099666595458984, "critic_loss": 281.68896484375, "actor_loss": -1717.814208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.035233497619629, "alpha_loss": -0.23525407910346985, "alpha_value": 0.4446038982465212, "duration": 1.5332977771759033, "info_normalized_performance_mean": 0.45205196738243103, "info_normalized_performance_final": 0.4970131516456604, "info_performance_mean": 0.45205196738243103, "info_performance_final": 0.4970131516456604, "step": 1165000}
{"episode_reward": 904.10394265233, "episode": 11651.0, "batch_reward": 12.086519241333008, "critic_loss": 470.9553527832031, "actor_loss": -1668.951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.67180597782135, "alpha_loss": -0.5148884654045105, "alpha_value": 0.4589958346289267, "duration": 1.4535799026489258, "info_normalized_performance_mean": 0.509686291217804, "info_normalized_performance_final": 0.5490196347236633, "info_performance_mean": 0.509686291217804, "info_performance_final": 0.5490196347236633, "step": 1165500}
{"episode_reward": 1019.372549019609, "episode": 11656.0, "batch_reward": 12.359317779541016, "critic_loss": 356.4454650878906, "actor_loss": -1694.3897705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2132985591888428, "alpha_loss": -0.3234059512615204, "alpha_value": 0.4739688432445676, "duration": 1.6186535358428955, "info_normalized_performance_mean": 0.6998845934867859, "info_normalized_performance_final": 0.7590187788009644, "info_performance_mean": 0.6998845934867859, "info_performance_final": 0.7590187788009644, "step": 1166000}
{"episode_reward": 1399.769119769122, "episode": 11661.0, "batch_reward": 12.078048706054688, "critic_loss": 468.50115966796875, "actor_loss": -1730.019287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3137645721435547, "alpha_loss": -0.37994384765625, "alpha_value": 0.48844925943755274, "duration": 1.5283102989196777, "info_normalized_performance_mean": 0.8244643211364746, "info_normalized_performance_final": 0.8847402334213257, "info_performance_mean": 0.8244643211364746, "info_performance_final": 0.8847402334213257, "step": 1166500}
{"episode_reward": 1648.9285714285727, "episode": 11666.0, "batch_reward": 13.473661422729492, "critic_loss": 474.0875244140625, "actor_loss": -1801.292236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.457620620727539, "alpha_loss": -0.41769978404045105, "alpha_value": 0.5040082978062972, "duration": 1.6018593311309814, "info_normalized_performance_mean": 0.8104960918426514, "info_normalized_performance_final": 0.8690476417541504, "info_performance_mean": 0.8104960918426514, "info_performance_final": 0.8690476417541504, "step": 1167000}
{"episode_reward": 1620.9920634920616, "episode": 11671.0, "batch_reward": 12.017014503479004, "critic_loss": 268.69146728515625, "actor_loss": -1704.343505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.0348625183105469, "alpha_loss": -0.25810497999191284, "alpha_value": 0.5192160367477844, "duration": 1.4694316387176514, "info_normalized_performance_mean": 0.6282142400741577, "info_normalized_performance_final": 0.6822344064712524, "info_performance_mean": 0.6282142400741577, "info_performance_final": 0.6822344064712524, "step": 1167500}
{"episode_reward": 1256.4285714285725, "episode": 11676.0, "batch_reward": 11.932246208190918, "critic_loss": 338.91644287109375, "actor_loss": -1714.37939453125, "actor_target_entropy": -3.0, "actor_entropy": 1.2273449897766113, "alpha_loss": -0.36815977096557617, "alpha_value": 0.5335449840990074, "duration": 1.518033504486084, "info_normalized_performance_mean": 0.4443298280239105, "info_normalized_performance_final": 0.4774639308452606, "info_performance_mean": 0.4443298280239105, "info_performance_final": 0.4774639308452606, "step": 1168000}
{"episode_reward": 888.6598557692298, "episode": 11681.0, "batch_reward": 11.998516082763672, "critic_loss": 385.9296875, "actor_loss": -1725.057861328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0821683406829834, "alpha_loss": -0.2490411400794983, "alpha_value": 0.546667348124626, "duration": 1.531752347946167, "info_normalized_performance_mean": 0.7833505868911743, "info_normalized_performance_final": 0.8420138955116272, "info_performance_mean": 0.7833505868911743, "info_performance_final": 0.8420138955116272, "step": 1168500}
{"episode_reward": 1566.7013888888919, "episode": 11686.0, "batch_reward": 12.373709678649902, "critic_loss": 403.4461364746094, "actor_loss": -1747.699951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.6242196559906006, "alpha_loss": -0.1724025160074234, "alpha_value": 0.5588223298239597, "duration": 1.5757570266723633, "info_normalized_performance_mean": 0.7223125696182251, "info_normalized_performance_final": 0.7749999761581421, "info_performance_mean": 0.7223125696182251, "info_performance_final": 0.7749999761581421, "step": 1169000}
{"episode_reward": 1444.625, "episode": 11691.0, "batch_reward": 12.135612487792969, "critic_loss": 331.34442138671875, "actor_loss": -1772.2352294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3009848594665527, "alpha_loss": -0.00816376507282257, "alpha_value": 0.5708609799750812, "duration": 1.757194995880127, "info_normalized_performance_mean": 0.3967909514904022, "info_normalized_performance_final": 0.44871795177459717, "info_performance_mean": 0.3967909514904022, "info_performance_final": 0.44871795177459717, "step": 1169500}
{"episode_reward": 793.5817307692312, "episode": 11696.0, "batch_reward": 11.726405143737793, "critic_loss": 154.75274658203125, "actor_loss": -1768.54931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1988334655761719, "alpha_loss": -0.404532790184021, "alpha_value": 0.5829002659464371, "step": 1170000}
{"duration": 18.722283363342285, "info_normalized_performance_mean": 0.5127767324447632, "info_normalized_performance_final": 0.5896103978157043, "info_performance_mean": 0.5127767324447632, "info_performance_final": 0.5896103978157043, "step": 1170000}
{"episode_reward": 1025.5532467532482, "episode": 11701.0, "batch_reward": 11.877058982849121, "critic_loss": 337.2720947265625, "actor_loss": -1782.345458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.21514892578125, "alpha_loss": -0.2599881589412689, "alpha_value": 0.594838151026889, "duration": 1.5394299030303955, "info_normalized_performance_mean": 0.3005022406578064, "info_normalized_performance_final": 0.3322109878063202, "info_performance_mean": 0.3005022406578064, "info_performance_final": 0.3322109878063202, "step": 1170500}
{"episode_reward": 601.0044893378226, "episode": 11706.0, "batch_reward": 12.105184555053711, "critic_loss": 713.8326416015625, "actor_loss": -1772.0966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1548793315887451, "alpha_loss": -0.21101967990398407, "alpha_value": 0.6049791078163468, "duration": 1.513007640838623, "info_normalized_performance_mean": 0.5684340000152588, "info_normalized_performance_final": 0.6274038553237915, "info_performance_mean": 0.5684340000152588, "info_performance_final": 0.6274038553237915, "step": 1171000}
{"episode_reward": 1136.8681318681308, "episode": 11711.0, "batch_reward": 12.373997688293457, "critic_loss": 1125.559814453125, "actor_loss": -1816.264892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1669442653656006, "alpha_loss": -0.5307055115699768, "alpha_value": 0.6131428504888246, "duration": 1.4823806285858154, "info_normalized_performance_mean": 0.7115592956542969, "info_normalized_performance_final": 0.7645202279090881, "info_performance_mean": 0.7115592956542969, "info_performance_final": 0.7645202279090881, "step": 1171500}
{"episode_reward": 1423.1186868686839, "episode": 11716.0, "batch_reward": 13.376644134521484, "critic_loss": 317.4718017578125, "actor_loss": -1873.407470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.5604832172393799, "alpha_loss": 0.46028804779052734, "alpha_value": 0.6193318668597235, "duration": 1.5481042861938477, "info_normalized_performance_mean": 0.9102500081062317, "info_normalized_performance_final": 0.9964285492897034, "info_performance_mean": 0.9102500081062317, "info_performance_final": 0.9964285492897034, "step": 1172000}
{"episode_reward": 1820.4999999999968, "episode": 11721.0, "batch_reward": 11.849753379821777, "critic_loss": 279.57525634765625, "actor_loss": -1827.75927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9794371128082275, "alpha_loss": -0.18581166863441467, "alpha_value": 0.6202700852068319, "duration": 1.564465045928955, "info_normalized_performance_mean": 0.7688207030296326, "info_normalized_performance_final": 0.8344671130180359, "info_performance_mean": 0.7688207030296326, "info_performance_final": 0.8344671130180359, "step": 1172500}
{"episode_reward": 1537.6417233560103, "episode": 11726.0, "batch_reward": 12.476824760437012, "critic_loss": 425.90545654296875, "actor_loss": -1792.1719970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.167332649230957, "alpha_loss": 0.04403049498796463, "alpha_value": 0.617147662408621, "duration": 1.584963083267212, "info_normalized_performance_mean": 0.46873214840888977, "info_normalized_performance_final": 0.5144824385643005, "info_performance_mean": 0.46873214840888977, "info_performance_final": 0.5144824385643005, "step": 1173000}
{"episode_reward": 937.4643874643893, "episode": 11731.0, "batch_reward": 11.777252197265625, "critic_loss": 701.7486572265625, "actor_loss": -1834.509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0126241445541382, "alpha_loss": 0.00257129967212677, "alpha_value": 0.6113768961567081, "duration": 1.5725915431976318, "info_normalized_performance_mean": 0.438425749540329, "info_normalized_performance_final": 0.4855252206325531, "info_performance_mean": 0.438425749540329, "info_performance_final": 0.4855252206325531, "step": 1173500}
{"episode_reward": 876.8513923352625, "episode": 11736.0, "batch_reward": 12.148834228515625, "critic_loss": 200.13580322265625, "actor_loss": -1821.322998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1654586791992188, "alpha_loss": -0.06904435157775879, "alpha_value": 0.6056126064972143, "duration": 1.5839624404907227, "info_normalized_performance_mean": 0.8419998288154602, "info_normalized_performance_final": 0.9049019813537598, "info_performance_mean": 0.8419998288154602, "info_performance_final": 0.9049019813537598, "step": 1174000}
{"episode_reward": 1683.9999999999977, "episode": 11741.0, "batch_reward": 12.03693675994873, "critic_loss": 277.8197937011719, "actor_loss": -1818.013427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1825766563415527, "alpha_loss": 0.3132050633430481, "alpha_value": 0.5954659261731424, "duration": 1.6073999404907227, "info_normalized_performance_mean": 0.8665068745613098, "info_normalized_performance_final": 0.929411768913269, "info_performance_mean": 0.8665068745613098, "info_performance_final": 0.929411768913269, "step": 1174500}
{"episode_reward": 1733.013574660631, "episode": 11746.0, "batch_reward": 12.080921173095703, "critic_loss": 813.910888671875, "actor_loss": -1800.953125, "actor_target_entropy": -3.0, "actor_entropy": 0.931396484375, "alpha_loss": 0.08017716556787491, "alpha_value": 0.5837613978198654, "duration": 1.3414654731750488, "info_normalized_performance_mean": 0.4160715341567993, "info_normalized_performance_final": 0.4464285671710968, "info_performance_mean": 0.4160715341567993, "info_performance_final": 0.4464285671710968, "step": 1175000}
{"episode_reward": 832.142857142858, "episode": 11751.0, "batch_reward": 12.729654312133789, "critic_loss": 862.6939086914062, "actor_loss": -1834.6689453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7157419919967651, "alpha_loss": 0.0014122799038887024, "alpha_value": 0.5742993565766574, "duration": 1.516913652420044, "info_normalized_performance_mean": 0.9238520860671997, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9238520860671997, "info_performance_final": 1.0, "step": 1175500}
{"episode_reward": 1847.704081632653, "episode": 11756.0, "batch_reward": 12.761926651000977, "critic_loss": 174.2860870361328, "actor_loss": -1828.6361083984375, "actor_target_entropy": -3.0, "actor_entropy": 1.2610584497451782, "alpha_loss": 0.3384571075439453, "alpha_value": 0.562304899314517, "duration": 1.5571496486663818, "info_normalized_performance_mean": 0.8745181560516357, "info_normalized_performance_final": 0.9401041865348816, "info_performance_mean": 0.8745181560516357, "info_performance_final": 0.9401041865348816, "step": 1176000}
{"episode_reward": 1749.0364583333312, "episode": 11761.0, "batch_reward": 12.001239776611328, "critic_loss": 521.1660766601562, "actor_loss": -1808.15771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7085392475128174, "alpha_loss": 0.2600245773792267, "alpha_value": 0.5474197273472492, "duration": 1.594151258468628, "info_normalized_performance_mean": 0.7474372982978821, "info_normalized_performance_final": 0.8025000095367432, "info_performance_mean": 0.7474372982978821, "info_performance_final": 0.8025000095367432, "step": 1176500}
{"episode_reward": 1494.8749999999975, "episode": 11766.0, "batch_reward": 11.826000213623047, "critic_loss": 358.73291015625, "actor_loss": -1788.661865234375, "actor_target_entropy": -3.0, "actor_entropy": 0.9334467649459839, "alpha_loss": -0.0072874948382377625, "alpha_value": 0.5339573336773954, "duration": 1.5288496017456055, "info_normalized_performance_mean": 0.8722941875457764, "info_normalized_performance_final": 0.9372549057006836, "info_performance_mean": 0.8722941875457764, "info_performance_final": 0.9372549057006836, "step": 1177000}
{"episode_reward": 1744.588235294118, "episode": 11771.0, "batch_reward": 12.85030746459961, "critic_loss": 598.18310546875, "actor_loss": -1883.4866943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9146362543106079, "alpha_loss": 0.30835089087486267, "alpha_value": 0.5220255869945001, "duration": 1.5859639644622803, "info_normalized_performance_mean": 0.3523999750614166, "info_normalized_performance_final": 0.3890109956264496, "info_performance_mean": 0.3523999750614166, "info_performance_final": 0.3890109956264496, "step": 1177500}
{"episode_reward": 704.8000000000006, "episode": 11776.0, "batch_reward": 12.580411911010742, "critic_loss": 936.9417114257812, "actor_loss": -1857.657470703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9843108654022217, "alpha_loss": 0.16952267289161682, "alpha_value": 0.5108132827337417, "duration": 1.577399492263794, "info_normalized_performance_mean": 0.3311500549316406, "info_normalized_performance_final": 0.36924999952316284, "info_performance_mean": 0.3311500549316406, "info_performance_final": 0.36924999952316284, "step": 1178000}
{"episode_reward": 662.2999999999994, "episode": 11781.0, "batch_reward": 11.235322952270508, "critic_loss": 544.7047119140625, "actor_loss": -1763.489501953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1402214765548706, "alpha_loss": 0.20602329075336456, "alpha_value": 0.5009814362388572, "duration": 1.559708833694458, "info_normalized_performance_mean": 0.5669901967048645, "info_normalized_performance_final": 0.6078431606292725, "info_performance_mean": 0.5669901967048645, "info_performance_final": 0.6078431606292725, "step": 1178500}
{"episode_reward": 1133.9803921568619, "episode": 11786.0, "batch_reward": 12.469978332519531, "critic_loss": 434.053955078125, "actor_loss": -1832.1370849609375, "actor_target_entropy": -3.0, "actor_entropy": 1.0635027885437012, "alpha_loss": 0.3675222098827362, "alpha_value": 0.48794757949814394, "duration": 1.5212452411651611, "info_normalized_performance_mean": 0.6692013740539551, "info_normalized_performance_final": 0.734375, "info_performance_mean": 0.6692013740539551, "info_performance_final": 0.734375, "step": 1179000}
{"episode_reward": 1338.4027777777778, "episode": 11791.0, "batch_reward": 12.11822509765625, "critic_loss": 561.3136596679688, "actor_loss": -1837.8603515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7333859205245972, "alpha_loss": 0.24185466766357422, "alpha_value": 0.4779557905823166, "duration": 1.5183420181274414, "info_normalized_performance_mean": 0.42207813262939453, "info_normalized_performance_final": 0.4593621492385864, "info_performance_mean": 0.42207813262939453, "info_performance_final": 0.4593621492385864, "step": 1179500}
{"episode_reward": 844.1563786008248, "episode": 11796.0, "batch_reward": 12.316330909729004, "critic_loss": 195.17794799804688, "actor_loss": -1822.452392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.4651687145233154, "alpha_loss": 0.3535522222518921, "alpha_value": 0.4667421607749376, "step": 1180000}
{"duration": 18.833714246749878, "info_normalized_performance_mean": 0.8317724466323853, "info_normalized_performance_final": 0.9027777910232544, "info_performance_mean": 0.8317724466323853, "info_performance_final": 0.9027777910232544, "step": 1180000}
{"episode_reward": 1663.5449735449765, "episode": 11801.0, "batch_reward": 12.816973686218262, "critic_loss": 211.06825256347656, "actor_loss": -1814.1856689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.344547152519226, "alpha_loss": 0.48491328954696655, "alpha_value": 0.45575387511690213, "duration": 1.445359706878662, "info_normalized_performance_mean": 0.40562495589256287, "info_normalized_performance_final": 0.4348958432674408, "info_performance_mean": 0.40562495589256287, "info_performance_final": 0.4348958432674408, "step": 1180500}
{"episode_reward": 811.2499999999991, "episode": 11806.0, "batch_reward": 11.672503471374512, "critic_loss": 477.00531005859375, "actor_loss": -1759.45263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.742656946182251, "alpha_loss": 0.1752396821975708, "alpha_value": 0.4456153476168488, "duration": 1.5537188053131104, "info_normalized_performance_mean": 0.5868750810623169, "info_normalized_performance_final": 0.6535027623176575, "info_performance_mean": 0.5868750810623169, "info_performance_final": 0.6535027623176575, "step": 1181000}
{"episode_reward": 1173.749999999999, "episode": 11811.0, "batch_reward": 13.090307235717773, "critic_loss": 224.08360290527344, "actor_loss": -1829.73779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.1239467859268188, "alpha_loss": 0.24319282174110413, "alpha_value": 0.43433120209390635, "duration": 1.5843300819396973, "info_normalized_performance_mean": 0.8571531176567078, "info_normalized_performance_final": 0.9164705872535706, "info_performance_mean": 0.8571531176567078, "info_performance_final": 0.9164705872535706, "step": 1181500}
{"episode_reward": 1714.3058823529393, "episode": 11816.0, "batch_reward": 12.83377456665039, "critic_loss": 243.4446563720703, "actor_loss": -1794.1932373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1166975498199463, "alpha_loss": 0.5221707820892334, "alpha_value": 0.42421182894585757, "duration": 1.581982135772705, "info_normalized_performance_mean": 0.8105621337890625, "info_normalized_performance_final": 0.8836601376533508, "info_performance_mean": 0.8105621337890625, "info_performance_final": 0.8836601376533508, "step": 1182000}
{"episode_reward": 1621.1241830065355, "episode": 11821.0, "batch_reward": 12.264503479003906, "critic_loss": 215.19198608398438, "actor_loss": -1826.0650634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.7621681094169617, "alpha_loss": 0.13528218865394592, "alpha_value": 0.41542313621545457, "duration": 1.646848440170288, "info_normalized_performance_mean": 0.7169695496559143, "info_normalized_performance_final": 0.7784993052482605, "info_performance_mean": 0.7169695496559143, "info_performance_final": 0.7784993052482605, "step": 1182500}
{"episode_reward": 1433.939393939395, "episode": 11826.0, "batch_reward": 11.964495658874512, "critic_loss": 422.40618896484375, "actor_loss": -1740.27587890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9454923272132874, "alpha_loss": 0.17830540239810944, "alpha_value": 0.4060265666412251, "duration": 1.590526819229126, "info_normalized_performance_mean": 0.8795686364173889, "info_normalized_performance_final": 0.9431372284889221, "info_performance_mean": 0.8795686364173889, "info_performance_final": 0.9431372284889221, "step": 1183000}
{"episode_reward": 1759.1372549019572, "episode": 11831.0, "batch_reward": 12.46474838256836, "critic_loss": 308.043701171875, "actor_loss": -1783.714111328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8764528036117554, "alpha_loss": 0.2906988859176636, "alpha_value": 0.3969206849434256, "duration": 1.5625710487365723, "info_normalized_performance_mean": 0.8986718058586121, "info_normalized_performance_final": 0.9674479365348816, "info_performance_mean": 0.8986718058586121, "info_performance_final": 0.9674479365348816, "step": 1183500}
{"episode_reward": 1797.343749999998, "episode": 11836.0, "batch_reward": 12.21622085571289, "critic_loss": 1226.275146484375, "actor_loss": -1757.2060546875, "actor_target_entropy": -3.0, "actor_entropy": 0.823851466178894, "alpha_loss": 0.316434383392334, "alpha_value": 0.3866402856544449, "duration": 1.6088924407958984, "info_normalized_performance_mean": 0.5257881283760071, "info_normalized_performance_final": 0.5821462273597717, "info_performance_mean": 0.5257881283760071, "info_performance_final": 0.5821462273597717, "step": 1184000}
{"episode_reward": 1051.576448243115, "episode": 11841.0, "batch_reward": 12.99382209777832, "critic_loss": 708.502197265625, "actor_loss": -1779.1275634765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0861185789108276, "alpha_loss": 0.4137897193431854, "alpha_value": 0.3778130606608081, "duration": 1.5703778266906738, "info_normalized_performance_mean": 0.8311430215835571, "info_normalized_performance_final": 0.8928571343421936, "info_performance_mean": 0.8311430215835571, "info_performance_final": 0.8928571343421936, "step": 1184500}
{"episode_reward": 1662.285714285716, "episode": 11846.0, "batch_reward": 11.715337753295898, "critic_loss": 261.762451171875, "actor_loss": -1752.989990234375, "actor_target_entropy": -3.0, "actor_entropy": 0.3103795349597931, "alpha_loss": 0.02382799983024597, "alpha_value": 0.369356560434101, "duration": 1.4029936790466309, "info_normalized_performance_mean": 0.45437511801719666, "info_normalized_performance_final": 0.4937500059604645, "info_performance_mean": 0.45437511801719666, "info_performance_final": 0.4937500059604645, "step": 1185000}
{"episode_reward": 908.75, "episode": 11851.0, "batch_reward": 12.035160064697266, "critic_loss": 815.910400390625, "actor_loss": -1765.686279296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8219164609909058, "alpha_loss": 0.2864995002746582, "alpha_value": 0.36215942084237074, "duration": 1.6239590644836426, "info_normalized_performance_mean": 0.45804595947265625, "info_normalized_performance_final": 0.5120833516120911, "info_performance_mean": 0.45804595947265625, "info_performance_final": 0.5120833516120911, "step": 1185500}
{"episode_reward": 916.0916666666673, "episode": 11856.0, "batch_reward": 12.055715560913086, "critic_loss": 629.7151489257812, "actor_loss": -1744.592041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.7416920065879822, "alpha_loss": 0.16959747672080994, "alpha_value": 0.35408266143801304, "duration": 1.6410987377166748, "info_normalized_performance_mean": 0.384948194026947, "info_normalized_performance_final": 0.480063796043396, "info_performance_mean": 0.384948194026947, "info_performance_final": 0.480063796043396, "step": 1186000}
{"episode_reward": 769.8963317384362, "episode": 11861.0, "batch_reward": 11.803815841674805, "critic_loss": 347.56793212890625, "actor_loss": -1724.2247314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6226826906204224, "alpha_loss": 0.11830276250839233, "alpha_value": 0.34757108762925853, "duration": 1.4842536449432373, "info_normalized_performance_mean": 0.6047528386116028, "info_normalized_performance_final": 0.6497252583503723, "info_performance_mean": 0.6047528386116028, "info_performance_final": 0.6497252583503723, "step": 1186500}
{"episode_reward": 1209.5054945054947, "episode": 11866.0, "batch_reward": 12.162455558776855, "critic_loss": 165.44000244140625, "actor_loss": -1745.4688720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.8425460457801819, "alpha_loss": 0.11192744225263596, "alpha_value": 0.3417440695153616, "duration": 1.5278472900390625, "info_normalized_performance_mean": 0.5506216287612915, "info_normalized_performance_final": 0.6047390103340149, "info_performance_mean": 0.5506216287612915, "info_performance_final": 0.6047390103340149, "step": 1187000}
{"episode_reward": 1101.2431318681308, "episode": 11871.0, "batch_reward": 12.600115776062012, "critic_loss": 287.39703369140625, "actor_loss": -1749.044921875, "actor_target_entropy": -3.0, "actor_entropy": 0.6479209661483765, "alpha_loss": 0.18772703409194946, "alpha_value": 0.33517114761271616, "duration": 1.5511996746063232, "info_normalized_performance_mean": 0.5356379747390747, "info_normalized_performance_final": 0.5891926884651184, "info_performance_mean": 0.5356379747390747, "info_performance_final": 0.5891926884651184, "step": 1187500}
{"episode_reward": 1071.2760416666658, "episode": 11876.0, "batch_reward": 12.443410873413086, "critic_loss": 348.42230224609375, "actor_loss": -1731.84814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6715893745422363, "alpha_loss": 0.13842621445655823, "alpha_value": 0.3281540651977692, "duration": 1.5961148738861084, "info_normalized_performance_mean": 0.8017090559005737, "info_normalized_performance_final": 0.860909104347229, "info_performance_mean": 0.8017090559005737, "info_performance_final": 0.860909104347229, "step": 1188000}
{"episode_reward": 1603.418181818184, "episode": 11881.0, "batch_reward": 12.102239608764648, "critic_loss": 873.4136352539062, "actor_loss": -1722.2919921875, "actor_target_entropy": -3.0, "actor_entropy": -0.07356631755828857, "alpha_loss": -0.09204007685184479, "alpha_value": 0.32163568253153174, "duration": 1.598055124282837, "info_normalized_performance_mean": 0.7911750674247742, "info_normalized_performance_final": 0.8708333373069763, "info_performance_mean": 0.7911750674247742, "info_performance_final": 0.8708333373069763, "step": 1188500}
{"episode_reward": 1582.3500000000015, "episode": 11886.0, "batch_reward": 12.068166732788086, "critic_loss": 289.1238098144531, "actor_loss": -1734.976806640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8283877372741699, "alpha_loss": 0.18233206868171692, "alpha_value": 0.31573788457294644, "duration": 1.4920806884765625, "info_normalized_performance_mean": 0.6890525221824646, "info_normalized_performance_final": 0.7614087462425232, "info_performance_mean": 0.6890525221824646, "info_performance_final": 0.7614087462425232, "step": 1189000}
{"episode_reward": 1378.1051587301597, "episode": 11891.0, "batch_reward": 12.680122375488281, "critic_loss": 268.8370361328125, "actor_loss": -1728.622314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5707729458808899, "alpha_loss": 0.2408411055803299, "alpha_value": 0.30936139113682903, "duration": 1.5290184020996094, "info_normalized_performance_mean": 0.4141511619091034, "info_normalized_performance_final": 0.4591071903705597, "info_performance_mean": 0.4141511619091034, "info_performance_final": 0.4591071903705597, "step": 1189500}
{"episode_reward": 828.3023786249582, "episode": 11896.0, "batch_reward": 12.008369445800781, "critic_loss": 495.8289794921875, "actor_loss": -1670.107666015625, "actor_target_entropy": -3.0, "actor_entropy": 0.7530125379562378, "alpha_loss": 0.1391696333885193, "alpha_value": 0.30418043751393437, "step": 1190000}
{"duration": 18.6847186088562, "info_normalized_performance_mean": 0.500079333782196, "info_normalized_performance_final": 0.5500991940498352, "info_performance_mean": 0.500079333782196, "info_performance_final": 0.5500991940498352, "step": 1190000}
{"episode_reward": 1000.1587301587296, "episode": 11901.0, "batch_reward": 12.8363618850708, "critic_loss": 288.09796142578125, "actor_loss": -1712.894287109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9285076856613159, "alpha_loss": 0.23027244210243225, "alpha_value": 0.299280910361266, "duration": 1.5160961151123047, "info_normalized_performance_mean": 0.6552549600601196, "info_normalized_performance_final": 0.7182103395462036, "info_performance_mean": 0.6552549600601196, "info_performance_final": 0.7182103395462036, "step": 1190500}
{"episode_reward": 1310.5102040816334, "episode": 11906.0, "batch_reward": 11.646526336669922, "critic_loss": 1016.4332275390625, "actor_loss": -1677.420654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.42561763525009155, "alpha_loss": 0.06664633750915527, "alpha_value": 0.29440764858788104, "duration": 1.4821929931640625, "info_normalized_performance_mean": 0.6990857124328613, "info_normalized_performance_final": 0.7511574029922485, "info_performance_mean": 0.6990857124328613, "info_performance_final": 0.7511574029922485, "step": 1191000}
{"episode_reward": 1398.1712962962938, "episode": 11911.0, "batch_reward": 12.129352569580078, "critic_loss": 523.968017578125, "actor_loss": -1702.5047607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.48499035835266113, "alpha_loss": 0.13594818115234375, "alpha_value": 0.2897363520736806, "duration": 1.5276260375976562, "info_normalized_performance_mean": 0.6837988495826721, "info_normalized_performance_final": 0.7520292401313782, "info_performance_mean": 0.6837988495826721, "info_performance_final": 0.7520292401313782, "step": 1191500}
{"episode_reward": 1367.5974025973997, "episode": 11916.0, "batch_reward": 12.27935791015625, "critic_loss": 437.77117919921875, "actor_loss": -1671.1563720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.662522554397583, "alpha_loss": 0.13138750195503235, "alpha_value": 0.28516335386946656, "duration": 1.5714898109436035, "info_normalized_performance_mean": 0.29668545722961426, "info_normalized_performance_final": 0.3264583349227905, "info_performance_mean": 0.29668545722961426, "info_performance_final": 0.3264583349227905, "step": 1192000}
{"episode_reward": 593.3708333333327, "episode": 11921.0, "batch_reward": 12.149949073791504, "critic_loss": 193.77102661132812, "actor_loss": -1679.9822998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.7219933867454529, "alpha_loss": 0.22571083903312683, "alpha_value": 0.28240637274165453, "duration": 1.7454962730407715, "info_normalized_performance_mean": 0.511198103427887, "info_normalized_performance_final": 0.6237789988517761, "info_performance_mean": 0.511198103427887, "info_performance_final": 0.6237789988517761, "step": 1192500}
{"episode_reward": 1022.3962148962157, "episode": 11926.0, "batch_reward": 12.679519653320312, "critic_loss": 202.50526428222656, "actor_loss": -1675.83154296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7729926705360413, "alpha_loss": 0.21470311284065247, "alpha_value": 0.2811648516807791, "duration": 1.6185412406921387, "info_normalized_performance_mean": 0.6300818920135498, "info_normalized_performance_final": 0.6852678656578064, "info_performance_mean": 0.6300818920135498, "info_performance_final": 0.6852678656578064, "step": 1193000}
{"episode_reward": 1260.1636904761892, "episode": 11931.0, "batch_reward": 12.136226654052734, "critic_loss": 284.39263916015625, "actor_loss": -1658.730224609375, "actor_target_entropy": -3.0, "actor_entropy": 0.6070681810379028, "alpha_loss": 0.05577186867594719, "alpha_value": 0.27900890682389584, "duration": 1.494006872177124, "info_normalized_performance_mean": 0.47198978066444397, "info_normalized_performance_final": 0.5129513144493103, "info_performance_mean": 0.47198978066444397, "info_performance_final": 0.5129513144493103, "step": 1193500}
{"episode_reward": 943.9795918367329, "episode": 11936.0, "batch_reward": 11.859404563903809, "critic_loss": 339.28680419921875, "actor_loss": -1653.4195556640625, "actor_target_entropy": -3.0, "actor_entropy": 0.531306266784668, "alpha_loss": 0.1064457967877388, "alpha_value": 0.2759155157571511, "duration": 1.4638466835021973, "info_normalized_performance_mean": 0.7652380466461182, "info_normalized_performance_final": 0.8234127163887024, "info_performance_mean": 0.7652380466461182, "info_performance_final": 0.8234127163887024, "step": 1194000}
{"episode_reward": 1530.476190476191, "episode": 11941.0, "batch_reward": 12.144533157348633, "critic_loss": 334.5361022949219, "actor_loss": -1672.661865234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8831706047058105, "alpha_loss": 0.13373121619224548, "alpha_value": 0.2730576301389317, "duration": 1.6016690731048584, "info_normalized_performance_mean": 0.5776125192642212, "info_normalized_performance_final": 0.625, "info_performance_mean": 0.5776125192642212, "info_performance_final": 0.625, "step": 1194500}
{"episode_reward": 1155.225, "episode": 11946.0, "batch_reward": 11.912317276000977, "critic_loss": 364.4072265625, "actor_loss": -1645.316162109375, "actor_target_entropy": -3.0, "actor_entropy": 0.44782301783561707, "alpha_loss": -0.09731237590312958, "alpha_value": 0.2717520690544384, "duration": 1.6581635475158691, "info_normalized_performance_mean": 0.32880568504333496, "info_normalized_performance_final": 0.4076187014579773, "info_performance_mean": 0.32880568504333496, "info_performance_final": 0.4076187014579773, "step": 1195000}
{"episode_reward": 657.6113360323873, "episode": 11951.0, "batch_reward": 12.161081314086914, "critic_loss": 394.78662109375, "actor_loss": -1668.58349609375, "actor_target_entropy": -3.0, "actor_entropy": 0.28720203042030334, "alpha_loss": -0.11706296354532242, "alpha_value": 0.2713751808910913, "duration": 1.4722349643707275, "info_normalized_performance_mean": 0.5940971970558167, "info_normalized_performance_final": 0.6527777910232544, "info_performance_mean": 0.5940971970558167, "info_performance_final": 0.6527777910232544, "step": 1195500}
{"episode_reward": 1188.1944444444448, "episode": 11956.0, "batch_reward": 11.803422927856445, "critic_loss": 981.3239135742188, "actor_loss": -1655.9466552734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8408476114273071, "alpha_loss": -0.17177581787109375, "alpha_value": 0.2714984113368145, "duration": 1.5407657623291016, "info_normalized_performance_mean": 0.7952231764793396, "info_normalized_performance_final": 0.875, "info_performance_mean": 0.7952231764793396, "info_performance_final": 0.875, "step": 1196000}
{"episode_reward": 1590.4464285714284, "episode": 11961.0, "batch_reward": 12.615840911865234, "critic_loss": 839.492431640625, "actor_loss": -1709.52783203125, "actor_target_entropy": -3.0, "actor_entropy": 0.5602735877037048, "alpha_loss": -0.009564489126205444, "alpha_value": 0.2709479584773236, "duration": 1.483825445175171, "info_normalized_performance_mean": 0.6803826093673706, "info_normalized_performance_final": 0.7315050959587097, "info_performance_mean": 0.6803826093673706, "info_performance_final": 0.7315050959587097, "step": 1196500}
{"episode_reward": 1360.765306122452, "episode": 11966.0, "batch_reward": 11.324129104614258, "critic_loss": 276.5704650878906, "actor_loss": -1616.19580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.40077829360961914, "alpha_loss": -0.12163283675909042, "alpha_value": 0.27428586655649845, "duration": 1.5788609981536865, "info_normalized_performance_mean": 0.6696779131889343, "info_normalized_performance_final": 0.7298176884651184, "info_performance_mean": 0.6696779131889343, "info_performance_final": 0.7298176884651184, "step": 1197000}
{"episode_reward": 1339.3554687500007, "episode": 11971.0, "batch_reward": 11.659594535827637, "critic_loss": 444.27374267578125, "actor_loss": -1635.1026611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.532511830329895, "alpha_loss": -0.25350621342658997, "alpha_value": 0.27844516182311113, "duration": 1.508251667022705, "info_normalized_performance_mean": 0.4963064193725586, "info_normalized_performance_final": 0.5407986044883728, "info_performance_mean": 0.4963064193725586, "info_performance_final": 0.5407986044883728, "step": 1197500}
{"episode_reward": 992.6128472222202, "episode": 11976.0, "batch_reward": 13.38255500793457, "critic_loss": 128.5908966064453, "actor_loss": -1680.9163818359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9224541187286377, "alpha_loss": 0.02398695796728134, "alpha_value": 0.2842072431683269, "duration": 1.5155956745147705, "info_normalized_performance_mean": 0.6871833801269531, "info_normalized_performance_final": 0.7383333444595337, "info_performance_mean": 0.6871833801269531, "info_performance_final": 0.7383333444595337, "step": 1198000}
{"episode_reward": 1374.3666666666654, "episode": 11981.0, "batch_reward": 12.790728569030762, "critic_loss": 331.1782531738281, "actor_loss": -1692.904052734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8104398846626282, "alpha_loss": 0.029977701604366302, "alpha_value": 0.2892002338435559, "duration": 1.6134161949157715, "info_normalized_performance_mean": 0.4634125530719757, "info_normalized_performance_final": 0.5179166793823242, "info_performance_mean": 0.4634125530719757, "info_performance_final": 0.5179166793823242, "step": 1198500}
{"episode_reward": 926.8250000000012, "episode": 11986.0, "batch_reward": 11.946344375610352, "critic_loss": 472.94647216796875, "actor_loss": -1621.074462890625, "actor_target_entropy": -3.0, "actor_entropy": 0.5849518775939941, "alpha_loss": -0.2151256799697876, "alpha_value": 0.29650936386712307, "duration": 1.4737780094146729, "info_normalized_performance_mean": 0.6643196940422058, "info_normalized_performance_final": 0.7239229083061218, "info_performance_mean": 0.6643196940422058, "info_performance_final": 0.7239229083061218, "step": 1199000}
{"episode_reward": 1328.639455782311, "episode": 11991.0, "batch_reward": 11.921213150024414, "critic_loss": 345.739990234375, "actor_loss": -1615.263916015625, "actor_target_entropy": -3.0, "actor_entropy": 0.5278921127319336, "alpha_loss": -0.14970259368419647, "alpha_value": 0.3053178627794136, "duration": 1.5173954963684082, "info_normalized_performance_mean": 0.5633376836776733, "info_normalized_performance_final": 0.6119791865348816, "info_performance_mean": 0.5633376836776733, "info_performance_final": 0.6119791865348816, "step": 1199500}
{"episode_reward": 1126.6753472222229, "episode": 11996.0, "batch_reward": 11.892313957214355, "critic_loss": 281.0274963378906, "actor_loss": -1658.66455078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7262926697731018, "alpha_loss": -0.3300812244415283, "alpha_value": 0.31445506136835066, "step": 1200000}
{"duration": 18.77388882637024, "info_normalized_performance_mean": 0.47199997305870056, "info_normalized_performance_final": 0.5288095474243164, "info_performance_mean": 0.47199997305870056, "info_performance_final": 0.5288095474243164, "step": 1200000}
{"episode_reward": 944.0000000000017, "episode": 12001.0, "batch_reward": 12.07041072845459, "critic_loss": 162.062255859375, "actor_loss": -1585.470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0093669891357422, "alpha_loss": -0.06326007843017578, "alpha_value": 0.3222230188790279, "duration": 1.6068274974822998, "info_normalized_performance_mean": 0.5716699957847595, "info_normalized_performance_final": 0.6307500004768372, "info_performance_mean": 0.5716699957847595, "info_performance_final": 0.6307500004768372, "step": 1200500}
{"episode_reward": 1143.3400000000006, "episode": 12006.0, "batch_reward": 12.000642776489258, "critic_loss": 396.610595703125, "actor_loss": -1641.7447509765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8805406093597412, "alpha_loss": -0.20281772315502167, "alpha_value": 0.3296705531266286, "duration": 1.685603141784668, "info_normalized_performance_mean": 0.46607252955436707, "info_normalized_performance_final": 0.6610845327377319, "info_performance_mean": 0.46607252955436707, "info_performance_final": 0.6610845327377319, "step": 1201000}
{"episode_reward": 932.1451355661874, "episode": 12011.0, "batch_reward": 12.552355766296387, "critic_loss": 319.1789245605469, "actor_loss": -1671.26171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7341868877410889, "alpha_loss": -0.04929351806640625, "alpha_value": 0.3365892130378558, "duration": 1.4335885047912598, "info_normalized_performance_mean": 0.7535713315010071, "info_normalized_performance_final": 0.8184523582458496, "info_performance_mean": 0.7535713315010071, "info_performance_final": 0.8184523582458496, "step": 1201500}
{"episode_reward": 1507.1428571428585, "episode": 12016.0, "batch_reward": 12.230184555053711, "critic_loss": 145.44854736328125, "actor_loss": -1660.9520263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.7754123210906982, "alpha_loss": -0.25558724999427795, "alpha_value": 0.34286171598288856, "duration": 1.5462427139282227, "info_normalized_performance_mean": 0.4365977346897125, "info_normalized_performance_final": 0.4805624485015869, "info_performance_mean": 0.4365977346897125, "info_performance_final": 0.4805624485015869, "step": 1202000}
{"episode_reward": 873.1954783567697, "episode": 12021.0, "batch_reward": 12.380738258361816, "critic_loss": 287.47076416015625, "actor_loss": -1657.8599853515625, "actor_target_entropy": -3.0, "actor_entropy": 0.989778459072113, "alpha_loss": -0.03604171425104141, "alpha_value": 0.34736003600134663, "duration": 1.4884448051452637, "info_normalized_performance_mean": 0.6562445759773254, "info_normalized_performance_final": 0.713203489780426, "info_performance_mean": 0.6562445759773254, "info_performance_final": 0.713203489780426, "step": 1202500}
{"episode_reward": 1312.4891774891776, "episode": 12026.0, "batch_reward": 12.351686477661133, "critic_loss": 133.48275756835938, "actor_loss": -1638.109130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.817752480506897, "alpha_loss": -0.027112368494272232, "alpha_value": 0.34930944545072173, "duration": 1.4925751686096191, "info_normalized_performance_mean": 0.4290730953216553, "info_normalized_performance_final": 0.47336646914482117, "info_performance_mean": 0.4290730953216553, "info_performance_final": 0.47336646914482117, "step": 1203000}
{"episode_reward": 858.146306818181, "episode": 12031.0, "batch_reward": 12.523324966430664, "critic_loss": 274.23779296875, "actor_loss": -1655.767333984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8806281089782715, "alpha_loss": 0.23962169885635376, "alpha_value": 0.349605961402633, "duration": 1.4557197093963623, "info_normalized_performance_mean": 0.6385523080825806, "info_normalized_performance_final": 0.6862244606018066, "info_performance_mean": 0.6385523080825806, "info_performance_final": 0.6862244606018066, "step": 1203500}
{"episode_reward": 1277.1045918367322, "episode": 12036.0, "batch_reward": 12.43100357055664, "critic_loss": 632.2098388671875, "actor_loss": -1669.45849609375, "actor_target_entropy": -3.0, "actor_entropy": 0.6393019556999207, "alpha_loss": 0.13058708608150482, "alpha_value": 0.3505014757220286, "duration": 1.5362493991851807, "info_normalized_performance_mean": 0.7345453500747681, "info_normalized_performance_final": 0.7905844449996948, "info_performance_mean": 0.7345453500747681, "info_performance_final": 0.7905844449996948, "step": 1204000}
{"episode_reward": 1469.0909090909101, "episode": 12041.0, "batch_reward": 12.88199234008789, "critic_loss": 269.09600830078125, "actor_loss": -1660.74609375, "actor_target_entropy": -3.0, "actor_entropy": 0.610427975654602, "alpha_loss": -0.01608153060078621, "alpha_value": 0.350122709264129, "duration": 1.5382680892944336, "info_normalized_performance_mean": 0.40609562397003174, "info_normalized_performance_final": 0.4578189253807068, "info_performance_mean": 0.40609562397003174, "info_performance_final": 0.4578189253807068, "step": 1204500}
{"episode_reward": 812.1913580246897, "episode": 12046.0, "batch_reward": 11.757028579711914, "critic_loss": 452.65985107421875, "actor_loss": -1611.073974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.7360919713973999, "alpha_loss": -0.06295569986104965, "alpha_value": 0.3494408683250357, "duration": 1.5062503814697266, "info_normalized_performance_mean": 0.6011289358139038, "info_normalized_performance_final": 0.6447703838348389, "info_performance_mean": 0.6011289358139038, "info_performance_final": 0.6447703838348389, "step": 1205000}
{"episode_reward": 1202.2576530612241, "episode": 12051.0, "batch_reward": 13.325851440429688, "critic_loss": 395.04669189453125, "actor_loss": -1705.51513671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8444957733154297, "alpha_loss": 0.20108412206172943, "alpha_value": 0.34836956440753614, "duration": 1.5667800903320312, "info_normalized_performance_mean": 0.8089531064033508, "info_normalized_performance_final": 0.875, "info_performance_mean": 0.8089531064033508, "info_performance_final": 0.875, "step": 1205500}
{"episode_reward": 1617.90625, "episode": 12056.0, "batch_reward": 12.507705688476562, "critic_loss": 174.0193328857422, "actor_loss": -1664.153564453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6230765581130981, "alpha_loss": 0.16670703887939453, "alpha_value": 0.3467191387086462, "duration": 1.620173454284668, "info_normalized_performance_mean": 0.4073645770549774, "info_normalized_performance_final": 0.4556249976158142, "info_performance_mean": 0.4073645770549774, "info_performance_final": 0.4556249976158142, "step": 1206000}
{"episode_reward": 814.7291666666656, "episode": 12061.0, "batch_reward": 12.235584259033203, "critic_loss": 594.6517333984375, "actor_loss": -1664.5592041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.4928972125053406, "alpha_loss": 0.04782365262508392, "alpha_value": 0.3470665274693026, "duration": 1.5111291408538818, "info_normalized_performance_mean": 0.5854036211967468, "info_normalized_performance_final": 0.6302083134651184, "info_performance_mean": 0.5854036211967468, "info_performance_final": 0.6302083134651184, "step": 1206500}
{"episode_reward": 1170.8072916666663, "episode": 12066.0, "batch_reward": 12.007551193237305, "critic_loss": 347.37286376953125, "actor_loss": -1628.9295654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.6082993745803833, "alpha_loss": -0.10895711183547974, "alpha_value": 0.34436275701987534, "duration": 1.5213086605072021, "info_normalized_performance_mean": 0.5009725689888, "info_normalized_performance_final": 0.5453125238418579, "info_performance_mean": 0.5009725689888, "info_performance_final": 0.5453125238418579, "step": 1207000}
{"episode_reward": 1001.9453125, "episode": 12071.0, "batch_reward": 12.404549598693848, "critic_loss": 205.156494140625, "actor_loss": -1684.4168701171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7896482944488525, "alpha_loss": 0.06801605224609375, "alpha_value": 0.3426754528267313, "duration": 1.4239444732666016, "info_normalized_performance_mean": 0.5154018998146057, "info_normalized_performance_final": 0.5558035969734192, "info_performance_mean": 0.5154018998146057, "info_performance_final": 0.5558035969734192, "step": 1207500}
{"episode_reward": 1030.8035714285722, "episode": 12076.0, "batch_reward": 12.61367416381836, "critic_loss": 505.79766845703125, "actor_loss": -1682.07763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.6818329095840454, "alpha_loss": 0.05670605227351189, "alpha_value": 0.3377147652429873, "duration": 1.7374560832977295, "info_normalized_performance_mean": 0.4117213487625122, "info_normalized_performance_final": 0.4848126173019409, "info_performance_mean": 0.4117213487625122, "info_performance_final": 0.4848126173019409, "step": 1208000}
{"episode_reward": 823.4424720578554, "episode": 12081.0, "batch_reward": 12.496709823608398, "critic_loss": 283.72235107421875, "actor_loss": -1686.7279052734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7168470621109009, "alpha_loss": 0.10554499924182892, "alpha_value": 0.3350115930553858, "duration": 1.5779683589935303, "info_normalized_performance_mean": 0.4503612518310547, "info_normalized_performance_final": 0.4950000047683716, "info_performance_mean": 0.4503612518310547, "info_performance_final": 0.4950000047683716, "step": 1208500}
{"episode_reward": 900.7227272727259, "episode": 12086.0, "batch_reward": 11.63622760772705, "critic_loss": 322.9527282714844, "actor_loss": -1673.4930419921875, "actor_target_entropy": -3.0, "actor_entropy": 0.5648649334907532, "alpha_loss": 0.010931670665740967, "alpha_value": 0.3291667964215806, "duration": 1.5892746448516846, "info_normalized_performance_mean": 0.4551994204521179, "info_normalized_performance_final": 0.5135327577590942, "info_performance_mean": 0.4551994204521179, "info_performance_final": 0.5135327577590942, "step": 1209000}
{"episode_reward": 910.3988603988616, "episode": 12091.0, "batch_reward": 12.175783157348633, "critic_loss": 104.35782623291016, "actor_loss": -1618.397705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8058516383171082, "alpha_loss": 0.1585995852947235, "alpha_value": 0.3241120091393489, "duration": 1.440490961074829, "info_normalized_performance_mean": 0.22928130626678467, "info_normalized_performance_final": 0.24687500298023224, "info_performance_mean": 0.22928130626678467, "info_performance_final": 0.24687500298023224, "step": 1209500}
{"episode_reward": 458.5625, "episode": 12096.0, "batch_reward": 11.610414505004883, "critic_loss": 240.38475036621094, "actor_loss": -1653.8465576171875, "actor_target_entropy": -3.0, "actor_entropy": 0.696286678314209, "alpha_loss": 0.11135810613632202, "alpha_value": 0.31791751057267087, "step": 1210000}
{"duration": 19.022356510162354, "info_normalized_performance_mean": 0.563093364238739, "info_normalized_performance_final": 0.6047979593276978, "info_performance_mean": 0.563093364238739, "info_performance_final": 0.6047979593276978, "step": 1210000}
{"episode_reward": 1126.186868686868, "episode": 12101.0, "batch_reward": 12.375152587890625, "critic_loss": 333.2490234375, "actor_loss": -1658.949951171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8415164947509766, "alpha_loss": 0.14506900310516357, "alpha_value": 0.3126385370859732, "duration": 1.3331308364868164, "info_normalized_performance_mean": 0.46724990010261536, "info_normalized_performance_final": 0.5062500238418579, "info_performance_mean": 0.46724990010261536, "info_performance_final": 0.5062500238418579, "step": 1210500}
{"episode_reward": 934.5, "episode": 12106.0, "batch_reward": 11.937228202819824, "critic_loss": 275.52215576171875, "actor_loss": -1632.89794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.3156512379646301, "alpha_loss": 0.03179437667131424, "alpha_value": 0.30769750730588435, "duration": 1.617210865020752, "info_normalized_performance_mean": 0.6638118028640747, "info_normalized_performance_final": 0.7245370149612427, "info_performance_mean": 0.6638118028640747, "info_performance_final": 0.7245370149612427, "step": 1211000}
{"episode_reward": 1327.6234567901226, "episode": 12111.0, "batch_reward": 12.442499160766602, "critic_loss": 297.8095703125, "actor_loss": -1645.0126953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7016124129295349, "alpha_loss": 0.1967083215713501, "alpha_value": 0.30225327343523806, "duration": 1.610694408416748, "info_normalized_performance_mean": 0.5336393117904663, "info_normalized_performance_final": 0.5952577590942383, "info_performance_mean": 0.5336393117904663, "info_performance_final": 0.5952577590942383, "step": 1211500}
{"episode_reward": 1067.2787427626126, "episode": 12116.0, "batch_reward": 11.922212600708008, "critic_loss": 154.0027618408203, "actor_loss": -1676.20654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.5206190347671509, "alpha_loss": 0.08550682663917542, "alpha_value": 0.29839347148089634, "duration": 1.5375654697418213, "info_normalized_performance_mean": 0.83349609375, "info_normalized_performance_final": 0.90234375, "info_performance_mean": 0.83349609375, "info_performance_final": 0.90234375, "step": 1212000}
{"episode_reward": 1666.9921875, "episode": 12121.0, "batch_reward": 12.055153846740723, "critic_loss": 269.94427490234375, "actor_loss": -1630.0931396484375, "actor_target_entropy": -3.0, "actor_entropy": 0.5788353681564331, "alpha_loss": 0.13084542751312256, "alpha_value": 0.29323253625966583, "duration": 1.603304386138916, "info_normalized_performance_mean": 0.8266076445579529, "info_normalized_performance_final": 0.9049019813537598, "info_performance_mean": 0.8266076445579529, "info_performance_final": 0.9049019813537598, "step": 1212500}
{"episode_reward": 1653.2156862745078, "episode": 12126.0, "batch_reward": 12.846172332763672, "critic_loss": 311.76123046875, "actor_loss": -1667.7904052734375, "actor_target_entropy": -3.0, "actor_entropy": 0.6926056742668152, "alpha_loss": 0.2694125175476074, "alpha_value": 0.2870372929862748, "duration": 1.399756669998169, "info_normalized_performance_mean": 0.00013392856635618955, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.00013392856635618955, "info_performance_final": 0.0, "step": 1213000}
{"episode_reward": 0.26785714285714285, "episode": 12131.0, "batch_reward": 11.185626029968262, "critic_loss": 324.8777160644531, "actor_loss": -1607.6314697265625, "actor_target_entropy": -3.0, "actor_entropy": 0.5188809037208557, "alpha_loss": -0.11966992169618607, "alpha_value": 0.2831147944394055, "duration": 1.5538733005523682, "info_normalized_performance_mean": 0.6139250993728638, "info_normalized_performance_final": 0.6612499952316284, "info_performance_mean": 0.6139250993728638, "info_performance_final": 0.6612499952316284, "step": 1213500}
{"episode_reward": 1227.85, "episode": 12136.0, "batch_reward": 11.513420104980469, "critic_loss": 399.62548828125, "actor_loss": -1630.9208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.30006569623947144, "alpha_loss": -0.17628395557403564, "alpha_value": 0.28042555080306913, "duration": 1.4190199375152588, "info_normalized_performance_mean": 0.875999927520752, "info_normalized_performance_final": 0.9392856955528259, "info_performance_mean": 0.875999927520752, "info_performance_final": 0.9392856955528259, "step": 1214000}
{"episode_reward": 1751.9999999999986, "episode": 12141.0, "batch_reward": 12.01685905456543, "critic_loss": 179.14590454101562, "actor_loss": -1628.2149658203125, "actor_target_entropy": -3.0, "actor_entropy": 0.5423934459686279, "alpha_loss": -0.08495741337537766, "alpha_value": 0.27832368199623353, "duration": 1.6961541175842285, "info_normalized_performance_mean": 0.43605849146842957, "info_normalized_performance_final": 0.5144628286361694, "info_performance_mean": 0.43605849146842957, "info_performance_final": 0.5144628286361694, "step": 1214500}
{"episode_reward": 872.1169739351542, "episode": 12146.0, "batch_reward": 12.226780891418457, "critic_loss": 322.95751953125, "actor_loss": -1625.8507080078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7599449753761292, "alpha_loss": 0.07355571538209915, "alpha_value": 0.27625582027178286, "duration": 1.5257642269134521, "info_normalized_performance_mean": 0.8982738256454468, "info_normalized_performance_final": 0.966269850730896, "info_performance_mean": 0.8982738256454468, "info_performance_final": 0.966269850730896, "step": 1215000}
{"episode_reward": 1796.5476190476215, "episode": 12151.0, "batch_reward": 12.621678352355957, "critic_loss": 268.2953186035156, "actor_loss": -1651.8321533203125, "actor_target_entropy": -3.0, "actor_entropy": 0.6528830528259277, "alpha_loss": -0.11026150733232498, "alpha_value": 0.2754663205447185, "duration": 1.5391676425933838, "info_normalized_performance_mean": 0.9255209565162659, "info_normalized_performance_final": 0.9973958134651184, "info_performance_mean": 0.9255209565162659, "info_performance_final": 0.9973958134651184, "step": 1215500}
{"episode_reward": 1851.041666666669, "episode": 12156.0, "batch_reward": 12.598674774169922, "critic_loss": 367.98529052734375, "actor_loss": -1663.952880859375, "actor_target_entropy": -3.0, "actor_entropy": 0.8904390335083008, "alpha_loss": 0.06606154143810272, "alpha_value": 0.27697858437833306, "duration": 1.6368768215179443, "info_normalized_performance_mean": 0.804520845413208, "info_normalized_performance_final": 0.8770833611488342, "info_performance_mean": 0.804520845413208, "info_performance_final": 0.8770833611488342, "step": 1216000}
{"episode_reward": 1609.0416666666683, "episode": 12161.0, "batch_reward": 12.327479362487793, "critic_loss": 298.67254638671875, "actor_loss": -1659.356201171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7797788381576538, "alpha_loss": -0.08592095971107483, "alpha_value": 0.28045976732550465, "duration": 1.4830777645111084, "info_normalized_performance_mean": 0.5638020634651184, "info_normalized_performance_final": 0.609375, "info_performance_mean": 0.5638020634651184, "info_performance_final": 0.609375, "step": 1216500}
{"episode_reward": 1127.6041666666667, "episode": 12166.0, "batch_reward": 12.22459602355957, "critic_loss": 544.3155517578125, "actor_loss": -1656.99267578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6475157141685486, "alpha_loss": -0.011146657168865204, "alpha_value": 0.2832981604958452, "duration": 1.634796142578125, "info_normalized_performance_mean": 0.7424585223197937, "info_normalized_performance_final": 0.7986111044883728, "info_performance_mean": 0.7424585223197937, "info_performance_final": 0.7986111044883728, "step": 1217000}
{"episode_reward": 1484.9166666666638, "episode": 12171.0, "batch_reward": 11.8828125, "critic_loss": 289.8321533203125, "actor_loss": -1606.7437744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.48266279697418213, "alpha_loss": -0.15067294239997864, "alpha_value": 0.28538924123513526, "duration": 1.6065151691436768, "info_normalized_performance_mean": 0.8181598782539368, "info_normalized_performance_final": 0.8939999938011169, "info_performance_mean": 0.8181598782539368, "info_performance_final": 0.8939999938011169, "step": 1217500}
{"episode_reward": 1636.3200000000036, "episode": 12176.0, "batch_reward": 12.016164779663086, "critic_loss": 522.305908203125, "actor_loss": -1640.769775390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8000704646110535, "alpha_loss": -0.12933595478534698, "alpha_value": 0.2872025054584344, "duration": 1.5893447399139404, "info_normalized_performance_mean": 0.8133127093315125, "info_normalized_performance_final": 0.8762500286102295, "info_performance_mean": 0.8133127093315125, "info_performance_final": 0.8762500286102295, "step": 1218000}
{"episode_reward": 1626.6250000000023, "episode": 12181.0, "batch_reward": 12.017705917358398, "critic_loss": 109.47071075439453, "actor_loss": -1604.240478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7423340082168579, "alpha_loss": 0.01752195507287979, "alpha_value": 0.2906058059966475, "duration": 1.6521673202514648, "info_normalized_performance_mean": 0.7127977013587952, "info_normalized_performance_final": 0.773809552192688, "info_performance_mean": 0.7127977013587952, "info_performance_final": 0.773809552192688, "step": 1218500}
{"episode_reward": 1425.5952380952356, "episode": 12186.0, "batch_reward": 12.630619049072266, "critic_loss": 350.9400634765625, "actor_loss": -1601.2310791015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9947100281715393, "alpha_loss": 0.0026495931670069695, "alpha_value": 0.29414013579555714, "duration": 1.4984769821166992, "info_normalized_performance_mean": 0.4694317579269409, "info_normalized_performance_final": 0.5170454382896423, "info_performance_mean": 0.4694317579269409, "info_performance_final": 0.5170454382896423, "step": 1219000}
{"episode_reward": 938.863636363637, "episode": 12191.0, "batch_reward": 13.466056823730469, "critic_loss": 589.609130859375, "actor_loss": -1641.039794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.9596210718154907, "alpha_loss": 0.16462741792201996, "alpha_value": 0.2974462691715609, "duration": 1.4859564304351807, "info_normalized_performance_mean": 0.6304576396942139, "info_normalized_performance_final": 0.6852678656578064, "info_performance_mean": 0.6304576396942139, "info_performance_final": 0.6852678656578064, "step": 1219500}
{"episode_reward": 1260.9151785714273, "episode": 12196.0, "batch_reward": 12.394586563110352, "critic_loss": 265.7829284667969, "actor_loss": -1635.501220703125, "actor_target_entropy": -3.0, "actor_entropy": 0.7554045915603638, "alpha_loss": 0.04906674474477768, "alpha_value": 0.29857668150228284, "step": 1220000}
{"duration": 19.54151463508606, "info_normalized_performance_mean": 0.5059306025505066, "info_normalized_performance_final": 0.556934118270874, "info_performance_mean": 0.5059306025505066, "info_performance_final": 0.556934118270874, "step": 1220000}
{"episode_reward": 1011.8610421836242, "episode": 12201.0, "batch_reward": 12.61088752746582, "critic_loss": 244.21697998046875, "actor_loss": -1632.848876953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7789801359176636, "alpha_loss": 0.13198158144950867, "alpha_value": 0.2985363831665143, "duration": 1.5973773002624512, "info_normalized_performance_mean": 0.8685734272003174, "info_normalized_performance_final": 0.9470587968826294, "info_performance_mean": 0.8685734272003174, "info_performance_final": 0.9470587968826294, "step": 1220500}
{"episode_reward": 1737.1470588235327, "episode": 12206.0, "batch_reward": 11.992633819580078, "critic_loss": 230.79302978515625, "actor_loss": -1586.779052734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0250282287597656, "alpha_loss": 0.05879143625497818, "alpha_value": 0.2944586374696057, "duration": 1.558690071105957, "info_normalized_performance_mean": 0.9086408019065857, "info_normalized_performance_final": 0.979687511920929, "info_performance_mean": 0.9086408019065857, "info_performance_final": 0.979687511920929, "step": 1221000}
{"episode_reward": 1817.28125, "episode": 12211.0, "batch_reward": 11.101144790649414, "critic_loss": 1445.76220703125, "actor_loss": -1612.5650634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.5205636024475098, "alpha_loss": -0.15732961893081665, "alpha_value": 0.2922792475204562, "duration": 1.5362470149993896, "info_normalized_performance_mean": 0.8461877703666687, "info_normalized_performance_final": 0.909375011920929, "info_performance_mean": 0.8461877703666687, "info_performance_final": 0.909375011920929, "step": 1221500}
{"episode_reward": 1692.375, "episode": 12216.0, "batch_reward": 13.235747337341309, "critic_loss": 166.62451171875, "actor_loss": -1658.048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9081958532333374, "alpha_loss": 0.09616245329380035, "alpha_value": 0.28915579630521726, "duration": 1.4690577983856201, "info_normalized_performance_mean": 0.5601012706756592, "info_normalized_performance_final": 0.6089285612106323, "info_performance_mean": 0.5601012706756592, "info_performance_final": 0.6089285612106323, "step": 1222000}
{"episode_reward": 1120.2023809523812, "episode": 12221.0, "batch_reward": 12.620630264282227, "critic_loss": 136.52574157714844, "actor_loss": -1646.619384765625, "actor_target_entropy": -3.0, "actor_entropy": 1.5029239654541016, "alpha_loss": 0.024459347128868103, "alpha_value": 0.2878322166728397, "duration": 1.6218698024749756, "info_normalized_performance_mean": 0.4265212118625641, "info_normalized_performance_final": 0.45899471640586853, "info_performance_mean": 0.4265212118625641, "info_performance_final": 0.45899471640586853, "step": 1222500}
{"episode_reward": 853.0423280423279, "episode": 12226.0, "batch_reward": 12.342063903808594, "critic_loss": 196.596435546875, "actor_loss": -1619.3980712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6636255979537964, "alpha_loss": 0.03501969203352928, "alpha_value": 0.2866744421867262, "duration": 1.475860834121704, "info_normalized_performance_mean": 0.6093162298202515, "info_normalized_performance_final": 0.6556122303009033, "info_performance_mean": 0.6093162298202515, "info_performance_final": 0.6556122303009033, "step": 1223000}
{"episode_reward": 1218.6326530612243, "episode": 12231.0, "batch_reward": 11.554683685302734, "critic_loss": 440.12689208984375, "actor_loss": -1613.845947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0390384197235107, "alpha_loss": 0.08419159054756165, "alpha_value": 0.28436271484321723, "duration": 1.541658878326416, "info_normalized_performance_mean": 0.7254565358161926, "info_normalized_performance_final": 0.7800480723381042, "info_performance_mean": 0.7254565358161926, "info_performance_final": 0.7800480723381042, "step": 1223500}
{"episode_reward": 1450.9134615384592, "episode": 12236.0, "batch_reward": 12.320211410522461, "critic_loss": 664.2008056640625, "actor_loss": -1615.2745361328125, "actor_target_entropy": -3.0, "actor_entropy": 0.5277996063232422, "alpha_loss": 0.05914238467812538, "alpha_value": 0.2838923697480093, "duration": 1.392045259475708, "info_normalized_performance_mean": 0.6523213386535645, "info_normalized_performance_final": 0.699999988079071, "info_performance_mean": 0.6523213386535645, "info_performance_final": 0.699999988079071, "step": 1224000}
{"episode_reward": 1304.642857142857, "episode": 12241.0, "batch_reward": 11.696775436401367, "critic_loss": 182.24380493164062, "actor_loss": -1567.796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7355266809463501, "alpha_loss": -0.17129041254520416, "alpha_value": 0.28171650957877786, "duration": 1.6126437187194824, "info_normalized_performance_mean": 0.8266116380691528, "info_normalized_performance_final": 0.8905882239341736, "info_performance_mean": 0.8266116380691528, "info_performance_final": 0.8905882239341736, "step": 1224500}
{"episode_reward": 1653.223529411761, "episode": 12246.0, "batch_reward": 11.941389083862305, "critic_loss": 205.64617919921875, "actor_loss": -1570.4052734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7632439136505127, "alpha_loss": -0.057112470269203186, "alpha_value": 0.27844639072211463, "duration": 1.459991216659546, "info_normalized_performance_mean": 0.9075297713279724, "info_normalized_performance_final": 0.976190447807312, "info_performance_mean": 0.9075297713279724, "info_performance_final": 0.976190447807312, "step": 1225000}
{"episode_reward": 1815.059523809528, "episode": 12251.0, "batch_reward": 11.650850296020508, "critic_loss": 810.986328125, "actor_loss": -1578.0726318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.7139549255371094, "alpha_loss": 0.09966112673282623, "alpha_value": 0.278331281583701, "duration": 1.4664757251739502, "info_normalized_performance_mean": 0.5895312428474426, "info_normalized_performance_final": 0.6328125, "info_performance_mean": 0.5895312428474426, "info_performance_final": 0.6328125, "step": 1225500}
{"episode_reward": 1179.0625, "episode": 12256.0, "batch_reward": 12.050397872924805, "critic_loss": 141.45057678222656, "actor_loss": -1566.3475341796875, "actor_target_entropy": -3.0, "actor_entropy": 0.6828848123550415, "alpha_loss": 0.018018312752246857, "alpha_value": 0.28039219584151265, "duration": 1.4873523712158203, "info_normalized_performance_mean": 0.5121223330497742, "info_normalized_performance_final": 0.5520833134651184, "info_performance_mean": 0.5121223330497742, "info_performance_final": 0.5520833134651184, "step": 1226000}
{"episode_reward": 1024.2447916666654, "episode": 12261.0, "batch_reward": 12.478336334228516, "critic_loss": 172.01512145996094, "actor_loss": -1590.8583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.0396603345870972, "alpha_loss": 0.11918361485004425, "alpha_value": 0.2826262978196162, "duration": 1.610680103302002, "info_normalized_performance_mean": 0.7218794226646423, "info_normalized_performance_final": 0.7755101919174194, "info_performance_mean": 0.7218794226646423, "info_performance_final": 0.7755101919174194, "step": 1226500}
{"episode_reward": 1443.7585034013634, "episode": 12266.0, "batch_reward": 12.378326416015625, "critic_loss": 217.28787231445312, "actor_loss": -1607.3743896484375, "actor_target_entropy": -3.0, "actor_entropy": 0.698601245880127, "alpha_loss": -0.13895969092845917, "alpha_value": 0.2845517525218805, "duration": 1.5679914951324463, "info_normalized_performance_mean": 0.7979298233985901, "info_normalized_performance_final": 0.8645833134651184, "info_performance_mean": 0.7979298233985901, "info_performance_final": 0.8645833134651184, "step": 1227000}
{"episode_reward": 1595.8593750000016, "episode": 12271.0, "batch_reward": 11.461711883544922, "critic_loss": 280.33599853515625, "actor_loss": -1576.6912841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.28757423162460327, "alpha_loss": -0.19196026027202606, "alpha_value": 0.2857478547081154, "duration": 1.6171727180480957, "info_normalized_performance_mean": 0.7788867354393005, "info_normalized_performance_final": 0.837104082107544, "info_performance_mean": 0.7788867354393005, "info_performance_final": 0.837104082107544, "step": 1227500}
{"episode_reward": 1557.773755656106, "episode": 12276.0, "batch_reward": 11.502462387084961, "critic_loss": 171.70669555664062, "actor_loss": -1569.198974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.3943033218383789, "alpha_loss": -0.15425150096416473, "alpha_value": 0.287625078077903, "duration": 1.571544885635376, "info_normalized_performance_mean": 0.49115797877311707, "info_normalized_performance_final": 0.5417700409889221, "info_performance_mean": 0.49115797877311707, "info_performance_final": 0.5417700409889221, "step": 1228000}
{"episode_reward": 982.3159636062845, "episode": 12281.0, "batch_reward": 12.073195457458496, "critic_loss": 166.49557495117188, "actor_loss": -1582.655029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9451590180397034, "alpha_loss": 0.0044064000248909, "alpha_value": 0.28895710115543755, "duration": 1.743283748626709, "info_normalized_performance_mean": 0.6248458623886108, "info_normalized_performance_final": 0.7516788840293884, "info_performance_mean": 0.6248458623886108, "info_performance_final": 0.7516788840293884, "step": 1228500}
{"episode_reward": 1249.6916971916958, "episode": 12286.0, "batch_reward": 11.335601806640625, "critic_loss": 228.36993408203125, "actor_loss": -1555.9381103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7339369058609009, "alpha_loss": -0.11447001248598099, "alpha_value": 0.28917997998335876, "duration": 1.6149814128875732, "info_normalized_performance_mean": 0.846568763256073, "info_normalized_performance_final": 0.9098039269447327, "info_performance_mean": 0.846568763256073, "info_performance_final": 0.9098039269447327, "step": 1229000}
{"episode_reward": 1693.1372549019636, "episode": 12291.0, "batch_reward": 13.552865982055664, "critic_loss": 221.45687866210938, "actor_loss": -1633.131591796875, "actor_target_entropy": -3.0, "actor_entropy": 0.822232186794281, "alpha_loss": 0.221066415309906, "alpha_value": 0.287234466194085, "duration": 1.4746320247650146, "info_normalized_performance_mean": 0.49504074454307556, "info_normalized_performance_final": 0.5377551317214966, "info_performance_mean": 0.49504074454307556, "info_performance_final": 0.5377551317214966, "step": 1229500}
{"episode_reward": 990.0816326530637, "episode": 12296.0, "batch_reward": 12.306756019592285, "critic_loss": 671.5868530273438, "actor_loss": -1531.91015625, "actor_target_entropy": -3.0, "actor_entropy": 1.0756404399871826, "alpha_loss": 0.06468622386455536, "alpha_value": 0.2838765204671679, "step": 1230000}
{"duration": 18.864065885543823, "info_normalized_performance_mean": 0.6519685983657837, "info_normalized_performance_final": 0.699999988079071, "info_performance_mean": 0.6519685983657837, "info_performance_final": 0.699999988079071, "step": 1230000}
{"episode_reward": 1303.9375, "episode": 12301.0, "batch_reward": 12.520519256591797, "critic_loss": 419.0632019042969, "actor_loss": -1622.9405517578125, "actor_target_entropy": -3.0, "actor_entropy": 0.5402213335037231, "alpha_loss": -0.19015266001224518, "alpha_value": 0.2794383797367562, "duration": 1.555018663406372, "info_normalized_performance_mean": 0.8606874942779541, "info_normalized_performance_final": 0.9281250238418579, "info_performance_mean": 0.8606874942779541, "info_performance_final": 0.9281250238418579, "step": 1230500}
{"episode_reward": 1721.375, "episode": 12306.0, "batch_reward": 12.178909301757812, "critic_loss": 298.2237243652344, "actor_loss": -1554.423583984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8144280910491943, "alpha_loss": 0.07590977847576141, "alpha_value": 0.27491582097883954, "duration": 1.632882833480835, "info_normalized_performance_mean": 0.7533547878265381, "info_normalized_performance_final": 0.8203462958335876, "info_performance_mean": 0.7533547878265381, "info_performance_final": 0.8203462958335876, "step": 1231000}
{"episode_reward": 1506.7099567099597, "episode": 12311.0, "batch_reward": 12.375940322875977, "critic_loss": 422.81365966796875, "actor_loss": -1575.86669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8371220827102661, "alpha_loss": 0.03345287963747978, "alpha_value": 0.27142047606737313, "duration": 1.513850450515747, "info_normalized_performance_mean": 0.41506507992744446, "info_normalized_performance_final": 0.4514974057674408, "info_performance_mean": 0.41506507992744446, "info_performance_final": 0.4514974057674408, "step": 1231500}
{"episode_reward": 830.1302083333325, "episode": 12316.0, "batch_reward": 12.61889362335205, "critic_loss": 320.78668212890625, "actor_loss": -1548.77392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1279387474060059, "alpha_loss": 0.2727845013141632, "alpha_value": 0.26750972608896095, "duration": 1.5625901222229004, "info_normalized_performance_mean": 0.8107953071594238, "info_normalized_performance_final": 0.8849431872367859, "info_performance_mean": 0.8107953071594238, "info_performance_final": 0.8849431872367859, "step": 1232000}
{"episode_reward": 1621.5909090909122, "episode": 12321.0, "batch_reward": 12.386110305786133, "critic_loss": 338.7996520996094, "actor_loss": -1584.73291015625, "actor_target_entropy": -3.0, "actor_entropy": 0.8035089373588562, "alpha_loss": -0.012146037071943283, "alpha_value": 0.2649358828423773, "duration": 1.5323059558868408, "info_normalized_performance_mean": 0.9299777150154114, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9299777150154114, "info_performance_final": 1.0, "step": 1232500}
{"episode_reward": 1859.955357142857, "episode": 12326.0, "batch_reward": 12.553838729858398, "critic_loss": 353.64776611328125, "actor_loss": -1647.3128662109375, "actor_target_entropy": -3.0, "actor_entropy": 0.5680453777313232, "alpha_loss": 0.008028833195567131, "alpha_value": 0.2634214523758681, "duration": 1.5862882137298584, "info_normalized_performance_mean": 0.8065124750137329, "info_normalized_performance_final": 0.8675000071525574, "info_performance_mean": 0.8065124750137329, "info_performance_final": 0.8675000071525574, "step": 1233000}
{"episode_reward": 1613.0249999999978, "episode": 12331.0, "batch_reward": 12.149746894836426, "critic_loss": 212.4556427001953, "actor_loss": -1520.061767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.20997154712677, "alpha_loss": 0.10623149573802948, "alpha_value": 0.2623703875580334, "duration": 1.484679937362671, "info_normalized_performance_mean": 0.6386440992355347, "info_normalized_performance_final": 0.6947544813156128, "info_performance_mean": 0.6386440992355347, "info_performance_final": 0.6947544813156128, "step": 1233500}
{"episode_reward": 1277.2879464285718, "episode": 12336.0, "batch_reward": 12.515135765075684, "critic_loss": 192.87034606933594, "actor_loss": -1577.249267578125, "actor_target_entropy": -3.0, "actor_entropy": 0.8545030355453491, "alpha_loss": 0.03436872735619545, "alpha_value": 0.26375336638534463, "duration": 1.4226775169372559, "info_normalized_performance_mean": 0.8044641017913818, "info_normalized_performance_final": 0.8571428656578064, "info_performance_mean": 0.8044641017913818, "info_performance_final": 0.8571428656578064, "step": 1234000}
{"episode_reward": 1608.9285714285697, "episode": 12341.0, "batch_reward": 12.159724235534668, "critic_loss": 291.191650390625, "actor_loss": -1531.01708984375, "actor_target_entropy": -3.0, "actor_entropy": 0.5578336715698242, "alpha_loss": 0.018288269639015198, "alpha_value": 0.26211528046053495, "duration": 1.4842851161956787, "info_normalized_performance_mean": 0.8459897041320801, "info_normalized_performance_final": 0.9114583134651184, "info_performance_mean": 0.8459897041320801, "info_performance_final": 0.9114583134651184, "step": 1234500}
{"episode_reward": 1691.9791666666686, "episode": 12346.0, "batch_reward": 12.49907112121582, "critic_loss": 296.8980407714844, "actor_loss": -1581.4967041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9058523178100586, "alpha_loss": -0.033373285084962845, "alpha_value": 0.26133181280875445, "duration": 1.555701732635498, "info_normalized_performance_mean": 0.6036979556083679, "info_normalized_performance_final": 0.6578776240348816, "info_performance_mean": 0.6036979556083679, "info_performance_final": 0.6578776240348816, "step": 1235000}
{"episode_reward": 1207.3958333333335, "episode": 12351.0, "batch_reward": 11.922216415405273, "critic_loss": 768.34619140625, "actor_loss": -1587.127685546875, "actor_target_entropy": -3.0, "actor_entropy": 0.6708580255508423, "alpha_loss": 0.011555969715118408, "alpha_value": 0.26029119851475185, "duration": 1.6323282718658447, "info_normalized_performance_mean": 0.7478139996528625, "info_normalized_performance_final": 0.8030303120613098, "info_performance_mean": 0.7478139996528625, "info_performance_final": 0.8030303120613098, "step": 1235500}
{"episode_reward": 1495.6277056277022, "episode": 12356.0, "batch_reward": 11.946155548095703, "critic_loss": 1265.570556640625, "actor_loss": -1557.017822265625, "actor_target_entropy": -3.0, "actor_entropy": 0.6312867403030396, "alpha_loss": -0.01237240806221962, "alpha_value": 0.2594412976356653, "duration": 1.6475296020507812, "info_normalized_performance_mean": 0.8616964817047119, "info_normalized_performance_final": 0.9275793433189392, "info_performance_mean": 0.8616964817047119, "info_performance_final": 0.9275793433189392, "step": 1236000}
{"episode_reward": 1723.3928571428555, "episode": 12361.0, "batch_reward": 11.977038383483887, "critic_loss": 152.24490356445312, "actor_loss": -1585.949462890625, "actor_target_entropy": -3.0, "actor_entropy": 0.2358623594045639, "alpha_loss": 0.021777711808681488, "alpha_value": 0.2580354719971002, "duration": 1.7385668754577637, "info_normalized_performance_mean": 0.4509996175765991, "info_normalized_performance_final": 0.5173236131668091, "info_performance_mean": 0.4509996175765991, "info_performance_final": 0.5173236131668091, "step": 1236500}
{"episode_reward": 901.9993642720907, "episode": 12366.0, "batch_reward": 12.689434051513672, "critic_loss": 285.55157470703125, "actor_loss": -1559.751708984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8890376687049866, "alpha_loss": 0.028170442208647728, "alpha_value": 0.2561678813895536, "duration": 1.5155308246612549, "info_normalized_performance_mean": 0.6652211546897888, "info_normalized_performance_final": 0.7270408272743225, "info_performance_mean": 0.6652211546897888, "info_performance_final": 0.7270408272743225, "step": 1237000}
{"episode_reward": 1330.4421768707477, "episode": 12371.0, "batch_reward": 12.289960861206055, "critic_loss": 514.845703125, "actor_loss": -1527.96337890625, "actor_target_entropy": -3.0, "actor_entropy": 0.4552570581436157, "alpha_loss": 0.009542800486087799, "alpha_value": 0.2554700443106112, "duration": 1.5286803245544434, "info_normalized_performance_mean": 0.7923436760902405, "info_normalized_performance_final": 0.8463541865348816, "info_performance_mean": 0.7923436760902405, "info_performance_final": 0.8463541865348816, "step": 1237500}
{"episode_reward": 1584.6874999999984, "episode": 12376.0, "batch_reward": 11.452224731445312, "critic_loss": 266.8437194824219, "actor_loss": -1537.2669677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.35091832280158997, "alpha_loss": -0.1204652339220047, "alpha_value": 0.2552779740847113, "duration": 1.6249048709869385, "info_normalized_performance_mean": 0.7789919972419739, "info_normalized_performance_final": 0.8452380895614624, "info_performance_mean": 0.7789919972419739, "info_performance_final": 0.8452380895614624, "step": 1238000}
{"episode_reward": 1557.9841269841286, "episode": 12381.0, "batch_reward": 12.729854583740234, "critic_loss": 217.1674346923828, "actor_loss": -1560.519287109375, "actor_target_entropy": -3.0, "actor_entropy": 0.7833251953125, "alpha_loss": 0.021040890365839005, "alpha_value": 0.2546360409001565, "duration": 1.5868239402770996, "info_normalized_performance_mean": 0.5331944823265076, "info_normalized_performance_final": 0.5895061492919922, "info_performance_mean": 0.5331944823265076, "info_performance_final": 0.5895061492919922, "step": 1238500}
{"episode_reward": 1066.3888888888864, "episode": 12386.0, "batch_reward": 11.950098991394043, "critic_loss": 144.59201049804688, "actor_loss": -1542.48974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.7609162926673889, "alpha_loss": 0.1484825760126114, "alpha_value": 0.25477416884803056, "duration": 1.5814199447631836, "info_normalized_performance_mean": 0.8067119121551514, "info_normalized_performance_final": 0.875283420085907, "info_performance_mean": 0.8067119121551514, "info_performance_final": 0.875283420085907, "step": 1239000}
{"episode_reward": 1613.424036281183, "episode": 12391.0, "batch_reward": 12.00741195678711, "critic_loss": 155.78814697265625, "actor_loss": -1511.6920166015625, "actor_target_entropy": -3.0, "actor_entropy": 0.5370371341705322, "alpha_loss": -0.008862413465976715, "alpha_value": 0.25272677488424744, "duration": 1.4809253215789795, "info_normalized_performance_mean": 0.6408424377441406, "info_normalized_performance_final": 0.6862027049064636, "info_performance_mean": 0.6408424377441406, "info_performance_final": 0.6862027049064636, "step": 1239500}
{"episode_reward": 1281.6849816849813, "episode": 12396.0, "batch_reward": 12.31744384765625, "critic_loss": 513.8016357421875, "actor_loss": -1545.227783203125, "actor_target_entropy": -3.0, "actor_entropy": 0.8387416005134583, "alpha_loss": 0.019658192992210388, "alpha_value": 0.25542321588432315, "step": 1240000}
{"duration": 18.793734312057495, "info_normalized_performance_mean": 0.6479763984680176, "info_normalized_performance_final": 0.6988235116004944, "info_performance_mean": 0.6479763984680176, "info_performance_final": 0.6988235116004944, "step": 1240000}
{"episode_reward": 1295.952941176472, "episode": 12401.0, "batch_reward": 12.574644088745117, "critic_loss": 117.74983215332031, "actor_loss": -1528.81396484375, "actor_target_entropy": -3.0, "actor_entropy": 0.9156594276428223, "alpha_loss": 0.07447013258934021, "alpha_value": 0.2566402812541974, "duration": 1.6354200839996338, "info_normalized_performance_mean": 0.6648959517478943, "info_normalized_performance_final": 0.722470223903656, "info_performance_mean": 0.6648959517478943, "info_performance_final": 0.722470223903656, "step": 1240500}
{"episode_reward": 1329.7916666666697, "episode": 12406.0, "batch_reward": 11.94679069519043, "critic_loss": 324.335205078125, "actor_loss": -1521.39599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2642912864685059, "alpha_loss": 0.08356843888759613, "alpha_value": 0.25546087779375537, "duration": 1.5528285503387451, "info_normalized_performance_mean": 0.8239200711250305, "info_normalized_performance_final": 0.8859999775886536, "info_performance_mean": 0.8239200711250305, "info_performance_final": 0.8859999775886536, "step": 1241000}
{"episode_reward": 1647.840000000002, "episode": 12411.0, "batch_reward": 12.75441837310791, "critic_loss": 121.93806457519531, "actor_loss": -1560.7313232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9618488550186157, "alpha_loss": 0.03516880422830582, "alpha_value": 0.25617880251218167, "duration": 1.5121729373931885, "info_normalized_performance_mean": 0.9264323711395264, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9264323711395264, "info_performance_final": 1.0, "step": 1241500}
{"episode_reward": 1852.8645833333333, "episode": 12416.0, "batch_reward": 12.581932067871094, "critic_loss": 201.78697204589844, "actor_loss": -1568.1455078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7786178588867188, "alpha_loss": 0.10321460664272308, "alpha_value": 0.25521436183659957, "duration": 1.6171503067016602, "info_normalized_performance_mean": 0.6882671117782593, "info_normalized_performance_final": 0.7493386268615723, "info_performance_mean": 0.6882671117782593, "info_performance_final": 0.7493386268615723, "step": 1242000}
{"episode_reward": 1376.53439153439, "episode": 12421.0, "batch_reward": 12.13786506652832, "critic_loss": 250.0179443359375, "actor_loss": -1561.7637939453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5793737173080444, "alpha_loss": -0.03404425084590912, "alpha_value": 0.253512622521844, "duration": 1.7533988952636719, "info_normalized_performance_mean": 0.3897120952606201, "info_normalized_performance_final": 0.45197996497154236, "info_performance_mean": 0.3897120952606201, "info_performance_final": 0.45197996497154236, "step": 1242500}
{"episode_reward": 779.4242148384158, "episode": 12426.0, "batch_reward": 12.112713813781738, "critic_loss": 185.87489318847656, "actor_loss": -1548.9718017578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6761288642883301, "alpha_loss": -0.10335355997085571, "alpha_value": 0.2506146147147917, "duration": 1.7319741249084473, "info_normalized_performance_mean": 0.7178027629852295, "info_normalized_performance_final": 0.8627162575721741, "info_performance_mean": 0.7178027629852295, "info_performance_final": 0.8627162575721741, "step": 1243000}
{"episode_reward": 1435.6054471843925, "episode": 12431.0, "batch_reward": 12.82864761352539, "critic_loss": 339.7073974609375, "actor_loss": -1557.6611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7394684553146362, "alpha_loss": 0.11582998186349869, "alpha_value": 0.2489472196436341, "duration": 1.4482030868530273, "info_normalized_performance_mean": 0.09617187827825546, "info_normalized_performance_final": 0.115234375, "info_performance_mean": 0.09617187827825546, "info_performance_final": 0.115234375, "step": 1243500}
{"episode_reward": 192.34375, "episode": 12436.0, "batch_reward": 13.993209838867188, "critic_loss": 275.016357421875, "actor_loss": -1619.546875, "actor_target_entropy": -3.0, "actor_entropy": 0.8561305999755859, "alpha_loss": 0.19573065638542175, "alpha_value": 0.2453496522793894, "duration": 1.659942626953125, "info_normalized_performance_mean": 0.3801164925098419, "info_normalized_performance_final": 0.4186701774597168, "info_performance_mean": 0.3801164925098419, "info_performance_final": 0.4186701774597168, "step": 1244000}
{"episode_reward": 760.2329075882802, "episode": 12441.0, "batch_reward": 13.002326011657715, "critic_loss": 164.0113067626953, "actor_loss": -1556.806640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8839148879051208, "alpha_loss": -0.03011993132531643, "alpha_value": 0.2428878353385234, "duration": 1.503100872039795, "info_normalized_performance_mean": 0.5922526121139526, "info_normalized_performance_final": 0.6440972089767456, "info_performance_mean": 0.5922526121139526, "info_performance_final": 0.6440972089767456, "step": 1244500}
{"episode_reward": 1184.5052083333328, "episode": 12446.0, "batch_reward": 12.692849159240723, "critic_loss": 349.83587646484375, "actor_loss": -1544.767822265625, "actor_target_entropy": -3.0, "actor_entropy": 0.43918612599372864, "alpha_loss": 0.08840866386890411, "alpha_value": 0.2424880130849188, "duration": 1.7189240455627441, "info_normalized_performance_mean": 0.3103255033493042, "info_normalized_performance_final": 0.39048030972480774, "info_performance_mean": 0.3103255033493042, "info_performance_final": 0.39048030972480774, "step": 1245000}
{"episode_reward": 620.6510416666673, "episode": 12451.0, "batch_reward": 12.133749961853027, "critic_loss": 601.748046875, "actor_loss": -1556.8558349609375, "actor_target_entropy": -3.0, "actor_entropy": 0.5249300599098206, "alpha_loss": 0.0006696805357933044, "alpha_value": 0.24071078622684203, "duration": 1.5963809490203857, "info_normalized_performance_mean": 0.82012939453125, "info_normalized_performance_final": 0.8952941298484802, "info_performance_mean": 0.82012939453125, "info_performance_final": 0.8952941298484802, "step": 1245500}
{"episode_reward": 1640.2588235294136, "episode": 12456.0, "batch_reward": 11.649835586547852, "critic_loss": 190.08004760742188, "actor_loss": -1499.4327392578125, "actor_target_entropy": -3.0, "actor_entropy": 0.3502620458602905, "alpha_loss": -0.06272523105144501, "alpha_value": 0.23936513658795225, "duration": 1.5643389225006104, "info_normalized_performance_mean": 0.7053124904632568, "info_normalized_performance_final": 0.7740384340286255, "info_performance_mean": 0.7053124904632568, "info_performance_final": 0.7740384340286255, "step": 1246000}
{"episode_reward": 1410.625000000003, "episode": 12461.0, "batch_reward": 12.072311401367188, "critic_loss": 131.83180236816406, "actor_loss": -1519.29345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.001889705657959, "alpha_loss": -0.06481505185365677, "alpha_value": 0.2394693364414299, "duration": 1.4935009479522705, "info_normalized_performance_mean": 0.5761784911155701, "info_normalized_performance_final": 0.6321428418159485, "info_performance_mean": 0.5761784911155701, "info_performance_final": 0.6321428418159485, "step": 1246500}
{"episode_reward": 1152.3571428571418, "episode": 12466.0, "batch_reward": 12.455710411071777, "critic_loss": 303.642822265625, "actor_loss": -1547.702392578125, "actor_target_entropy": -3.0, "actor_entropy": 0.65499347448349, "alpha_loss": 0.09955751895904541, "alpha_value": 0.2411718273965395, "duration": 1.5629887580871582, "info_normalized_performance_mean": 0.6746909618377686, "info_normalized_performance_final": 0.7372159361839294, "info_performance_mean": 0.6746909618377686, "info_performance_final": 0.7372159361839294, "step": 1247000}
{"episode_reward": 1349.382102272727, "episode": 12471.0, "batch_reward": 11.78931999206543, "critic_loss": 166.73587036132812, "actor_loss": -1552.7705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.6119000911712646, "alpha_loss": -0.14193399250507355, "alpha_value": 0.24405977695655628, "duration": 1.497173547744751, "info_normalized_performance_mean": 0.6293998956680298, "info_normalized_performance_final": 0.6835317611694336, "info_performance_mean": 0.6293998956680298, "info_performance_final": 0.6835317611694336, "step": 1247500}
{"episode_reward": 1258.7996031746043, "episode": 12476.0, "batch_reward": 11.8804349899292, "critic_loss": 342.74554443359375, "actor_loss": -1490.58056640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8803135752677917, "alpha_loss": -0.049809981137514114, "alpha_value": 0.2457372303993988, "duration": 1.5483720302581787, "info_normalized_performance_mean": 0.5754386782646179, "info_normalized_performance_final": 0.6253004670143127, "info_performance_mean": 0.5754386782646179, "info_performance_final": 0.6253004670143127, "step": 1248000}
{"episode_reward": 1150.8774038461545, "episode": 12481.0, "batch_reward": 12.767189025878906, "critic_loss": 542.139892578125, "actor_loss": -1558.8685302734375, "actor_target_entropy": -3.0, "actor_entropy": 0.879645586013794, "alpha_loss": -0.23599468171596527, "alpha_value": 0.2476294635078102, "duration": 1.4853687286376953, "info_normalized_performance_mean": 0.5320804119110107, "info_normalized_performance_final": 0.5725623369216919, "info_performance_mean": 0.5320804119110107, "info_performance_final": 0.5725623369216919, "step": 1248500}
{"episode_reward": 1064.1609977324267, "episode": 12486.0, "batch_reward": 11.845531463623047, "critic_loss": 319.4239807128906, "actor_loss": -1577.462646484375, "actor_target_entropy": -3.0, "actor_entropy": 0.5392665863037109, "alpha_loss": -0.15306338667869568, "alpha_value": 0.25221127310991975, "duration": 1.5281333923339844, "info_normalized_performance_mean": 0.6584567427635193, "info_normalized_performance_final": 0.7155612111091614, "info_performance_mean": 0.6584567427635193, "info_performance_final": 0.7155612111091614, "step": 1249000}
{"episode_reward": 1316.9132653061213, "episode": 12491.0, "batch_reward": 11.480719566345215, "critic_loss": 418.520263671875, "actor_loss": -1509.709716796875, "actor_target_entropy": -3.0, "actor_entropy": 0.9071344137191772, "alpha_loss": 0.011412281543016434, "alpha_value": 0.255419127335567, "duration": 1.6264164447784424, "info_normalized_performance_mean": 0.22232097387313843, "info_normalized_performance_final": 0.24655647575855255, "info_performance_mean": 0.22232097387313843, "info_performance_final": 0.24655647575855255, "step": 1249500}
{"episode_reward": 444.64187327823754, "episode": 12496.0, "batch_reward": 11.762545585632324, "critic_loss": 424.456298828125, "actor_loss": -1515.0390625, "actor_target_entropy": -3.0, "actor_entropy": 0.4094460606575012, "alpha_loss": -0.16949701309204102, "alpha_value": 0.2575877036214431, "step": 1250000}
{"duration": 18.953883171081543, "info_normalized_performance_mean": 0.5885915756225586, "info_normalized_performance_final": 0.6416666507720947, "info_performance_mean": 0.5885915756225586, "info_performance_final": 0.6416666507720947, "step": 1250000}
{"episode_reward": 1177.1833333333336, "episode": 12501.0, "batch_reward": 13.08144760131836, "critic_loss": 299.459716796875, "actor_loss": -1553.37451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8993733525276184, "alpha_loss": -0.010447479784488678, "alpha_value": 0.26187211188089266, "duration": 1.5284452438354492, "info_normalized_performance_mean": 0.8705682158470154, "info_normalized_performance_final": 0.9350649118423462, "info_performance_mean": 0.8705682158470154, "info_performance_final": 0.9350649118423462, "step": 1250500}
{"episode_reward": 1741.1363636363676, "episode": 12506.0, "batch_reward": 12.28265380859375, "critic_loss": 200.75381469726562, "actor_loss": -1514.349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3025697469711304, "alpha_loss": -0.07144170254468918, "alpha_value": 0.26617196956892913, "duration": 1.5975518226623535, "info_normalized_performance_mean": 0.4711948335170746, "info_normalized_performance_final": 0.5251948237419128, "info_performance_mean": 0.4711948335170746, "info_performance_final": 0.5251948237419128, "step": 1251000}
{"episode_reward": 942.3896103896093, "episode": 12511.0, "batch_reward": 12.842254638671875, "critic_loss": 127.42179107666016, "actor_loss": -1539.9228515625, "actor_target_entropy": -3.0, "actor_entropy": 0.954655647277832, "alpha_loss": -0.20271842181682587, "alpha_value": 0.2710805213701069, "duration": 1.5593533515930176, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1251500}
{"episode_reward": 0.0, "episode": 12516.0, "batch_reward": 12.071466445922852, "critic_loss": 280.3528137207031, "actor_loss": -1526.4501953125, "actor_target_entropy": -3.0, "actor_entropy": 0.7533621788024902, "alpha_loss": -0.09825193136930466, "alpha_value": 0.27609329071970184, "duration": 1.7165288925170898, "info_normalized_performance_mean": 0.41345351934432983, "info_normalized_performance_final": 0.46360456943511963, "info_performance_mean": 0.41345351934432983, "info_performance_final": 0.46360456943511963, "step": 1252000}
{"episode_reward": 826.9071837253666, "episode": 12521.0, "batch_reward": 12.444600105285645, "critic_loss": 140.4398956298828, "actor_loss": -1524.7288818359375, "actor_target_entropy": -3.0, "actor_entropy": 0.8670569062232971, "alpha_loss": -0.06397631764411926, "alpha_value": 0.28126488474712713, "duration": 1.5820910930633545, "info_normalized_performance_mean": 0.1694047600030899, "info_normalized_performance_final": 0.18571428954601288, "info_performance_mean": 0.1694047600030899, "info_performance_final": 0.18571428954601288, "step": 1252500}
{"episode_reward": 338.80952380952414, "episode": 12526.0, "batch_reward": 11.375669479370117, "critic_loss": 144.69464111328125, "actor_loss": -1492.840576171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8992294073104858, "alpha_loss": -0.07085652649402618, "alpha_value": 0.28649924479872413, "duration": 1.526855707168579, "info_normalized_performance_mean": 0.48135414719581604, "info_normalized_performance_final": 0.5398065447807312, "info_performance_mean": 0.48135414719581604, "info_performance_final": 0.5398065447807312, "step": 1253000}
{"episode_reward": 962.708333333334, "episode": 12531.0, "batch_reward": 12.181154251098633, "critic_loss": 256.3128662109375, "actor_loss": -1547.0926513671875, "actor_target_entropy": -3.0, "actor_entropy": 0.963537871837616, "alpha_loss": -0.03992065414786339, "alpha_value": 0.28883255920528406, "duration": 1.613569736480713, "info_normalized_performance_mean": 0.8112918138504028, "info_normalized_performance_final": 0.871666669845581, "info_performance_mean": 0.8112918138504028, "info_performance_final": 0.871666669845581, "step": 1253500}
{"episode_reward": 1622.583333333334, "episode": 12536.0, "batch_reward": 12.072463989257812, "critic_loss": 315.71929931640625, "actor_loss": -1574.9423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.0273076295852661, "alpha_loss": 0.007675619795918465, "alpha_value": 0.290488464480919, "duration": 1.5286991596221924, "info_normalized_performance_mean": 0.7674131989479065, "info_normalized_performance_final": 0.828125, "info_performance_mean": 0.7674131989479065, "info_performance_final": 0.828125, "step": 1254000}
{"episode_reward": 1534.826388888889, "episode": 12541.0, "batch_reward": 13.019233703613281, "critic_loss": 451.7303466796875, "actor_loss": -1593.790771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0584278106689453, "alpha_loss": -0.20897424221038818, "alpha_value": 0.2943565112334135, "duration": 1.672912836074829, "info_normalized_performance_mean": 0.8038359880447388, "info_normalized_performance_final": 0.875, "info_performance_mean": 0.8038359880447388, "info_performance_final": 0.875, "step": 1254500}
{"episode_reward": 1607.6719576719577, "episode": 12546.0, "batch_reward": 12.302139282226562, "critic_loss": 192.00418090820312, "actor_loss": -1578.4344482421875, "actor_target_entropy": -3.0, "actor_entropy": 0.7560054063796997, "alpha_loss": -0.04500489681959152, "alpha_value": 0.2986195032673664, "duration": 1.5601277351379395, "info_normalized_performance_mean": 0.6486625075340271, "info_normalized_performance_final": 0.7012500166893005, "info_performance_mean": 0.6486625075340271, "info_performance_final": 0.7012500166893005, "step": 1255000}
{"episode_reward": 1297.3250000000007, "episode": 12551.0, "batch_reward": 12.900081634521484, "critic_loss": 277.34771728515625, "actor_loss": -1611.8116455078125, "actor_target_entropy": -3.0, "actor_entropy": 1.1952922344207764, "alpha_loss": -0.08655179291963577, "alpha_value": 0.302138469006898, "duration": 1.5789575576782227, "info_normalized_performance_mean": 0.4342043995857239, "info_normalized_performance_final": 0.49824175238609314, "info_performance_mean": 0.4342043995857239, "info_performance_final": 0.49824175238609314, "step": 1255500}
{"episode_reward": 868.4087912087932, "episode": 12556.0, "batch_reward": 12.013988494873047, "critic_loss": 424.7408447265625, "actor_loss": -1556.181396484375, "actor_target_entropy": -3.0, "actor_entropy": 0.634474515914917, "alpha_loss": -0.016429444774985313, "alpha_value": 0.30975690127733324, "duration": 1.5905003547668457, "info_normalized_performance_mean": 0.606495201587677, "info_normalized_performance_final": 0.6990476250648499, "info_performance_mean": 0.606495201587677, "info_performance_final": 0.6990476250648499, "step": 1256000}
{"episode_reward": 1212.9904761904784, "episode": 12561.0, "batch_reward": 12.417743682861328, "critic_loss": 186.62979125976562, "actor_loss": -1654.6142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2056457996368408, "alpha_loss": -0.2466946244239807, "alpha_value": 0.32043123141884955, "duration": 1.519115686416626, "info_normalized_performance_mean": 0.547656238079071, "info_normalized_performance_final": 0.596484363079071, "info_performance_mean": 0.547656238079071, "info_performance_final": 0.596484363079071, "step": 1256500}
{"episode_reward": 1095.3125, "episode": 12566.0, "batch_reward": 13.614757537841797, "critic_loss": 306.37579345703125, "actor_loss": -1656.1875, "actor_target_entropy": -3.0, "actor_entropy": 1.1539790630340576, "alpha_loss": -0.057185620069503784, "alpha_value": 0.32920160647161173, "duration": 1.6793155670166016, "info_normalized_performance_mean": 0.449005126953125, "info_normalized_performance_final": 0.5208200812339783, "info_performance_mean": 0.449005126953125, "info_performance_final": 0.5208200812339783, "step": 1257000}
{"episode_reward": 898.0101716465374, "episode": 12571.0, "batch_reward": 12.987462997436523, "critic_loss": 320.07818603515625, "actor_loss": -1615.22119140625, "actor_target_entropy": -3.0, "actor_entropy": 1.2051833868026733, "alpha_loss": -0.21211004257202148, "alpha_value": 0.33758287641220114, "duration": 1.6430046558380127, "info_normalized_performance_mean": 0.7891126275062561, "info_normalized_performance_final": 0.8533950448036194, "info_performance_mean": 0.7891126275062561, "info_performance_final": 0.8533950448036194, "step": 1257500}
{"episode_reward": 1578.225308641975, "episode": 12576.0, "batch_reward": 12.417283058166504, "critic_loss": 230.52957153320312, "actor_loss": -1568.92431640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2246419191360474, "alpha_loss": -0.05094712972640991, "alpha_value": 0.3472839840982976, "duration": 1.6371135711669922, "info_normalized_performance_mean": 0.7144364714622498, "info_normalized_performance_final": 0.7777777910232544, "info_performance_mean": 0.7144364714622498, "info_performance_final": 0.7777777910232544, "step": 1258000}
{"episode_reward": 1428.873015873018, "episode": 12581.0, "batch_reward": 13.249042510986328, "critic_loss": 141.031005859375, "actor_loss": -1655.8946533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.3442070484161377, "alpha_loss": -0.09167711436748505, "alpha_value": 0.35564121244438013, "duration": 1.5973215103149414, "info_normalized_performance_mean": 0.684723973274231, "info_normalized_performance_final": 0.7357466220855713, "info_performance_mean": 0.684723973274231, "info_performance_final": 0.7357466220855713, "step": 1258500}
{"episode_reward": 1369.4479638009032, "episode": 12586.0, "batch_reward": 11.929061889648438, "critic_loss": 393.9102783203125, "actor_loss": -1644.858642578125, "actor_target_entropy": -3.0, "actor_entropy": 0.7580426931381226, "alpha_loss": -0.2038615494966507, "alpha_value": 0.3644124101903053, "duration": 1.474750280380249, "info_normalized_performance_mean": 0.28142184019088745, "info_normalized_performance_final": 0.3031249940395355, "info_performance_mean": 0.28142184019088745, "info_performance_final": 0.3031249940395355, "step": 1259000}
{"episode_reward": 562.84375, "episode": 12591.0, "batch_reward": 12.679407119750977, "critic_loss": 277.67205810546875, "actor_loss": -1659.3795166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.256268858909607, "alpha_loss": -0.04151841998100281, "alpha_value": 0.375282664705701, "duration": 1.5759921073913574, "info_normalized_performance_mean": 0.8271428942680359, "info_normalized_performance_final": 0.8885714411735535, "info_performance_mean": 0.8271428942680359, "info_performance_final": 0.8885714411735535, "step": 1259500}
{"episode_reward": 1654.2857142857126, "episode": 12596.0, "batch_reward": 12.176765441894531, "critic_loss": 294.58892822265625, "actor_loss": -1634.380615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.0985561609268188, "alpha_loss": -0.3165522515773773, "alpha_value": 0.3837205007121875, "step": 1260000}
{"duration": 19.08600878715515, "info_normalized_performance_mean": 0.9310714602470398, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9310714602470398, "info_performance_final": 1.0, "step": 1260000}
{"episode_reward": 1862.142857142857, "episode": 12601.0, "batch_reward": 12.89111328125, "critic_loss": 251.01150512695312, "actor_loss": -1687.30517578125, "actor_target_entropy": -3.0, "actor_entropy": 0.9180741906166077, "alpha_loss": -0.23206833004951477, "alpha_value": 0.39062846984808536, "duration": 1.4810917377471924, "info_normalized_performance_mean": 0.7580579519271851, "info_normalized_performance_final": 0.8169642686843872, "info_performance_mean": 0.7580579519271851, "info_performance_final": 0.8169642686843872, "step": 1260500}
{"episode_reward": 1516.116071428572, "episode": 12606.0, "batch_reward": 12.87779712677002, "critic_loss": 644.6497802734375, "actor_loss": -1724.27880859375, "actor_target_entropy": -3.0, "actor_entropy": 0.9392250776290894, "alpha_loss": -0.04395494610071182, "alpha_value": 0.3985566133496537, "duration": 1.6092760562896729, "info_normalized_performance_mean": 0.8194706439971924, "info_normalized_performance_final": 0.8803921341896057, "info_performance_mean": 0.8194706439971924, "info_performance_final": 0.8803921341896057, "step": 1261000}
{"episode_reward": 1638.9411764705856, "episode": 12611.0, "batch_reward": 13.694451332092285, "critic_loss": 758.9345703125, "actor_loss": -1750.80078125, "actor_target_entropy": -3.0, "actor_entropy": 1.5160884857177734, "alpha_loss": 0.10828176885843277, "alpha_value": 0.4056290433008315, "duration": 1.5702519416809082, "info_normalized_performance_mean": 0.669197678565979, "info_normalized_performance_final": 0.7328385710716248, "info_performance_mean": 0.669197678565979, "info_performance_final": 0.7328385710716248, "step": 1261500}
{"episode_reward": 1338.3951762523204, "episode": 12616.0, "batch_reward": 12.555679321289062, "critic_loss": 194.5260467529297, "actor_loss": -1672.61669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.984143853187561, "alpha_loss": 0.04803229123353958, "alpha_value": 0.41100300233179277, "duration": 1.5427367687225342, "info_normalized_performance_mean": 0.6293509602546692, "info_normalized_performance_final": 0.6754807829856873, "info_performance_mean": 0.6293509602546692, "info_performance_final": 0.6754807829856873, "step": 1262000}
{"episode_reward": 1258.701923076923, "episode": 12621.0, "batch_reward": 12.128227233886719, "critic_loss": 214.0838623046875, "actor_loss": -1706.0286865234375, "actor_target_entropy": -3.0, "actor_entropy": 0.95741868019104, "alpha_loss": -0.110370934009552, "alpha_value": 0.4162090488724587, "duration": 1.3639538288116455, "info_normalized_performance_mean": 0.25816959142684937, "info_normalized_performance_final": 0.2767857015132904, "info_performance_mean": 0.25816959142684937, "info_performance_final": 0.2767857015132904, "step": 1262500}
{"episode_reward": 516.3392857142852, "episode": 12626.0, "batch_reward": 13.024807929992676, "critic_loss": 175.05897521972656, "actor_loss": -1725.40625, "actor_target_entropy": -3.0, "actor_entropy": 1.019853115081787, "alpha_loss": 0.06553365290164948, "alpha_value": 0.41772613278218074, "duration": 1.4181697368621826, "info_normalized_performance_mean": 0.873526930809021, "info_normalized_performance_final": 0.9330357313156128, "info_performance_mean": 0.873526930809021, "info_performance_final": 0.9330357313156128, "step": 1263000}
{"episode_reward": 1747.0535714285702, "episode": 12631.0, "batch_reward": 12.396592140197754, "critic_loss": 344.9500732421875, "actor_loss": -1720.83251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.2573758363723755, "alpha_loss": -0.10400038212537766, "alpha_value": 0.41992628534271204, "duration": 1.570897102355957, "info_normalized_performance_mean": 0.8235714435577393, "info_normalized_performance_final": 0.8842856884002686, "info_performance_mean": 0.8235714435577393, "info_performance_final": 0.8842856884002686, "step": 1263500}
{"episode_reward": 1647.1428571428592, "episode": 12636.0, "batch_reward": 12.871305465698242, "critic_loss": 220.50152587890625, "actor_loss": -1751.586181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.040900468826294, "alpha_loss": 0.02337031066417694, "alpha_value": 0.42341590658682576, "duration": 1.613286018371582, "info_normalized_performance_mean": 0.7990000247955322, "info_normalized_performance_final": 0.873846173286438, "info_performance_mean": 0.7990000247955322, "info_performance_final": 0.873846173286438, "step": 1264000}
{"episode_reward": 1598.0000000000034, "episode": 12641.0, "batch_reward": 12.34077262878418, "critic_loss": 282.9631042480469, "actor_loss": -1713.9544677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3139088153839111, "alpha_loss": -0.16459885239601135, "alpha_value": 0.4238857382187156, "duration": 1.5254971981048584, "info_normalized_performance_mean": 0.8117187023162842, "info_normalized_performance_final": 0.8638392686843872, "info_performance_mean": 0.8117187023162842, "info_performance_final": 0.8638392686843872, "step": 1264500}
{"episode_reward": 1623.437500000001, "episode": 12646.0, "batch_reward": 11.749427795410156, "critic_loss": 605.7131958007812, "actor_loss": -1725.1612548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8212683796882629, "alpha_loss": -0.09930794686079025, "alpha_value": 0.4196678888780986, "duration": 1.439040184020996, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1265000}
{"episode_reward": 0.0, "episode": 12651.0, "batch_reward": 13.419645309448242, "critic_loss": 487.3876037597656, "actor_loss": -1734.3768310546875, "actor_target_entropy": -3.0, "actor_entropy": 0.7887519598007202, "alpha_loss": 0.23286496102809906, "alpha_value": 0.40971941127472505, "duration": 1.6149537563323975, "info_normalized_performance_mean": 0.8671131730079651, "info_normalized_performance_final": 0.9484162926673889, "info_performance_mean": 0.8671131730079651, "info_performance_final": 0.9484162926673889, "step": 1265500}
{"episode_reward": 1734.2262443438942, "episode": 12656.0, "batch_reward": 12.726436614990234, "critic_loss": 443.2430114746094, "actor_loss": -1813.8057861328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8826688528060913, "alpha_loss": 0.20590832829475403, "alpha_value": 0.4018283514381099, "duration": 1.4154410362243652, "info_normalized_performance_mean": 0.43634316325187683, "info_normalized_performance_final": 0.4682539701461792, "info_performance_mean": 0.43634316325187683, "info_performance_final": 0.4682539701461792, "step": 1266000}
{"episode_reward": 872.6862026862032, "episode": 12661.0, "batch_reward": 12.552146911621094, "critic_loss": 476.78887939453125, "actor_loss": -1725.2196044921875, "actor_target_entropy": -3.0, "actor_entropy": 1.2381088733673096, "alpha_loss": 0.2159510999917984, "alpha_value": 0.3976905966540815, "duration": 1.562863826751709, "info_normalized_performance_mean": 0.6994731426239014, "info_normalized_performance_final": 0.7698924541473389, "info_performance_mean": 0.6994731426239014, "info_performance_final": 0.7698924541473389, "step": 1266500}
{"episode_reward": 1398.9462365591412, "episode": 12666.0, "batch_reward": 12.858821868896484, "critic_loss": 170.7626953125, "actor_loss": -1776.24462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.341509461402893, "alpha_loss": 0.37772804498672485, "alpha_value": 0.3912752029725607, "duration": 1.5895395278930664, "info_normalized_performance_mean": 0.42004671692848206, "info_normalized_performance_final": 0.4890909194946289, "info_performance_mean": 0.42004671692848206, "info_performance_final": 0.4890909194946289, "step": 1267000}
{"episode_reward": 840.0935064935063, "episode": 12671.0, "batch_reward": 12.775477409362793, "critic_loss": 411.2710266113281, "actor_loss": -1744.6297607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3492324352264404, "alpha_loss": 0.2556561231613159, "alpha_value": 0.3826428982297406, "duration": 1.6361441612243652, "info_normalized_performance_mean": 0.6796112656593323, "info_normalized_performance_final": 0.7396825551986694, "info_performance_mean": 0.6796112656593323, "info_performance_final": 0.7396825551986694, "step": 1267500}
{"episode_reward": 1359.2222222222247, "episode": 12676.0, "batch_reward": 13.176959037780762, "critic_loss": 381.8049621582031, "actor_loss": -1776.40283203125, "actor_target_entropy": -3.0, "actor_entropy": 0.9980592131614685, "alpha_loss": 0.3300863802433014, "alpha_value": 0.3740441764306814, "duration": 1.5747880935668945, "info_normalized_performance_mean": 0.7839001417160034, "info_normalized_performance_final": 0.8450000286102295, "info_performance_mean": 0.7839001417160034, "info_performance_final": 0.8450000286102295, "step": 1268000}
{"episode_reward": 1567.800000000002, "episode": 12681.0, "batch_reward": 13.125640869140625, "critic_loss": 642.240234375, "actor_loss": -1745.6851806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0409033298492432, "alpha_loss": 0.29012852907180786, "alpha_value": 0.3627225653884896, "duration": 1.4439072608947754, "info_normalized_performance_mean": 0.49628907442092896, "info_normalized_performance_final": 0.55859375, "info_performance_mean": 0.49628907442092896, "info_performance_final": 0.55859375, "step": 1268500}
{"episode_reward": 992.578125, "episode": 12686.0, "batch_reward": 12.580720901489258, "critic_loss": 576.3905639648438, "actor_loss": -1789.635009765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0377628803253174, "alpha_loss": 0.3590962290763855, "alpha_value": 0.35540199781027315, "duration": 1.6630752086639404, "info_normalized_performance_mean": 0.506136417388916, "info_normalized_performance_final": 0.6090510487556458, "info_performance_mean": 0.506136417388916, "info_performance_final": 0.6090510487556458, "step": 1269000}
{"episode_reward": 1012.272727272727, "episode": 12691.0, "batch_reward": 12.194255828857422, "critic_loss": 684.4368896484375, "actor_loss": -1717.7275390625, "actor_target_entropy": -3.0, "actor_entropy": 0.7920669317245483, "alpha_loss": 0.12143485248088837, "alpha_value": 0.3493701928716247, "duration": 1.4941051006317139, "info_normalized_performance_mean": 0.46610409021377563, "info_normalized_performance_final": 0.5121864080429077, "info_performance_mean": 0.46610409021377563, "info_performance_final": 0.5121864080429077, "step": 1269500}
{"episode_reward": 932.2078853046609, "episode": 12696.0, "batch_reward": 13.415277481079102, "critic_loss": 541.0435791015625, "actor_loss": -1764.693603515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1184353828430176, "alpha_loss": 0.2039749026298523, "alpha_value": 0.3445031263630083, "step": 1270000}
{"duration": 19.052446126937866, "info_normalized_performance_mean": 0.14227430522441864, "info_normalized_performance_final": 0.15625, "info_performance_mean": 0.14227430522441864, "info_performance_final": 0.15625, "step": 1270000}
{"episode_reward": 284.5486111111111, "episode": 12701.0, "batch_reward": 12.152792930603027, "critic_loss": 717.3099975585938, "actor_loss": -1747.15087890625, "actor_target_entropy": -3.0, "actor_entropy": 0.5630868673324585, "alpha_loss": 0.0207529217004776, "alpha_value": 0.3398315571984599, "duration": 1.4249401092529297, "info_normalized_performance_mean": 0.34375, "info_normalized_performance_final": 0.3863636255264282, "info_performance_mean": 0.34375, "info_performance_final": 0.3863636255264282, "step": 1270500}
{"episode_reward": 687.5000000000009, "episode": 12706.0, "batch_reward": 12.262663841247559, "critic_loss": 1474.37646484375, "actor_loss": -1748.172119140625, "actor_target_entropy": -3.0, "actor_entropy": 0.5103581547737122, "alpha_loss": 0.009930431842803955, "alpha_value": 0.33699440313508144, "duration": 1.452636957168579, "info_normalized_performance_mean": 0.2805580496788025, "info_normalized_performance_final": 0.3348214328289032, "info_performance_mean": 0.2805580496788025, "info_performance_final": 0.3348214328289032, "step": 1271000}
{"episode_reward": 561.1160714285709, "episode": 12711.0, "batch_reward": 13.266603469848633, "critic_loss": 887.17431640625, "actor_loss": -1787.756103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7890779972076416, "alpha_loss": 0.06311336159706116, "alpha_value": 0.3333749116335536, "duration": 1.3442103862762451, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1271500}
{"episode_reward": 0.0, "episode": 12716.0, "batch_reward": 12.59605884552002, "critic_loss": 2442.698974609375, "actor_loss": -1728.622802734375, "actor_target_entropy": -3.0, "actor_entropy": 0.35977572202682495, "alpha_loss": -0.02210501953959465, "alpha_value": 0.33011004749934836, "duration": 1.4809448719024658, "info_normalized_performance_mean": 0.24026042222976685, "info_normalized_performance_final": 0.2699652910232544, "info_performance_mean": 0.24026042222976685, "info_performance_final": 0.2699652910232544, "step": 1272000}
{"episode_reward": 480.5208333333326, "episode": 12721.0, "batch_reward": 12.78504467010498, "critic_loss": 643.4346923828125, "actor_loss": -1778.346923828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9182555675506592, "alpha_loss": 0.06402575969696045, "alpha_value": 0.32926184555175836, "duration": 1.6290254592895508, "info_normalized_performance_mean": 0.2458137571811676, "info_normalized_performance_final": 0.2806738615036011, "info_performance_mean": 0.2458137571811676, "info_performance_final": 0.2806738615036011, "step": 1272500}
{"episode_reward": 491.62746344564516, "episode": 12726.0, "batch_reward": 12.98784065246582, "critic_loss": 991.1468505859375, "actor_loss": -1762.139892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.5914993286132812, "alpha_loss": 0.11504389345645905, "alpha_value": 0.329420124412487, "duration": 1.3628761768341064, "info_normalized_performance_mean": 0.2012774646282196, "info_normalized_performance_final": 0.22756409645080566, "info_performance_mean": 0.2012774646282196, "info_performance_final": 0.22756409645080566, "step": 1273000}
{"episode_reward": 402.55494505494454, "episode": 12731.0, "batch_reward": 12.444448471069336, "critic_loss": 4534.89794921875, "actor_loss": -1801.85107421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8915377855300903, "alpha_loss": -0.015737764537334442, "alpha_value": 0.3298733157827914, "duration": 1.4941539764404297, "info_normalized_performance_mean": 0.34040358662605286, "info_normalized_performance_final": 0.38079777359962463, "info_performance_mean": 0.34040358662605286, "info_performance_final": 0.38079777359962463, "step": 1273500}
{"episode_reward": 680.807050092764, "episode": 12736.0, "batch_reward": 12.533344268798828, "critic_loss": 513.2451782226562, "actor_loss": -1721.6904296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8152501583099365, "alpha_loss": 0.05553751066327095, "alpha_value": 0.33296919818755066, "duration": 1.6534476280212402, "info_normalized_performance_mean": 0.38984915614128113, "info_normalized_performance_final": 0.46613913774490356, "info_performance_mean": 0.38984915614128113, "info_performance_final": 0.46613913774490356, "step": 1274000}
{"episode_reward": 779.6981965403025, "episode": 12741.0, "batch_reward": 12.128853797912598, "critic_loss": 2455.00732421875, "actor_loss": -1653.0491943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.7733513116836548, "alpha_loss": -0.03123486042022705, "alpha_value": 0.33791452732600963, "duration": 1.4989426136016846, "info_normalized_performance_mean": 0.3785795569419861, "info_normalized_performance_final": 0.4249188303947449, "info_performance_mean": 0.3785795569419861, "info_performance_final": 0.4249188303947449, "step": 1274500}
{"episode_reward": 757.1590909090913, "episode": 12746.0, "batch_reward": 12.195828437805176, "critic_loss": 2579.16552734375, "actor_loss": -1800.6456298828125, "actor_target_entropy": -3.0, "actor_entropy": 0.6432877779006958, "alpha_loss": -0.2526358366012573, "alpha_value": 0.34248965992255664, "duration": 1.380075216293335, "info_normalized_performance_mean": 0.007516743149608374, "info_normalized_performance_final": 0.008928571827709675, "info_performance_mean": 0.007516743149608374, "info_performance_final": 0.008928571827709675, "step": 1275000}
{"episode_reward": 15.033482142857157, "episode": 12751.0, "batch_reward": 12.195886611938477, "critic_loss": 1043.405029296875, "actor_loss": -1815.289306640625, "actor_target_entropy": -3.0, "actor_entropy": 0.9519047737121582, "alpha_loss": -0.2734684944152832, "alpha_value": 0.35051902526809786, "duration": 1.4291939735412598, "info_normalized_performance_mean": 0.044156260788440704, "info_normalized_performance_final": 0.05195312574505806, "info_performance_mean": 0.044156260788440704, "info_performance_final": 0.05195312574505806, "step": 1275500}
{"episode_reward": 88.3125, "episode": 12756.0, "batch_reward": 12.555120468139648, "critic_loss": 1346.347900390625, "actor_loss": -1752.3526611328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8324356079101562, "alpha_loss": -0.19686588644981384, "alpha_value": 0.35984176687411484, "duration": 1.4079103469848633, "info_normalized_performance_mean": 0.06185269355773926, "info_normalized_performance_final": 0.0714285746216774, "info_performance_mean": 0.06185269355773926, "info_performance_final": 0.0714285746216774, "step": 1276000}
{"episode_reward": 123.70535714285725, "episode": 12761.0, "batch_reward": 12.04457950592041, "critic_loss": 1671.8306884765625, "actor_loss": -1880.50390625, "actor_target_entropy": -3.0, "actor_entropy": 0.4303107261657715, "alpha_loss": -0.46509885787963867, "alpha_value": 0.37273906685524716, "duration": 1.442842960357666, "info_normalized_performance_mean": 1.1764705050154589e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 1.1764705050154589e-05, "info_performance_final": 0.0, "step": 1276500}
{"episode_reward": 0.023529411764705882, "episode": 12766.0, "batch_reward": 12.199399948120117, "critic_loss": 759.3673095703125, "actor_loss": -1945.234619140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8581587076187134, "alpha_loss": -0.42827051877975464, "alpha_value": 0.38625648520972133, "duration": 1.4112803936004639, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1277000}
{"episode_reward": 0.0, "episode": 12771.0, "batch_reward": 12.120991706848145, "critic_loss": 7751.677734375, "actor_loss": -1842.250732421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0932767391204834, "alpha_loss": -0.2701624631881714, "alpha_value": 0.4010918962826038, "duration": 1.3444163799285889, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1277500}
{"episode_reward": 0.0, "episode": 12776.0, "batch_reward": 11.620251655578613, "critic_loss": 3162.0400390625, "actor_loss": -1980.19677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.6149591207504272, "alpha_loss": -0.8948700428009033, "alpha_value": 0.4165699947343643, "duration": 1.433969259262085, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1278000}
{"episode_reward": 0.0, "episode": 12781.0, "batch_reward": 12.374309539794922, "critic_loss": 4449.44921875, "actor_loss": -1909.95947265625, "actor_target_entropy": -3.0, "actor_entropy": 0.8905950784683228, "alpha_loss": -0.749603271484375, "alpha_value": 0.4322774580048731, "duration": 1.390669584274292, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1278500}
{"episode_reward": 0.0, "episode": 12786.0, "batch_reward": 10.72224235534668, "critic_loss": 885.4336547851562, "actor_loss": -2042.7022705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.5843864679336548, "alpha_loss": -0.9421083927154541, "alpha_value": 0.44950533453239333, "duration": 1.39914870262146, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1279000}
{"episode_reward": 0.0, "episode": 12791.0, "batch_reward": 11.977943420410156, "critic_loss": 1129.516357421875, "actor_loss": -2011.5931396484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7564913034439087, "alpha_loss": -0.9826700687408447, "alpha_value": 0.46677011251028916, "duration": 1.308133602142334, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1279500}
{"episode_reward": 0.0, "episode": 12796.0, "batch_reward": 11.403778076171875, "critic_loss": 3890.38916015625, "actor_loss": -2042.02099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.182171106338501, "alpha_loss": -0.934576690196991, "alpha_value": 0.4832151080214718, "step": 1280000}
{"duration": 18.0781147480011, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1280000}
{"episode_reward": 0.0, "episode": 12801.0, "batch_reward": 12.457109451293945, "critic_loss": 1645.0311279296875, "actor_loss": -2044.0369873046875, "actor_target_entropy": -3.0, "actor_entropy": 0.7686119079589844, "alpha_loss": -1.1951689720153809, "alpha_value": 0.499976160208129, "duration": 1.4286887645721436, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1280500}
{"episode_reward": 0.0, "episode": 12806.0, "batch_reward": 11.55186653137207, "critic_loss": 1323.0538330078125, "actor_loss": -2074.807373046875, "actor_target_entropy": -3.0, "actor_entropy": 0.5685235261917114, "alpha_loss": -1.5360817909240723, "alpha_value": 0.5162623096011264, "duration": 1.4674782752990723, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1281000}
{"episode_reward": 0.0, "episode": 12811.0, "batch_reward": 11.587709426879883, "critic_loss": 1081.146484375, "actor_loss": -2183.642822265625, "actor_target_entropy": -3.0, "actor_entropy": 0.6086488366127014, "alpha_loss": -1.1620903015136719, "alpha_value": 0.5334017791739352, "duration": 1.4593617916107178, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1281500}
{"episode_reward": 0.0, "episode": 12816.0, "batch_reward": 11.538816452026367, "critic_loss": 1558.528564453125, "actor_loss": -2212.251708984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8184620141983032, "alpha_loss": -1.6128910779953003, "alpha_value": 0.5508348961949607, "duration": 1.370818853378296, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1282000}
{"episode_reward": 0.0, "episode": 12821.0, "batch_reward": 9.818352699279785, "critic_loss": 5159.41064453125, "actor_loss": -2245.81494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.5291810631752014, "alpha_loss": -1.4284106492996216, "alpha_value": 0.5677130597183964, "duration": 1.5929450988769531, "info_normalized_performance_mean": 0.048377588391304016, "info_normalized_performance_final": 0.055402930825948715, "info_performance_mean": 0.048377588391304016, "info_performance_final": 0.055402930825948715, "step": 1282500}
{"episode_reward": 96.75518925518935, "episode": 12826.0, "batch_reward": 11.734820365905762, "critic_loss": 4959.1474609375, "actor_loss": -2249.162841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7070032358169556, "alpha_loss": -1.1771419048309326, "alpha_value": 0.5850466723057295, "duration": 1.4633769989013672, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1283000}
{"episode_reward": 0.0, "episode": 12831.0, "batch_reward": 11.891493797302246, "critic_loss": 3325.8994140625, "actor_loss": -2331.9951171875, "actor_target_entropy": -3.0, "actor_entropy": 0.791309118270874, "alpha_loss": -1.4844939708709717, "alpha_value": 0.6009988277112435, "duration": 1.5012106895446777, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1283500}
{"episode_reward": 0.0, "episode": 12836.0, "batch_reward": 10.697795867919922, "critic_loss": 1569.5003662109375, "actor_loss": -2382.878662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.0254030227661133, "alpha_loss": -1.7949330806732178, "alpha_value": 0.6182086550495737, "duration": 1.4274637699127197, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1284000}
{"episode_reward": 0.0, "episode": 12841.0, "batch_reward": 11.206368446350098, "critic_loss": 1461.649658203125, "actor_loss": -2421.851318359375, "actor_target_entropy": -3.0, "actor_entropy": 0.8170245885848999, "alpha_loss": -1.209639310836792, "alpha_value": 0.6354504091557818, "duration": 1.4056365489959717, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1284500}
{"episode_reward": 0.0, "episode": 12846.0, "batch_reward": 11.835537910461426, "critic_loss": 997.0926513671875, "actor_loss": -2315.348388671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9589388966560364, "alpha_loss": -1.5045058727264404, "alpha_value": 0.6530664051498001, "duration": 1.4355361461639404, "info_normalized_performance_mean": 5.10204081365373e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 5.10204081365373e-05, "info_performance_final": 0.0, "step": 1285000}
{"episode_reward": 0.10204081632653061, "episode": 12851.0, "batch_reward": 11.476470947265625, "critic_loss": 1477.3408203125, "actor_loss": -2345.953857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.1156419515609741, "alpha_loss": -1.3673248291015625, "alpha_value": 0.6706417525169337, "duration": 1.5815551280975342, "info_normalized_performance_mean": 0.4503808617591858, "info_normalized_performance_final": 0.603515625, "info_performance_mean": 0.4503808617591858, "info_performance_final": 0.603515625, "step": 1285500}
{"episode_reward": 900.76171875, "episode": 12856.0, "batch_reward": 10.643685340881348, "critic_loss": 2722.65234375, "actor_loss": -2476.6162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.0267263650894165, "alpha_loss": -1.6794015169143677, "alpha_value": 0.6880322258743561, "duration": 1.6183297634124756, "info_normalized_performance_mean": 0.034891776740550995, "info_normalized_performance_final": 0.036796536296606064, "info_performance_mean": 0.034891776740550995, "info_performance_final": 0.036796536296606064, "step": 1286000}
{"episode_reward": 69.78354978354983, "episode": 12861.0, "batch_reward": 10.535219192504883, "critic_loss": 1156.0596923828125, "actor_loss": -2372.9970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.2909055948257446, "alpha_loss": -1.571819543838501, "alpha_value": 0.7059334908238273, "duration": 1.6739931106567383, "info_normalized_performance_mean": 0.30942144989967346, "info_normalized_performance_final": 0.3331611454486847, "info_performance_mean": 0.30942144989967346, "info_performance_final": 0.3331611454486847, "step": 1286500}
{"episode_reward": 618.8429752066119, "episode": 12866.0, "batch_reward": 10.034423828125, "critic_loss": 882.2530517578125, "actor_loss": -2559.47265625, "actor_target_entropy": -3.0, "actor_entropy": 1.041179895401001, "alpha_loss": -1.7149652242660522, "alpha_value": 0.7243492678364435, "duration": 1.4780120849609375, "info_normalized_performance_mean": 0.2355021983385086, "info_normalized_performance_final": 0.2530864179134369, "info_performance_mean": 0.2355021983385086, "info_performance_final": 0.2530864179134369, "step": 1287000}
{"episode_reward": 471.00448933782224, "episode": 12871.0, "batch_reward": 11.056471824645996, "critic_loss": 1927.34228515625, "actor_loss": -2426.5029296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3457931280136108, "alpha_loss": -1.2759761810302734, "alpha_value": 0.7422295959572093, "duration": 1.6139698028564453, "info_normalized_performance_mean": 0.47007277607917786, "info_normalized_performance_final": 0.5740740895271301, "info_performance_mean": 0.47007277607917786, "info_performance_final": 0.5740740895271301, "step": 1287500}
{"episode_reward": 940.145502645504, "episode": 12876.0, "batch_reward": 10.800731658935547, "critic_loss": 907.9781494140625, "actor_loss": -2390.125, "actor_target_entropy": -3.0, "actor_entropy": 1.492231845855713, "alpha_loss": -1.3083667755126953, "alpha_value": 0.7594439886530865, "duration": 1.4227023124694824, "info_normalized_performance_mean": 0.41156548261642456, "info_normalized_performance_final": 0.4565476179122925, "info_performance_mean": 0.41156548261642456, "info_performance_final": 0.4565476179122925, "step": 1288000}
{"episode_reward": 823.130952380954, "episode": 12881.0, "batch_reward": 10.746406555175781, "critic_loss": 914.983642578125, "actor_loss": -2416.769775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1414592266082764, "alpha_loss": -1.1427372694015503, "alpha_value": 0.7762528740659437, "duration": 1.6405143737792969, "info_normalized_performance_mean": 0.2710530757904053, "info_normalized_performance_final": 0.31379732489585876, "info_performance_mean": 0.2710530757904053, "info_performance_final": 0.31379732489585876, "step": 1288500}
{"episode_reward": 542.1062271062276, "episode": 12886.0, "batch_reward": 9.537307739257812, "critic_loss": 1547.1217041015625, "actor_loss": -2499.130126953125, "actor_target_entropy": -3.0, "actor_entropy": 1.373460292816162, "alpha_loss": -1.5021326541900635, "alpha_value": 0.7921537638566474, "duration": 1.6052501201629639, "info_normalized_performance_mean": 0.6421042084693909, "info_normalized_performance_final": 0.7256944179534912, "info_performance_mean": 0.6421042084693909, "info_performance_final": 0.7256944179534912, "step": 1289000}
{"episode_reward": 1284.208333333335, "episode": 12891.0, "batch_reward": 11.008820533752441, "critic_loss": 3008.980712890625, "actor_loss": -2498.648193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2604902982711792, "alpha_loss": -1.2343130111694336, "alpha_value": 0.8098893637503815, "duration": 1.4423024654388428, "info_normalized_performance_mean": 0.2267250269651413, "info_normalized_performance_final": 0.27000001072883606, "info_performance_mean": 0.2267250269651413, "info_performance_final": 0.27000001072883606, "step": 1289500}
{"episode_reward": 453.44999999999936, "episode": 12896.0, "batch_reward": 10.795267105102539, "critic_loss": 1210.21484375, "actor_loss": -2406.724609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1440353393554688, "alpha_loss": -1.602074146270752, "alpha_value": 0.8300136909028174, "step": 1290000}
{"duration": 18.17799997329712, "info_normalized_performance_mean": 0.36809664964675903, "info_normalized_performance_final": 0.42080965638160706, "info_performance_mean": 0.36809664964675903, "info_performance_final": 0.42080965638160706, "step": 1290000}
{"episode_reward": 736.1931818181806, "episode": 12901.0, "batch_reward": 10.929121971130371, "critic_loss": 965.1947631835938, "actor_loss": -2469.65966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1564438343048096, "alpha_loss": -2.1753759384155273, "alpha_value": 0.8549509839721395, "duration": 1.5775184631347656, "info_normalized_performance_mean": 0.22134922444820404, "info_normalized_performance_final": 0.2777777910232544, "info_performance_mean": 0.22134922444820404, "info_performance_final": 0.2777777910232544, "step": 1290500}
{"episode_reward": 442.6984126984125, "episode": 12906.0, "batch_reward": 10.738479614257812, "critic_loss": 1333.4757080078125, "actor_loss": -2628.958740234375, "actor_target_entropy": -3.0, "actor_entropy": 1.361974835395813, "alpha_loss": -2.788787603378296, "alpha_value": 0.8848931248106078, "duration": 1.5884270668029785, "info_normalized_performance_mean": 0.40882959961891174, "info_normalized_performance_final": 0.4506172835826874, "info_performance_mean": 0.40882959961891174, "info_performance_final": 0.4506172835826874, "step": 1291000}
{"episode_reward": 817.6590693257367, "episode": 12911.0, "batch_reward": 9.09842586517334, "critic_loss": 1805.042724609375, "actor_loss": -2615.70263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.0407989025115967, "alpha_loss": -2.814239501953125, "alpha_value": 0.9135355462335143, "duration": 1.5084259510040283, "info_normalized_performance_mean": 0.25226646661758423, "info_normalized_performance_final": 0.2747252881526947, "info_performance_mean": 0.25226646661758423, "info_performance_final": 0.2747252881526947, "step": 1291500}
{"episode_reward": 504.5329670329679, "episode": 12916.0, "batch_reward": 10.824512481689453, "critic_loss": 1146.46630859375, "actor_loss": -2733.129638671875, "actor_target_entropy": -3.0, "actor_entropy": 1.73618483543396, "alpha_loss": -2.4103901386260986, "alpha_value": 0.9450463072314915, "duration": 1.5347237586975098, "info_normalized_performance_mean": 0.2350902557373047, "info_normalized_performance_final": 0.2527777850627899, "info_performance_mean": 0.2350902557373047, "info_performance_final": 0.2527777850627899, "step": 1292000}
{"episode_reward": 470.18055555555475, "episode": 12921.0, "batch_reward": 10.498727798461914, "critic_loss": 3306.7490234375, "actor_loss": -2911.218505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.497754693031311, "alpha_loss": -3.2924692630767822, "alpha_value": 0.9792443143436896, "duration": 1.5858170986175537, "info_normalized_performance_mean": 0.46453872323036194, "info_normalized_performance_final": 0.4977678656578064, "info_performance_mean": 0.46453872323036194, "info_performance_final": 0.4977678656578064, "step": 1292500}
{"episode_reward": 929.0773809523802, "episode": 12926.0, "batch_reward": 9.890820503234863, "critic_loss": 2252.47216796875, "actor_loss": -2988.56689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.3203015327453613, "alpha_loss": -2.979343891143799, "alpha_value": 1.0111398408957837, "duration": 1.422872543334961, "info_normalized_performance_mean": 0.38566476106643677, "info_normalized_performance_final": 0.4161706268787384, "info_performance_mean": 0.38566476106643677, "info_performance_final": 0.4161706268787384, "step": 1293000}
{"episode_reward": 771.3293650793642, "episode": 12931.0, "batch_reward": 10.49059772491455, "critic_loss": 3598.625732421875, "actor_loss": -3099.230712890625, "actor_target_entropy": -3.0, "actor_entropy": 1.1312408447265625, "alpha_loss": -3.4277796745300293, "alpha_value": 1.0414667428673823, "duration": 1.4248123168945312, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1293500}
{"episode_reward": 0.0, "episode": 12936.0, "batch_reward": 10.805940628051758, "critic_loss": 3300.212646484375, "actor_loss": -3253.365966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0237650871276855, "alpha_loss": -2.699606418609619, "alpha_value": 1.0693171167139517, "duration": 1.61210036277771, "info_normalized_performance_mean": 0.6321349740028381, "info_normalized_performance_final": 0.6730158925056458, "info_performance_mean": 0.6321349740028381, "info_performance_final": 0.6730158925056458, "step": 1294000}
{"episode_reward": 1264.26984126984, "episode": 12941.0, "batch_reward": 9.198492050170898, "critic_loss": 3422.332275390625, "actor_loss": -3320.3115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5465400218963623, "alpha_loss": -2.86336088180542, "alpha_value": 1.0966120020237518, "duration": 1.5416722297668457, "info_normalized_performance_mean": 0.33677586913108826, "info_normalized_performance_final": 0.36358171701431274, "info_performance_mean": 0.33677586913108826, "info_performance_final": 0.36358171701431274, "step": 1294500}
{"episode_reward": 673.5516826923091, "episode": 12946.0, "batch_reward": 9.529020309448242, "critic_loss": 3816.65869140625, "actor_loss": -3395.998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9654661417007446, "alpha_loss": -2.0252838134765625, "alpha_value": 1.122986732453537, "duration": 1.4348773956298828, "info_normalized_performance_mean": 0.4271378219127655, "info_normalized_performance_final": 0.45783731341362, "info_performance_mean": 0.4271378219127655, "info_performance_final": 0.45783731341362, "step": 1295000}
{"episode_reward": 854.275793650793, "episode": 12951.0, "batch_reward": 10.469491958618164, "critic_loss": 3658.103759765625, "actor_loss": -3519.2998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9209246635437012, "alpha_loss": -2.0062575340270996, "alpha_value": 1.1491545234334102, "duration": 1.5522494316101074, "info_normalized_performance_mean": 0.5889682769775391, "info_normalized_performance_final": 0.6292517185211182, "info_performance_mean": 0.5889682769775391, "info_performance_final": 0.6292517185211182, "step": 1295500}
{"episode_reward": 1177.936507936508, "episode": 12956.0, "batch_reward": 9.942402839660645, "critic_loss": 2794.2685546875, "actor_loss": -3583.323974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.944127082824707, "alpha_loss": -1.9311145544052124, "alpha_value": 1.1719960910679812, "duration": 1.6579792499542236, "info_normalized_performance_mean": 0.159833624958992, "info_normalized_performance_final": 0.19597069919109344, "info_performance_mean": 0.159833624958992, "info_performance_final": 0.19597069919109344, "step": 1296000}
{"episode_reward": 319.667277167277, "episode": 12961.0, "batch_reward": 10.490316390991211, "critic_loss": 2054.69482421875, "actor_loss": -3610.872314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.8529150485992432, "alpha_loss": -1.4895763397216797, "alpha_value": 1.1933495066978148, "duration": 1.5045948028564453, "info_normalized_performance_mean": 0.4887760281562805, "info_normalized_performance_final": 0.5325520634651184, "info_performance_mean": 0.4887760281562805, "info_performance_final": 0.5325520634651184, "step": 1296500}
{"episode_reward": 977.5520833333321, "episode": 12966.0, "batch_reward": 10.54308032989502, "critic_loss": 2138.203125, "actor_loss": -3689.853759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.029731273651123, "alpha_loss": -2.3061933517456055, "alpha_value": 1.2140143717414034, "duration": 1.534780502319336, "info_normalized_performance_mean": 0.133991539478302, "info_normalized_performance_final": 0.14998160302639008, "info_performance_mean": 0.133991539478302, "info_performance_final": 0.14998160302639008, "step": 1297000}
{"episode_reward": 267.9830695620174, "episode": 12971.0, "batch_reward": 10.369352340698242, "critic_loss": 1859.4403076171875, "actor_loss": -3673.642333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.4269858598709106, "alpha_loss": -1.7147856950759888, "alpha_value": 1.2339575185882918, "duration": 1.603365421295166, "info_normalized_performance_mean": 0.5315565466880798, "info_normalized_performance_final": 0.5791855454444885, "info_performance_mean": 0.5315565466880798, "info_performance_final": 0.5791855454444885, "step": 1297500}
{"episode_reward": 1063.1131221719443, "episode": 12976.0, "batch_reward": 10.600464820861816, "critic_loss": 2091.108642578125, "actor_loss": -3725.90673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.0451242923736572, "alpha_loss": -1.8175891637802124, "alpha_value": 1.2530113614662048, "duration": 1.4479868412017822, "info_normalized_performance_mean": 0.4320703148841858, "info_normalized_performance_final": 0.46562498807907104, "info_performance_mean": 0.4320703148841858, "info_performance_final": 0.46562498807907104, "step": 1298000}
{"episode_reward": 864.140625, "episode": 12981.0, "batch_reward": 9.16514778137207, "critic_loss": 2882.2314453125, "actor_loss": -3766.00439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.1848983764648438, "alpha_loss": -1.607696294784546, "alpha_value": 1.2710826518287244, "duration": 1.460479497909546, "info_normalized_performance_mean": 0.07711996883153915, "info_normalized_performance_final": 0.08791209012269974, "info_performance_mean": 0.07711996883153915, "info_performance_final": 0.08791209012269974, "step": 1298500}
{"episode_reward": 154.23992673992646, "episode": 12986.0, "batch_reward": 10.30362319946289, "critic_loss": 1958.890625, "actor_loss": -3752.81640625, "actor_target_entropy": -3.0, "actor_entropy": 1.3914729356765747, "alpha_loss": -1.4482934474945068, "alpha_value": 1.2938340850102057, "duration": 1.4111802577972412, "info_normalized_performance_mean": 2.8344671591185033e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 2.8344671591185033e-05, "info_performance_final": 0.0, "step": 1299000}
{"episode_reward": 0.05668934240362812, "episode": 12991.0, "batch_reward": 10.173917770385742, "critic_loss": 2076.319091796875, "actor_loss": -3641.24462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.450729489326477, "alpha_loss": -1.6477060317993164, "alpha_value": 1.3181470678533966, "duration": 1.5093493461608887, "info_normalized_performance_mean": 0.2974869906902313, "info_normalized_performance_final": 0.3216145932674408, "info_performance_mean": 0.2974869906902313, "info_performance_final": 0.3216145932674408, "step": 1299500}
{"episode_reward": 594.9739583333335, "episode": 12996.0, "batch_reward": 9.865508079528809, "critic_loss": 1361.8074951171875, "actor_loss": -3866.10107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3387768268585205, "alpha_loss": -0.837810754776001, "alpha_value": 1.3427648821681122, "step": 1300000}
{"duration": 18.726728439331055, "info_normalized_performance_mean": 0.7025377750396729, "info_normalized_performance_final": 0.7630252242088318, "info_performance_mean": 0.7025377750396729, "info_performance_final": 0.7630252242088318, "step": 1300000}
{"episode_reward": 1405.0756302521017, "episode": 13001.0, "batch_reward": 9.578495025634766, "critic_loss": 1412.303955078125, "actor_loss": -3699.342041015625, "actor_target_entropy": -3.0, "actor_entropy": 1.3369415998458862, "alpha_loss": -1.4655427932739258, "alpha_value": 1.3688460407920953, "duration": 1.593432903289795, "info_normalized_performance_mean": 0.7755882740020752, "info_normalized_performance_final": 0.8450980186462402, "info_performance_mean": 0.7755882740020752, "info_performance_final": 0.8450980186462402, "step": 1300500}
{"episode_reward": 1551.1764705882372, "episode": 13006.0, "batch_reward": 10.001640319824219, "critic_loss": 3130.94970703125, "actor_loss": -3827.57275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5725406408309937, "alpha_loss": -1.3973039388656616, "alpha_value": 1.393771262361661, "duration": 1.5132505893707275, "info_normalized_performance_mean": 0.736856997013092, "info_normalized_performance_final": 0.7946428656578064, "info_performance_mean": 0.736856997013092, "info_performance_final": 0.7946428656578064, "step": 1301000}
{"episode_reward": 1473.7142857142842, "episode": 13011.0, "batch_reward": 9.070257186889648, "critic_loss": 1336.614501953125, "actor_loss": -3757.350341796875, "actor_target_entropy": -3.0, "actor_entropy": 1.4615302085876465, "alpha_loss": -1.3625239133834839, "alpha_value": 1.4208506780878203, "duration": 1.5463535785675049, "info_normalized_performance_mean": 0.7037500143051147, "info_normalized_performance_final": 0.755859375, "info_performance_mean": 0.7037500143051147, "info_performance_final": 0.755859375, "step": 1301500}
{"episode_reward": 1407.5, "episode": 13016.0, "batch_reward": 9.184206008911133, "critic_loss": 2814.53076171875, "actor_loss": -3681.64794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4095947742462158, "alpha_loss": -0.9958251714706421, "alpha_value": 1.4483165432356437, "duration": 1.526571273803711, "info_normalized_performance_mean": 0.5562890768051147, "info_normalized_performance_final": 0.6015625, "info_performance_mean": 0.5562890768051147, "info_performance_final": 0.6015625, "step": 1302000}
{"episode_reward": 1112.578125, "episode": 13021.0, "batch_reward": 9.96875, "critic_loss": 3629.21337890625, "actor_loss": -3814.46240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4475986957550049, "alpha_loss": -0.5914129614830017, "alpha_value": 1.4761191158669171, "duration": 1.6110925674438477, "info_normalized_performance_mean": 0.7188687324523926, "info_normalized_performance_final": 0.770135760307312, "info_performance_mean": 0.7188687324523926, "info_performance_final": 0.770135760307312, "step": 1302500}
{"episode_reward": 1437.7375565610853, "episode": 13026.0, "batch_reward": 10.022598266601562, "critic_loss": 1558.2757568359375, "actor_loss": -3836.41845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3399581909179688, "alpha_loss": -1.2214255332946777, "alpha_value": 1.505403428463135, "duration": 1.5510869026184082, "info_normalized_performance_mean": 0.2554067373275757, "info_normalized_performance_final": 0.2738095223903656, "info_performance_mean": 0.2554067373275757, "info_performance_final": 0.2738095223903656, "step": 1303000}
{"episode_reward": 510.81349206349245, "episode": 13031.0, "batch_reward": 9.507604598999023, "critic_loss": 4214.92041015625, "actor_loss": -3834.986572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6521637439727783, "alpha_loss": -1.130188226699829, "alpha_value": 1.5361545514272428, "duration": 1.5365078449249268, "info_normalized_performance_mean": 0.7901136875152588, "info_normalized_performance_final": 0.8490259647369385, "info_performance_mean": 0.7901136875152588, "info_performance_final": 0.8490259647369385, "step": 1303500}
{"episode_reward": 1580.22727272727, "episode": 13036.0, "batch_reward": 10.468589782714844, "critic_loss": 872.8482666015625, "actor_loss": -3765.0732421875, "actor_target_entropy": -3.0, "actor_entropy": 1.5201960802078247, "alpha_loss": -0.4767206013202667, "alpha_value": 1.562320687684347, "duration": 1.4840970039367676, "info_normalized_performance_mean": 0.37933677434921265, "info_normalized_performance_final": 0.40816327929496765, "info_performance_mean": 0.37933677434921265, "info_performance_final": 0.40816327929496765, "step": 1304000}
{"episode_reward": 758.6734693877545, "episode": 13041.0, "batch_reward": 9.8363037109375, "critic_loss": 1323.8758544921875, "actor_loss": -3845.66650390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5161768198013306, "alpha_loss": -0.5789757966995239, "alpha_value": 1.5843140458209364, "duration": 1.7091600894927979, "info_normalized_performance_mean": 0.26753515005111694, "info_normalized_performance_final": 0.2945665419101715, "info_performance_mean": 0.26753515005111694, "info_performance_final": 0.2945665419101715, "step": 1304500}
{"episode_reward": 535.070207570207, "episode": 13046.0, "batch_reward": 10.437152862548828, "critic_loss": 1711.3594970703125, "actor_loss": -4008.48095703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6939566135406494, "alpha_loss": 0.42416173219680786, "alpha_value": 1.6098727145904994, "duration": 1.5237886905670166, "info_normalized_performance_mean": 0.26099997758865356, "info_normalized_performance_final": 0.2862337529659271, "info_performance_mean": 0.26099997758865356, "info_performance_final": 0.2862337529659271, "step": 1305000}
{"episode_reward": 522.0000000000005, "episode": 13051.0, "batch_reward": 9.954769134521484, "critic_loss": 852.8968505859375, "actor_loss": -3958.259033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4997327327728271, "alpha_loss": 0.10436714440584183, "alpha_value": 1.6316640291494005, "duration": 1.5718200206756592, "info_normalized_performance_mean": 0.833424985408783, "info_normalized_performance_final": 0.8949999809265137, "info_performance_mean": 0.833424985408783, "info_performance_final": 0.8949999809265137, "step": 1305500}
{"episode_reward": 1666.8500000000024, "episode": 13056.0, "batch_reward": 10.96854305267334, "critic_loss": 747.9240112304688, "actor_loss": -3849.6982421875, "actor_target_entropy": -3.0, "actor_entropy": 1.7308323383331299, "alpha_loss": 0.8090829849243164, "alpha_value": 1.6411189632732144, "duration": 1.5846991539001465, "info_normalized_performance_mean": 0.8153999447822571, "info_normalized_performance_final": 0.8847059011459351, "info_performance_mean": 0.8153999447822571, "info_performance_final": 0.8847059011459351, "step": 1306000}
{"episode_reward": 1630.8000000000031, "episode": 13061.0, "batch_reward": 10.502460479736328, "critic_loss": 1382.067138671875, "actor_loss": -3884.931884765625, "actor_target_entropy": -3.0, "actor_entropy": 1.466944932937622, "alpha_loss": 0.09859822690486908, "alpha_value": 1.6454312195492988, "duration": 1.6065354347229004, "info_normalized_performance_mean": 0.6341835260391235, "info_normalized_performance_final": 0.6916099786758423, "info_performance_mean": 0.6341835260391235, "info_performance_final": 0.6916099786758423, "step": 1306500}
{"episode_reward": 1268.3673469387772, "episode": 13066.0, "batch_reward": 9.615310668945312, "critic_loss": 927.185546875, "actor_loss": -3916.61669921875, "actor_target_entropy": -3.0, "actor_entropy": 1.770845890045166, "alpha_loss": -0.005512714385986328, "alpha_value": 1.6540536744657754, "duration": 1.5658314228057861, "info_normalized_performance_mean": 0.7907142639160156, "info_normalized_performance_final": 0.8497023582458496, "info_performance_mean": 0.7907142639160156, "info_performance_final": 0.8497023582458496, "step": 1307000}
{"episode_reward": 1581.4285714285732, "episode": 13071.0, "batch_reward": 9.401073455810547, "critic_loss": 1421.0135498046875, "actor_loss": -3814.4189453125, "actor_target_entropy": -3.0, "actor_entropy": 1.6213908195495605, "alpha_loss": 0.01788581907749176, "alpha_value": 1.6561645934772466, "duration": 1.4295144081115723, "info_normalized_performance_mean": 0.2532455027103424, "info_normalized_performance_final": 0.2745535671710968, "info_performance_mean": 0.2532455027103424, "info_performance_final": 0.2745535671710968, "step": 1307500}
{"episode_reward": 506.4910714285719, "episode": 13076.0, "batch_reward": 10.808780670166016, "critic_loss": 1086.466064453125, "actor_loss": -3979.943603515625, "actor_target_entropy": -3.0, "actor_entropy": 1.4805810451507568, "alpha_loss": 0.24378076195716858, "alpha_value": 1.654235100823749, "duration": 1.4635393619537354, "info_normalized_performance_mean": 0.9062755107879639, "info_normalized_performance_final": 0.9744898080825806, "info_performance_mean": 0.9062755107879639, "info_performance_final": 0.9744898080825806, "step": 1308000}
{"episode_reward": 1812.5510204081588, "episode": 13081.0, "batch_reward": 9.879283905029297, "critic_loss": 3138.44287109375, "actor_loss": -3838.685791015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5317829847335815, "alpha_loss": 0.6724439263343811, "alpha_value": 1.651345138130647, "duration": 1.4394586086273193, "info_normalized_performance_mean": 0.7531622052192688, "info_normalized_performance_final": 0.8247863054275513, "info_performance_mean": 0.7531622052192688, "info_performance_final": 0.8247863054275513, "step": 1308500}
{"episode_reward": 1506.3247863247866, "episode": 13086.0, "batch_reward": 11.007654190063477, "critic_loss": 1584.98876953125, "actor_loss": -3906.1474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.5534422397613525, "alpha_loss": 0.5645498633384705, "alpha_value": 1.6418885048861798, "duration": 1.4956765174865723, "info_normalized_performance_mean": 0.5896697044372559, "info_normalized_performance_final": 0.6397321224212646, "info_performance_mean": 0.5896697044372559, "info_performance_final": 0.6397321224212646, "step": 1309000}
{"episode_reward": 1179.339285714287, "episode": 13091.0, "batch_reward": 9.911737442016602, "critic_loss": 1570.998046875, "actor_loss": -3840.68212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.5717886686325073, "alpha_loss": 0.7441341280937195, "alpha_value": 1.634076093437373, "duration": 1.5300333499908447, "info_normalized_performance_mean": 0.5966666340827942, "info_normalized_performance_final": 0.640625, "info_performance_mean": 0.5966666340827942, "info_performance_final": 0.640625, "step": 1309500}
{"episode_reward": 1193.3333333333335, "episode": 13096.0, "batch_reward": 9.752984046936035, "critic_loss": 1346.7283935546875, "actor_loss": -3782.168212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.5870914459228516, "alpha_loss": -0.370804101228714, "alpha_value": 1.6260444408621346, "step": 1310000}
{"duration": 18.476144552230835, "info_normalized_performance_mean": 0.3763214945793152, "info_normalized_performance_final": 0.42071428894996643, "info_performance_mean": 0.3763214945793152, "info_performance_final": 0.42071428894996643, "step": 1310000}
{"episode_reward": 752.6428571428569, "episode": 13101.0, "batch_reward": 8.570716857910156, "critic_loss": 2728.2216796875, "actor_loss": -3706.23583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.4756574630737305, "alpha_loss": -0.25719261169433594, "alpha_value": 1.6177369172398288, "duration": 1.527886152267456, "info_normalized_performance_mean": 0.4381698668003082, "info_normalized_performance_final": 0.48456791043281555, "info_performance_mean": 0.4381698668003082, "info_performance_final": 0.48456791043281555, "step": 1310500}
{"episode_reward": 876.3395061728385, "episode": 13106.0, "batch_reward": 10.932291030883789, "critic_loss": 1099.533935546875, "actor_loss": -4022.3330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.6554574966430664, "alpha_loss": 1.2136893272399902, "alpha_value": 1.5962687400315347, "duration": 1.4556348323822021, "info_normalized_performance_mean": 0.22285720705986023, "info_normalized_performance_final": 0.24234694242477417, "info_performance_mean": 0.22285720705986023, "info_performance_final": 0.24234694242477417, "step": 1311000}
{"episode_reward": 445.7142857142851, "episode": 13111.0, "batch_reward": 9.885415077209473, "critic_loss": 2056.453369140625, "actor_loss": -3880.0673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.4258577823638916, "alpha_loss": -0.426840603351593, "alpha_value": 1.578049399217636, "duration": 1.575214147567749, "info_normalized_performance_mean": 0.8736931085586548, "info_normalized_performance_final": 0.9389204382896423, "info_performance_mean": 0.8736931085586548, "info_performance_final": 0.9389204382896423, "step": 1311500}
{"episode_reward": 1747.3863636363617, "episode": 13116.0, "batch_reward": 9.959843635559082, "critic_loss": 1457.7801513671875, "actor_loss": -3842.30908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4125008583068848, "alpha_loss": 0.5998011827468872, "alpha_value": 1.5546042312167905, "duration": 1.6012084484100342, "info_normalized_performance_mean": 0.8681959509849548, "info_normalized_performance_final": 0.9401960968971252, "info_performance_mean": 0.8681959509849548, "info_performance_final": 0.9401960968971252, "step": 1312000}
{"episode_reward": 1736.392156862742, "episode": 13121.0, "batch_reward": 9.761037826538086, "critic_loss": 1606.666259765625, "actor_loss": -3744.2412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.652223825454712, "alpha_loss": -0.0832471251487732, "alpha_value": 1.5315932921584932, "duration": 1.6242539882659912, "info_normalized_performance_mean": 0.42239460349082947, "info_normalized_performance_final": 0.4743366539478302, "info_performance_mean": 0.42239460349082947, "info_performance_final": 0.4743366539478302, "step": 1312500}
{"episode_reward": 844.7890387124858, "episode": 13126.0, "batch_reward": 9.607396125793457, "critic_loss": 1158.665771484375, "actor_loss": -3713.812744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.8048927783966064, "alpha_loss": 0.4137228727340698, "alpha_value": 1.5090360668299452, "duration": 1.4061739444732666, "info_normalized_performance_mean": 0.3396527171134949, "info_normalized_performance_final": 0.3645833432674408, "info_performance_mean": 0.3396527171134949, "info_performance_final": 0.3645833432674408, "step": 1313000}
{"episode_reward": 679.3055555555552, "episode": 13131.0, "batch_reward": 9.515308380126953, "critic_loss": 868.5894775390625, "actor_loss": -3696.98974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.400795340538025, "alpha_loss": 1.0504164695739746, "alpha_value": 1.4782361855536954, "duration": 1.5352296829223633, "info_normalized_performance_mean": 0.8551963567733765, "info_normalized_performance_final": 0.9303571581840515, "info_performance_mean": 0.8551963567733765, "info_performance_final": 0.9303571581840515, "step": 1313500}
{"episode_reward": 1710.392857142859, "episode": 13136.0, "batch_reward": 9.998655319213867, "critic_loss": 1408.516845703125, "actor_loss": -3639.490478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.6600004434585571, "alpha_loss": 1.0362887382507324, "alpha_value": 1.445702672887852, "duration": 1.5288920402526855, "info_normalized_performance_mean": 0.11683736741542816, "info_normalized_performance_final": 0.1318681389093399, "info_performance_mean": 0.11683736741542816, "info_performance_final": 0.1318681389093399, "step": 1314000}
{"episode_reward": 233.67472527472498, "episode": 13141.0, "batch_reward": 10.045392036437988, "critic_loss": 1086.680908203125, "actor_loss": -3667.47607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.5582408905029297, "alpha_loss": 0.7857075929641724, "alpha_value": 1.4164630243258745, "duration": 1.605682373046875, "info_normalized_performance_mean": 0.7417353987693787, "info_normalized_performance_final": 0.795098066329956, "info_performance_mean": 0.7417353987693787, "info_performance_final": 0.795098066329956, "step": 1314500}
{"episode_reward": 1483.4705882352955, "episode": 13146.0, "batch_reward": 10.0007905960083, "critic_loss": 1293.597412109375, "actor_loss": -3671.212646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.784347653388977, "alpha_loss": 0.5302039384841919, "alpha_value": 1.3938337244155647, "duration": 1.5413732528686523, "info_normalized_performance_mean": 0.6523860692977905, "info_normalized_performance_final": 0.7182103395462036, "info_performance_mean": 0.6523860692977905, "info_performance_final": 0.7182103395462036, "step": 1315000}
{"episode_reward": 1304.7723704866569, "episode": 13151.0, "batch_reward": 9.135895729064941, "critic_loss": 1393.3629150390625, "actor_loss": -3624.22705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4101088047027588, "alpha_loss": 0.4388974905014038, "alpha_value": 1.3678420572368684, "duration": 1.5642695426940918, "info_normalized_performance_mean": 0.3826551139354706, "info_normalized_performance_final": 0.411255419254303, "info_performance_mean": 0.3826551139354706, "info_performance_final": 0.411255419254303, "step": 1315500}
{"episode_reward": 765.3102453102447, "episode": 13156.0, "batch_reward": 9.331643104553223, "critic_loss": 1116.42724609375, "actor_loss": -3665.32763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2026654481887817, "alpha_loss": 0.3885813355445862, "alpha_value": 1.3386953540500588, "duration": 1.5554776191711426, "info_normalized_performance_mean": 0.35511505603790283, "info_normalized_performance_final": 0.39085298776626587, "info_performance_mean": 0.35511505603790283, "info_performance_final": 0.39085298776626587, "step": 1316000}
{"episode_reward": 710.2300785634108, "episode": 13161.0, "batch_reward": 10.308809280395508, "critic_loss": 1234.930419921875, "actor_loss": -3567.6484375, "actor_target_entropy": -3.0, "actor_entropy": 1.693762183189392, "alpha_loss": 1.4250339269638062, "alpha_value": 1.314681309286542, "duration": 1.633207082748413, "info_normalized_performance_mean": 0.7704582214355469, "info_normalized_performance_final": 0.8433333039283752, "info_performance_mean": 0.7704582214355469, "info_performance_final": 0.8433333039283752, "step": 1316500}
{"episode_reward": 1540.9166666666638, "episode": 13166.0, "batch_reward": 9.553886413574219, "critic_loss": 1525.7763671875, "actor_loss": -3459.4482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.698241949081421, "alpha_loss": 0.5707278251647949, "alpha_value": 1.2966119148074546, "duration": 1.5603008270263672, "info_normalized_performance_mean": 0.3723313808441162, "info_normalized_performance_final": 0.41405507922172546, "info_performance_mean": 0.3723313808441162, "info_performance_final": 0.41405507922172546, "step": 1317000}
{"episode_reward": 744.6628679962021, "episode": 13171.0, "batch_reward": 10.13559341430664, "critic_loss": 2205.316162109375, "actor_loss": -3575.07421875, "actor_target_entropy": -3.0, "actor_entropy": 1.5992062091827393, "alpha_loss": -0.22145646810531616, "alpha_value": 1.2829456637270538, "duration": 1.4929320812225342, "info_normalized_performance_mean": 0.5310937762260437, "info_normalized_performance_final": 0.574999988079071, "info_performance_mean": 0.5310937762260437, "info_performance_final": 0.574999988079071, "step": 1317500}
{"episode_reward": 1062.1875, "episode": 13176.0, "batch_reward": 8.877354621887207, "critic_loss": 1351.6846923828125, "actor_loss": -3393.10498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.600696086883545, "alpha_loss": -0.28633248805999756, "alpha_value": 1.2713770057277534, "duration": 1.5693328380584717, "info_normalized_performance_mean": 0.44739046692848206, "info_normalized_performance_final": 0.49354657530784607, "info_performance_mean": 0.44739046692848206, "info_performance_final": 0.49354657530784607, "step": 1318000}
{"episode_reward": 894.7811447811431, "episode": 13181.0, "batch_reward": 9.117835998535156, "critic_loss": 1666.34814453125, "actor_loss": -3441.51806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.4915660619735718, "alpha_loss": 0.6809206604957581, "alpha_value": 1.2556272482494624, "duration": 1.619645595550537, "info_normalized_performance_mean": 0.7946787476539612, "info_normalized_performance_final": 0.85158371925354, "info_performance_mean": 0.7946787476539612, "info_performance_final": 0.85158371925354, "step": 1318500}
{"episode_reward": 1589.3574660633458, "episode": 13186.0, "batch_reward": 9.649345397949219, "critic_loss": 1890.864501953125, "actor_loss": -3409.720703125, "actor_target_entropy": -3.0, "actor_entropy": 1.572914958000183, "alpha_loss": 0.33891114592552185, "alpha_value": 1.2431370715129615, "duration": 1.7052481174468994, "info_normalized_performance_mean": 0.44055312871932983, "info_normalized_performance_final": 0.49634456634521484, "info_performance_mean": 0.44055312871932983, "info_performance_final": 0.49634456634521484, "step": 1319000}
{"episode_reward": 881.1061665607131, "episode": 13191.0, "batch_reward": 10.189891815185547, "critic_loss": 2328.959716796875, "actor_loss": -3434.19580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.296724796295166, "alpha_loss": 0.1104397401213646, "alpha_value": 1.2245775080147066, "duration": 1.6340265274047852, "info_normalized_performance_mean": 0.6058631539344788, "info_normalized_performance_final": 0.6577380895614624, "info_performance_mean": 0.6058631539344788, "info_performance_final": 0.6577380895614624, "step": 1319500}
{"episode_reward": 1211.726190476192, "episode": 13196.0, "batch_reward": 9.006551742553711, "critic_loss": 1017.9290161132812, "actor_loss": -3363.59423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.4161208868026733, "alpha_loss": 0.5994164347648621, "alpha_value": 1.2047015045030278, "step": 1320000}
{"duration": 18.52682900428772, "info_normalized_performance_mean": 0.7647526264190674, "info_normalized_performance_final": 0.8372395634651184, "info_performance_mean": 0.7647526264190674, "info_performance_final": 0.8372395634651184, "step": 1320000}
{"episode_reward": 1529.5052083333348, "episode": 13201.0, "batch_reward": 9.658065795898438, "critic_loss": 781.3527221679688, "actor_loss": -3359.05126953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1002044677734375, "alpha_loss": 0.6413581371307373, "alpha_value": 1.18183156112049, "duration": 1.6076772212982178, "info_normalized_performance_mean": 0.6806082725524902, "info_normalized_performance_final": 0.7425000071525574, "info_performance_mean": 0.6806082725524902, "info_performance_final": 0.7425000071525574, "step": 1320500}
{"episode_reward": 1361.2166666666658, "episode": 13206.0, "batch_reward": 9.78132438659668, "critic_loss": 696.97119140625, "actor_loss": -3316.51953125, "actor_target_entropy": -3.0, "actor_entropy": 1.4449876546859741, "alpha_loss": 0.798560380935669, "alpha_value": 1.1598366659427004, "duration": 1.458245038986206, "info_normalized_performance_mean": 0.8477380275726318, "info_normalized_performance_final": 0.9107142686843872, "info_performance_mean": 0.8477380275726318, "info_performance_final": 0.9107142686843872, "step": 1321000}
{"episode_reward": 1695.4761904761917, "episode": 13211.0, "batch_reward": 8.388326644897461, "critic_loss": 1405.4993896484375, "actor_loss": -3264.298828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8731868267059326, "alpha_loss": 0.06819291412830353, "alpha_value": 1.136060461131734, "duration": 1.579035997390747, "info_normalized_performance_mean": 0.07994570583105087, "info_normalized_performance_final": 0.08778280764818192, "info_performance_mean": 0.07994570583105087, "info_performance_final": 0.08778280764818192, "step": 1321500}
{"episode_reward": 159.89140271493207, "episode": 13216.0, "batch_reward": 9.517572402954102, "critic_loss": 1850.318359375, "actor_loss": -3318.23583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.283340573310852, "alpha_loss": 0.3730389475822449, "alpha_value": 1.1166597084464445, "duration": 1.598304271697998, "info_normalized_performance_mean": 0.3940737843513489, "info_normalized_performance_final": 0.4347619116306305, "info_performance_mean": 0.3940737843513489, "info_performance_final": 0.4347619116306305, "step": 1322000}
{"episode_reward": 788.1476190476191, "episode": 13221.0, "batch_reward": 10.070055961608887, "critic_loss": 1739.0218505859375, "actor_loss": -3361.494873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.2093284130096436, "alpha_loss": 0.15699319541454315, "alpha_value": 1.0954565802944294, "duration": 1.4582397937774658, "info_normalized_performance_mean": 0.3834895193576813, "info_normalized_performance_final": 0.4114583432674408, "info_performance_mean": 0.3834895193576813, "info_performance_final": 0.4114583432674408, "step": 1322500}
{"episode_reward": 766.9791666666661, "episode": 13226.0, "batch_reward": 10.045701026916504, "critic_loss": 1217.44580078125, "actor_loss": -3264.92626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.3520839214324951, "alpha_loss": 0.32652682065963745, "alpha_value": 1.0728171927088233, "duration": 1.528027057647705, "info_normalized_performance_mean": 0.37654319405555725, "info_normalized_performance_final": 0.40965208411216736, "info_performance_mean": 0.37654319405555725, "info_performance_final": 0.40965208411216736, "step": 1323000}
{"episode_reward": 753.0864197530861, "episode": 13231.0, "batch_reward": 9.303863525390625, "critic_loss": 971.4932861328125, "actor_loss": -3149.699462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.251790165901184, "alpha_loss": 0.35386762022972107, "alpha_value": 1.0493554784596326, "duration": 1.5408368110656738, "info_normalized_performance_mean": 0.829702615737915, "info_normalized_performance_final": 0.8928571343421936, "info_performance_mean": 0.829702615737915, "info_performance_final": 0.8928571343421936, "step": 1323500}
{"episode_reward": 1659.4047619047635, "episode": 13236.0, "batch_reward": 9.854460716247559, "critic_loss": 1169.79541015625, "actor_loss": -3196.472900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1914796829223633, "alpha_loss": 0.3277900218963623, "alpha_value": 1.0305330588839292, "duration": 1.50412917137146, "info_normalized_performance_mean": 0.6030924320220947, "info_normalized_performance_final": 0.6639610528945923, "info_performance_mean": 0.6030924320220947, "info_performance_final": 0.6639610528945923, "step": 1324000}
{"episode_reward": 1206.1850649350647, "episode": 13241.0, "batch_reward": 9.877693176269531, "critic_loss": 1103.96533203125, "actor_loss": -3168.701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3140480518341064, "alpha_loss": 0.2653700113296509, "alpha_value": 1.0089384387251854, "duration": 1.4466171264648438, "info_normalized_performance_mean": 0.3965824246406555, "info_normalized_performance_final": 0.435019850730896, "info_performance_mean": 0.3965824246406555, "info_performance_final": 0.435019850730896, "step": 1324500}
{"episode_reward": 793.1646825396834, "episode": 13246.0, "batch_reward": 9.028158187866211, "critic_loss": 1334.1700439453125, "actor_loss": -3113.5283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.0098612308502197, "alpha_loss": 0.21037037670612335, "alpha_value": 0.9953438206302525, "duration": 1.487367868423462, "info_normalized_performance_mean": 0.7868140339851379, "info_normalized_performance_final": 0.8696145415306091, "info_performance_mean": 0.7868140339851379, "info_performance_final": 0.8696145415306091, "step": 1325000}
{"episode_reward": 1573.6281179138305, "episode": 13251.0, "batch_reward": 9.265617370605469, "critic_loss": 1884.79443359375, "actor_loss": -3124.6767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.108739972114563, "alpha_loss": 0.28373342752456665, "alpha_value": 0.976725537931652, "duration": 1.7397160530090332, "info_normalized_performance_mean": 0.40842941403388977, "info_normalized_performance_final": 0.4590010643005371, "info_performance_mean": 0.40842941403388977, "info_performance_final": 0.4590010643005371, "step": 1325500}
{"episode_reward": 816.858974358974, "episode": 13256.0, "batch_reward": 10.251787185668945, "critic_loss": 748.8829345703125, "actor_loss": -3153.748046875, "actor_target_entropy": -3.0, "actor_entropy": 1.250640630722046, "alpha_loss": 0.5141034722328186, "alpha_value": 0.9626287974635692, "duration": 1.554480791091919, "info_normalized_performance_mean": 0.48055189847946167, "info_normalized_performance_final": 0.5301074981689453, "info_performance_mean": 0.48055189847946167, "info_performance_final": 0.5301074981689453, "step": 1326000}
{"episode_reward": 961.103942652331, "episode": 13261.0, "batch_reward": 9.46957778930664, "critic_loss": 728.9888916015625, "actor_loss": -3036.657470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1531391143798828, "alpha_loss": 0.5025983452796936, "alpha_value": 0.9437656941560303, "duration": 1.5937049388885498, "info_normalized_performance_mean": 0.4581031799316406, "info_normalized_performance_final": 0.4992063343524933, "info_performance_mean": 0.4581031799316406, "info_performance_final": 0.4992063343524933, "step": 1326500}
{"episode_reward": 916.2063492063495, "episode": 13266.0, "batch_reward": 9.060234069824219, "critic_loss": 1334.01513671875, "actor_loss": -2966.52978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.2968090772628784, "alpha_loss": 0.16055932641029358, "alpha_value": 0.930229831423184, "duration": 1.6112990379333496, "info_normalized_performance_mean": 0.29324671626091003, "info_normalized_performance_final": 0.350649356842041, "info_performance_mean": 0.29324671626091003, "info_performance_final": 0.350649356842041, "step": 1327000}
{"episode_reward": 586.4935064935066, "episode": 13271.0, "batch_reward": 9.179187774658203, "critic_loss": 1107.5936279296875, "actor_loss": -2986.33251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.243764877319336, "alpha_loss": -0.1601463407278061, "alpha_value": 0.919798203551623, "duration": 1.5616252422332764, "info_normalized_performance_mean": 0.4331536889076233, "info_normalized_performance_final": 0.4783950746059418, "info_performance_mean": 0.4331536889076233, "info_performance_final": 0.4783950746059418, "step": 1327500}
{"episode_reward": 866.3075196408528, "episode": 13276.0, "batch_reward": 10.219011306762695, "critic_loss": 703.966796875, "actor_loss": -3042.552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.5224701166152954, "alpha_loss": 0.6570291519165039, "alpha_value": 0.9089680644086314, "duration": 1.6076135635375977, "info_normalized_performance_mean": 0.7622700333595276, "info_normalized_performance_final": 0.8289999961853027, "info_performance_mean": 0.7622700333595276, "info_performance_final": 0.8289999961853027, "step": 1328000}
{"episode_reward": 1524.5399999999986, "episode": 13281.0, "batch_reward": 9.28607177734375, "critic_loss": 1333.9287109375, "actor_loss": -2967.222412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.8161077499389648, "alpha_loss": 0.446491539478302, "alpha_value": 0.8985915918276748, "duration": 1.5597875118255615, "info_normalized_performance_mean": 0.8811427354812622, "info_normalized_performance_final": 0.9428571462631226, "info_performance_mean": 0.8811427354812622, "info_performance_final": 0.9428571462631226, "step": 1328500}
{"episode_reward": 1762.285714285716, "episode": 13286.0, "batch_reward": 9.733314514160156, "critic_loss": 679.031982421875, "actor_loss": -2988.75146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.716726541519165, "alpha_loss": 0.12161069363355637, "alpha_value": 0.8873876102891592, "duration": 1.4929933547973633, "info_normalized_performance_mean": 0.8392810225486755, "info_normalized_performance_final": 0.903124988079071, "info_performance_mean": 0.8392810225486755, "info_performance_final": 0.903124988079071, "step": 1329000}
{"episode_reward": 1678.5625, "episode": 13291.0, "batch_reward": 8.935548782348633, "critic_loss": 1226.51953125, "actor_loss": -2913.501708984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8779249787330627, "alpha_loss": 0.047955550253391266, "alpha_value": 0.8746735699418492, "duration": 1.6515986919403076, "info_normalized_performance_mean": 0.5879827737808228, "info_normalized_performance_final": 0.6375661492347717, "info_performance_mean": 0.5879827737808228, "info_performance_final": 0.6375661492347717, "step": 1329500}
{"episode_reward": 1175.9656084656071, "episode": 13296.0, "batch_reward": 9.618465423583984, "critic_loss": 1177.1998291015625, "actor_loss": -2891.07666015625, "actor_target_entropy": -3.0, "actor_entropy": 1.5040653944015503, "alpha_loss": 0.2778134346008301, "alpha_value": 0.8623832330031025, "step": 1330000}
{"duration": 18.6246075630188, "info_normalized_performance_mean": 0.4309751093387604, "info_normalized_performance_final": 0.47165533900260925, "info_performance_mean": 0.4309751093387604, "info_performance_final": 0.47165533900260925, "step": 1330000}
{"episode_reward": 861.950113378686, "episode": 13301.0, "batch_reward": 9.483637809753418, "critic_loss": 605.7598876953125, "actor_loss": -2849.56103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0460753440856934, "alpha_loss": 0.6216120719909668, "alpha_value": 0.8509616647103713, "duration": 1.5801174640655518, "info_normalized_performance_mean": 0.7184999585151672, "info_normalized_performance_final": 0.7890625, "info_performance_mean": 0.7184999585151672, "info_performance_final": 0.7890625, "step": 1330500}
{"episode_reward": 1437.0, "episode": 13306.0, "batch_reward": 9.5129976272583, "critic_loss": 2767.49951171875, "actor_loss": -2800.82958984375, "actor_target_entropy": -3.0, "actor_entropy": 0.872218906879425, "alpha_loss": 0.19709667563438416, "alpha_value": 0.8418940839396905, "duration": 1.5832834243774414, "info_normalized_performance_mean": 0.4181325435638428, "info_normalized_performance_final": 0.4659999907016754, "info_performance_mean": 0.4181325435638428, "info_performance_final": 0.4659999907016754, "step": 1331000}
{"episode_reward": 836.2650000000015, "episode": 13311.0, "batch_reward": 9.841531753540039, "critic_loss": 673.9815673828125, "actor_loss": -2808.6474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3145750761032104, "alpha_loss": 0.7658447623252869, "alpha_value": 0.8369723030251163, "duration": 1.4998106956481934, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1331500}
{"episode_reward": 0.0, "episode": 13316.0, "batch_reward": 9.013823509216309, "critic_loss": 1437.6478271484375, "actor_loss": -2750.95556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0396109819412231, "alpha_loss": 0.1003108024597168, "alpha_value": 0.8310306843437663, "duration": 1.6054494380950928, "info_normalized_performance_mean": 0.7374706864356995, "info_normalized_performance_final": 0.8078431487083435, "info_performance_mean": 0.7374706864356995, "info_performance_final": 0.8078431487083435, "step": 1332000}
{"episode_reward": 1474.9411764705892, "episode": 13321.0, "batch_reward": 9.44830322265625, "critic_loss": 557.274169921875, "actor_loss": -2747.2431640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2434141635894775, "alpha_loss": 0.22383245825767517, "alpha_value": 0.8221502700595081, "duration": 1.4501011371612549, "info_normalized_performance_mean": 0.4725573658943176, "info_normalized_performance_final": 0.5140306353569031, "info_performance_mean": 0.4725573658943176, "info_performance_final": 0.5140306353569031, "step": 1332500}
{"episode_reward": 945.1147959183668, "episode": 13326.0, "batch_reward": 9.097274780273438, "critic_loss": 1523.1220703125, "actor_loss": -2716.73974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1780822277069092, "alpha_loss": -0.02514185756444931, "alpha_value": 0.8167989201242268, "duration": 1.586470603942871, "info_normalized_performance_mean": 0.5953433513641357, "info_normalized_performance_final": 0.660601019859314, "info_performance_mean": 0.5953433513641357, "info_performance_final": 0.660601019859314, "step": 1333000}
{"episode_reward": 1190.686517783291, "episode": 13331.0, "batch_reward": 9.609821319580078, "critic_loss": 763.4854125976562, "actor_loss": -2745.72412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1006338596343994, "alpha_loss": -0.011739015579223633, "alpha_value": 0.8055942417188806, "duration": 1.4326109886169434, "info_normalized_performance_mean": 0.5246427655220032, "info_normalized_performance_final": 0.5696428418159485, "info_performance_mean": 0.5246427655220032, "info_performance_final": 0.5696428418159485, "step": 1333500}
{"episode_reward": 1049.2857142857133, "episode": 13336.0, "batch_reward": 8.894742965698242, "critic_loss": 1697.9326171875, "actor_loss": -2666.2138671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9847508072853088, "alpha_loss": 0.1968919038772583, "alpha_value": 0.7953617211591547, "duration": 1.5085337162017822, "info_normalized_performance_mean": 0.8246204853057861, "info_normalized_performance_final": 0.8995535969734192, "info_performance_mean": 0.8246204853057861, "info_performance_final": 0.8995535969734192, "step": 1334000}
{"episode_reward": 1649.2410714285686, "episode": 13341.0, "batch_reward": 9.33615493774414, "critic_loss": 1840.2733154296875, "actor_loss": -2656.1103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0391645431518555, "alpha_loss": 0.3068864345550537, "alpha_value": 0.7838923540673589, "duration": 1.6385753154754639, "info_normalized_performance_mean": 0.8331429362297058, "info_normalized_performance_final": 0.9055555462837219, "info_performance_mean": 0.8331429362297058, "info_performance_final": 0.9055555462837219, "step": 1334500}
{"episode_reward": 1666.2857142857124, "episode": 13346.0, "batch_reward": 9.962246894836426, "critic_loss": 1024.6671142578125, "actor_loss": -2645.5810546875, "actor_target_entropy": -3.0, "actor_entropy": 0.9160275459289551, "alpha_loss": 0.34865471720695496, "alpha_value": 0.774443564249512, "duration": 1.4819376468658447, "info_normalized_performance_mean": 0.5705037117004395, "info_normalized_performance_final": 0.636904776096344, "info_performance_mean": 0.5705037117004395, "info_performance_final": 0.636904776096344, "step": 1335000}
{"episode_reward": 1141.0073260073234, "episode": 13351.0, "batch_reward": 10.389333724975586, "critic_loss": 675.6259765625, "actor_loss": -2666.442626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1436017751693726, "alpha_loss": 0.3377448320388794, "alpha_value": 0.7629254718945425, "duration": 1.5428612232208252, "info_normalized_performance_mean": 0.9280359148979187, "info_normalized_performance_final": 0.9980158805847168, "info_performance_mean": 0.9280359148979187, "info_performance_final": 0.9980158805847168, "step": 1335500}
{"episode_reward": 1856.0714285714246, "episode": 13356.0, "batch_reward": 9.723273277282715, "critic_loss": 636.7198486328125, "actor_loss": -2620.244140625, "actor_target_entropy": -3.0, "actor_entropy": 1.4190411567687988, "alpha_loss": 0.2582969069480896, "alpha_value": 0.7551236968212915, "duration": 1.5610499382019043, "info_normalized_performance_mean": 0.5250308513641357, "info_normalized_performance_final": 0.5802469253540039, "info_performance_mean": 0.5250308513641357, "info_performance_final": 0.5802469253540039, "step": 1336000}
{"episode_reward": 1050.0617283950633, "episode": 13361.0, "batch_reward": 8.879956245422363, "critic_loss": 1411.905029296875, "actor_loss": -2523.142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1506474018096924, "alpha_loss": 0.2773798108100891, "alpha_value": 0.7493713181546053, "duration": 1.566504716873169, "info_normalized_performance_mean": 0.8516344428062439, "info_normalized_performance_final": 0.9148351550102234, "info_performance_mean": 0.8516344428062439, "info_performance_final": 0.9148351550102234, "step": 1336500}
{"episode_reward": 1703.269230769231, "episode": 13366.0, "batch_reward": 9.088111877441406, "critic_loss": 1541.587890625, "actor_loss": -2522.242919921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7226517796516418, "alpha_loss": -0.19400683045387268, "alpha_value": 0.7401350129265147, "duration": 1.6147782802581787, "info_normalized_performance_mean": 0.6138815879821777, "info_normalized_performance_final": 0.6594516634941101, "info_performance_mean": 0.6138815879821777, "info_performance_final": 0.6594516634941101, "step": 1337000}
{"episode_reward": 1227.7633477633485, "episode": 13371.0, "batch_reward": 10.229656219482422, "critic_loss": 724.462890625, "actor_loss": -2609.78125, "actor_target_entropy": -3.0, "actor_entropy": 1.2082555294036865, "alpha_loss": 0.21120204031467438, "alpha_value": 0.7324744441183012, "duration": 1.6215941905975342, "info_normalized_performance_mean": 0.594916582107544, "info_normalized_performance_final": 0.6465277671813965, "info_performance_mean": 0.594916582107544, "info_performance_final": 0.6465277671813965, "step": 1337500}
{"episode_reward": 1189.8333333333337, "episode": 13376.0, "batch_reward": 9.716706275939941, "critic_loss": 1281.0316162109375, "actor_loss": -2552.59130859375, "actor_target_entropy": -3.0, "actor_entropy": 0.7970739603042603, "alpha_loss": 0.16152708232402802, "alpha_value": 0.7226144231019732, "duration": 1.5925614833831787, "info_normalized_performance_mean": 0.4590258300304413, "info_normalized_performance_final": 0.5124675035476685, "info_performance_mean": 0.4590258300304413, "info_performance_final": 0.5124675035476685, "step": 1338000}
{"episode_reward": 918.0519480519473, "episode": 13381.0, "batch_reward": 9.197460174560547, "critic_loss": 902.137451171875, "actor_loss": -2441.5751953125, "actor_target_entropy": -3.0, "actor_entropy": 1.0151269435882568, "alpha_loss": 0.23741602897644043, "alpha_value": 0.7132301766645248, "duration": 1.5968999862670898, "info_normalized_performance_mean": 0.5896428823471069, "info_normalized_performance_final": 0.6333333253860474, "info_performance_mean": 0.5896428823471069, "info_performance_final": 0.6333333253860474, "step": 1338500}
{"episode_reward": 1179.285714285714, "episode": 13386.0, "batch_reward": 10.15422534942627, "critic_loss": 885.681884765625, "actor_loss": -2549.04248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5194534063339233, "alpha_loss": 0.2702658176422119, "alpha_value": 0.7019749618143349, "duration": 1.4959800243377686, "info_normalized_performance_mean": 0.3395659625530243, "info_normalized_performance_final": 0.375, "info_performance_mean": 0.3395659625530243, "info_performance_final": 0.375, "step": 1339000}
{"episode_reward": 679.1319444444445, "episode": 13391.0, "batch_reward": 8.423537254333496, "critic_loss": 1515.1761474609375, "actor_loss": -2367.591552734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9044559597969055, "alpha_loss": -0.08976765722036362, "alpha_value": 0.6896531832970749, "duration": 1.5379724502563477, "info_normalized_performance_mean": 0.4451953172683716, "info_normalized_performance_final": 0.484375, "info_performance_mean": 0.4451953172683716, "info_performance_final": 0.484375, "step": 1339500}
{"episode_reward": 890.390625, "episode": 13396.0, "batch_reward": 9.530279159545898, "critic_loss": 1309.883056640625, "actor_loss": -2398.11767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2191708087921143, "alpha_loss": 0.27556097507476807, "alpha_value": 0.6789394167548684, "step": 1340000}
{"duration": 19.16761088371277, "info_normalized_performance_mean": 0.4689044952392578, "info_normalized_performance_final": 0.524545431137085, "info_performance_mean": 0.4689044952392578, "info_performance_final": 0.524545431137085, "step": 1340000}
{"episode_reward": 937.8090909090914, "episode": 13401.0, "batch_reward": 8.942649841308594, "critic_loss": 718.5117797851562, "actor_loss": -2355.40380859375, "actor_target_entropy": -3.0, "actor_entropy": 0.6527528762817383, "alpha_loss": 0.01637040078639984, "alpha_value": 0.6701777379435297, "duration": 1.6020643711090088, "info_normalized_performance_mean": 0.5269834399223328, "info_normalized_performance_final": 0.5674999952316284, "info_performance_mean": 0.5269834399223328, "info_performance_final": 0.5674999952316284, "step": 1340500}
{"episode_reward": 1053.9666666666678, "episode": 13406.0, "batch_reward": 8.353042602539062, "critic_loss": 682.7364501953125, "actor_loss": -2347.49755859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1036818027496338, "alpha_loss": 0.31538456678390503, "alpha_value": 0.6599240805705667, "duration": 1.5853943824768066, "info_normalized_performance_mean": 0.800811767578125, "info_normalized_performance_final": 0.8611764907836914, "info_performance_mean": 0.800811767578125, "info_performance_final": 0.8611764907836914, "step": 1341000}
{"episode_reward": 1601.6235294117664, "episode": 13411.0, "batch_reward": 9.367511749267578, "critic_loss": 1227.883544921875, "actor_loss": -2360.0556640625, "actor_target_entropy": -3.0, "actor_entropy": 0.6924128532409668, "alpha_loss": -0.013686718419194221, "alpha_value": 0.6476619367782896, "duration": 1.596787452697754, "info_normalized_performance_mean": 0.6603912115097046, "info_normalized_performance_final": 0.7176870703697205, "info_performance_mean": 0.6603912115097046, "info_performance_final": 0.7176870703697205, "step": 1341500}
{"episode_reward": 1320.7823129251692, "episode": 13416.0, "batch_reward": 8.611173629760742, "critic_loss": 1576.848876953125, "actor_loss": -2308.641357421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8011816740036011, "alpha_loss": 0.09640856832265854, "alpha_value": 0.6385162490420225, "duration": 1.5949559211730957, "info_normalized_performance_mean": 0.4313485026359558, "info_normalized_performance_final": 0.48148149251937866, "info_performance_mean": 0.4313485026359558, "info_performance_final": 0.48148149251937866, "step": 1342000}
{"episode_reward": 862.6970560303906, "episode": 13421.0, "batch_reward": 8.739154815673828, "critic_loss": 1469.9371337890625, "actor_loss": -2273.665771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1796486377716064, "alpha_loss": -0.11938455700874329, "alpha_value": 0.6311847064501168, "duration": 1.6083433628082275, "info_normalized_performance_mean": 0.8480961322784424, "info_normalized_performance_final": 0.9069518446922302, "info_performance_mean": 0.8480961322784424, "info_performance_final": 0.9069518446922302, "step": 1342500}
{"episode_reward": 1696.1925133689872, "episode": 13426.0, "batch_reward": 9.096845626831055, "critic_loss": 885.6060180664062, "actor_loss": -2277.59326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3408536911010742, "alpha_loss": 0.37481623888015747, "alpha_value": 0.6227347515370213, "duration": 1.5668656826019287, "info_normalized_performance_mean": 0.7874851822853088, "info_normalized_performance_final": 0.8558823466300964, "info_performance_mean": 0.7874851822853088, "info_performance_final": 0.8558823466300964, "step": 1343000}
{"episode_reward": 1574.970588235291, "episode": 13431.0, "batch_reward": 9.473313331604004, "critic_loss": 1293.52880859375, "actor_loss": -2333.9375, "actor_target_entropy": -3.0, "actor_entropy": 1.2880079746246338, "alpha_loss": 0.04828384146094322, "alpha_value": 0.6190348306647826, "duration": 1.6003479957580566, "info_normalized_performance_mean": 0.5317844152450562, "info_normalized_performance_final": 0.5924675464630127, "info_performance_mean": 0.5317844152450562, "info_performance_final": 0.5924675464630127, "step": 1343500}
{"episode_reward": 1063.568831168831, "episode": 13436.0, "batch_reward": 10.018878936767578, "critic_loss": 2013.564208984375, "actor_loss": -2337.302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.2625279426574707, "alpha_loss": -0.1327642798423767, "alpha_value": 0.612861943767747, "duration": 1.5050365924835205, "info_normalized_performance_mean": 0.6060556769371033, "info_normalized_performance_final": 0.65070641040802, "info_performance_mean": 0.6060556769371033, "info_performance_final": 0.65070641040802, "step": 1344000}
{"episode_reward": 1212.1114599686016, "episode": 13441.0, "batch_reward": 8.592979431152344, "critic_loss": 960.2581787109375, "actor_loss": -2251.94921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7573724985122681, "alpha_loss": 0.18318170309066772, "alpha_value": 0.6052859405597689, "duration": 1.5116653442382812, "info_normalized_performance_mean": 0.3857540190219879, "info_normalized_performance_final": 0.4186508059501648, "info_performance_mean": 0.3857540190219879, "info_performance_final": 0.4186508059501648, "step": 1344500}
{"episode_reward": 771.5079365079383, "episode": 13446.0, "batch_reward": 9.426301002502441, "critic_loss": 468.32171630859375, "actor_loss": -2221.6572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2023075819015503, "alpha_loss": 0.3334681987762451, "alpha_value": 0.5992651097651972, "duration": 1.6653048992156982, "info_normalized_performance_mean": 0.7833192944526672, "info_normalized_performance_final": 0.8576388955116272, "info_performance_mean": 0.7833192944526672, "info_performance_final": 0.8576388955116272, "step": 1345000}
{"episode_reward": 1566.6388888888919, "episode": 13451.0, "batch_reward": 9.989295959472656, "critic_loss": 1066.777099609375, "actor_loss": -2264.64697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0740759372711182, "alpha_loss": 0.16285666823387146, "alpha_value": 0.5917158236862227, "duration": 1.6879000663757324, "info_normalized_performance_mean": 0.3550657033920288, "info_normalized_performance_final": 0.40338829159736633, "info_performance_mean": 0.3550657033920288, "info_performance_final": 0.40338829159736633, "step": 1345500}
{"episode_reward": 710.131257631258, "episode": 13456.0, "batch_reward": 9.943838119506836, "critic_loss": 959.3845825195312, "actor_loss": -2212.669921875, "actor_target_entropy": -3.0, "actor_entropy": 1.135993242263794, "alpha_loss": 0.3306533396244049, "alpha_value": 0.5848746997408986, "duration": 1.7182111740112305, "info_normalized_performance_mean": 0.42817917466163635, "info_normalized_performance_final": 0.4832112193107605, "info_performance_mean": 0.42817917466163635, "info_performance_final": 0.4832112193107605, "step": 1346000}
{"episode_reward": 856.3583638583638, "episode": 13461.0, "batch_reward": 9.006367683410645, "critic_loss": 1145.3349609375, "actor_loss": -2163.6015625, "actor_target_entropy": -3.0, "actor_entropy": 1.019313097000122, "alpha_loss": 0.27251601219177246, "alpha_value": 0.5822128718325279, "duration": 1.4798600673675537, "info_normalized_performance_mean": 0.7403645515441895, "info_normalized_performance_final": 0.796875, "info_performance_mean": 0.7403645515441895, "info_performance_final": 0.796875, "step": 1346500}
{"episode_reward": 1480.7291666666665, "episode": 13466.0, "batch_reward": 9.09255599975586, "critic_loss": 1083.8499755859375, "actor_loss": -2163.30712890625, "actor_target_entropy": -3.0, "actor_entropy": 1.471527338027954, "alpha_loss": 0.2072446644306183, "alpha_value": 0.578504401130074, "duration": 1.5024158954620361, "info_normalized_performance_mean": 0.36379989981651306, "info_normalized_performance_final": 0.38999998569488525, "info_performance_mean": 0.36379989981651306, "info_performance_final": 0.38999998569488525, "step": 1347000}
{"episode_reward": 727.5999999999992, "episode": 13471.0, "batch_reward": 9.245309829711914, "critic_loss": 901.14306640625, "actor_loss": -2165.515625, "actor_target_entropy": -3.0, "actor_entropy": 1.291920781135559, "alpha_loss": -0.025992266833782196, "alpha_value": 0.5751080250214946, "duration": 1.4254038333892822, "info_normalized_performance_mean": 0.2220117151737213, "info_normalized_performance_final": 0.2421875, "info_performance_mean": 0.2220117151737213, "info_performance_final": 0.2421875, "step": 1347500}
{"episode_reward": 444.0234375, "episode": 13476.0, "batch_reward": 9.122625350952148, "critic_loss": 1125.158935546875, "actor_loss": -2168.121826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1900660991668701, "alpha_loss": 0.11012369394302368, "alpha_value": 0.5762668786834527, "duration": 1.5622096061706543, "info_normalized_performance_mean": 0.4746457636356354, "info_normalized_performance_final": 0.5357044339179993, "info_performance_mean": 0.4746457636356354, "info_performance_final": 0.5357044339179993, "step": 1348000}
{"episode_reward": 949.291425420459, "episode": 13481.0, "batch_reward": 8.402976036071777, "critic_loss": 2066.61279296875, "actor_loss": -2162.43798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7951503992080688, "alpha_loss": -0.09890495240688324, "alpha_value": 0.5790640792202386, "duration": 1.4616599082946777, "info_normalized_performance_mean": 0.6783332228660583, "info_normalized_performance_final": 0.7321428656578064, "info_performance_mean": 0.6783332228660583, "info_performance_final": 0.7321428656578064, "step": 1348500}
{"episode_reward": 1356.6666666666652, "episode": 13486.0, "batch_reward": 9.052119255065918, "critic_loss": 767.3114013671875, "actor_loss": -2123.391845703125, "actor_target_entropy": -3.0, "actor_entropy": 0.8888393640518188, "alpha_loss": -0.19809578359127045, "alpha_value": 0.584032674266887, "duration": 1.449272632598877, "info_normalized_performance_mean": 0.23028291761875153, "info_normalized_performance_final": 0.252782940864563, "info_performance_mean": 0.23028291761875153, "info_performance_final": 0.252782940864563, "step": 1349000}
{"episode_reward": 460.56586270872066, "episode": 13491.0, "batch_reward": 9.62781810760498, "critic_loss": 718.845458984375, "actor_loss": -2134.65771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0683705806732178, "alpha_loss": -0.19463969767093658, "alpha_value": 0.586037696970572, "duration": 1.4467639923095703, "info_normalized_performance_mean": 0.04878246411681175, "info_normalized_performance_final": 0.055194806307554245, "info_performance_mean": 0.04878246411681175, "info_performance_final": 0.055194806307554245, "step": 1349500}
{"episode_reward": 97.56493506493513, "episode": 13496.0, "batch_reward": 8.840412139892578, "critic_loss": 1582.446044921875, "actor_loss": -2085.3330078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8558704853057861, "alpha_loss": 0.01681869849562645, "alpha_value": 0.5904749524588979, "step": 1350000}
{"duration": 18.69627285003662, "info_normalized_performance_mean": 0.529739260673523, "info_normalized_performance_final": 0.5748299360275269, "info_performance_mean": 0.529739260673523, "info_performance_final": 0.5748299360275269, "step": 1350000}
{"episode_reward": 1059.4784580498863, "episode": 13501.0, "batch_reward": 8.927675247192383, "critic_loss": 1845.808349609375, "actor_loss": -2106.62890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7276322841644287, "alpha_loss": -0.33941036462783813, "alpha_value": 0.5920714399043324, "duration": 1.415400743484497, "info_normalized_performance_mean": 0.33485129475593567, "info_normalized_performance_final": 0.3839285671710968, "info_performance_mean": 0.33485129475593567, "info_performance_final": 0.3839285671710968, "step": 1350500}
{"episode_reward": 669.702380952382, "episode": 13506.0, "batch_reward": 8.670125961303711, "critic_loss": 722.7396240234375, "actor_loss": -2006.693603515625, "actor_target_entropy": -3.0, "actor_entropy": 1.239047646522522, "alpha_loss": 0.36715757846832275, "alpha_value": 0.593071641127013, "duration": 1.5116033554077148, "info_normalized_performance_mean": 0.8418619632720947, "info_normalized_performance_final": 0.9056122303009033, "info_performance_mean": 0.8418619632720947, "info_performance_final": 0.9056122303009033, "step": 1351000}
{"episode_reward": 1683.7244897959206, "episode": 13511.0, "batch_reward": 9.098856925964355, "critic_loss": 711.043701171875, "actor_loss": -2028.294677734375, "actor_target_entropy": -3.0, "actor_entropy": 0.8622373342514038, "alpha_loss": -0.008730202913284302, "alpha_value": 0.5962704690861375, "duration": 1.4897146224975586, "info_normalized_performance_mean": 0.441112220287323, "info_normalized_performance_final": 0.4790816307067871, "info_performance_mean": 0.441112220287323, "info_performance_final": 0.4790816307067871, "step": 1351500}
{"episode_reward": 882.2244897959173, "episode": 13516.0, "batch_reward": 9.016979217529297, "critic_loss": 420.454345703125, "actor_loss": -2058.761474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.12531316280365, "alpha_loss": -0.10384798049926758, "alpha_value": 0.5929202195365514, "duration": 1.61427640914917, "info_normalized_performance_mean": 0.5309299826622009, "info_normalized_performance_final": 0.590749979019165, "info_performance_mean": 0.5309299826622009, "info_performance_final": 0.590749979019165, "step": 1352000}
{"episode_reward": 1061.8600000000024, "episode": 13521.0, "batch_reward": 8.890312194824219, "critic_loss": 816.1612548828125, "actor_loss": -1953.3548583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.2357842922210693, "alpha_loss": 0.20823727548122406, "alpha_value": 0.5882431660385321, "duration": 1.525334358215332, "info_normalized_performance_mean": 0.5160222053527832, "info_normalized_performance_final": 0.5621744990348816, "info_performance_mean": 0.5160222053527832, "info_performance_final": 0.5621744990348816, "step": 1352500}
{"episode_reward": 1032.0442708333346, "episode": 13526.0, "batch_reward": 8.750129699707031, "critic_loss": 3782.3291015625, "actor_loss": -1946.6204833984375, "actor_target_entropy": -3.0, "actor_entropy": 1.29079270362854, "alpha_loss": 0.2716969847679138, "alpha_value": 0.588199253149803, "duration": 1.5533406734466553, "info_normalized_performance_mean": 0.3511204421520233, "info_normalized_performance_final": 0.38568180799484253, "info_performance_mean": 0.3511204421520233, "info_performance_final": 0.38568180799484253, "step": 1353000}
{"episode_reward": 702.2409090909092, "episode": 13531.0, "batch_reward": 9.271881103515625, "critic_loss": 2249.10888671875, "actor_loss": -2029.9530029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8260546922683716, "alpha_loss": -0.260916531085968, "alpha_value": 0.5856752554873175, "duration": 1.4802613258361816, "info_normalized_performance_mean": 0.28684520721435547, "info_normalized_performance_final": 0.3154761791229248, "info_performance_mean": 0.28684520721435547, "info_performance_final": 0.3154761791229248, "step": 1353500}
{"episode_reward": 573.6904761904758, "episode": 13536.0, "batch_reward": 8.781450271606445, "critic_loss": 524.95068359375, "actor_loss": -1949.42138671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9527564644813538, "alpha_loss": 0.05405798926949501, "alpha_value": 0.5868479173908929, "duration": 1.605959415435791, "info_normalized_performance_mean": 0.633077085018158, "info_normalized_performance_final": 0.7092307806015015, "info_performance_mean": 0.633077085018158, "info_performance_final": 0.7092307806015015, "step": 1354000}
{"episode_reward": 1266.1538461538476, "episode": 13541.0, "batch_reward": 7.45509147644043, "critic_loss": 1466.2386474609375, "actor_loss": -1938.95361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0392889976501465, "alpha_loss": -0.4217928647994995, "alpha_value": 0.5873890613542706, "duration": 1.4956226348876953, "info_normalized_performance_mean": 0.4371565878391266, "info_normalized_performance_final": 0.5604395866394043, "info_performance_mean": 0.4371565878391266, "info_performance_final": 0.5604395866394043, "step": 1354500}
{"episode_reward": 874.3131868131873, "episode": 13546.0, "batch_reward": 8.866559982299805, "critic_loss": 1072.03125, "actor_loss": -1952.055419921875, "actor_target_entropy": -3.0, "actor_entropy": 1.1811845302581787, "alpha_loss": 0.1369514912366867, "alpha_value": 0.5839086750379792, "duration": 1.3423762321472168, "info_normalized_performance_mean": 0.33705735206604004, "info_normalized_performance_final": 0.3663003742694855, "info_performance_mean": 0.33705735206604004, "info_performance_final": 0.3663003742694855, "step": 1355000}
{"episode_reward": 674.1147741147739, "episode": 13551.0, "batch_reward": 8.916498184204102, "critic_loss": 789.667724609375, "actor_loss": -1960.09521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.2149083614349365, "alpha_loss": 0.16024480760097504, "alpha_value": 0.5793397690081599, "duration": 1.4988629817962646, "info_normalized_performance_mean": 0.16932697594165802, "info_normalized_performance_final": 0.19951923191547394, "info_performance_mean": 0.16932697594165802, "info_performance_final": 0.19951923191547394, "step": 1355500}
{"episode_reward": 338.6538461538466, "episode": 13556.0, "batch_reward": 8.80034065246582, "critic_loss": 889.069580078125, "actor_loss": -1961.47265625, "actor_target_entropy": -3.0, "actor_entropy": 0.9251383543014526, "alpha_loss": -0.05384421348571777, "alpha_value": 0.5711492148428651, "duration": 1.4511675834655762, "info_normalized_performance_mean": 0.3656817376613617, "info_normalized_performance_final": 0.4025973975658417, "info_performance_mean": 0.3656817376613617, "info_performance_final": 0.4025973975658417, "step": 1356000}
{"episode_reward": 731.3636363636374, "episode": 13561.0, "batch_reward": 8.322076797485352, "critic_loss": 1182.099609375, "actor_loss": -1913.56787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3217378854751587, "alpha_loss": 0.1644931137561798, "alpha_value": 0.5661158852405633, "duration": 1.4806370735168457, "info_normalized_performance_mean": 0.409842312335968, "info_normalized_performance_final": 0.44480520486831665, "info_performance_mean": 0.409842312335968, "info_performance_final": 0.44480520486831665, "step": 1356500}
{"episode_reward": 819.6846011131735, "episode": 13566.0, "batch_reward": 8.89535903930664, "critic_loss": 1293.6005859375, "actor_loss": -1928.347900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0036871433258057, "alpha_loss": -0.032340481877326965, "alpha_value": 0.5602151400508322, "duration": 1.5165197849273682, "info_normalized_performance_mean": 0.5110165476799011, "info_normalized_performance_final": 0.557692289352417, "info_performance_mean": 0.5110165476799011, "info_performance_final": 0.557692289352417, "step": 1357000}
{"episode_reward": 1022.0329670329683, "episode": 13571.0, "batch_reward": 8.83817195892334, "critic_loss": 792.00244140625, "actor_loss": -1896.2333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.2233525514602661, "alpha_loss": 0.21686427295207977, "alpha_value": 0.550005202569784, "duration": 1.5591778755187988, "info_normalized_performance_mean": 0.2343529462814331, "info_normalized_performance_final": 0.2541176378726959, "info_performance_mean": 0.2343529462814331, "info_performance_final": 0.2541176378726959, "step": 1357500}
{"episode_reward": 468.70588235294065, "episode": 13576.0, "batch_reward": 9.850281715393066, "critic_loss": 824.3157348632812, "actor_loss": -1914.385986328125, "actor_target_entropy": -3.0, "actor_entropy": 1.105552315711975, "alpha_loss": 0.27960819005966187, "alpha_value": 0.5425869301380359, "duration": 1.4876151084899902, "info_normalized_performance_mean": 0.2880666255950928, "info_normalized_performance_final": 0.3100000023841858, "info_performance_mean": 0.2880666255950928, "info_performance_final": 0.3100000023841858, "step": 1358000}
{"episode_reward": 576.1333333333332, "episode": 13581.0, "batch_reward": 8.757550239562988, "critic_loss": 1280.075927734375, "actor_loss": -1864.722412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1666648387908936, "alpha_loss": -0.025546453893184662, "alpha_value": 0.5351138831870842, "duration": 1.4617526531219482, "info_normalized_performance_mean": 0.5361847877502441, "info_normalized_performance_final": 0.5764706134796143, "info_performance_mean": 0.5361847877502441, "info_performance_final": 0.5764706134796143, "step": 1358500}
{"episode_reward": 1072.3697478991578, "episode": 13586.0, "batch_reward": 8.600207328796387, "critic_loss": 3991.39697265625, "actor_loss": -1869.733154296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8650816082954407, "alpha_loss": -0.09994249790906906, "alpha_value": 0.5294977668886366, "duration": 1.532329797744751, "info_normalized_performance_mean": 0.3416574001312256, "info_normalized_performance_final": 0.3777777850627899, "info_performance_mean": 0.3416574001312256, "info_performance_final": 0.3777777850627899, "step": 1359000}
{"episode_reward": 683.3148148148139, "episode": 13591.0, "batch_reward": 9.112173080444336, "critic_loss": 460.4894714355469, "actor_loss": -1930.943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9174450635910034, "alpha_loss": 0.17305169999599457, "alpha_value": 0.5279366114941545, "duration": 1.5542147159576416, "info_normalized_performance_mean": 0.5372405648231506, "info_normalized_performance_final": 0.5764706134796143, "info_performance_mean": 0.5372405648231506, "info_performance_final": 0.5764706134796143, "step": 1359500}
{"episode_reward": 1074.481283422458, "episode": 13596.0, "batch_reward": 8.94740104675293, "critic_loss": 1023.76513671875, "actor_loss": -1803.6158447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.4638628959655762, "alpha_loss": 0.09942486882209778, "alpha_value": 0.5242412504560358, "step": 1360000}
{"duration": 18.775551795959473, "info_normalized_performance_mean": 0.559955358505249, "info_normalized_performance_final": 0.609375, "info_performance_mean": 0.559955358505249, "info_performance_final": 0.609375, "step": 1360000}
{"episode_reward": 1119.9107142857142, "episode": 13601.0, "batch_reward": 8.824470520019531, "critic_loss": 890.612548828125, "actor_loss": -1836.2515869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.894355058670044, "alpha_loss": 0.16339074075222015, "alpha_value": 0.5239329998928898, "duration": 1.5294511318206787, "info_normalized_performance_mean": 0.7654465436935425, "info_normalized_performance_final": 0.8377976417541504, "info_performance_mean": 0.7654465436935425, "info_performance_final": 0.8377976417541504, "step": 1360500}
{"episode_reward": 1530.8928571428557, "episode": 13606.0, "batch_reward": 10.257944107055664, "critic_loss": 386.71478271484375, "actor_loss": -1862.6719970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6178152561187744, "alpha_loss": 0.5363243222236633, "alpha_value": 0.5219612310944363, "duration": 1.520467758178711, "info_normalized_performance_mean": 0.34665122628211975, "info_normalized_performance_final": 0.4119318127632141, "info_performance_mean": 0.34665122628211975, "info_performance_final": 0.4119318127632141, "step": 1361000}
{"episode_reward": 693.3025568181815, "episode": 13611.0, "batch_reward": 8.097390174865723, "critic_loss": 951.1509399414062, "actor_loss": -1765.597900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.6482410430908203, "alpha_loss": 0.22102805972099304, "alpha_value": 0.5180000288741324, "duration": 1.5087151527404785, "info_normalized_performance_mean": 0.8381150960922241, "info_normalized_performance_final": 0.9047619104385376, "info_performance_mean": 0.8381150960922241, "info_performance_final": 0.9047619104385376, "step": 1361500}
{"episode_reward": 1676.2301587301572, "episode": 13616.0, "batch_reward": 8.137676239013672, "critic_loss": 829.260986328125, "actor_loss": -1748.255615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2015769481658936, "alpha_loss": 0.059547070413827896, "alpha_value": 0.5165238779841389, "duration": 1.6461875438690186, "info_normalized_performance_mean": 0.5365121364593506, "info_normalized_performance_final": 0.5993406772613525, "info_performance_mean": 0.5365121364593506, "info_performance_final": 0.5993406772613525, "step": 1362000}
{"episode_reward": 1073.0241758241746, "episode": 13621.0, "batch_reward": 8.196873664855957, "critic_loss": 749.2874755859375, "actor_loss": -1789.384521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.2495877742767334, "alpha_loss": -0.09606227278709412, "alpha_value": 0.5150426771060517, "duration": 1.471569299697876, "info_normalized_performance_mean": 0.7741818428039551, "info_normalized_performance_final": 0.857753336429596, "info_performance_mean": 0.7741818428039551, "info_performance_final": 0.857753336429596, "step": 1362500}
{"episode_reward": 1548.3638583638594, "episode": 13626.0, "batch_reward": 8.933416366577148, "critic_loss": 979.565185546875, "actor_loss": -1790.714111328125, "actor_target_entropy": -3.0, "actor_entropy": 0.6550037860870361, "alpha_loss": -0.15070964395999908, "alpha_value": 0.5157751693641155, "duration": 1.647538185119629, "info_normalized_performance_mean": 0.731299877166748, "info_normalized_performance_final": 0.7960000038146973, "info_performance_mean": 0.731299877166748, "info_performance_final": 0.7960000038146973, "step": 1363000}
{"episode_reward": 1462.600000000001, "episode": 13631.0, "batch_reward": 7.621060371398926, "critic_loss": 602.0354614257812, "actor_loss": -1748.888671875, "actor_target_entropy": -3.0, "actor_entropy": 0.7854651808738708, "alpha_loss": -0.11491740494966507, "alpha_value": 0.5153650086798173, "duration": 1.6435260772705078, "info_normalized_performance_mean": 0.657916784286499, "info_normalized_performance_final": 0.7159722447395325, "info_performance_mean": 0.657916784286499, "info_performance_final": 0.7159722447395325, "step": 1363500}
{"episode_reward": 1315.833333333332, "episode": 13636.0, "batch_reward": 7.867849349975586, "critic_loss": 704.9006958007812, "actor_loss": -1736.48193359375, "actor_target_entropy": -3.0, "actor_entropy": 0.7076219320297241, "alpha_loss": -0.34236007928848267, "alpha_value": 0.516991058160784, "duration": 1.6049590110778809, "info_normalized_performance_mean": 0.3266541659832001, "info_normalized_performance_final": 0.3762499988079071, "info_performance_mean": 0.3266541659832001, "info_performance_final": 0.3762499988079071, "step": 1364000}
{"episode_reward": 653.3083333333321, "episode": 13641.0, "batch_reward": 8.546865463256836, "critic_loss": 652.7197875976562, "actor_loss": -1777.02783203125, "actor_target_entropy": -3.0, "actor_entropy": 0.678871750831604, "alpha_loss": -0.2459527999162674, "alpha_value": 0.5202253376908919, "duration": 1.4400713443756104, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1364500}
{"episode_reward": 0.0, "episode": 13646.0, "batch_reward": 9.09711742401123, "critic_loss": 1243.0291748046875, "actor_loss": -1753.223388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2102563381195068, "alpha_loss": -0.25230672955513, "alpha_value": 0.5293374994903967, "duration": 1.420950174331665, "info_normalized_performance_mean": 0.5632015466690063, "info_normalized_performance_final": 0.6045918464660645, "info_performance_mean": 0.5632015466690063, "info_performance_final": 0.6045918464660645, "step": 1365000}
{"episode_reward": 1126.4030612244894, "episode": 13651.0, "batch_reward": 8.176942825317383, "critic_loss": 901.4628295898438, "actor_loss": -1717.3736572265625, "actor_target_entropy": -3.0, "actor_entropy": 0.7776088714599609, "alpha_loss": -0.5233893990516663, "alpha_value": 0.5477249331717037, "duration": 1.6194815635681152, "info_normalized_performance_mean": 0.7927690148353577, "info_normalized_performance_final": 0.8524305820465088, "info_performance_mean": 0.7927690148353577, "info_performance_final": 0.8524305820465088, "step": 1365500}
{"episode_reward": 1585.5381944444425, "episode": 13656.0, "batch_reward": 8.280065536499023, "critic_loss": 542.4927368164062, "actor_loss": -1770.3359375, "actor_target_entropy": -3.0, "actor_entropy": 0.4421076476573944, "alpha_loss": -0.7866307497024536, "alpha_value": 0.5613881323804513, "duration": 1.435797929763794, "info_normalized_performance_mean": 0.669452965259552, "info_normalized_performance_final": 0.7291666865348816, "info_performance_mean": 0.669452965259552, "info_performance_final": 0.7291666865348816, "step": 1366000}
{"episode_reward": 1338.9062499999993, "episode": 13661.0, "batch_reward": 8.51457405090332, "critic_loss": 740.3372802734375, "actor_loss": -1730.30078125, "actor_target_entropy": -3.0, "actor_entropy": 1.113762617111206, "alpha_loss": -0.29419684410095215, "alpha_value": 0.5764188646902478, "duration": 1.6998014450073242, "info_normalized_performance_mean": 0.2760380804538727, "info_normalized_performance_final": 0.30979618430137634, "info_performance_mean": 0.2760380804538727, "info_performance_final": 0.30979618430137634, "step": 1366500}
{"episode_reward": 552.076265614726, "episode": 13666.0, "batch_reward": 8.936991691589355, "critic_loss": 886.4417724609375, "actor_loss": -1755.29736328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7079288363456726, "alpha_loss": -0.6012619137763977, "alpha_value": 0.5912113981239067, "duration": 1.4797227382659912, "info_normalized_performance_mean": 0.8291367888450623, "info_normalized_performance_final": 0.8898809552192688, "info_performance_mean": 0.8291367888450623, "info_performance_final": 0.8898809552192688, "step": 1367000}
{"episode_reward": 1658.2738095238087, "episode": 13671.0, "batch_reward": 8.644501686096191, "critic_loss": 1377.23779296875, "actor_loss": -1742.5289306640625, "actor_target_entropy": -3.0, "actor_entropy": 0.7301738262176514, "alpha_loss": -0.40201932191848755, "alpha_value": 0.6053811575251221, "duration": 1.5678393840789795, "info_normalized_performance_mean": 0.6246668100357056, "info_normalized_performance_final": 0.6683333516120911, "info_performance_mean": 0.6246668100357056, "info_performance_final": 0.6683333516120911, "step": 1367500}
{"episode_reward": 1249.3333333333321, "episode": 13676.0, "batch_reward": 9.1329345703125, "critic_loss": 2358.8466796875, "actor_loss": -1786.8585205078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2243738174438477, "alpha_loss": -0.08723483979701996, "alpha_value": 0.6161486398229643, "duration": 1.5935328006744385, "info_normalized_performance_mean": 0.8254470825195312, "info_normalized_performance_final": 0.8894117474555969, "info_performance_mean": 0.8254470825195312, "info_performance_final": 0.8894117474555969, "step": 1368000}
{"episode_reward": 1650.8941176470569, "episode": 13681.0, "batch_reward": 8.400516510009766, "critic_loss": 1396.1375732421875, "actor_loss": -1673.158203125, "actor_target_entropy": -3.0, "actor_entropy": 0.8594562411308289, "alpha_loss": -0.5682924389839172, "alpha_value": 0.6280664292355472, "duration": 1.649690866470337, "info_normalized_performance_mean": 0.4525488317012787, "info_normalized_performance_final": 0.5238542556762695, "info_performance_mean": 0.4525488317012787, "info_performance_final": 0.5238542556762695, "step": 1368500}
{"episode_reward": 905.0976709241157, "episode": 13686.0, "batch_reward": 9.646515846252441, "critic_loss": 614.6983032226562, "actor_loss": -1784.6412353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.2479288578033447, "alpha_loss": 0.029134076088666916, "alpha_value": 0.6385293165923709, "duration": 1.444223165512085, "info_normalized_performance_mean": 0.38816332817077637, "info_normalized_performance_final": 0.41989797353744507, "info_performance_mean": 0.38816332817077637, "info_performance_final": 0.41989797353744507, "step": 1369000}
{"episode_reward": 776.3265306122462, "episode": 13691.0, "batch_reward": 8.75493049621582, "critic_loss": 440.8434753417969, "actor_loss": -1777.867919921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7131550312042236, "alpha_loss": -0.2503088414669037, "alpha_value": 0.6463440830453293, "duration": 1.5988705158233643, "info_normalized_performance_mean": 0.7185450792312622, "info_normalized_performance_final": 0.7804232835769653, "info_performance_mean": 0.7185450792312622, "info_performance_final": 0.7804232835769653, "step": 1369500}
{"episode_reward": 1437.089947089948, "episode": 13696.0, "batch_reward": 8.075031280517578, "critic_loss": 823.102783203125, "actor_loss": -1644.39208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9084054827690125, "alpha_loss": -0.18107664585113525, "alpha_value": 0.6542989730980303, "step": 1370000}
{"duration": 19.075238466262817, "info_normalized_performance_mean": 0.6583850383758545, "info_normalized_performance_final": 0.7155080437660217, "info_performance_mean": 0.6583850383758545, "info_performance_final": 0.7155080437660217, "step": 1370000}
{"episode_reward": 1316.7700534759329, "episode": 13701.0, "batch_reward": 9.274934768676758, "critic_loss": 813.9935913085938, "actor_loss": -1707.2822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3347922563552856, "alpha_loss": 0.042688824236392975, "alpha_value": 0.6571705224723818, "duration": 1.4253535270690918, "info_normalized_performance_mean": 0.30660712718963623, "info_normalized_performance_final": 0.3285714387893677, "info_performance_mean": 0.30660712718963623, "info_performance_final": 0.3285714387893677, "step": 1370500}
{"episode_reward": 613.2142857142851, "episode": 13706.0, "batch_reward": 9.430011749267578, "critic_loss": 373.03485107421875, "actor_loss": -1664.04541015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9790129065513611, "alpha_loss": -0.13958638906478882, "alpha_value": 0.6572515162558054, "duration": 1.629906177520752, "info_normalized_performance_mean": 0.7813137769699097, "info_normalized_performance_final": 0.8549019694328308, "info_performance_mean": 0.7813137769699097, "info_performance_final": 0.8549019694328308, "step": 1371000}
{"episode_reward": 1562.6274509803904, "episode": 13711.0, "batch_reward": 9.246078491210938, "critic_loss": 1074.79052734375, "actor_loss": -1670.726806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2855662107467651, "alpha_loss": -0.05017685890197754, "alpha_value": 0.6579876545777968, "duration": 1.5577197074890137, "info_normalized_performance_mean": 0.15989583730697632, "info_normalized_performance_final": 0.17578125, "info_performance_mean": 0.15989583730697632, "info_performance_final": 0.17578125, "step": 1371500}
{"episode_reward": 319.79166666666663, "episode": 13716.0, "batch_reward": 9.64207935333252, "critic_loss": 300.48736572265625, "actor_loss": -1709.593505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.0186505317687988, "alpha_loss": 0.5286650657653809, "alpha_value": 0.6541175744956329, "duration": 1.6523385047912598, "info_normalized_performance_mean": 0.7664484977722168, "info_normalized_performance_final": 0.841269850730896, "info_performance_mean": 0.7664484977722168, "info_performance_final": 0.841269850730896, "step": 1372000}
{"episode_reward": 1532.8968253968276, "episode": 13721.0, "batch_reward": 8.701683044433594, "critic_loss": 660.14111328125, "actor_loss": -1679.3572998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.046839952468872, "alpha_loss": 0.20303675532341003, "alpha_value": 0.6488383266871665, "duration": 1.5070247650146484, "info_normalized_performance_mean": 0.49419647455215454, "info_normalized_performance_final": 0.5879464149475098, "info_performance_mean": 0.49419647455215454, "info_performance_final": 0.5879464149475098, "step": 1372500}
{"episode_reward": 988.392857142856, "episode": 13726.0, "batch_reward": 9.529688835144043, "critic_loss": 735.8697509765625, "actor_loss": -1716.8212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0090442895889282, "alpha_loss": 0.02391742914915085, "alpha_value": 0.6396708862147076, "duration": 1.6116812229156494, "info_normalized_performance_mean": 0.6072471737861633, "info_normalized_performance_final": 0.6674107313156128, "info_performance_mean": 0.6072471737861633, "info_performance_final": 0.6674107313156128, "step": 1373000}
{"episode_reward": 1214.4940476190484, "episode": 13731.0, "batch_reward": 9.064289093017578, "critic_loss": 566.7144775390625, "actor_loss": -1681.705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7793550491333008, "alpha_loss": 0.16013512015342712, "alpha_value": 0.6283858768126871, "duration": 1.6368916034698486, "info_normalized_performance_mean": 0.6762762665748596, "info_normalized_performance_final": 0.7341269850730896, "info_performance_mean": 0.6762762665748596, "info_performance_final": 0.7341269850730896, "step": 1373500}
{"episode_reward": 1352.5529100529104, "episode": 13736.0, "batch_reward": 8.960235595703125, "critic_loss": 560.49072265625, "actor_loss": -1666.81103515625, "actor_target_entropy": -3.0, "actor_entropy": 0.9843573570251465, "alpha_loss": 0.1495961844921112, "alpha_value": 0.6157897263610023, "duration": 1.4940204620361328, "info_normalized_performance_mean": 0.34427720308303833, "info_normalized_performance_final": 0.379676878452301, "info_performance_mean": 0.34427720308303833, "info_performance_final": 0.379676878452301, "step": 1374000}
{"episode_reward": 688.5544217687078, "episode": 13741.0, "batch_reward": 8.639426231384277, "critic_loss": 656.1400756835938, "actor_loss": -1689.212158203125, "actor_target_entropy": -3.0, "actor_entropy": 1.168243408203125, "alpha_loss": 0.04706043377518654, "alpha_value": 0.602800779653425, "duration": 1.601445198059082, "info_normalized_performance_mean": 0.5739225149154663, "info_normalized_performance_final": 0.6369248032569885, "info_performance_mean": 0.5739225149154663, "info_performance_final": 0.6369248032569885, "step": 1374500}
{"episode_reward": 1147.8451178451185, "episode": 13746.0, "batch_reward": 8.87332534790039, "critic_loss": 380.98779296875, "actor_loss": -1642.994384765625, "actor_target_entropy": -3.0, "actor_entropy": 1.328382134437561, "alpha_loss": 0.44018277525901794, "alpha_value": 0.5925192070428336, "duration": 1.6234560012817383, "info_normalized_performance_mean": 0.7821862697601318, "info_normalized_performance_final": 0.8535353541374207, "info_performance_mean": 0.7821862697601318, "info_performance_final": 0.8535353541374207, "step": 1375000}
{"episode_reward": 1564.372294372296, "episode": 13751.0, "batch_reward": 10.667655944824219, "critic_loss": 953.8846435546875, "actor_loss": -1700.179931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1414906978607178, "alpha_loss": 0.3913421034812927, "alpha_value": 0.5820962695092643, "duration": 1.5767483711242676, "info_normalized_performance_mean": 0.5948999524116516, "info_normalized_performance_final": 0.6387500166893005, "info_performance_mean": 0.5948999524116516, "info_performance_final": 0.6387500166893005, "step": 1375500}
{"episode_reward": 1189.8, "episode": 13756.0, "batch_reward": 9.233885765075684, "critic_loss": 516.0911865234375, "actor_loss": -1674.2578125, "actor_target_entropy": -3.0, "actor_entropy": 1.130569577217102, "alpha_loss": 0.31294453144073486, "alpha_value": 0.5738239153987686, "duration": 1.6976866722106934, "info_normalized_performance_mean": 0.42251548171043396, "info_normalized_performance_final": 0.47692838311195374, "info_performance_mean": 0.42251548171043396, "info_performance_final": 0.47692838311195374, "step": 1376000}
{"episode_reward": 845.030991735538, "episode": 13761.0, "batch_reward": 9.754158020019531, "critic_loss": 581.1971435546875, "actor_loss": -1648.403564453125, "actor_target_entropy": -3.0, "actor_entropy": 1.1967110633850098, "alpha_loss": 0.10871017724275589, "alpha_value": 0.5659747820460115, "duration": 1.5911505222320557, "info_normalized_performance_mean": 0.42158183455467224, "info_normalized_performance_final": 0.45636364817619324, "info_performance_mean": 0.42158183455467224, "info_performance_final": 0.45636364817619324, "step": 1376500}
{"episode_reward": 843.1636363636362, "episode": 13766.0, "batch_reward": 9.9893798828125, "critic_loss": 514.3587646484375, "actor_loss": -1658.6976318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3258013725280762, "alpha_loss": 0.18337661027908325, "alpha_value": 0.5595583016050312, "duration": 1.6135375499725342, "info_normalized_performance_mean": 0.49474087357521057, "info_normalized_performance_final": 0.5450000166893005, "info_performance_mean": 0.49474087357521057, "info_performance_final": 0.5450000166893005, "step": 1377000}
{"episode_reward": 989.4818181818167, "episode": 13771.0, "batch_reward": 8.217704772949219, "critic_loss": 853.7862548828125, "actor_loss": -1575.332763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.184293270111084, "alpha_loss": 0.18650653958320618, "alpha_value": 0.5518875771613762, "duration": 1.5848479270935059, "info_normalized_performance_mean": 0.8548705577850342, "info_normalized_performance_final": 0.9188235402107239, "info_performance_mean": 0.8548705577850342, "info_performance_final": 0.9188235402107239, "step": 1377500}
{"episode_reward": 1709.741176470592, "episode": 13776.0, "batch_reward": 9.185430526733398, "critic_loss": 664.0944213867188, "actor_loss": -1684.01806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.0845685005187988, "alpha_loss": -0.0552341490983963, "alpha_value": 0.544332968782786, "duration": 1.4474804401397705, "info_normalized_performance_mean": 0.5549219846725464, "info_normalized_performance_final": 0.6361607313156128, "info_performance_mean": 0.5549219846725464, "info_performance_final": 0.6361607313156128, "step": 1378000}
{"episode_reward": 1109.8437500000016, "episode": 13781.0, "batch_reward": 8.373320579528809, "critic_loss": 857.0587768554688, "actor_loss": -1581.2080078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7788941860198975, "alpha_loss": -0.2196454405784607, "alpha_value": 0.5376012032239518, "duration": 1.5386791229248047, "info_normalized_performance_mean": 0.30377840995788574, "info_normalized_performance_final": 0.32919034361839294, "info_performance_mean": 0.30377840995788574, "info_performance_final": 0.32919034361839294, "step": 1378500}
{"episode_reward": 607.5568181818186, "episode": 13786.0, "batch_reward": 9.702862739562988, "critic_loss": 727.061767578125, "actor_loss": -1637.1630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1878334283828735, "alpha_loss": -0.16942504048347473, "alpha_value": 0.5334751253974095, "duration": 1.6151199340820312, "info_normalized_performance_mean": 0.6289682984352112, "info_normalized_performance_final": 0.6760461926460266, "info_performance_mean": 0.6289682984352112, "info_performance_final": 0.6760461926460266, "step": 1379000}
{"episode_reward": 1257.9365079365077, "episode": 13791.0, "batch_reward": 9.493293762207031, "critic_loss": 548.418212890625, "actor_loss": -1599.97265625, "actor_target_entropy": -3.0, "actor_entropy": 1.2985831499099731, "alpha_loss": 0.5035640001296997, "alpha_value": 0.5284880113649605, "duration": 1.5089809894561768, "info_normalized_performance_mean": 0.9234523177146912, "info_normalized_performance_final": 0.9970238208770752, "info_performance_mean": 0.9234523177146912, "info_performance_final": 0.9970238208770752, "step": 1379500}
{"episode_reward": 1846.9047619047594, "episode": 13796.0, "batch_reward": 8.725040435791016, "critic_loss": 650.43212890625, "actor_loss": -1592.0113525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.7337328195571899, "alpha_loss": 0.13011959195137024, "alpha_value": 0.5215521461399955, "step": 1380000}
{"duration": 19.287686347961426, "info_normalized_performance_mean": 0.37313133478164673, "info_normalized_performance_final": 0.4166666567325592, "info_performance_mean": 0.37313133478164673, "info_performance_final": 0.4166666567325592, "step": 1380000}
{"episode_reward": 746.2625000000006, "episode": 13801.0, "batch_reward": 9.494436264038086, "critic_loss": 623.62646484375, "actor_loss": -1604.305419921875, "actor_target_entropy": -3.0, "actor_entropy": 1.1658562421798706, "alpha_loss": 0.13424542546272278, "alpha_value": 0.5148576826895566, "duration": 1.565434455871582, "info_normalized_performance_mean": 0.8509374856948853, "info_normalized_performance_final": 0.9140625, "info_performance_mean": 0.8509374856948853, "info_performance_final": 0.9140625, "step": 1380500}
{"episode_reward": 1701.875, "episode": 13806.0, "batch_reward": 10.048752784729004, "critic_loss": 400.87469482421875, "actor_loss": -1627.0001220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3313312530517578, "alpha_loss": 0.04899042099714279, "alpha_value": 0.5087558505436809, "duration": 1.5277988910675049, "info_normalized_performance_mean": 0.3174828290939331, "info_normalized_performance_final": 0.35336539149284363, "info_performance_mean": 0.3174828290939331, "info_performance_final": 0.35336539149284363, "step": 1381000}
{"episode_reward": 634.9656593406594, "episode": 13811.0, "batch_reward": 9.702681541442871, "critic_loss": 426.2083740234375, "actor_loss": -1632.4818115234375, "actor_target_entropy": -3.0, "actor_entropy": 1.211141586303711, "alpha_loss": 0.09029535949230194, "alpha_value": 0.5046552605566154, "duration": 1.4831840991973877, "info_normalized_performance_mean": 0.637281596660614, "info_normalized_performance_final": 0.6919642686843872, "info_performance_mean": 0.637281596660614, "info_performance_final": 0.6919642686843872, "step": 1381500}
{"episode_reward": 1274.5634920634916, "episode": 13816.0, "batch_reward": 10.069291114807129, "critic_loss": 632.1490478515625, "actor_loss": -1620.4747314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.2871172428131104, "alpha_loss": 0.0546274296939373, "alpha_value": 0.4976096523362444, "duration": 1.4324016571044922, "info_normalized_performance_mean": 0.6955059170722961, "info_normalized_performance_final": 0.7470238208770752, "info_performance_mean": 0.6955059170722961, "info_performance_final": 0.7470238208770752, "step": 1382000}
{"episode_reward": 1391.0119047619025, "episode": 13821.0, "batch_reward": 10.419779777526855, "critic_loss": 338.09307861328125, "actor_loss": -1606.510498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.7067949771881104, "alpha_loss": 0.26141127943992615, "alpha_value": 0.49226309642993005, "duration": 1.460644245147705, "info_normalized_performance_mean": 0.5871371626853943, "info_normalized_performance_final": 0.6303854584693909, "info_performance_mean": 0.5871371626853943, "info_performance_final": 0.6303854584693909, "step": 1382500}
{"episode_reward": 1174.2743764172333, "episode": 13826.0, "batch_reward": 10.08537483215332, "critic_loss": 885.8131103515625, "actor_loss": -1604.39013671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2242131233215332, "alpha_loss": 0.21530023217201233, "alpha_value": 0.4866270246999533, "duration": 1.684142827987671, "info_normalized_performance_mean": 0.7194575667381287, "info_normalized_performance_final": 0.7830687761306763, "info_performance_mean": 0.7194575667381287, "info_performance_final": 0.7830687761306763, "step": 1383000}
{"episode_reward": 1438.915343915343, "episode": 13831.0, "batch_reward": 8.909341812133789, "critic_loss": 408.7623596191406, "actor_loss": -1537.36083984375, "actor_target_entropy": -3.0, "actor_entropy": 1.1739038228988647, "alpha_loss": 0.05426037311553955, "alpha_value": 0.4789640889227482, "duration": 1.6333165168762207, "info_normalized_performance_mean": 0.5865327715873718, "info_normalized_performance_final": 0.636904776096344, "info_performance_mean": 0.5865327715873718, "info_performance_final": 0.636904776096344, "step": 1383500}
{"episode_reward": 1173.0654761904734, "episode": 13836.0, "batch_reward": 10.667082786560059, "critic_loss": 789.4096069335938, "actor_loss": -1583.6094970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0471928119659424, "alpha_loss": 0.3736531138420105, "alpha_value": 0.4754381820400918, "duration": 1.558058261871338, "info_normalized_performance_mean": 0.7577201724052429, "info_normalized_performance_final": 0.8140000104904175, "info_performance_mean": 0.7577201724052429, "info_performance_final": 0.8140000104904175, "step": 1384000}
{"episode_reward": 1515.439999999998, "episode": 13841.0, "batch_reward": 9.956768989562988, "critic_loss": 829.3136596679688, "actor_loss": -1581.74951171875, "actor_target_entropy": -3.0, "actor_entropy": 0.838338315486908, "alpha_loss": -0.2049746811389923, "alpha_value": 0.4733154215575602, "duration": 1.5090606212615967, "info_normalized_performance_mean": 0.45708030462265015, "info_normalized_performance_final": 0.5026192665100098, "info_performance_mean": 0.45708030462265015, "info_performance_final": 0.5026192665100098, "step": 1384500}
{"episode_reward": 914.1604631927207, "episode": 13846.0, "batch_reward": 10.840211868286133, "critic_loss": 525.4940185546875, "actor_loss": -1636.993408203125, "actor_target_entropy": -3.0, "actor_entropy": 1.0094835758209229, "alpha_loss": -0.17218001186847687, "alpha_value": 0.4752604948108667, "duration": 1.4866435527801514, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1385000}
{"episode_reward": 0.0, "episode": 13851.0, "batch_reward": 10.782822608947754, "critic_loss": 524.713134765625, "actor_loss": -1603.444580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2618210315704346, "alpha_loss": 0.29030370712280273, "alpha_value": 0.47366139811692476, "duration": 1.555070161819458, "info_normalized_performance_mean": 0.7794902920722961, "info_normalized_performance_final": 0.8372548818588257, "info_performance_mean": 0.7794902920722961, "info_performance_final": 0.8372548818588257, "step": 1385500}
{"episode_reward": 1558.980392156863, "episode": 13856.0, "batch_reward": 9.615764617919922, "critic_loss": 414.61956787109375, "actor_loss": -1560.9620361328125, "actor_target_entropy": -3.0, "actor_entropy": 0.6379089951515198, "alpha_loss": -0.30582040548324585, "alpha_value": 0.47031327012226787, "duration": 1.4576382637023926, "info_normalized_performance_mean": 9.411764040123671e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 9.411764040123671e-05, "info_performance_final": 0.0, "step": 1386000}
{"episode_reward": 0.18823529411764706, "episode": 13861.0, "batch_reward": 10.506471633911133, "critic_loss": 1027.9931640625, "actor_loss": -1610.74755859375, "actor_target_entropy": -3.0, "actor_entropy": 0.920895516872406, "alpha_loss": -0.13366791605949402, "alpha_value": 0.4672400653039007, "duration": 1.5212256908416748, "info_normalized_performance_mean": 0.4591601490974426, "info_normalized_performance_final": 0.507031261920929, "info_performance_mean": 0.4591601490974426, "info_performance_final": 0.507031261920929, "step": 1386500}
{"episode_reward": 918.3203125, "episode": 13866.0, "batch_reward": 10.930658340454102, "critic_loss": 406.001708984375, "actor_loss": -1617.76904296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8547913432121277, "alpha_loss": -0.0831393152475357, "alpha_value": 0.4663639475513835, "duration": 1.5112130641937256, "info_normalized_performance_mean": 0.7868162393569946, "info_normalized_performance_final": 0.8581632375717163, "info_performance_mean": 0.7868162393569946, "info_performance_final": 0.8581632375717163, "step": 1387000}
{"episode_reward": 1573.6326530612225, "episode": 13871.0, "batch_reward": 9.859407424926758, "critic_loss": 889.200927734375, "actor_loss": -1539.379638671875, "actor_target_entropy": -3.0, "actor_entropy": 0.6943486332893372, "alpha_loss": -0.08593873679637909, "alpha_value": 0.4668480655566013, "duration": 1.5933260917663574, "info_normalized_performance_mean": 0.6790589094161987, "info_normalized_performance_final": 0.7369614243507385, "info_performance_mean": 0.6790589094161987, "info_performance_final": 0.7369614243507385, "step": 1387500}
{"episode_reward": 1358.117913832199, "episode": 13876.0, "batch_reward": 11.369091033935547, "critic_loss": 2379.47216796875, "actor_loss": -1659.919677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.178844690322876, "alpha_loss": 0.0685228481888771, "alpha_value": 0.4630173545804737, "duration": 1.6093456745147705, "info_normalized_performance_mean": 0.7864997982978821, "info_normalized_performance_final": 0.8627272844314575, "info_performance_mean": 0.7864997982978821, "info_performance_final": 0.8627272844314575, "step": 1388000}
{"episode_reward": 1572.9999999999998, "episode": 13881.0, "batch_reward": 9.21352767944336, "critic_loss": 1441.1197509765625, "actor_loss": -1543.055419921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7941846251487732, "alpha_loss": -0.046586960554122925, "alpha_value": 0.4612766873090377, "duration": 1.530233383178711, "info_normalized_performance_mean": 0.4782421588897705, "info_normalized_performance_final": 0.5276692509651184, "info_performance_mean": 0.4782421588897705, "info_performance_final": 0.5276692509651184, "step": 1388500}
{"episode_reward": 956.4843749999987, "episode": 13886.0, "batch_reward": 10.5233154296875, "critic_loss": 487.29705810546875, "actor_loss": -1540.40673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3789916038513184, "alpha_loss": 0.1527424156665802, "alpha_value": 0.46075738697288127, "duration": 1.50651216506958, "info_normalized_performance_mean": 0.7351561188697815, "info_normalized_performance_final": 0.7946428656578064, "info_performance_mean": 0.7351561188697815, "info_performance_final": 0.7946428656578064, "step": 1389000}
{"episode_reward": 1470.3124999999984, "episode": 13891.0, "batch_reward": 10.004247665405273, "critic_loss": 520.1981201171875, "actor_loss": -1605.421630859375, "actor_target_entropy": -3.0, "actor_entropy": 0.9335874915122986, "alpha_loss": 0.12770995497703552, "alpha_value": 0.45957498975250843, "duration": 1.660064697265625, "info_normalized_performance_mean": 0.36953139305114746, "info_normalized_performance_final": 0.4293345510959625, "info_performance_mean": 0.36953139305114746, "info_performance_final": 0.4293345510959625, "step": 1389500}
{"episode_reward": 739.062881562881, "episode": 13896.0, "batch_reward": 9.7284574508667, "critic_loss": 905.9804077148438, "actor_loss": -1582.576416015625, "actor_target_entropy": -3.0, "actor_entropy": 1.034148931503296, "alpha_loss": -0.028174154460430145, "alpha_value": 0.46029688096660476, "step": 1390000}
{"duration": 18.758460998535156, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1390000}
{"episode_reward": 0.0, "episode": 13901.0, "batch_reward": 10.795555114746094, "critic_loss": 529.8561401367188, "actor_loss": -1608.482177734375, "actor_target_entropy": -3.0, "actor_entropy": 1.331152319908142, "alpha_loss": -0.05476188659667969, "alpha_value": 0.4595860575998596, "duration": 1.6192049980163574, "info_normalized_performance_mean": 0.7036140561103821, "info_normalized_performance_final": 0.7644557952880859, "info_performance_mean": 0.7036140561103821, "info_performance_final": 0.7644557952880859, "step": 1390500}
{"episode_reward": 1407.2278911564651, "episode": 13906.0, "batch_reward": 11.255476951599121, "critic_loss": 751.927978515625, "actor_loss": -1672.2930908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.158590316772461, "alpha_loss": 0.08149304986000061, "alpha_value": 0.4618795829375716, "duration": 1.5314865112304688, "info_normalized_performance_mean": 0.5581466555595398, "info_normalized_performance_final": 0.6184895634651184, "info_performance_mean": 0.5581466555595398, "info_performance_final": 0.6184895634651184, "step": 1391000}
{"episode_reward": 1116.2934027777771, "episode": 13911.0, "batch_reward": 10.343366622924805, "critic_loss": 461.145751953125, "actor_loss": -1706.92724609375, "actor_target_entropy": -3.0, "actor_entropy": 1.0573465824127197, "alpha_loss": -0.20466263592243195, "alpha_value": 0.46653294974465515, "duration": 1.4396522045135498, "info_normalized_performance_mean": 0.5541607141494751, "info_normalized_performance_final": 0.6023809313774109, "info_performance_mean": 0.5541607141494751, "info_performance_final": 0.6023809313774109, "step": 1391500}
{"episode_reward": 1108.3214285714278, "episode": 13916.0, "batch_reward": 10.899413108825684, "critic_loss": 648.5062255859375, "actor_loss": -1648.1214599609375, "actor_target_entropy": -3.0, "actor_entropy": 0.9855268597602844, "alpha_loss": -0.01946254074573517, "alpha_value": 0.46864927006213336, "duration": 1.628319263458252, "info_normalized_performance_mean": 0.7453272342681885, "info_normalized_performance_final": 0.8102678656578064, "info_performance_mean": 0.7453272342681885, "info_performance_final": 0.8102678656578064, "step": 1392000}
{"episode_reward": 1490.6547619047603, "episode": 13921.0, "batch_reward": 9.783193588256836, "critic_loss": 1269.750244140625, "actor_loss": -1622.43505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.0266430377960205, "alpha_loss": -0.15562334656715393, "alpha_value": 0.4680276923337718, "duration": 1.4821093082427979, "info_normalized_performance_mean": 0.4777763783931732, "info_normalized_performance_final": 0.5211764574050903, "info_performance_mean": 0.4777763783931732, "info_performance_final": 0.5211764574050903, "step": 1392500}
{"episode_reward": 955.552941176469, "episode": 13926.0, "batch_reward": 10.844654083251953, "critic_loss": 1602.8350830078125, "actor_loss": -1713.8375244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.874985933303833, "alpha_loss": -0.13863281905651093, "alpha_value": 0.4696667588451862, "duration": 1.6255519390106201, "info_normalized_performance_mean": 0.5828385949134827, "info_normalized_performance_final": 0.6258680820465088, "info_performance_mean": 0.5828385949134827, "info_performance_final": 0.6258680820465088, "step": 1393000}
{"episode_reward": 1165.6770833333317, "episode": 13931.0, "batch_reward": 10.390718460083008, "critic_loss": 552.4066162109375, "actor_loss": -1643.3291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.2989298105239868, "alpha_loss": -0.08405528217554092, "alpha_value": 0.4722833615029068, "duration": 1.6205816268920898, "info_normalized_performance_mean": 0.5701191425323486, "info_normalized_performance_final": 0.6205357313156128, "info_performance_mean": 0.5701191425323486, "info_performance_final": 0.6205357313156128, "step": 1393500}
{"episode_reward": 1140.2380952380963, "episode": 13936.0, "batch_reward": 10.579900741577148, "critic_loss": 504.20172119140625, "actor_loss": -1607.075927734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1656687259674072, "alpha_loss": -0.09686257690191269, "alpha_value": 0.47542854898589665, "duration": 1.6640396118164062, "info_normalized_performance_mean": 0.34523436427116394, "info_normalized_performance_final": 0.3910590410232544, "info_performance_mean": 0.34523436427116394, "info_performance_final": 0.3910590410232544, "step": 1394000}
{"episode_reward": 690.4687499999992, "episode": 13941.0, "batch_reward": 11.057767868041992, "critic_loss": 404.58154296875, "actor_loss": -1655.82763671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9655789732933044, "alpha_loss": 0.08581481873989105, "alpha_value": 0.4781755157069805, "duration": 1.5677261352539062, "info_normalized_performance_mean": 0.8134216070175171, "info_normalized_performance_final": 0.864062488079071, "info_performance_mean": 0.8134216070175171, "info_performance_final": 0.864062488079071, "step": 1394500}
{"episode_reward": 1626.84375, "episode": 13946.0, "batch_reward": 10.841531753540039, "critic_loss": 1944.39697265625, "actor_loss": -1666.20947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.358952522277832, "alpha_loss": -0.14272671937942505, "alpha_value": 0.48492233096713855, "duration": 1.5483973026275635, "info_normalized_performance_mean": 0.5929166674613953, "info_normalized_performance_final": 0.6366666555404663, "info_performance_mean": 0.5929166674613953, "info_performance_final": 0.6366666555404663, "step": 1395000}
{"episode_reward": 1185.8333333333346, "episode": 13951.0, "batch_reward": 10.975828170776367, "critic_loss": 869.263671875, "actor_loss": -1678.20947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.3438119888305664, "alpha_loss": -0.09181377291679382, "alpha_value": 0.48911017389212075, "duration": 1.5261602401733398, "info_normalized_performance_mean": 0.44277822971343994, "info_normalized_performance_final": 0.48054298758506775, "info_performance_mean": 0.44277822971343994, "info_performance_final": 0.48054298758506775, "step": 1395500}
{"episode_reward": 885.5565610859712, "episode": 13956.0, "batch_reward": 11.371467590332031, "critic_loss": 538.2843017578125, "actor_loss": -1653.64697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6314423084259033, "alpha_loss": 0.3450716733932495, "alpha_value": 0.4946418342897367, "duration": 1.4897990226745605, "info_normalized_performance_mean": 0.5775137543678284, "info_normalized_performance_final": 0.6268315315246582, "info_performance_mean": 0.5775137543678284, "info_performance_final": 0.6268315315246582, "step": 1396000}
{"episode_reward": 1155.0274725274728, "episode": 13961.0, "batch_reward": 10.754571914672852, "critic_loss": 504.728515625, "actor_loss": -1693.4075927734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3275082111358643, "alpha_loss": -0.06718166172504425, "alpha_value": 0.5011966914081948, "duration": 1.6727685928344727, "info_normalized_performance_mean": 0.509639322757721, "info_normalized_performance_final": 0.5726897120475769, "info_performance_mean": 0.509639322757721, "info_performance_final": 0.5726897120475769, "step": 1396500}
{"episode_reward": 1019.2787377911349, "episode": 13966.0, "batch_reward": 10.75365924835205, "critic_loss": 637.335693359375, "actor_loss": -1646.4237060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.295738697052002, "alpha_loss": 0.14948472380638123, "alpha_value": 0.5076763351914596, "duration": 1.5423893928527832, "info_normalized_performance_mean": 0.7759643793106079, "info_normalized_performance_final": 0.8732143044471741, "info_performance_mean": 0.7759643793106079, "info_performance_final": 0.8732143044471741, "step": 1397000}
{"episode_reward": 1551.928571428572, "episode": 13971.0, "batch_reward": 10.659724235534668, "critic_loss": 1622.21142578125, "actor_loss": -1702.6435546875, "actor_target_entropy": -3.0, "actor_entropy": 0.9687130451202393, "alpha_loss": -0.2914764881134033, "alpha_value": 0.5155657048011018, "duration": 1.644209623336792, "info_normalized_performance_mean": 0.6229166388511658, "info_normalized_performance_final": 0.6752645373344421, "info_performance_mean": 0.6229166388511658, "info_performance_final": 0.6752645373344421, "step": 1397500}
{"episode_reward": 1245.833333333333, "episode": 13976.0, "batch_reward": 10.967387199401855, "critic_loss": 652.0067138671875, "actor_loss": -1676.68994140625, "actor_target_entropy": -3.0, "actor_entropy": 1.25336754322052, "alpha_loss": -0.05002938583493233, "alpha_value": 0.5211678633944233, "duration": 1.7096469402313232, "info_normalized_performance_mean": 0.4293864369392395, "info_normalized_performance_final": 0.4813797175884247, "info_performance_mean": 0.4293864369392395, "info_performance_final": 0.4813797175884247, "step": 1398000}
{"episode_reward": 858.7728937728928, "episode": 13981.0, "batch_reward": 10.286412239074707, "critic_loss": 990.9755859375, "actor_loss": -1660.419921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6495015621185303, "alpha_loss": -0.4336041212081909, "alpha_value": 0.523087091154828, "duration": 1.6211464405059814, "info_normalized_performance_mean": 0.6526860594749451, "info_normalized_performance_final": 0.7083333134651184, "info_performance_mean": 0.6526860594749451, "info_performance_final": 0.7083333134651184, "step": 1398500}
{"episode_reward": 1305.372023809524, "episode": 13986.0, "batch_reward": 11.277788162231445, "critic_loss": 572.7427978515625, "actor_loss": -1748.2947998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5017532110214233, "alpha_loss": 0.2790250778198242, "alpha_value": 0.5196153370187928, "duration": 1.6642189025878906, "info_normalized_performance_mean": 0.6065351366996765, "info_normalized_performance_final": 0.7069377899169922, "info_performance_mean": 0.6065351366996765, "info_performance_final": 0.7069377899169922, "step": 1399000}
{"episode_reward": 1213.0701754385964, "episode": 13991.0, "batch_reward": 11.332416534423828, "critic_loss": 869.5697631835938, "actor_loss": -1764.56884765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0123100280761719, "alpha_loss": -0.25878241658210754, "alpha_value": 0.510452402041709, "duration": 1.4835944175720215, "info_normalized_performance_mean": 0.7663265466690063, "info_normalized_performance_final": 0.8418367505073547, "info_performance_mean": 0.7663265466690063, "info_performance_final": 0.8418367505073547, "step": 1399500}
{"episode_reward": 1532.6530612244917, "episode": 13996.0, "batch_reward": 10.787148475646973, "critic_loss": 1481.21240234375, "actor_loss": -1681.3004150390625, "actor_target_entropy": -3.0, "actor_entropy": 0.789265513420105, "alpha_loss": 0.025047339498996735, "alpha_value": 0.5028492238605734, "step": 1400000}
{"duration": 19.151003122329712, "info_normalized_performance_mean": 0.40316078066825867, "info_normalized_performance_final": 0.4504464268684387, "info_performance_mean": 0.40316078066825867, "info_performance_final": 0.4504464268684387, "step": 1400000}
{"episode_reward": 806.3214285714278, "episode": 14001.0, "batch_reward": 11.643167495727539, "critic_loss": 2396.87255859375, "actor_loss": -1709.110107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0964369773864746, "alpha_loss": 0.2025788277387619, "alpha_value": 0.49655433950620614, "duration": 1.6068906784057617, "info_normalized_performance_mean": 0.791666567325592, "info_normalized_performance_final": 0.8619791865348816, "info_performance_mean": 0.791666567325592, "info_performance_final": 0.8619791865348816, "step": 1400500}
{"episode_reward": 1583.333333333332, "episode": 14006.0, "batch_reward": 10.721080780029297, "critic_loss": 1116.0439453125, "actor_loss": -1723.5662841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5039944648742676, "alpha_loss": 0.05349233001470566, "alpha_value": 0.4908525611632455, "duration": 1.7007200717926025, "info_normalized_performance_mean": 0.4668314456939697, "info_normalized_performance_final": 0.5473138093948364, "info_performance_mean": 0.4668314456939697, "info_performance_final": 0.5473138093948364, "step": 1401000}
{"episode_reward": 933.6630036630027, "episode": 14011.0, "batch_reward": 11.870919227600098, "critic_loss": 1642.828125, "actor_loss": -1758.0377197265625, "actor_target_entropy": -3.0, "actor_entropy": 1.1758134365081787, "alpha_loss": 0.01762358471751213, "alpha_value": 0.4829871289624825, "duration": 1.437875747680664, "info_normalized_performance_mean": 0.33682289719581604, "info_normalized_performance_final": 0.3628472089767456, "info_performance_mean": 0.33682289719581604, "info_performance_final": 0.3628472089767456, "step": 1401500}
{"episode_reward": 673.6458333333343, "episode": 14016.0, "batch_reward": 11.51622200012207, "critic_loss": 695.0228271484375, "actor_loss": -1700.0386962890625, "actor_target_entropy": -3.0, "actor_entropy": 1.3243787288665771, "alpha_loss": 0.3174811005592346, "alpha_value": 0.4778371737058584, "duration": 1.5271825790405273, "info_normalized_performance_mean": 0.4531639814376831, "info_normalized_performance_final": 0.49289771914482117, "info_performance_mean": 0.4531639814376831, "info_performance_final": 0.49289771914482117, "step": 1402000}
{"episode_reward": 906.3281249999989, "episode": 14021.0, "batch_reward": 10.504837989807129, "critic_loss": 588.7607421875, "actor_loss": -1633.9488525390625, "actor_target_entropy": -3.0, "actor_entropy": 1.6569392681121826, "alpha_loss": 0.17309477925300598, "alpha_value": 0.4737274728787433, "duration": 1.5817759037017822, "info_normalized_performance_mean": 0.4993399679660797, "info_normalized_performance_final": 0.5577499866485596, "info_performance_mean": 0.4993399679660797, "info_performance_final": 0.5577499866485596, "step": 1402500}
{"episode_reward": 998.6799999999982, "episode": 14026.0, "batch_reward": 10.493453979492188, "critic_loss": 1236.52587890625, "actor_loss": -1694.22802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0515636205673218, "alpha_loss": -0.1601470708847046, "alpha_value": 0.46867907708491613, "duration": 1.4297258853912354, "info_normalized_performance_mean": 0.5184375047683716, "info_normalized_performance_final": 0.5644132494926453, "info_performance_mean": 0.5184375047683716, "info_performance_final": 0.5644132494926453, "step": 1403000}
{"episode_reward": 1036.8749999999986, "episode": 14031.0, "batch_reward": 10.85781192779541, "critic_loss": 952.1578369140625, "actor_loss": -1711.075927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9764730930328369, "alpha_loss": 0.10052426904439926, "alpha_value": 0.46080462385834103, "duration": 1.5354502201080322, "info_normalized_performance_mean": 0.35945481061935425, "info_normalized_performance_final": 0.40119048953056335, "info_performance_mean": 0.35945481061935425, "info_performance_final": 0.40119048953056335, "step": 1403500}
{"episode_reward": 718.9095238095234, "episode": 14036.0, "batch_reward": 11.35146427154541, "critic_loss": 580.2115478515625, "actor_loss": -1715.75830078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8085078597068787, "alpha_loss": -0.015265107154846191, "alpha_value": 0.45437477135290255, "duration": 1.587775468826294, "info_normalized_performance_mean": 0.6610894799232483, "info_normalized_performance_final": 0.7178932428359985, "info_performance_mean": 0.6610894799232483, "info_performance_final": 0.7178932428359985, "step": 1404000}
{"episode_reward": 1322.1789321789342, "episode": 14041.0, "batch_reward": 10.042911529541016, "critic_loss": 592.2277221679688, "actor_loss": -1630.9385986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.9697608947753906, "alpha_loss": 0.14023131132125854, "alpha_value": 0.44745547586363715, "duration": 1.59696364402771, "info_normalized_performance_mean": 0.6885666847229004, "info_normalized_performance_final": 0.8566666841506958, "info_performance_mean": 0.6885666847229004, "info_performance_final": 0.8566666841506958, "step": 1404500}
{"episode_reward": 1377.1333333333353, "episode": 14046.0, "batch_reward": 10.782790184020996, "critic_loss": 960.025146484375, "actor_loss": -1678.52587890625, "actor_target_entropy": -3.0, "actor_entropy": 0.8985084891319275, "alpha_loss": 0.18514090776443481, "alpha_value": 0.4410328297418539, "duration": 1.5722744464874268, "info_normalized_performance_mean": 0.8738095760345459, "info_normalized_performance_final": 0.9583333134651184, "info_performance_mean": 0.8738095760345459, "info_performance_final": 0.9583333134651184, "step": 1405000}
{"episode_reward": 1747.6190476190498, "episode": 14051.0, "batch_reward": 10.379591941833496, "critic_loss": 541.865234375, "actor_loss": -1600.238037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.6146726608276367, "alpha_loss": -0.11912936717271805, "alpha_value": 0.43641239036133816, "duration": 1.5187098979949951, "info_normalized_performance_mean": 0.5413771271705627, "info_normalized_performance_final": 0.6074862480163574, "info_performance_mean": 0.5413771271705627, "info_performance_final": 0.6074862480163574, "step": 1405500}
{"episode_reward": 1082.7541208791201, "episode": 14056.0, "batch_reward": 10.234879493713379, "critic_loss": 282.59130859375, "actor_loss": -1614.171875, "actor_target_entropy": -3.0, "actor_entropy": 0.9960598945617676, "alpha_loss": 0.005079913884401321, "alpha_value": 0.4313719705475462, "duration": 1.5473880767822266, "info_normalized_performance_mean": 0.31057146191596985, "info_normalized_performance_final": 0.347012996673584, "info_performance_mean": 0.31057146191596985, "info_performance_final": 0.347012996673584, "step": 1406000}
{"episode_reward": 621.1428571428581, "episode": 14061.0, "batch_reward": 10.190688133239746, "critic_loss": 1125.0589599609375, "actor_loss": -1608.189697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0202949047088623, "alpha_loss": 0.04497479647397995, "alpha_value": 0.4281210775966407, "duration": 1.4369704723358154, "info_normalized_performance_mean": 0.4876736104488373, "info_normalized_performance_final": 0.5367063283920288, "info_performance_mean": 0.4876736104488373, "info_performance_final": 0.5367063283920288, "step": 1406500}
{"episode_reward": 975.3472222222225, "episode": 14066.0, "batch_reward": 10.945378303527832, "critic_loss": 646.8991088867188, "actor_loss": -1677.80517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2378475666046143, "alpha_loss": 0.1025145947933197, "alpha_value": 0.4214388269263367, "duration": 1.5020642280578613, "info_normalized_performance_mean": 0.4749319553375244, "info_normalized_performance_final": 0.5250850319862366, "info_performance_mean": 0.4749319553375244, "info_performance_final": 0.5250850319862366, "step": 1407000}
{"episode_reward": 949.863945578229, "episode": 14071.0, "batch_reward": 10.95518684387207, "critic_loss": 447.05859375, "actor_loss": -1698.0223388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.010333776473999, "alpha_loss": 0.07943862676620483, "alpha_value": 0.4147746395042363, "duration": 1.6699647903442383, "info_normalized_performance_mean": 0.4594278633594513, "info_normalized_performance_final": 0.5205342769622803, "info_performance_mean": 0.4594278633594513, "info_performance_final": 0.5205342769622803, "step": 1407500}
{"episode_reward": 918.8556618819775, "episode": 14076.0, "batch_reward": 11.749261856079102, "critic_loss": 841.3851318359375, "actor_loss": -1726.4652099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.008643627166748, "alpha_loss": 0.08472317457199097, "alpha_value": 0.41123230022697194, "duration": 1.6027491092681885, "info_normalized_performance_mean": 0.7045659422874451, "info_normalized_performance_final": 0.7569444179534912, "info_performance_mean": 0.7045659422874451, "info_performance_final": 0.7569444179534912, "step": 1408000}
{"episode_reward": 1409.1319444444462, "episode": 14081.0, "batch_reward": 11.244478225708008, "critic_loss": 424.46490478515625, "actor_loss": -1698.628173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.4397952556610107, "alpha_loss": 0.09892420470714569, "alpha_value": 0.4061450946145763, "duration": 1.466294288635254, "info_normalized_performance_mean": 0.44834768772125244, "info_normalized_performance_final": 0.49960753321647644, "info_performance_mean": 0.44834768772125244, "info_performance_final": 0.49960753321647644, "step": 1408500}
{"episode_reward": 896.6954474097323, "episode": 14086.0, "batch_reward": 11.112662315368652, "critic_loss": 782.4517822265625, "actor_loss": -1655.8232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9462683200836182, "alpha_loss": 0.15768736600875854, "alpha_value": 0.4031342381184089, "duration": 1.6394457817077637, "info_normalized_performance_mean": 0.6379696130752563, "info_normalized_performance_final": 0.7083333134651184, "info_performance_mean": 0.6379696130752563, "info_performance_final": 0.7083333134651184, "step": 1409000}
{"episode_reward": 1275.9391534391539, "episode": 14091.0, "batch_reward": 11.293258666992188, "critic_loss": 797.5845336914062, "actor_loss": -1710.637451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.0838310718536377, "alpha_loss": 0.3088078498840332, "alpha_value": 0.3990565154352209, "duration": 1.4915406703948975, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1409500}
{"episode_reward": 0.0, "episode": 14096.0, "batch_reward": 9.936227798461914, "critic_loss": 340.62451171875, "actor_loss": -1622.744140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7886712551116943, "alpha_loss": -0.1549350470304489, "alpha_value": 0.39560521152218026, "step": 1410000}
{"duration": 19.036367893218994, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1410000}
{"episode_reward": 0.0, "episode": 14101.0, "batch_reward": 11.44076156616211, "critic_loss": 1119.5428466796875, "actor_loss": -1715.0020751953125, "actor_target_entropy": -3.0, "actor_entropy": 0.6833336353302002, "alpha_loss": -0.00033010728657245636, "alpha_value": 0.3922253270337261, "duration": 1.586012840270996, "info_normalized_performance_mean": 0.8227749466896057, "info_normalized_performance_final": 0.8974999785423279, "info_performance_mean": 0.8227749466896057, "info_performance_final": 0.8974999785423279, "step": 1410500}
{"episode_reward": 1645.5500000000027, "episode": 14106.0, "batch_reward": 10.654187202453613, "critic_loss": 1857.8212890625, "actor_loss": -1633.586181640625, "actor_target_entropy": -3.0, "actor_entropy": 0.880408525466919, "alpha_loss": -0.20074963569641113, "alpha_value": 0.39105944100711276, "duration": 1.4730756282806396, "info_normalized_performance_mean": 0.5562202334403992, "info_normalized_performance_final": 0.6061508059501648, "info_performance_mean": 0.5562202334403992, "info_performance_final": 0.6061508059501648, "step": 1411000}
{"episode_reward": 1112.440476190477, "episode": 14111.0, "batch_reward": 10.729241371154785, "critic_loss": 1210.0023193359375, "actor_loss": -1662.718994140625, "actor_target_entropy": -3.0, "actor_entropy": 1.0981909036636353, "alpha_loss": -0.20334672927856445, "alpha_value": 0.38919805016601544, "duration": 1.496020793914795, "info_normalized_performance_mean": 0.7786383628845215, "info_normalized_performance_final": 0.84375, "info_performance_mean": 0.7786383628845215, "info_performance_final": 0.84375, "step": 1411500}
{"episode_reward": 1557.2767857142858, "episode": 14116.0, "batch_reward": 11.23759651184082, "critic_loss": 685.580078125, "actor_loss": -1645.39794921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8811280727386475, "alpha_loss": -0.014992088079452515, "alpha_value": 0.388725148598678, "duration": 1.523587703704834, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1412000}
{"episode_reward": 0.0, "episode": 14121.0, "batch_reward": 11.124883651733398, "critic_loss": 608.291259765625, "actor_loss": -1712.81103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.2217750549316406, "alpha_loss": 0.14414530992507935, "alpha_value": 0.39067228444488106, "duration": 1.629889965057373, "info_normalized_performance_mean": 0.2679929733276367, "info_normalized_performance_final": 0.30815017223358154, "info_performance_mean": 0.2679929733276367, "info_performance_final": 0.30815017223358154, "step": 1412500}
{"episode_reward": 535.9859584859591, "episode": 14126.0, "batch_reward": 10.600679397583008, "critic_loss": 871.9583740234375, "actor_loss": -1635.198974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.7380398511886597, "alpha_loss": -0.0032002925872802734, "alpha_value": 0.3931520852499198, "duration": 1.5913000106811523, "info_normalized_performance_mean": 0.5547643303871155, "info_normalized_performance_final": 0.6217259168624878, "info_performance_mean": 0.5547643303871155, "info_performance_final": 0.6217259168624878, "step": 1413000}
{"episode_reward": 1109.5285359801471, "episode": 14131.0, "batch_reward": 11.017601013183594, "critic_loss": 707.636474609375, "actor_loss": -1678.2413330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2899587154388428, "alpha_loss": -0.054532527923583984, "alpha_value": 0.3932163070871642, "duration": 1.4866819381713867, "info_normalized_performance_mean": 0.5628508925437927, "info_normalized_performance_final": 0.6135203838348389, "info_performance_mean": 0.5628508925437927, "info_performance_final": 0.6135203838348389, "step": 1413500}
{"episode_reward": 1125.7015306122446, "episode": 14136.0, "batch_reward": 11.330339431762695, "critic_loss": 1449.01904296875, "actor_loss": -1685.999755859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1171258687973022, "alpha_loss": -0.051227811723947525, "alpha_value": 0.39697792702791435, "duration": 1.6329741477966309, "info_normalized_performance_mean": 0.778908371925354, "info_normalized_performance_final": 0.9958333373069763, "info_performance_mean": 0.778908371925354, "info_performance_final": 0.9958333373069763, "step": 1414000}
{"episode_reward": 1557.8166666666666, "episode": 14141.0, "batch_reward": 11.294574737548828, "critic_loss": 970.109130859375, "actor_loss": -1674.178466796875, "actor_target_entropy": -3.0, "actor_entropy": 0.9947487115859985, "alpha_loss": 0.06502607464790344, "alpha_value": 0.39932596224246225, "duration": 1.7314908504486084, "info_normalized_performance_mean": 0.4151148200035095, "info_normalized_performance_final": 0.4899839758872986, "info_performance_mean": 0.4151148200035095, "info_performance_final": 0.4899839758872986, "step": 1414500}
{"episode_reward": 830.2297008546997, "episode": 14146.0, "batch_reward": 10.782096862792969, "critic_loss": 921.0747680664062, "actor_loss": -1670.925048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.6872532963752747, "alpha_loss": -0.18780246376991272, "alpha_value": 0.40238815359111146, "duration": 1.4858098030090332, "info_normalized_performance_mean": 0.5842262506484985, "info_normalized_performance_final": 0.641865074634552, "info_performance_mean": 0.5842262506484985, "info_performance_final": 0.641865074634552, "step": 1415000}
{"episode_reward": 1168.452380952381, "episode": 14151.0, "batch_reward": 11.273113250732422, "critic_loss": 1340.1064453125, "actor_loss": -1658.0101318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.0812784433364868, "alpha_loss": 0.11649516224861145, "alpha_value": 0.4048094605456195, "duration": 1.4380748271942139, "info_normalized_performance_mean": 0.9300000071525574, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9300000071525574, "info_performance_final": 1.0, "step": 1415500}
{"episode_reward": 1860.0, "episode": 14156.0, "batch_reward": 10.640877723693848, "critic_loss": 597.92431640625, "actor_loss": -1648.160888671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2546203136444092, "alpha_loss": -0.1372300386428833, "alpha_value": 0.4092724953256894, "duration": 1.5553388595581055, "info_normalized_performance_mean": 0.7444319725036621, "info_normalized_performance_final": 0.8167613744735718, "info_performance_mean": 0.7444319725036621, "info_performance_final": 0.8167613744735718, "step": 1416000}
{"episode_reward": 1488.863636363635, "episode": 14161.0, "batch_reward": 10.599974632263184, "critic_loss": 1148.40576171875, "actor_loss": -1633.9873046875, "actor_target_entropy": -3.0, "actor_entropy": 0.7989397644996643, "alpha_loss": -0.18342271447181702, "alpha_value": 0.4172108465824061, "duration": 1.616542100906372, "info_normalized_performance_mean": 0.638757050037384, "info_normalized_performance_final": 0.6847222447395325, "info_performance_mean": 0.638757050037384, "info_performance_final": 0.6847222447395325, "step": 1416500}
{"episode_reward": 1277.5138888888878, "episode": 14166.0, "batch_reward": 10.529609680175781, "critic_loss": 725.7399291992188, "actor_loss": -1659.354736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.215933084487915, "alpha_loss": -0.35763734579086304, "alpha_value": 0.428147899793089, "duration": 1.6523425579071045, "info_normalized_performance_mean": 0.6707078814506531, "info_normalized_performance_final": 0.7294973731040955, "info_performance_mean": 0.6707078814506531, "info_performance_final": 0.7294973731040955, "step": 1417000}
{"episode_reward": 1341.415343915347, "episode": 14171.0, "batch_reward": 10.26598834991455, "critic_loss": 1722.92578125, "actor_loss": -1699.3583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3060405254364014, "alpha_loss": -0.18356916308403015, "alpha_value": 0.44195275532470396, "duration": 1.6259315013885498, "info_normalized_performance_mean": 0.5983492136001587, "info_normalized_performance_final": 0.6579365134239197, "info_performance_mean": 0.5983492136001587, "info_performance_final": 0.6579365134239197, "step": 1417500}
{"episode_reward": 1196.6984126984112, "episode": 14176.0, "batch_reward": 10.740814208984375, "critic_loss": 880.0401000976562, "actor_loss": -1650.55224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1163372993469238, "alpha_loss": -0.15344257652759552, "alpha_value": 0.45033915280600556, "duration": 1.6889722347259521, "info_normalized_performance_mean": 0.518711507320404, "info_normalized_performance_final": 0.5876923203468323, "info_performance_mean": 0.518711507320404, "info_performance_final": 0.5876923203468323, "step": 1418000}
{"episode_reward": 1037.4230769230746, "episode": 14181.0, "batch_reward": 11.198603630065918, "critic_loss": 787.0676879882812, "actor_loss": -1702.261474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.9731296300888062, "alpha_loss": -0.44164761900901794, "alpha_value": 0.4607319506778182, "duration": 1.4088351726531982, "info_normalized_performance_mean": 0.1270572990179062, "info_normalized_performance_final": 0.1588541716337204, "info_performance_mean": 0.1270572990179062, "info_performance_final": 0.1588541716337204, "step": 1418500}
{"episode_reward": 254.11458333333363, "episode": 14186.0, "batch_reward": 11.090312004089355, "critic_loss": 1650.817138671875, "actor_loss": -1704.647705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.0214946269989014, "alpha_loss": -0.202779620885849, "alpha_value": 0.46610317510540333, "duration": 1.5760023593902588, "info_normalized_performance_mean": 0.6446893811225891, "info_normalized_performance_final": 0.718638002872467, "info_performance_mean": 0.6446893811225891, "info_performance_final": 0.718638002872467, "step": 1419000}
{"episode_reward": 1289.3787335722839, "episode": 14191.0, "batch_reward": 11.468473434448242, "critic_loss": 1545.15625, "actor_loss": -1691.3538818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6055021286010742, "alpha_loss": 0.055156730115413666, "alpha_value": 0.4736461072167552, "duration": 1.5778589248657227, "info_normalized_performance_mean": 0.7795499563217163, "info_normalized_performance_final": 0.8349999785423279, "info_performance_mean": 0.7795499563217163, "info_performance_final": 0.8349999785423279, "step": 1419500}
{"episode_reward": 1559.1000000000026, "episode": 14196.0, "batch_reward": 10.814382553100586, "critic_loss": 606.2568359375, "actor_loss": -1671.9830322265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0795295238494873, "alpha_loss": -0.33439454436302185, "alpha_value": 0.4768351371049724, "step": 1420000}
{"duration": 18.617217779159546, "info_normalized_performance_mean": 0.632415771484375, "info_normalized_performance_final": 0.6954365372657776, "info_performance_mean": 0.632415771484375, "info_performance_final": 0.6954365372657776, "step": 1420000}
{"episode_reward": 1264.8313492063476, "episode": 14201.0, "batch_reward": 10.928886413574219, "critic_loss": 1069.810546875, "actor_loss": -1685.3232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0741753578186035, "alpha_loss": 0.04192223772406578, "alpha_value": 0.4769719513955269, "duration": 1.5472137928009033, "info_normalized_performance_mean": 0.5120179653167725, "info_normalized_performance_final": 0.5702508687973022, "info_performance_mean": 0.5120179653167725, "info_performance_final": 0.5702508687973022, "step": 1420500}
{"episode_reward": 1024.0358422939075, "episode": 14206.0, "batch_reward": 11.466009140014648, "critic_loss": 1245.103759765625, "actor_loss": -1728.6416015625, "actor_target_entropy": -3.0, "actor_entropy": 1.3157093524932861, "alpha_loss": -0.3195919096469879, "alpha_value": 0.4804060988329964, "duration": 1.5272610187530518, "info_normalized_performance_mean": 0.5149206519126892, "info_normalized_performance_final": 0.574404776096344, "info_performance_mean": 0.5149206519126892, "info_performance_final": 0.574404776096344, "step": 1421000}
{"episode_reward": 1029.8412698412676, "episode": 14211.0, "batch_reward": 10.689727783203125, "critic_loss": 989.2484130859375, "actor_loss": -1702.857666015625, "actor_target_entropy": -3.0, "actor_entropy": 1.016135811805725, "alpha_loss": -0.0757683664560318, "alpha_value": 0.48582196963027136, "duration": 1.6535570621490479, "info_normalized_performance_mean": 0.5359194278717041, "info_normalized_performance_final": 0.6051587462425232, "info_performance_mean": 0.5359194278717041, "info_performance_final": 0.6051587462425232, "step": 1421500}
{"episode_reward": 1071.8386243386249, "episode": 14216.0, "batch_reward": 11.265228271484375, "critic_loss": 646.01220703125, "actor_loss": -1689.22998046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9413151741027832, "alpha_loss": 0.021536357700824738, "alpha_value": 0.4879714607758821, "duration": 1.6372637748718262, "info_normalized_performance_mean": 0.768200159072876, "info_normalized_performance_final": 0.8450000286102295, "info_performance_mean": 0.768200159072876, "info_performance_final": 0.8450000286102295, "step": 1422000}
{"episode_reward": 1536.400000000002, "episode": 14221.0, "batch_reward": 11.326272964477539, "critic_loss": 811.640625, "actor_loss": -1734.334228515625, "actor_target_entropy": -3.0, "actor_entropy": 0.44675761461257935, "alpha_loss": -0.146244615316391, "alpha_value": 0.4884604108161168, "duration": 1.6420457363128662, "info_normalized_performance_mean": 0.8226832747459412, "info_normalized_performance_final": 0.9016666412353516, "info_performance_mean": 0.8226832747459412, "info_performance_final": 0.9016666412353516, "step": 1422500}
{"episode_reward": 1645.3666666666643, "episode": 14226.0, "batch_reward": 11.25607681274414, "critic_loss": 1115.77001953125, "actor_loss": -1740.044921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8855031728744507, "alpha_loss": -0.03541845083236694, "alpha_value": 0.48682839119940025, "duration": 1.6158034801483154, "info_normalized_performance_mean": 0.33634889125823975, "info_normalized_performance_final": 0.37725433707237244, "info_performance_mean": 0.33634889125823975, "info_performance_final": 0.37725433707237244, "step": 1423000}
{"episode_reward": 672.697828487301, "episode": 14231.0, "batch_reward": 10.487852096557617, "critic_loss": 784.7713623046875, "actor_loss": -1699.0244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7898346781730652, "alpha_loss": -0.05820849910378456, "alpha_value": 0.48336583146839796, "duration": 1.5318934917449951, "info_normalized_performance_mean": 0.25311848521232605, "info_normalized_performance_final": 0.2939453125, "info_performance_mean": 0.25311848521232605, "info_performance_final": 0.2939453125, "step": 1423500}
{"episode_reward": 506.2369791666667, "episode": 14236.0, "batch_reward": 9.538110733032227, "critic_loss": 6073.7890625, "actor_loss": -1732.806396484375, "actor_target_entropy": -3.0, "actor_entropy": 0.8479180335998535, "alpha_loss": -0.22001875936985016, "alpha_value": 0.47809885092577764, "duration": 1.4333786964416504, "info_normalized_performance_mean": 0.15324218571186066, "info_normalized_performance_final": 0.17578125, "info_performance_mean": 0.15324218571186066, "info_performance_final": 0.17578125, "step": 1424000}
{"episode_reward": 306.484375, "episode": 14241.0, "batch_reward": 10.685159683227539, "critic_loss": 1938.7001953125, "actor_loss": -1715.8082275390625, "actor_target_entropy": -3.0, "actor_entropy": 0.7572140693664551, "alpha_loss": -0.6297311782836914, "alpha_value": 0.4730101773019771, "duration": 1.4808926582336426, "info_normalized_performance_mean": 0.3268650770187378, "info_normalized_performance_final": 0.369047611951828, "info_performance_mean": 0.3268650770187378, "info_performance_final": 0.369047611951828, "step": 1424500}
{"episode_reward": 653.7301587301602, "episode": 14246.0, "batch_reward": 10.734078407287598, "critic_loss": 1260.77978515625, "actor_loss": -1684.783447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.4661543369293213, "alpha_loss": 0.4508945345878601, "alpha_value": 0.4707944247199224, "duration": 1.6375601291656494, "info_normalized_performance_mean": 0.1983763575553894, "info_normalized_performance_final": 0.32175925374031067, "info_performance_mean": 0.1983763575553894, "info_performance_final": 0.32175925374031067, "step": 1425000}
{"episode_reward": 396.75264550264484, "episode": 14251.0, "batch_reward": 11.571094512939453, "critic_loss": 760.8367919921875, "actor_loss": -1673.140380859375, "actor_target_entropy": -3.0, "actor_entropy": 1.1989754438400269, "alpha_loss": 0.4613633155822754, "alpha_value": 0.46449550681609086, "duration": 1.3675477504730225, "info_normalized_performance_mean": 0.4045703113079071, "info_normalized_performance_final": 0.50390625, "info_performance_mean": 0.4045703113079071, "info_performance_final": 0.50390625, "step": 1425500}
{"episode_reward": 809.140625, "episode": 14256.0, "batch_reward": 11.304173469543457, "critic_loss": 1175.8270263671875, "actor_loss": -1763.712158203125, "actor_target_entropy": -3.0, "actor_entropy": 0.685653567314148, "alpha_loss": 0.056378088891506195, "alpha_value": 0.46374254056548236, "duration": 1.461332082748413, "info_normalized_performance_mean": 0.5703384876251221, "info_normalized_performance_final": 0.6796875, "info_performance_mean": 0.5703384876251221, "info_performance_final": 0.6796875, "step": 1426000}
{"episode_reward": 1140.6770833333335, "episode": 14261.0, "batch_reward": 10.797374725341797, "critic_loss": 4724.150390625, "actor_loss": -1640.910888671875, "actor_target_entropy": -3.0, "actor_entropy": 0.7847952842712402, "alpha_loss": 0.18689487874507904, "alpha_value": 0.46501798070613215, "duration": 1.5023670196533203, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1426500}
{"episode_reward": 0.0, "episode": 14266.0, "batch_reward": 10.79640007019043, "critic_loss": 714.7208251953125, "actor_loss": -1655.4517822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.021517276763916, "alpha_loss": 0.23171362280845642, "alpha_value": 0.47368327958434703, "duration": 1.514911413192749, "info_normalized_performance_mean": 0.45715659856796265, "info_normalized_performance_final": 0.5236957669258118, "info_performance_mean": 0.45715659856796265, "info_performance_final": 0.5236957669258118, "step": 1427000}
{"episode_reward": 914.3130227001183, "episode": 14271.0, "batch_reward": 10.520962715148926, "critic_loss": 1607.47021484375, "actor_loss": -1699.8201904296875, "actor_target_entropy": -3.0, "actor_entropy": 0.6751514673233032, "alpha_loss": -0.37689805030822754, "alpha_value": 0.4777338338755022, "duration": 1.4779903888702393, "info_normalized_performance_mean": 0.4263726770877838, "info_normalized_performance_final": 0.5027901530265808, "info_performance_mean": 0.4263726770877838, "info_performance_final": 0.5027901530265808, "step": 1427500}
{"episode_reward": 852.7455357142849, "episode": 14276.0, "batch_reward": 10.686481475830078, "critic_loss": 2367.6806640625, "actor_loss": -1721.314697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.0361864566802979, "alpha_loss": 0.11710044741630554, "alpha_value": 0.4833571424019377, "duration": 1.6007637977600098, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1428000}
{"episode_reward": 0.0, "episode": 14281.0, "batch_reward": 10.862417221069336, "critic_loss": 4056.481689453125, "actor_loss": -1749.23291015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9091187715530396, "alpha_loss": 0.10525966435670853, "alpha_value": 0.48704908481052694, "duration": 1.5382249355316162, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1428500}
{"episode_reward": 0.0, "episode": 14286.0, "batch_reward": 11.209000587463379, "critic_loss": 1448.160888671875, "actor_loss": -1596.967041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9012713432312012, "alpha_loss": 0.2714533805847168, "alpha_value": 0.49238594473072983, "duration": 1.4910061359405518, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1429000}
{"episode_reward": 0.0, "episode": 14291.0, "batch_reward": 10.279092788696289, "critic_loss": 2433.953125, "actor_loss": -1668.450927734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7559254169464111, "alpha_loss": -0.37479352951049805, "alpha_value": 0.4996480156451976, "duration": 1.5096163749694824, "info_normalized_performance_mean": 0.2974404990673065, "info_normalized_performance_final": 0.7638888955116272, "info_performance_mean": 0.2974404990673065, "info_performance_final": 0.7638888955116272, "step": 1429500}
{"episode_reward": 594.8809523809525, "episode": 14296.0, "batch_reward": 9.611719131469727, "critic_loss": 2030.139892578125, "actor_loss": -1828.0999755859375, "actor_target_entropy": -3.0, "actor_entropy": 0.753962516784668, "alpha_loss": -0.47135740518569946, "alpha_value": 0.5124235195851241, "step": 1430000}
{"duration": 18.837666511535645, "info_normalized_performance_mean": 0.6485450267791748, "info_normalized_performance_final": 0.7993406653404236, "info_performance_mean": 0.6485450267791748, "info_performance_final": 0.7993406653404236, "step": 1430000}
{"episode_reward": 1297.0901098901086, "episode": 14301.0, "batch_reward": 10.21394157409668, "critic_loss": 1506.6875, "actor_loss": -1764.780029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.6508142948150635, "alpha_loss": -0.03469398245215416, "alpha_value": 0.5192005279962894, "duration": 1.4882442951202393, "info_normalized_performance_mean": 0.2690580487251282, "info_normalized_performance_final": 0.29827314615249634, "info_performance_mean": 0.2690580487251282, "info_performance_final": 0.29827314615249634, "step": 1430500}
{"episode_reward": 538.116169544741, "episode": 14306.0, "batch_reward": 11.187658309936523, "critic_loss": 794.7965087890625, "actor_loss": -1712.140869140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8383674621582031, "alpha_loss": 0.07722364366054535, "alpha_value": 0.5250460462207486, "duration": 1.5919222831726074, "info_normalized_performance_mean": 0.5214223861694336, "info_normalized_performance_final": 0.5924999713897705, "info_performance_mean": 0.5214223861694336, "info_performance_final": 0.5924999713897705, "step": 1431000}
{"episode_reward": 1042.8450000000012, "episode": 14311.0, "batch_reward": 10.174501419067383, "critic_loss": 4179.3369140625, "actor_loss": -1654.85302734375, "actor_target_entropy": -3.0, "actor_entropy": 0.6336058378219604, "alpha_loss": -0.009427037090063095, "alpha_value": 0.5296232159511419, "duration": 1.6438558101654053, "info_normalized_performance_mean": 0.4515809714794159, "info_normalized_performance_final": 0.5348883867263794, "info_performance_mean": 0.4515809714794159, "info_performance_final": 0.5348883867263794, "step": 1431500}
{"episode_reward": 903.1618819776718, "episode": 14316.0, "batch_reward": 9.989496231079102, "critic_loss": 2027.24365234375, "actor_loss": -1829.7783203125, "actor_target_entropy": -3.0, "actor_entropy": 0.7007946372032166, "alpha_loss": -0.4452288746833801, "alpha_value": 0.5425170772141865, "duration": 1.4633851051330566, "info_normalized_performance_mean": 0.6134248971939087, "info_normalized_performance_final": 0.7155067324638367, "info_performance_mean": 0.6134248971939087, "info_performance_final": 0.7155067324638367, "step": 1432000}
{"episode_reward": 1226.8498168498181, "episode": 14321.0, "batch_reward": 10.27081298828125, "critic_loss": 4512.75634765625, "actor_loss": -1741.8720703125, "actor_target_entropy": -3.0, "actor_entropy": 0.9792622923851013, "alpha_loss": -0.031541720032691956, "alpha_value": 0.5487358406343618, "duration": 1.5071802139282227, "info_normalized_performance_mean": 0.3821875751018524, "info_normalized_performance_final": 0.444399356842041, "info_performance_mean": 0.3821875751018524, "info_performance_final": 0.444399356842041, "step": 1432500}
{"episode_reward": 764.3749999999992, "episode": 14326.0, "batch_reward": 9.796921730041504, "critic_loss": 11552.1884765625, "actor_loss": -1788.6768798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7257555723190308, "alpha_loss": -0.20157459378242493, "alpha_value": 0.552367198948288, "duration": 1.6358652114868164, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1433000}
{"episode_reward": 0.0, "episode": 14331.0, "batch_reward": 11.103145599365234, "critic_loss": 1449.928955078125, "actor_loss": -1803.5908203125, "actor_target_entropy": -3.0, "actor_entropy": 0.8792057037353516, "alpha_loss": -0.5567580461502075, "alpha_value": 0.5661955497019767, "duration": 1.5102040767669678, "info_normalized_performance_mean": 0.528532087802887, "info_normalized_performance_final": 0.5820251107215881, "info_performance_mean": 0.528532087802887, "info_performance_final": 0.5820251107215881, "step": 1433500}
{"episode_reward": 1057.0643642072205, "episode": 14336.0, "batch_reward": 9.839836120605469, "critic_loss": 1740.0899658203125, "actor_loss": -1858.30712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.5631820559501648, "alpha_loss": -0.31694990396499634, "alpha_value": 0.5783797803275558, "duration": 1.5320627689361572, "info_normalized_performance_mean": 0.6683844923973083, "info_normalized_performance_final": 0.7551020383834839, "info_performance_mean": 0.6683844923973083, "info_performance_final": 0.7551020383834839, "step": 1434000}
{"episode_reward": 1336.7687074829917, "episode": 14341.0, "batch_reward": 9.091132164001465, "critic_loss": 2517.3134765625, "actor_loss": -1800.8583984375, "actor_target_entropy": -3.0, "actor_entropy": 0.5117630958557129, "alpha_loss": -0.36801350116729736, "alpha_value": 0.5910004879998173, "duration": 1.650533676147461, "info_normalized_performance_mean": 0.5212724208831787, "info_normalized_performance_final": 0.6495535969734192, "info_performance_mean": 0.5212724208831787, "info_performance_final": 0.6495535969734192, "step": 1434500}
{"episode_reward": 1042.5446428571436, "episode": 14346.0, "batch_reward": 10.150686264038086, "critic_loss": 6081.607421875, "actor_loss": -1912.378173828125, "actor_target_entropy": -3.0, "actor_entropy": 0.6559257507324219, "alpha_loss": -0.4069921374320984, "alpha_value": 0.6041716580200157, "duration": 1.5016109943389893, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1435000}
{"episode_reward": 0.0, "episode": 14351.0, "batch_reward": 9.959632873535156, "critic_loss": 8300.8857421875, "actor_loss": -1948.83642578125, "actor_target_entropy": -3.0, "actor_entropy": 0.8967952132225037, "alpha_loss": -0.6263250112533569, "alpha_value": 0.6145006732424043, "duration": 1.5450057983398438, "info_normalized_performance_mean": 0.04481770843267441, "info_normalized_performance_final": 0.21875, "info_performance_mean": 0.04481770843267441, "info_performance_final": 0.21875, "step": 1435500}
{"episode_reward": 89.63541666666666, "episode": 14356.0, "batch_reward": 9.87117862701416, "critic_loss": 2841.3515625, "actor_loss": -1781.8563232421875, "actor_target_entropy": -3.0, "actor_entropy": 0.3504830002784729, "alpha_loss": -0.31360238790512085, "alpha_value": 0.6221342823636478, "duration": 1.4630751609802246, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1436000}
{"episode_reward": 0.0, "episode": 14361.0, "batch_reward": 10.990575790405273, "critic_loss": 1918.1925048828125, "actor_loss": -1905.142578125, "actor_target_entropy": -3.0, "actor_entropy": 0.900686502456665, "alpha_loss": -0.2262563556432724, "alpha_value": 0.6327040263989472, "duration": 1.5517029762268066, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1436500}
{"episode_reward": 0.0, "episode": 14366.0, "batch_reward": 9.578412055969238, "critic_loss": 4888.619140625, "actor_loss": -1873.966064453125, "actor_target_entropy": -3.0, "actor_entropy": 0.15210439264774323, "alpha_loss": -0.30952325463294983, "alpha_value": 0.6422278659041065, "duration": 1.546344518661499, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1437000}
{"episode_reward": 0.0, "episode": 14371.0, "batch_reward": 9.54288101196289, "critic_loss": 3054.6044921875, "actor_loss": -2094.79443359375, "actor_target_entropy": -3.0, "actor_entropy": 0.04177826642990112, "alpha_loss": -0.3471566140651703, "alpha_value": 0.6523062997288427, "duration": 1.4315128326416016, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1437500}
{"episode_reward": 0.0, "episode": 14376.0, "batch_reward": 9.419034004211426, "critic_loss": 12719.615234375, "actor_loss": -2214.85986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.270062118768692, "alpha_loss": -0.29694244265556335, "alpha_value": 0.6625247002610154, "duration": 1.4802258014678955, "info_normalized_performance_mean": 0.07795951515436172, "info_normalized_performance_final": 0.0901920422911644, "info_performance_mean": 0.07795951515436172, "info_performance_final": 0.0901920422911644, "step": 1438000}
{"episode_reward": 155.9190672153634, "episode": 14381.0, "batch_reward": 10.227625846862793, "critic_loss": 11916.8408203125, "actor_loss": -1885.5045166015625, "actor_target_entropy": -3.0, "actor_entropy": 0.2667282521724701, "alpha_loss": -0.4124569594860077, "alpha_value": 0.6737895118853001, "duration": 1.435631513595581, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1438500}
{"episode_reward": 0.0, "episode": 14386.0, "batch_reward": 9.729536056518555, "critic_loss": 2632.411376953125, "actor_loss": -1935.2689208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.2799968421459198, "alpha_loss": -0.2481638491153717, "alpha_value": 0.6895182208895396, "duration": 1.4887511730194092, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1439000}
{"episode_reward": 0.0, "episode": 14391.0, "batch_reward": 10.51679801940918, "critic_loss": 17363.7421875, "actor_loss": -2162.6806640625, "actor_target_entropy": -3.0, "actor_entropy": 0.4985387623310089, "alpha_loss": 0.30140215158462524, "alpha_value": 0.7035858493524306, "duration": 1.5289652347564697, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1439500}
{"episode_reward": 0.0, "episode": 14396.0, "batch_reward": 9.414375305175781, "critic_loss": 37365.20703125, "actor_loss": -2231.23095703125, "actor_target_entropy": -3.0, "actor_entropy": -0.3813425302505493, "alpha_loss": -0.5001012682914734, "alpha_value": 0.7164480985490195, "step": 1440000}
{"duration": 18.645148754119873, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1440000}
{"episode_reward": 0.0, "episode": 14401.0, "batch_reward": 9.916003227233887, "critic_loss": 2162.513916015625, "actor_loss": -2010.4495849609375, "actor_target_entropy": -3.0, "actor_entropy": 0.2774755656719208, "alpha_loss": 0.023568972945213318, "alpha_value": 0.7296893698240439, "duration": 1.5949790477752686, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1440500}
{"episode_reward": 0.0, "episode": 14406.0, "batch_reward": 9.27945327758789, "critic_loss": 5611.19287109375, "actor_loss": -2268.36865234375, "actor_target_entropy": -3.0, "actor_entropy": -0.06143447384238243, "alpha_loss": -0.29729193449020386, "alpha_value": 0.7449477434984778, "duration": 1.5799579620361328, "info_normalized_performance_mean": 4.3497175283846445e-06, "info_normalized_performance_final": 0.0, "info_performance_mean": 4.3497175283846445e-06, "info_performance_final": 0.0, "step": 1441000}
{"episode_reward": 0.008699434536755112, "episode": 14411.0, "batch_reward": 9.266769409179688, "critic_loss": 57117.25, "actor_loss": -2266.3583984375, "actor_target_entropy": -3.0, "actor_entropy": -0.17726773023605347, "alpha_loss": -0.26071709394454956, "alpha_value": 0.7589682816347277, "duration": 1.414595127105713, "info_normalized_performance_mean": 0.32511720061302185, "info_normalized_performance_final": 0.36328125, "info_performance_mean": 0.32511720061302185, "info_performance_final": 0.36328125, "step": 1441500}
{"episode_reward": 650.234375, "episode": 14416.0, "batch_reward": 9.160530090332031, "critic_loss": 8307.72265625, "actor_loss": -2429.36572265625, "actor_target_entropy": -3.0, "actor_entropy": -0.27361470460891724, "alpha_loss": -0.5597939491271973, "alpha_value": 0.7727925521520508, "duration": 1.5677287578582764, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1442000}
{"episode_reward": 0.0, "episode": 14421.0, "batch_reward": 9.814282417297363, "critic_loss": 5454.611328125, "actor_loss": -2112.69775390625, "actor_target_entropy": -3.0, "actor_entropy": 0.09150566905736923, "alpha_loss": -0.043904662132263184, "alpha_value": 0.7887542132651622, "duration": 1.5968754291534424, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1442500}
{"episode_reward": 0.0, "episode": 14426.0, "batch_reward": 9.316741943359375, "critic_loss": 17980.20703125, "actor_loss": -2092.14208984375, "actor_target_entropy": -3.0, "actor_entropy": -0.03901619836688042, "alpha_loss": -0.23599687218666077, "alpha_value": 0.8030556193346293, "duration": 1.5894827842712402, "info_normalized_performance_mean": 4.999999873689376e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 4.999999873689376e-05, "info_performance_final": 0.0, "step": 1443000}
{"episode_reward": 0.1, "episode": 14431.0, "batch_reward": 9.472270011901855, "critic_loss": 188395.875, "actor_loss": -2227.9375, "actor_target_entropy": -3.0, "actor_entropy": 0.6585443615913391, "alpha_loss": 0.16376613080501556, "alpha_value": 0.8231810799264366, "duration": 1.4404585361480713, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1443500}
{"episode_reward": 0.0, "episode": 14436.0, "batch_reward": 8.849503517150879, "critic_loss": 71117.546875, "actor_loss": -2474.21728515625, "actor_target_entropy": -3.0, "actor_entropy": 0.02362532913684845, "alpha_loss": -0.35676485300064087, "alpha_value": 0.8419876394791073, "duration": 1.5185446739196777, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1444000}
{"episode_reward": 0.0, "episode": 14441.0, "batch_reward": 8.858094215393066, "critic_loss": 5777.9453125, "actor_loss": -2372.38427734375, "actor_target_entropy": -3.0, "actor_entropy": 0.22006607055664062, "alpha_loss": 0.18567267060279846, "alpha_value": 0.8610198640007647, "duration": 1.4826185703277588, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1444500}
{"episode_reward": 0.0, "episode": 14446.0, "batch_reward": 8.681631088256836, "critic_loss": 7936.5302734375, "actor_loss": -2492.880859375, "actor_target_entropy": -3.0, "actor_entropy": 0.004539415240287781, "alpha_loss": 0.17944036424160004, "alpha_value": 0.8769747651229493, "duration": 1.5252788066864014, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1445000}
{"episode_reward": 0.0, "episode": 14451.0, "batch_reward": 8.03380012512207, "critic_loss": 51797.74609375, "actor_loss": -2636.73583984375, "actor_target_entropy": -3.0, "actor_entropy": -0.599051833152771, "alpha_loss": -0.8418099284172058, "alpha_value": 0.896934194073547, "duration": 1.458664894104004, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1445500}
{"episode_reward": 0.0, "episode": 14456.0, "batch_reward": 9.250933647155762, "critic_loss": 16696.44140625, "actor_loss": -2263.1640625, "actor_target_entropy": -3.0, "actor_entropy": 0.21967008709907532, "alpha_loss": -0.6933416128158569, "alpha_value": 0.914074856623726, "duration": 1.5293059349060059, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1446000}
{"episode_reward": 0.0, "episode": 14461.0, "batch_reward": 9.311145782470703, "critic_loss": 57800.7578125, "actor_loss": -2187.581787109375, "actor_target_entropy": -3.0, "actor_entropy": 0.5360902547836304, "alpha_loss": -0.8070992231369019, "alpha_value": 0.9363277170974665, "duration": 1.8198859691619873, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1446500}
{"episode_reward": 0.0, "episode": 14466.0, "batch_reward": 9.199176788330078, "critic_loss": 110248.5234375, "actor_loss": -2792.50634765625, "actor_target_entropy": -3.0, "actor_entropy": 0.33631420135498047, "alpha_loss": -0.80547034740448, "alpha_value": 0.9570235545214768, "duration": 1.5358800888061523, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1447000}
{"episode_reward": 0.0, "episode": 14471.0, "batch_reward": 8.967296600341797, "critic_loss": 5081.46240234375, "actor_loss": -2290.309814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.5663703680038452, "alpha_loss": -0.3488563895225525, "alpha_value": 0.9857089613091375, "duration": 1.5628280639648438, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1447500}
{"episode_reward": 0.0, "episode": 14476.0, "batch_reward": 8.634496688842773, "critic_loss": 19694.80078125, "actor_loss": -2584.8984375, "actor_target_entropy": -3.0, "actor_entropy": 0.09396068751811981, "alpha_loss": -0.9817157983779907, "alpha_value": 1.0163379038595854, "duration": 1.4863626956939697, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1448000}
{"episode_reward": 0.0, "episode": 14481.0, "batch_reward": 8.771408081054688, "critic_loss": 10122.666015625, "actor_loss": -2709.66015625, "actor_target_entropy": -3.0, "actor_entropy": 0.0749785453081131, "alpha_loss": -0.5815523862838745, "alpha_value": 1.0494276923052963, "duration": 1.5504262447357178, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1448500}
{"episode_reward": 0.0, "episode": 14486.0, "batch_reward": 8.68802261352539, "critic_loss": 40535.15625, "actor_loss": -2556.655517578125, "actor_target_entropy": -3.0, "actor_entropy": 0.40654170513153076, "alpha_loss": -1.1672149896621704, "alpha_value": 1.0842242774885233, "duration": 1.539628028869629, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1449000}
{"episode_reward": 0.0, "episode": 14491.0, "batch_reward": 8.489425659179688, "critic_loss": 6405.4169921875, "actor_loss": -2728.98193359375, "actor_target_entropy": -3.0, "actor_entropy": 0.12906622886657715, "alpha_loss": -1.4896849393844604, "alpha_value": 1.1218727242497442, "duration": 1.562258005142212, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1449500}
{"episode_reward": 0.0, "episode": 14496.0, "batch_reward": 8.903474807739258, "critic_loss": 50686.6796875, "actor_loss": -2585.5390625, "actor_target_entropy": -3.0, "actor_entropy": 0.24661624431610107, "alpha_loss": -1.629655361175537, "alpha_value": 1.161171423237906, "step": 1450000}
{"duration": 18.533003330230713, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1450000}
{"episode_reward": 0.0, "episode": 14501.0, "batch_reward": 9.287925720214844, "critic_loss": 8684.7880859375, "actor_loss": -2582.70654296875, "actor_target_entropy": -3.0, "actor_entropy": 0.355274498462677, "alpha_loss": -0.8776434659957886, "alpha_value": 1.1983274852370094, "duration": 1.4659180641174316, "info_normalized_performance_mean": 0.06721483916044235, "info_normalized_performance_final": 0.08046875149011612, "info_performance_mean": 0.06721483916044235, "info_performance_final": 0.08046875149011612, "step": 1450500}
{"episode_reward": 134.4296875, "episode": 14506.0, "batch_reward": 7.6529622077941895, "critic_loss": 11702.47265625, "actor_loss": -2675.70263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.272746741771698, "alpha_loss": -1.9026665687561035, "alpha_value": 1.2371768518791721, "duration": 1.4401280879974365, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1451000}
{"episode_reward": 0.0, "episode": 14511.0, "batch_reward": 8.782257080078125, "critic_loss": 12916.251953125, "actor_loss": -2825.83544921875, "actor_target_entropy": -3.0, "actor_entropy": 0.06430639326572418, "alpha_loss": -1.2704226970672607, "alpha_value": 1.2796701488093214, "duration": 1.6612517833709717, "info_normalized_performance_mean": 0.23310095071792603, "info_normalized_performance_final": 0.266960471868515, "info_performance_mean": 0.23310095071792603, "info_performance_final": 0.266960471868515, "step": 1451500}
{"episode_reward": 466.2019230769236, "episode": 14516.0, "batch_reward": 9.100168228149414, "critic_loss": 6868.00048828125, "actor_loss": -2703.19580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.23418016731739044, "alpha_loss": -1.1372931003570557, "alpha_value": 1.3219436653696135, "duration": 1.4518446922302246, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1452000}
{"episode_reward": 0.0, "episode": 14521.0, "batch_reward": 8.70773696899414, "critic_loss": 13799.9873046875, "actor_loss": -2974.167236328125, "actor_target_entropy": -3.0, "actor_entropy": 0.6813247203826904, "alpha_loss": -2.0387959480285645, "alpha_value": 1.3621392617319728, "duration": 1.4890251159667969, "info_normalized_performance_mean": 0.1868131458759308, "info_normalized_performance_final": 0.28434064984321594, "info_performance_mean": 0.1868131458759308, "info_performance_final": 0.28434064984321594, "step": 1452500}
{"episode_reward": 373.626373626374, "episode": 14526.0, "batch_reward": 8.467864990234375, "critic_loss": 9475.998046875, "actor_loss": -3263.04443359375, "actor_target_entropy": -3.0, "actor_entropy": 0.045388057827949524, "alpha_loss": -1.8472787141799927, "alpha_value": 1.4002363840232879, "duration": 1.5670793056488037, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1453000}
{"episode_reward": 0.0, "episode": 14531.0, "batch_reward": 8.722709655761719, "critic_loss": 4771.3388671875, "actor_loss": -2736.48681640625, "actor_target_entropy": -3.0, "actor_entropy": 0.3134261965751648, "alpha_loss": -1.804771065711975, "alpha_value": 1.439783708382697, "duration": 1.3449246883392334, "info_normalized_performance_mean": 0.0013928571715950966, "info_normalized_performance_final": 0.0017857142956927419, "info_performance_mean": 0.0013928571715950966, "info_performance_final": 0.0017857142956927419, "step": 1453500}
{"episode_reward": 2.785714285714285, "episode": 14536.0, "batch_reward": 8.004006385803223, "critic_loss": 7074.0078125, "actor_loss": -2916.6064453125, "actor_target_entropy": -3.0, "actor_entropy": 0.08350098878145218, "alpha_loss": -1.9334081411361694, "alpha_value": 1.477122022203962, "duration": 1.47568678855896, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1454000}
{"episode_reward": 0.0, "episode": 14541.0, "batch_reward": 8.162419319152832, "critic_loss": 11494.517578125, "actor_loss": -3124.244140625, "actor_target_entropy": -3.0, "actor_entropy": -0.1501118242740631, "alpha_loss": -1.949812650680542, "alpha_value": 1.5110103405533728, "duration": 1.5305287837982178, "info_normalized_performance_mean": 0.2217058539390564, "info_normalized_performance_final": 0.2808823585510254, "info_performance_mean": 0.2217058539390564, "info_performance_final": 0.2808823585510254, "step": 1454500}
{"episode_reward": 443.4117647058828, "episode": 14546.0, "batch_reward": 8.590675354003906, "critic_loss": 12369.755859375, "actor_loss": -3435.66259765625, "actor_target_entropy": -3.0, "actor_entropy": 0.05993512272834778, "alpha_loss": -2.3736891746520996, "alpha_value": 1.5473601919491708, "duration": 1.5588736534118652, "info_normalized_performance_mean": 1.5893197087279987e-06, "info_normalized_performance_final": 0.0, "info_performance_mean": 1.5893197087279987e-06, "info_performance_final": 0.0, "step": 1455000}
{"episode_reward": 0.003178639542275906, "episode": 14551.0, "batch_reward": 7.596732139587402, "critic_loss": 11326.5888671875, "actor_loss": -3275.0244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.30677473545074463, "alpha_loss": -1.5339529514312744, "alpha_value": 1.5834153029237603, "duration": 1.5376017093658447, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1455500}
{"episode_reward": 0.0, "episode": 14556.0, "batch_reward": 7.345393180847168, "critic_loss": 37829.578125, "actor_loss": -3385.60498046875, "actor_target_entropy": -3.0, "actor_entropy": 0.06575518101453781, "alpha_loss": -2.1094608306884766, "alpha_value": 1.6254977981590455, "duration": 1.6539068222045898, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1456000}
{"episode_reward": 0.0, "episode": 14561.0, "batch_reward": 8.048853874206543, "critic_loss": 6305.93701171875, "actor_loss": -3335.2578125, "actor_target_entropy": -3.0, "actor_entropy": 0.07070019841194153, "alpha_loss": -1.9490940570831299, "alpha_value": 1.660913765681947, "duration": 1.448012113571167, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1456500}
{"episode_reward": 0.0, "episode": 14566.0, "batch_reward": 6.20819091796875, "critic_loss": 10762.451171875, "actor_loss": -3645.7412109375, "actor_target_entropy": -3.0, "actor_entropy": -0.15345335006713867, "alpha_loss": -2.9560210704803467, "alpha_value": 1.7008160214572856, "duration": 1.483924150466919, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1457000}
{"episode_reward": 0.0, "episode": 14571.0, "batch_reward": 8.291719436645508, "critic_loss": 244584.375, "actor_loss": -3466.006591796875, "actor_target_entropy": -3.0, "actor_entropy": 0.42001020908355713, "alpha_loss": -1.3242101669311523, "alpha_value": 1.7384642485561836, "duration": 1.442434310913086, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1457500}
{"episode_reward": 0.0, "episode": 14576.0, "batch_reward": 8.28602409362793, "critic_loss": 18344.99609375, "actor_loss": -3357.924072265625, "actor_target_entropy": -3.0, "actor_entropy": 0.3518906831741333, "alpha_loss": -1.39956533908844, "alpha_value": 1.773476778289039, "duration": 1.4988398551940918, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1458000}
{"episode_reward": 0.0, "episode": 14581.0, "batch_reward": 6.632334232330322, "critic_loss": 12100.259765625, "actor_loss": -3743.58544921875, "actor_target_entropy": -3.0, "actor_entropy": 0.1956728994846344, "alpha_loss": -1.8731858730316162, "alpha_value": 1.8088359741297486, "duration": 1.5611872673034668, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1458500}
{"episode_reward": 0.0, "episode": 14586.0, "batch_reward": 7.542910575866699, "critic_loss": 107495.71875, "actor_loss": -3840.879150390625, "actor_target_entropy": -3.0, "actor_entropy": 0.08413229882717133, "alpha_loss": -1.5968250036239624, "alpha_value": 1.8503613537700887, "duration": 1.5508396625518799, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1459000}
{"episode_reward": 0.0, "episode": 14591.0, "batch_reward": 7.594986915588379, "critic_loss": 9674.443359375, "actor_loss": -3578.605712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7840712666511536, "alpha_loss": -2.0654003620147705, "alpha_value": 1.9004466467121144, "duration": 1.577174425125122, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1459500}
{"episode_reward": 0.0, "episode": 14596.0, "batch_reward": 7.889883041381836, "critic_loss": 8325.9091796875, "actor_loss": -3364.1728515625, "actor_target_entropy": -3.0, "actor_entropy": 0.5242019891738892, "alpha_loss": -1.7131474018096924, "alpha_value": 1.9495574726450784, "step": 1460000}
{"duration": 18.304935932159424, "info_normalized_performance_mean": 4.578754669637419e-06, "info_normalized_performance_final": 0.0, "info_performance_mean": 4.578754669637419e-06, "info_performance_final": 0.0, "step": 1460000}
{"episode_reward": 0.009157509157509158, "episode": 14601.0, "batch_reward": 7.4468278884887695, "critic_loss": 5415.78662109375, "actor_loss": -3479.384521484375, "actor_target_entropy": -3.0, "actor_entropy": 0.5906674861907959, "alpha_loss": -0.8460566997528076, "alpha_value": 1.994474282196432, "duration": 1.548388957977295, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1460500}
{"episode_reward": 0.0, "episode": 14606.0, "batch_reward": 7.575225830078125, "critic_loss": 8069.83935546875, "actor_loss": -3727.3828125, "actor_target_entropy": -3.0, "actor_entropy": 0.37080058455467224, "alpha_loss": -2.23018741607666, "alpha_value": 2.0413805893140986, "duration": 1.5814757347106934, "info_normalized_performance_mean": 0.11835925281047821, "info_normalized_performance_final": 0.25757575035095215, "info_performance_mean": 0.11835925281047821, "info_performance_final": 0.25757575035095215, "step": 1461000}
{"episode_reward": 236.71850079744829, "episode": 14611.0, "batch_reward": 6.613585948944092, "critic_loss": 8481.634765625, "actor_loss": -3609.88330078125, "actor_target_entropy": -3.0, "actor_entropy": 0.23720398545265198, "alpha_loss": -0.9593067765235901, "alpha_value": 2.0804114541511307, "duration": 1.5047485828399658, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1461500}
{"episode_reward": 0.0, "episode": 14616.0, "batch_reward": 8.900690078735352, "critic_loss": 7644.5390625, "actor_loss": -3238.67529296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9550018906593323, "alpha_loss": -2.1335391998291016, "alpha_value": 2.1266284017594446, "duration": 1.5649340152740479, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1462000}
{"episode_reward": 0.0, "episode": 14621.0, "batch_reward": 8.040038108825684, "critic_loss": 45421.6875, "actor_loss": -3698.072021484375, "actor_target_entropy": -3.0, "actor_entropy": 0.7562875151634216, "alpha_loss": -0.7378641366958618, "alpha_value": 2.176500462519535, "duration": 1.491682767868042, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1462500}
{"episode_reward": 0.0, "episode": 14626.0, "batch_reward": 8.298744201660156, "critic_loss": 4221.90625, "actor_loss": -3699.925048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7396795749664307, "alpha_loss": -2.099437713623047, "alpha_value": 2.2343806570537543, "duration": 1.5250380039215088, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1463000}
{"episode_reward": 0.0, "episode": 14631.0, "batch_reward": 7.035102367401123, "critic_loss": 5636.90234375, "actor_loss": -3741.5478515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7585486769676208, "alpha_loss": -1.8746222257614136, "alpha_value": 2.2919949006344353, "duration": 1.6774370670318604, "info_normalized_performance_mean": 0.16696448624134064, "info_normalized_performance_final": 0.20819978415966034, "info_performance_mean": 0.16696448624134064, "info_performance_final": 0.20819978415966034, "step": 1463500}
{"episode_reward": 333.928952991453, "episode": 14636.0, "batch_reward": 7.354689598083496, "critic_loss": 34852.3203125, "actor_loss": -4068.14404296875, "actor_target_entropy": -3.0, "actor_entropy": 0.6966333985328674, "alpha_loss": -2.548990249633789, "alpha_value": 2.3548185039969876, "duration": 1.5756747722625732, "info_normalized_performance_mean": 0.2835690379142761, "info_normalized_performance_final": 0.322857141494751, "info_performance_mean": 0.2835690379142761, "info_performance_final": 0.322857141494751, "step": 1464000}
{"episode_reward": 567.1380952380956, "episode": 14641.0, "batch_reward": 6.68109130859375, "critic_loss": 12130.18359375, "actor_loss": -3704.250244140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7642990350723267, "alpha_loss": -2.9948391914367676, "alpha_value": 2.430770854657294, "duration": 1.5744404792785645, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1464500}
{"episode_reward": 0.0, "episode": 14646.0, "batch_reward": 7.592055320739746, "critic_loss": 34031.03125, "actor_loss": -3675.671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3598639965057373, "alpha_loss": -1.609241247177124, "alpha_value": 2.494273409893494, "duration": 1.4855608940124512, "info_normalized_performance_mean": 0.006906886585056782, "info_normalized_performance_final": 0.0076530613005161285, "info_performance_mean": 0.006906886585056782, "info_performance_final": 0.0076530613005161285, "step": 1465000}
{"episode_reward": 13.813775510204103, "episode": 14651.0, "batch_reward": 6.796286106109619, "critic_loss": 17676.578125, "actor_loss": -3979.041015625, "actor_target_entropy": -3.0, "actor_entropy": 0.6086081266403198, "alpha_loss": -2.8961071968078613, "alpha_value": 2.5577536369285503, "duration": 1.5804858207702637, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1465500}
{"episode_reward": 0.0, "episode": 14656.0, "batch_reward": 7.824028491973877, "critic_loss": 9125.552734375, "actor_loss": -3834.564208984375, "actor_target_entropy": -3.0, "actor_entropy": 0.7647356986999512, "alpha_loss": -1.553736686706543, "alpha_value": 2.613075938220154, "duration": 1.5012316703796387, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1466000}
{"episode_reward": 0.0, "episode": 14661.0, "batch_reward": 7.664708137512207, "critic_loss": 7325.60205078125, "actor_loss": -3668.502197265625, "actor_target_entropy": -3.0, "actor_entropy": 1.13139808177948, "alpha_loss": -1.2857747077941895, "alpha_value": 2.6599008747584745, "duration": 1.585463285446167, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1466500}
{"episode_reward": 0.0, "episode": 14666.0, "batch_reward": 7.421955108642578, "critic_loss": 6823.904296875, "actor_loss": -3735.21533203125, "actor_target_entropy": -3.0, "actor_entropy": 0.4832291007041931, "alpha_loss": -1.5474436283111572, "alpha_value": 2.7038682102504925, "duration": 1.5488059520721436, "info_normalized_performance_mean": 0.0003617216134443879, "info_normalized_performance_final": 0.0004578754596877843, "info_performance_mean": 0.0003617216134443879, "info_performance_final": 0.0004578754596877843, "step": 1467000}
{"episode_reward": 0.7234432234432232, "episode": 14671.0, "batch_reward": 6.268883228302002, "critic_loss": 11428.6083984375, "actor_loss": -3971.05810546875, "actor_target_entropy": -3.0, "actor_entropy": 0.8480678796768188, "alpha_loss": -1.8249856233596802, "alpha_value": 2.744560477663168, "duration": 1.5040390491485596, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1467500}
{"episode_reward": 0.0, "episode": 14676.0, "batch_reward": 6.742009162902832, "critic_loss": 12923.1259765625, "actor_loss": -3697.685791015625, "actor_target_entropy": -3.0, "actor_entropy": 0.892897367477417, "alpha_loss": -0.6951772570610046, "alpha_value": 2.7742136350669386, "duration": 1.5455152988433838, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1468000}
{"episode_reward": 0.0, "episode": 14681.0, "batch_reward": 6.8226776123046875, "critic_loss": 42205.0703125, "actor_loss": -3714.97314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.8791890144348145, "alpha_loss": -0.6765005588531494, "alpha_value": 2.7968241410022077, "duration": 1.5783724784851074, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1468500}
{"episode_reward": 0.0, "episode": 14686.0, "batch_reward": 6.7255859375, "critic_loss": 11873.4345703125, "actor_loss": -3643.019287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.0064949989318848, "alpha_loss": -0.4736926555633545, "alpha_value": 2.825434999188339, "duration": 1.470698595046997, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1469000}
{"episode_reward": 0.0, "episode": 14691.0, "batch_reward": 6.033968925476074, "critic_loss": 8646.54296875, "actor_loss": -4117.0166015625, "actor_target_entropy": -3.0, "actor_entropy": 0.604170560836792, "alpha_loss": -0.8210946321487427, "alpha_value": 2.845126550142929, "duration": 1.5890038013458252, "info_normalized_performance_mean": 0.11562251299619675, "info_normalized_performance_final": 0.1459999978542328, "info_performance_mean": 0.11562251299619675, "info_performance_final": 0.1459999978542328, "step": 1469500}
{"episode_reward": 231.2449999999996, "episode": 14696.0, "batch_reward": 6.63142728805542, "critic_loss": 18986.474609375, "actor_loss": -3957.987060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.201979637145996, "alpha_loss": 0.029542624950408936, "alpha_value": 2.8824861941726865, "step": 1470000}
{"duration": 19.41565489768982, "info_normalized_performance_mean": 0.041128478944301605, "info_normalized_performance_final": 0.0538194440305233, "info_performance_mean": 0.041128478944301605, "info_performance_final": 0.0538194440305233, "step": 1470000}
{"episode_reward": 82.25694444444431, "episode": 14701.0, "batch_reward": 6.778595924377441, "critic_loss": 6517.2705078125, "actor_loss": -3950.93115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5277420878410339, "alpha_loss": -0.7142369151115417, "alpha_value": 2.8948445859045924, "duration": 1.56734299659729, "info_normalized_performance_mean": 3.0864198379276786e-06, "info_normalized_performance_final": 0.0, "info_performance_mean": 3.0864198379276786e-06, "info_performance_final": 0.0, "step": 1470500}
{"episode_reward": 0.006172839506172839, "episode": 14706.0, "batch_reward": 6.062617301940918, "critic_loss": 12641.47265625, "actor_loss": -4155.8037109375, "actor_target_entropy": -3.0, "actor_entropy": 0.8269585967063904, "alpha_loss": -1.5218091011047363, "alpha_value": 2.915862543527053, "duration": 1.531172275543213, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1471000}
{"episode_reward": 0.0, "episode": 14711.0, "batch_reward": 6.797937393188477, "critic_loss": 41550.171875, "actor_loss": -4055.29248046875, "actor_target_entropy": -3.0, "actor_entropy": 0.5553840398788452, "alpha_loss": 1.3232927322387695, "alpha_value": 2.9470709392740044, "duration": 1.609703540802002, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1471500}
{"episode_reward": 0.0, "episode": 14716.0, "batch_reward": 5.677411079406738, "critic_loss": 7420.8330078125, "actor_loss": -3786.5615234375, "actor_target_entropy": -3.0, "actor_entropy": 0.7354696989059448, "alpha_loss": 0.835707426071167, "alpha_value": 2.97731145105685, "duration": 1.527162790298462, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1472000}
{"episode_reward": 0.0, "episode": 14721.0, "batch_reward": 6.057858467102051, "critic_loss": 5158.443359375, "actor_loss": -3902.961669921875, "actor_target_entropy": -3.0, "actor_entropy": 1.0333209037780762, "alpha_loss": 0.3816099464893341, "alpha_value": 3.0003400539065748, "duration": 1.5047976970672607, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1472500}
{"episode_reward": 0.0, "episode": 14726.0, "batch_reward": 6.908767223358154, "critic_loss": 7436.322265625, "actor_loss": -3807.983154296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8156254291534424, "alpha_loss": 0.21551722288131714, "alpha_value": 3.0230441397975074, "duration": 1.471898078918457, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1473000}
{"episode_reward": 0.0, "episode": 14731.0, "batch_reward": 5.320882797241211, "critic_loss": 6944.59375, "actor_loss": -3678.103759765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8008464574813843, "alpha_loss": 0.07642710208892822, "alpha_value": 3.0164468490124134, "duration": 1.513709545135498, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1473500}
{"episode_reward": 0.0, "episode": 14736.0, "batch_reward": 5.412606716156006, "critic_loss": 11810.3955078125, "actor_loss": -3903.991943359375, "actor_target_entropy": -3.0, "actor_entropy": 0.674627423286438, "alpha_loss": 0.10660623013973236, "alpha_value": 2.9939909271457243, "duration": 1.4874951839447021, "info_normalized_performance_mean": 0.00270408159121871, "info_normalized_performance_final": 0.005102040711790323, "info_performance_mean": 0.00270408159121871, "info_performance_final": 0.005102040711790323, "step": 1474000}
{"episode_reward": 5.408163265306118, "episode": 14741.0, "batch_reward": 6.218138694763184, "critic_loss": 17468.83984375, "actor_loss": -4016.925048828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7115134000778198, "alpha_loss": 1.2296538352966309, "alpha_value": 2.9704294447614474, "duration": 1.4878017902374268, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1474500}
{"episode_reward": 0.0, "episode": 14746.0, "batch_reward": 5.763283729553223, "critic_loss": 8378.833984375, "actor_loss": -3709.1494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8864611387252808, "alpha_loss": 0.702864408493042, "alpha_value": 2.928326380569674, "duration": 1.509141445159912, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1475000}
{"episode_reward": 0.0, "episode": 14751.0, "batch_reward": 6.094677925109863, "critic_loss": 11540.681640625, "actor_loss": -3793.434814453125, "actor_target_entropy": -3.0, "actor_entropy": 0.7164662480354309, "alpha_loss": 0.7369110584259033, "alpha_value": 2.8866501042795556, "duration": 1.4920401573181152, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1475500}
{"episode_reward": 0.0, "episode": 14756.0, "batch_reward": 5.351626396179199, "critic_loss": 9339.76953125, "actor_loss": -3899.01171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7226800918579102, "alpha_loss": 0.42195916175842285, "alpha_value": 2.8178680323094043, "duration": 1.5090670585632324, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1476000}
{"episode_reward": 0.0, "episode": 14761.0, "batch_reward": 6.578510761260986, "critic_loss": 11501.5546875, "actor_loss": -3628.758544921875, "actor_target_entropy": -3.0, "actor_entropy": 0.9997127652168274, "alpha_loss": 0.8755993247032166, "alpha_value": 2.775855824154456, "duration": 1.5220863819122314, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1476500}
{"episode_reward": 0.0, "episode": 14766.0, "batch_reward": 5.927532196044922, "critic_loss": 4932.78076171875, "actor_loss": -3626.22607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9380092024803162, "alpha_loss": -0.5850070714950562, "alpha_value": 2.7332793880187483, "duration": 1.458954095840454, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1477000}
{"episode_reward": 0.0, "episode": 14771.0, "batch_reward": 6.204845428466797, "critic_loss": 8154.765625, "actor_loss": -3781.70458984375, "actor_target_entropy": -3.0, "actor_entropy": 0.6032491326332092, "alpha_loss": -0.6815891861915588, "alpha_value": 2.7038465644516427, "duration": 1.4544281959533691, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1477500}
{"episode_reward": 0.0, "episode": 14776.0, "batch_reward": 5.128574848175049, "critic_loss": 6509.93212890625, "actor_loss": -3640.38330078125, "actor_target_entropy": -3.0, "actor_entropy": 0.7130641341209412, "alpha_loss": -0.36278441548347473, "alpha_value": 2.6704139760371, "duration": 1.7657740116119385, "info_normalized_performance_mean": 0.16446885466575623, "info_normalized_performance_final": 0.18894994258880615, "info_performance_mean": 0.16446885466575623, "info_performance_final": 0.18894994258880615, "step": 1478000}
{"episode_reward": 328.93772893772865, "episode": 14781.0, "batch_reward": 6.4303789138793945, "critic_loss": 6250.8447265625, "actor_loss": -3615.716064453125, "actor_target_entropy": -3.0, "actor_entropy": 0.9786058664321899, "alpha_loss": 0.2901213765144348, "alpha_value": 2.640402294225961, "duration": 1.538142442703247, "info_normalized_performance_mean": 0.0008000001544132829, "info_normalized_performance_final": 0.004166666883975267, "info_performance_mean": 0.0008000001544132829, "info_performance_final": 0.004166666883975267, "step": 1478500}
{"episode_reward": 1.5999999999999996, "episode": 14786.0, "batch_reward": 7.134230136871338, "critic_loss": 9594.498046875, "actor_loss": -3640.9375, "actor_target_entropy": -3.0, "actor_entropy": 0.8752462863922119, "alpha_loss": 1.2851788997650146, "alpha_value": 2.6163527495507233, "duration": 1.5037074089050293, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1479000}
{"episode_reward": 0.0, "episode": 14791.0, "batch_reward": 5.850581645965576, "critic_loss": 8749.4755859375, "actor_loss": -3555.6103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1255202293395996, "alpha_loss": -0.6151408553123474, "alpha_value": 2.599445359501272, "duration": 1.474740743637085, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1479500}
{"episode_reward": 0.0, "episode": 14796.0, "batch_reward": 5.317403316497803, "critic_loss": 8813.1533203125, "actor_loss": -3627.90283203125, "actor_target_entropy": -3.0, "actor_entropy": 0.9263085126876831, "alpha_loss": -0.20303477346897125, "alpha_value": 2.625846341539572, "step": 1480000}
{"duration": 19.05851459503174, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1480000}
{"episode_reward": 0.0, "episode": 14801.0, "batch_reward": 5.111570835113525, "critic_loss": 11443.8779296875, "actor_loss": -3550.318115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.5581666231155396, "alpha_loss": -1.381664514541626, "alpha_value": 2.6570648375268564, "duration": 1.4867017269134521, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1480500}
{"episode_reward": 0.0, "episode": 14806.0, "batch_reward": 5.3201470375061035, "critic_loss": 7063.94970703125, "actor_loss": -4083.663818359375, "actor_target_entropy": -3.0, "actor_entropy": 0.8606745004653931, "alpha_loss": -0.20248943567276, "alpha_value": 2.703403679303297, "duration": 1.5256812572479248, "info_normalized_performance_mean": 0.26605501770973206, "info_normalized_performance_final": 0.31986531615257263, "info_performance_mean": 0.26605501770973206, "info_performance_final": 0.31986531615257263, "step": 1481000}
{"episode_reward": 532.109988776656, "episode": 14811.0, "batch_reward": 5.687528133392334, "critic_loss": 5670.5517578125, "actor_loss": -3581.03857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.2737467288970947, "alpha_loss": -0.8313294053077698, "alpha_value": 2.765091181010288, "duration": 1.6393938064575195, "info_normalized_performance_mean": 0.21938705444335938, "info_normalized_performance_final": 0.277548223733902, "info_performance_mean": 0.21938705444335938, "info_performance_final": 0.277548223733902, "step": 1481500}
{"episode_reward": 438.7741046831964, "episode": 14816.0, "batch_reward": 5.663722038269043, "critic_loss": 7069.5322265625, "actor_loss": -3487.498779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.0726689100265503, "alpha_loss": -0.913871169090271, "alpha_value": 2.8455722537490074, "duration": 1.4635701179504395, "info_normalized_performance_mean": 0.2295454442501068, "info_normalized_performance_final": 0.2646103799343109, "info_performance_mean": 0.2295454442501068, "info_performance_final": 0.2646103799343109, "step": 1482000}
{"episode_reward": 459.09090909091003, "episode": 14821.0, "batch_reward": 5.7274580001831055, "critic_loss": 10102.185546875, "actor_loss": -3797.266845703125, "actor_target_entropy": -3.0, "actor_entropy": 0.5664441585540771, "alpha_loss": -2.8582258224487305, "alpha_value": 2.940908577426578, "duration": 1.400033950805664, "info_normalized_performance_mean": 0.38256704807281494, "info_normalized_performance_final": 0.4151785671710968, "info_performance_mean": 0.38256704807281494, "info_performance_final": 0.4151785671710968, "step": 1482500}
{"episode_reward": 765.1339285714294, "episode": 14826.0, "batch_reward": 5.106168746948242, "critic_loss": 8837.064453125, "actor_loss": -3843.698974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2315119504928589, "alpha_loss": 0.4535655677318573, "alpha_value": 3.010804440692056, "duration": 1.4594435691833496, "info_normalized_performance_mean": 0.18036751449108124, "info_normalized_performance_final": 0.1933221071958542, "info_performance_mean": 0.18036751449108124, "info_performance_final": 0.1933221071958542, "step": 1483000}
{"episode_reward": 360.7351290684616, "episode": 14831.0, "batch_reward": 5.189770698547363, "critic_loss": 7057.2080078125, "actor_loss": -3647.137939453125, "actor_target_entropy": -3.0, "actor_entropy": 1.305750846862793, "alpha_loss": -1.5576064586639404, "alpha_value": 3.061850493064199, "duration": 1.5448434352874756, "info_normalized_performance_mean": 0.12402715533971786, "info_normalized_performance_final": 0.17466063797473907, "info_performance_mean": 0.12402715533971786, "info_performance_final": 0.17466063797473907, "step": 1483500}
{"episode_reward": 248.05429864253404, "episode": 14836.0, "batch_reward": 6.210271835327148, "critic_loss": 17234.861328125, "actor_loss": -3814.740478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.101288080215454, "alpha_loss": -1.2774089574813843, "alpha_value": 3.095995283124922, "duration": 1.6235742568969727, "info_normalized_performance_mean": 0.16699327528476715, "info_normalized_performance_final": 0.18879730999469757, "info_performance_mean": 0.16699327528476715, "info_performance_final": 0.18879730999469757, "step": 1484000}
{"episode_reward": 333.98656898656924, "episode": 14841.0, "batch_reward": 3.8722424507141113, "critic_loss": 8287.57421875, "actor_loss": -3625.834716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.1712143421173096, "alpha_loss": -1.6777598857879639, "alpha_value": 3.1302741602429194, "duration": 1.551659107208252, "info_normalized_performance_mean": 0.22562751173973083, "info_normalized_performance_final": 0.2630000114440918, "info_performance_mean": 0.22562751173973083, "info_performance_final": 0.2630000114440918, "step": 1484500}
{"episode_reward": 451.2549999999999, "episode": 14846.0, "batch_reward": 5.5764665603637695, "critic_loss": 7355.28564453125, "actor_loss": -3636.10107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.49467134475708, "alpha_loss": -1.021674633026123, "alpha_value": 3.1376716020606668, "duration": 1.5152320861816406, "info_normalized_performance_mean": 0.0688960924744606, "info_normalized_performance_final": 0.08766233921051025, "info_performance_mean": 0.0688960924744606, "info_performance_final": 0.08766233921051025, "step": 1485000}
{"episode_reward": 137.79220779220762, "episode": 14851.0, "batch_reward": 5.890795707702637, "critic_loss": 8666.27734375, "actor_loss": -3725.39892578125, "actor_target_entropy": -3.0, "actor_entropy": 1.0476915836334229, "alpha_loss": 1.3305413722991943, "alpha_value": 3.152397393315552, "duration": 1.4914774894714355, "info_normalized_performance_mean": 0.08841518312692642, "info_normalized_performance_final": 0.09687499701976776, "info_performance_mean": 0.08841518312692642, "info_performance_final": 0.09687499701976776, "step": 1485500}
{"episode_reward": 176.83035714285714, "episode": 14856.0, "batch_reward": 4.928661346435547, "critic_loss": 9973.24609375, "actor_loss": -3707.7578125, "actor_target_entropy": -3.0, "actor_entropy": 1.0586895942687988, "alpha_loss": 1.7765915393829346, "alpha_value": 3.133961912235269, "duration": 1.6668460369110107, "info_normalized_performance_mean": 0.40443962812423706, "info_normalized_performance_final": 0.46666666865348816, "info_performance_mean": 0.40443962812423706, "info_performance_final": 0.46666666865348816, "step": 1486000}
{"episode_reward": 808.8791666666677, "episode": 14861.0, "batch_reward": 5.258586883544922, "critic_loss": 7054.7724609375, "actor_loss": -3532.77490234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1724101305007935, "alpha_loss": 0.5927417278289795, "alpha_value": 3.095354062089956, "duration": 1.4726459980010986, "info_normalized_performance_mean": 0.4089062511920929, "info_normalized_performance_final": 0.44921875, "info_performance_mean": 0.4089062511920929, "info_performance_final": 0.44921875, "step": 1486500}
{"episode_reward": 817.8125, "episode": 14866.0, "batch_reward": 6.143784523010254, "critic_loss": 8609.4970703125, "actor_loss": -3666.20556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.378096580505371, "alpha_loss": 1.7068827152252197, "alpha_value": 3.0496493330936865, "duration": 1.601571798324585, "info_normalized_performance_mean": 0.00017195766849908978, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.00017195766849908978, "info_performance_final": 0.0, "step": 1487000}
{"episode_reward": 0.3439153439153439, "episode": 14871.0, "batch_reward": 4.396405220031738, "critic_loss": 8142.4853515625, "actor_loss": -3590.685791015625, "actor_target_entropy": -3.0, "actor_entropy": 0.769739031791687, "alpha_loss": 0.9824239611625671, "alpha_value": 2.9875492780714867, "duration": 1.5737147331237793, "info_normalized_performance_mean": 0.040617652237415314, "info_normalized_performance_final": 0.136274516582489, "info_performance_mean": 0.040617652237415314, "info_performance_final": 0.136274516582489, "step": 1487500}
{"episode_reward": 81.23529411764703, "episode": 14876.0, "batch_reward": 4.598974227905273, "critic_loss": 7131.755859375, "actor_loss": -3552.89453125, "actor_target_entropy": -3.0, "actor_entropy": 0.930294394493103, "alpha_loss": 0.20447030663490295, "alpha_value": 2.919934395456818, "duration": 1.448509931564331, "info_normalized_performance_mean": 0.352191686630249, "info_normalized_performance_final": 0.4224664270877838, "info_performance_mean": 0.352191686630249, "info_performance_final": 0.4224664270877838, "step": 1488000}
{"episode_reward": 704.3833943833956, "episode": 14881.0, "batch_reward": 5.648310661315918, "critic_loss": 8406.994140625, "actor_loss": -3540.767578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6679023504257202, "alpha_loss": -0.1527026742696762, "alpha_value": 2.866100328027344, "duration": 1.6158881187438965, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1488500}
{"episode_reward": 0.0, "episode": 14886.0, "batch_reward": 4.370161533355713, "critic_loss": 8235.8544921875, "actor_loss": -3572.30859375, "actor_target_entropy": -3.0, "actor_entropy": 0.7578144073486328, "alpha_loss": 0.5237365365028381, "alpha_value": 2.8097220082116667, "duration": 1.4707858562469482, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1489000}
{"episode_reward": 0.0, "episode": 14891.0, "batch_reward": 4.6988844871521, "critic_loss": 5577.68896484375, "actor_loss": -3312.50341796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8113860487937927, "alpha_loss": 1.7803107500076294, "alpha_value": 2.755712161561204, "duration": 1.647587776184082, "info_normalized_performance_mean": 0.00028675468638539314, "info_normalized_performance_final": 0.00034137460170313716, "info_performance_mean": 0.00028675468638539314, "info_performance_final": 0.00034137460170313716, "step": 1489500}
{"episode_reward": 0.5735093309057818, "episode": 14896.0, "batch_reward": 4.433623313903809, "critic_loss": 11466.802734375, "actor_loss": -3225.65234375, "actor_target_entropy": -3.0, "actor_entropy": 0.9954752326011658, "alpha_loss": 0.9659391641616821, "alpha_value": 2.7129265698410423, "step": 1490000}
{"duration": 18.77485942840576, "info_normalized_performance_mean": 0.4367721676826477, "info_normalized_performance_final": 0.5781893134117126, "info_performance_mean": 0.4367721676826477, "info_performance_final": 0.5781893134117126, "step": 1490000}
{"episode_reward": 873.5442386831263, "episode": 14901.0, "batch_reward": 3.8813631534576416, "critic_loss": 6458.72607421875, "actor_loss": -3435.753662109375, "actor_target_entropy": -3.0, "actor_entropy": 0.6780604124069214, "alpha_loss": 0.7541634440422058, "alpha_value": 2.6690961513700433, "duration": 1.5450019836425781, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1490500}
{"episode_reward": 0.0, "episode": 14906.0, "batch_reward": 4.25831413269043, "critic_loss": 4813.9208984375, "actor_loss": -3192.10888671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8973016738891602, "alpha_loss": 0.5057801008224487, "alpha_value": 2.617678058736684, "duration": 1.5303971767425537, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1491000}
{"episode_reward": 0.0, "episode": 14911.0, "batch_reward": 4.036459922790527, "critic_loss": 5508.62451171875, "actor_loss": -3450.872314453125, "actor_target_entropy": -3.0, "actor_entropy": 0.21307805180549622, "alpha_loss": -0.16921007633209229, "alpha_value": 2.5629658506808837, "duration": 1.529200553894043, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1491500}
{"episode_reward": 0.0, "episode": 14916.0, "batch_reward": 4.360703945159912, "critic_loss": 5754.162109375, "actor_loss": -3415.41259765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8647010326385498, "alpha_loss": -0.09649835526943207, "alpha_value": 2.5251546189801797, "duration": 1.5043940544128418, "info_normalized_performance_mean": 0.043592311441898346, "info_normalized_performance_final": 0.05019230768084526, "info_performance_mean": 0.043592311441898346, "info_performance_final": 0.05019230768084526, "step": 1492000}
{"episode_reward": 87.18461538461544, "episode": 14921.0, "batch_reward": 4.03302526473999, "critic_loss": 13869.328125, "actor_loss": -3462.91845703125, "actor_target_entropy": -3.0, "actor_entropy": 0.2576919198036194, "alpha_loss": -0.1546230912208557, "alpha_value": 2.4965256705440493, "duration": 1.5687015056610107, "info_normalized_performance_mean": 0.13349539041519165, "info_normalized_performance_final": 0.14351852238178253, "info_performance_mean": 0.13349539041519165, "info_performance_final": 0.14351852238178253, "step": 1492500}
{"episode_reward": 266.9907407407411, "episode": 14926.0, "batch_reward": 4.530728340148926, "critic_loss": 4579.8876953125, "actor_loss": -3334.7890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6220992803573608, "alpha_loss": -0.30875393748283386, "alpha_value": 2.457906102971514, "duration": 1.5587568283081055, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1493000}
{"episode_reward": 0.0, "episode": 14931.0, "batch_reward": 4.86256217956543, "critic_loss": 8148.19921875, "actor_loss": -3207.65673828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8063617944717407, "alpha_loss": 0.17723152041435242, "alpha_value": 2.4256896468339337, "duration": 1.578869342803955, "info_normalized_performance_mean": 0.053888894617557526, "info_normalized_performance_final": 0.06181318685412407, "info_performance_mean": 0.053888894617557526, "info_performance_final": 0.06181318685412407, "step": 1493500}
{"episode_reward": 107.77777777777784, "episode": 14936.0, "batch_reward": 4.3287200927734375, "critic_loss": 7454.81298828125, "actor_loss": -3109.07763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1316337585449219, "alpha_loss": 1.2517330646514893, "alpha_value": 2.3889599278263987, "duration": 1.6447532176971436, "info_normalized_performance_mean": 0.023301100358366966, "info_normalized_performance_final": 0.060659341514110565, "info_performance_mean": 0.023301100358366966, "info_performance_final": 0.060659341514110565, "step": 1494000}
{"episode_reward": 46.60219780219782, "episode": 14941.0, "batch_reward": 4.965545177459717, "critic_loss": 6997.35302734375, "actor_loss": -3239.92236328125, "actor_target_entropy": -3.0, "actor_entropy": 0.7957916855812073, "alpha_loss": 1.1098387241363525, "alpha_value": 2.350039862977564, "duration": 1.4165520668029785, "info_normalized_performance_mean": 0.10654380917549133, "info_normalized_performance_final": 0.11698717623949051, "info_performance_mean": 0.10654380917549133, "info_performance_final": 0.11698717623949051, "step": 1494500}
{"episode_reward": 213.08760683760696, "episode": 14946.0, "batch_reward": 3.238588809967041, "critic_loss": 9482.4716796875, "actor_loss": -3145.720458984375, "actor_target_entropy": -3.0, "actor_entropy": 0.6356019377708435, "alpha_loss": 0.11023563146591187, "alpha_value": 2.316559831023509, "duration": 1.4901511669158936, "info_normalized_performance_mean": 0.42842185497283936, "info_normalized_performance_final": 0.520312488079071, "info_performance_mean": 0.42842185497283936, "info_performance_final": 0.520312488079071, "step": 1495000}
{"episode_reward": 856.84375, "episode": 14951.0, "batch_reward": 4.052822113037109, "critic_loss": 5916.9990234375, "actor_loss": -3009.360107421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9182249307632446, "alpha_loss": 0.40145692229270935, "alpha_value": 2.286863756076877, "duration": 1.4380390644073486, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1495500}
{"episode_reward": 0.0, "episode": 14956.0, "batch_reward": 3.4778528213500977, "critic_loss": 6062.798828125, "actor_loss": -3146.36767578125, "actor_target_entropy": -3.0, "actor_entropy": 0.6545723676681519, "alpha_loss": 0.6411763429641724, "alpha_value": 2.2614038124919396, "duration": 1.5540626049041748, "info_normalized_performance_mean": 0.24052944779396057, "info_normalized_performance_final": 0.27882352471351624, "info_performance_mean": 0.24052944779396057, "info_performance_final": 0.27882352471351624, "step": 1496000}
{"episode_reward": 481.058823529411, "episode": 14961.0, "batch_reward": 4.277388572692871, "critic_loss": 4501.32666015625, "actor_loss": -3151.77197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.9531095027923584, "alpha_loss": 0.7744307518005371, "alpha_value": 2.2537493656532406, "duration": 1.499882698059082, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1496500}
{"episode_reward": 0.0, "episode": 14966.0, "batch_reward": 4.845789909362793, "critic_loss": 6246.216796875, "actor_loss": -3184.2841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.6151242852210999, "alpha_loss": 0.02685868740081787, "alpha_value": 2.25550820061575, "duration": 1.4362366199493408, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1497000}
{"episode_reward": 0.0, "episode": 14971.0, "batch_reward": 3.595952033996582, "critic_loss": 6079.1435546875, "actor_loss": -3164.0986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.5838426947593689, "alpha_loss": -0.4202331304550171, "alpha_value": 2.2672905531898135, "duration": 1.4146509170532227, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1497500}
{"episode_reward": 0.0, "episode": 14976.0, "batch_reward": 4.756505966186523, "critic_loss": 13192.33203125, "actor_loss": -3063.66552734375, "actor_target_entropy": -3.0, "actor_entropy": 0.9139037132263184, "alpha_loss": 0.22215238213539124, "alpha_value": 2.2690826482489115, "duration": 1.5683574676513672, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1498000}
{"episode_reward": 0.0, "episode": 14981.0, "batch_reward": 4.247354984283447, "critic_loss": 7144.09521484375, "actor_loss": -3109.433837890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6049123406410217, "alpha_loss": -0.5149531960487366, "alpha_value": 2.2441731953580955, "duration": 1.5503184795379639, "info_normalized_performance_mean": 0.3952163755893707, "info_normalized_performance_final": 0.43629807233810425, "info_performance_mean": 0.3952163755893707, "info_performance_final": 0.43629807233810425, "step": 1498500}
{"episode_reward": 790.4326923076928, "episode": 14986.0, "batch_reward": 3.4995522499084473, "critic_loss": 6043.7197265625, "actor_loss": -2970.65966796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8882986903190613, "alpha_loss": -0.5438194274902344, "alpha_value": 2.2543272617275214, "duration": 1.5346736907958984, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1499000}
{"episode_reward": 0.0, "episode": 14991.0, "batch_reward": 4.366985321044922, "critic_loss": 4957.916015625, "actor_loss": -2985.22216796875, "actor_target_entropy": -3.0, "actor_entropy": 1.2805454730987549, "alpha_loss": 0.6738471984863281, "alpha_value": 2.265105020952141, "duration": 1.516221523284912, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1499500}
{"episode_reward": 0.0, "episode": 14996.0, "batch_reward": 3.446312427520752, "critic_loss": 6241.5302734375, "actor_loss": -3171.0439453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6840262413024902, "alpha_loss": -0.6374844312667847, "alpha_value": 2.2873781115108374, "step": 1500000}
{"duration": 18.12569761276245, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1500000}
{"episode_reward": 0.0, "episode": 15001.0, "batch_reward": 3.181058883666992, "critic_loss": 4918.25390625, "actor_loss": -3183.27294921875, "actor_target_entropy": -3.0, "actor_entropy": 0.19137370586395264, "alpha_loss": -1.7418583631515503, "alpha_value": 2.311433575553056, "duration": 1.440929651260376, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1500500}
{"episode_reward": 0.0, "episode": 15006.0, "batch_reward": 4.089696884155273, "critic_loss": 4811.1201171875, "actor_loss": -3011.77001953125, "actor_target_entropy": -3.0, "actor_entropy": 0.593830943107605, "alpha_loss": -0.462530255317688, "alpha_value": 2.3071629878471245, "duration": 1.4531490802764893, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1501000}
{"episode_reward": 0.0, "episode": 15011.0, "batch_reward": 4.1222453117370605, "critic_loss": 3198.407958984375, "actor_loss": -2936.36279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.1854956150054932, "alpha_loss": 0.7716576457023621, "alpha_value": 2.3043623896890972, "duration": 1.4252264499664307, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1501500}
{"episode_reward": 0.0, "episode": 15016.0, "batch_reward": 3.4111385345458984, "critic_loss": 6018.12548828125, "actor_loss": -2930.2373046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9457951188087463, "alpha_loss": -0.3294633626937866, "alpha_value": 2.315187180903974, "duration": 1.4270267486572266, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1502000}
{"episode_reward": 0.0, "episode": 15021.0, "batch_reward": 4.408439636230469, "critic_loss": 4276.64208984375, "actor_loss": -2863.472412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9946646094322205, "alpha_loss": 0.6031897664070129, "alpha_value": 2.326780058838895, "duration": 1.5212035179138184, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1502500}
{"episode_reward": 0.0, "episode": 15026.0, "batch_reward": 2.694939613342285, "critic_loss": 5369.396484375, "actor_loss": -2942.6455078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2434417009353638, "alpha_loss": 0.4004437327384949, "alpha_value": 2.328868413336382, "duration": 1.3720817565917969, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1503000}
{"episode_reward": 0.0, "episode": 15031.0, "batch_reward": 3.482616901397705, "critic_loss": 4737.9462890625, "actor_loss": -2999.78125, "actor_target_entropy": -3.0, "actor_entropy": 0.9116071462631226, "alpha_loss": 0.30759239196777344, "alpha_value": 2.339191853348584, "duration": 1.5360333919525146, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1503500}
{"episode_reward": 0.0, "episode": 15036.0, "batch_reward": 3.2456421852111816, "critic_loss": 5886.2412109375, "actor_loss": -2896.6767578125, "actor_target_entropy": -3.0, "actor_entropy": 0.9658151865005493, "alpha_loss": 0.690223217010498, "alpha_value": 2.33193063253891, "duration": 1.511551856994629, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1504000}
{"episode_reward": 0.0, "episode": 15041.0, "batch_reward": 3.433224678039551, "critic_loss": 4012.323974609375, "actor_loss": -2901.043212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.225403070449829, "alpha_loss": 0.7832430601119995, "alpha_value": 2.333087349076046, "duration": 1.5658693313598633, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1504500}
{"episode_reward": 0.0, "episode": 15046.0, "batch_reward": 3.19642972946167, "critic_loss": 8388.0302734375, "actor_loss": -2709.24560546875, "actor_target_entropy": -3.0, "actor_entropy": 0.967547595500946, "alpha_loss": 0.2670947015285492, "alpha_value": 2.3235458537791245, "duration": 1.484144926071167, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1505000}
{"episode_reward": 0.0, "episode": 15051.0, "batch_reward": 4.3104095458984375, "critic_loss": 3228.50341796875, "actor_loss": -2844.01123046875, "actor_target_entropy": -3.0, "actor_entropy": 0.9412931799888611, "alpha_loss": -0.09464061260223389, "alpha_value": 2.2975076560136767, "duration": 1.4859614372253418, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1505500}
{"episode_reward": 0.0, "episode": 15056.0, "batch_reward": 2.6340854167938232, "critic_loss": 11092.7060546875, "actor_loss": -2921.48974609375, "actor_target_entropy": -3.0, "actor_entropy": 0.29864615201950073, "alpha_loss": -0.634117841720581, "alpha_value": 2.2930841482127047, "duration": 1.430039644241333, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1506000}
{"episode_reward": 0.0, "episode": 15061.0, "batch_reward": 2.866956949234009, "critic_loss": 6081.7333984375, "actor_loss": -2725.66748046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8370684385299683, "alpha_loss": 0.40815025568008423, "alpha_value": 2.297760899957643, "duration": 1.5021405220031738, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1506500}
{"episode_reward": 0.0, "episode": 15066.0, "batch_reward": 3.183773994445801, "critic_loss": 12046.451171875, "actor_loss": -3033.16064453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6614717245101929, "alpha_loss": -0.0479293167591095, "alpha_value": 2.2915745162273575, "duration": 1.4700512886047363, "info_normalized_performance_mean": 0.03697115555405617, "info_normalized_performance_final": 0.06009615212678909, "info_performance_mean": 0.03697115555405617, "info_performance_final": 0.06009615212678909, "step": 1507000}
{"episode_reward": 73.94230769230779, "episode": 15071.0, "batch_reward": 3.2833786010742188, "critic_loss": 6370.72119140625, "actor_loss": -2876.64892578125, "actor_target_entropy": -3.0, "actor_entropy": 0.8906804919242859, "alpha_loss": 0.10578779876232147, "alpha_value": 2.311901028355154, "duration": 1.467209815979004, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1507500}
{"episode_reward": 0.0, "episode": 15076.0, "batch_reward": 3.028036117553711, "critic_loss": 6695.4970703125, "actor_loss": -2832.98681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1211220026016235, "alpha_loss": 0.3529728651046753, "alpha_value": 2.3337026267786425, "duration": 1.4683153629302979, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1508000}
{"episode_reward": 0.0, "episode": 15081.0, "batch_reward": 2.4372544288635254, "critic_loss": 8816.197265625, "actor_loss": -2900.442138671875, "actor_target_entropy": -3.0, "actor_entropy": 0.8086646795272827, "alpha_loss": -1.212891697883606, "alpha_value": 2.376928241911588, "duration": 1.5970423221588135, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1508500}
{"episode_reward": 0.0, "episode": 15086.0, "batch_reward": 2.510690212249756, "critic_loss": 6050.8115234375, "actor_loss": -2885.02978515625, "actor_target_entropy": -3.0, "actor_entropy": 0.8554803133010864, "alpha_loss": -0.863301157951355, "alpha_value": 2.433192864652315, "duration": 1.3740234375, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1509000}
{"episode_reward": 0.0, "episode": 15091.0, "batch_reward": 2.672471523284912, "critic_loss": 4036.323974609375, "actor_loss": -2980.700439453125, "actor_target_entropy": -3.0, "actor_entropy": 0.40271610021591187, "alpha_loss": -1.4774634838104248, "alpha_value": 2.5127103466321343, "duration": 1.4425926208496094, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1509500}
{"episode_reward": 0.0, "episode": 15096.0, "batch_reward": 2.735297918319702, "critic_loss": 4762.3291015625, "actor_loss": -2930.4912109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1698896884918213, "alpha_loss": -0.08711843192577362, "alpha_value": 2.5595666555264875, "step": 1510000}
{"duration": 17.857868909835815, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1510000}
{"episode_reward": 0.0, "episode": 15101.0, "batch_reward": 2.533088207244873, "critic_loss": 3396.10205078125, "actor_loss": -2881.19580078125, "actor_target_entropy": -3.0, "actor_entropy": 0.9458783864974976, "alpha_loss": -0.4856480658054352, "alpha_value": 2.5848048680303344, "duration": 1.454253911972046, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1510500}
{"episode_reward": 0.0, "episode": 15106.0, "batch_reward": 2.574941396713257, "critic_loss": 6323.6826171875, "actor_loss": -2844.0732421875, "actor_target_entropy": -3.0, "actor_entropy": 0.6174633502960205, "alpha_loss": -0.3128495216369629, "alpha_value": 2.6119288808247245, "duration": 1.4020044803619385, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1511000}
{"episode_reward": 0.0, "episode": 15111.0, "batch_reward": 2.6298813819885254, "critic_loss": 8891.55859375, "actor_loss": -2946.88330078125, "actor_target_entropy": -3.0, "actor_entropy": 0.6786823272705078, "alpha_loss": -0.44769713282585144, "alpha_value": 2.631154215156645, "duration": 1.4264297485351562, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1511500}
{"episode_reward": 0.0, "episode": 15116.0, "batch_reward": 2.950798988342285, "critic_loss": 4429.11328125, "actor_loss": -2847.26806640625, "actor_target_entropy": -3.0, "actor_entropy": 0.9286679029464722, "alpha_loss": 0.5268642902374268, "alpha_value": 2.645853162087068, "duration": 1.4099187850952148, "info_normalized_performance_mean": 0.07321429997682571, "info_normalized_performance_final": 0.0892857164144516, "info_performance_mean": 0.07321429997682571, "info_performance_final": 0.0892857164144516, "step": 1512000}
{"episode_reward": 146.42857142857153, "episode": 15121.0, "batch_reward": 2.718834161758423, "critic_loss": 5083.1474609375, "actor_loss": -2911.056640625, "actor_target_entropy": -3.0, "actor_entropy": 0.6734572052955627, "alpha_loss": -1.123738408088684, "alpha_value": 2.645077750348615, "duration": 1.501948356628418, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1512500}
{"episode_reward": 0.0, "episode": 15126.0, "batch_reward": 2.4676594734191895, "critic_loss": 4666.7021484375, "actor_loss": -2919.100830078125, "actor_target_entropy": -3.0, "actor_entropy": 0.921558678150177, "alpha_loss": 1.0314089059829712, "alpha_value": 2.649885173120662, "duration": 1.5259127616882324, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1513000}
{"episode_reward": 0.0, "episode": 15131.0, "batch_reward": 2.641536235809326, "critic_loss": 6752.33984375, "actor_loss": -2843.48779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.8695868253707886, "alpha_loss": 0.4729049801826477, "alpha_value": 2.617724207808658, "duration": 1.4925317764282227, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1513500}
{"episode_reward": 0.0, "episode": 15136.0, "batch_reward": 2.983428955078125, "critic_loss": 4289.001953125, "actor_loss": -2996.39453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0270752906799316, "alpha_loss": 0.8548388481140137, "alpha_value": 2.592995742247799, "duration": 1.4627165794372559, "info_normalized_performance_mean": 0.43662095069885254, "info_normalized_performance_final": 0.47664836049079895, "info_performance_mean": 0.43662095069885254, "info_performance_final": 0.47664836049079895, "step": 1514000}
{"episode_reward": 873.2417582417567, "episode": 15141.0, "batch_reward": 2.737154960632324, "critic_loss": 5569.74072265625, "actor_loss": -2877.736083984375, "actor_target_entropy": -3.0, "actor_entropy": 0.5542083978652954, "alpha_loss": -0.3080883026123047, "alpha_value": 2.5696291983208583, "duration": 1.43416428565979, "info_normalized_performance_mean": 0.754880964756012, "info_normalized_performance_final": 0.8035714030265808, "info_performance_mean": 0.754880964756012, "info_performance_final": 0.8035714030265808, "step": 1514500}
{"episode_reward": 1509.761904761907, "episode": 15146.0, "batch_reward": 2.409416675567627, "critic_loss": 3610.726806640625, "actor_loss": -2897.704833984375, "actor_target_entropy": -3.0, "actor_entropy": 0.8266811370849609, "alpha_loss": 0.37278223037719727, "alpha_value": 2.5528646410012494, "duration": 1.5227978229522705, "info_normalized_performance_mean": 0.6451623439788818, "info_normalized_performance_final": 0.725649356842041, "info_performance_mean": 0.6451623439788818, "info_performance_final": 0.725649356842041, "step": 1515000}
{"episode_reward": 1290.3246753246733, "episode": 15151.0, "batch_reward": 2.28318190574646, "critic_loss": 6352.763671875, "actor_loss": -2988.373779296875, "actor_target_entropy": -3.0, "actor_entropy": 0.6254451274871826, "alpha_loss": -0.21073469519615173, "alpha_value": 2.5378395131482994, "duration": 1.546189546585083, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1515500}
{"episode_reward": 0.0, "episode": 15156.0, "batch_reward": 1.6812496185302734, "critic_loss": 9382.708984375, "actor_loss": -3066.147216796875, "actor_target_entropy": -3.0, "actor_entropy": 0.24630507826805115, "alpha_loss": -0.5203422904014587, "alpha_value": 2.511560425502459, "duration": 1.5687808990478516, "info_normalized_performance_mean": 0.0471833311021328, "info_normalized_performance_final": 0.0533333346247673, "info_performance_mean": 0.0471833311021328, "info_performance_final": 0.0533333346247673, "step": 1516000}
{"episode_reward": 94.36666666666666, "episode": 15161.0, "batch_reward": 1.9235162734985352, "critic_loss": 5196.4462890625, "actor_loss": -2762.45166015625, "actor_target_entropy": -3.0, "actor_entropy": 0.6681843996047974, "alpha_loss": 0.4467260241508484, "alpha_value": 2.487031600931275, "duration": 1.5496792793273926, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1516500}
{"episode_reward": 0.0, "episode": 15166.0, "batch_reward": 1.9431676864624023, "critic_loss": 4556.25732421875, "actor_loss": -3002.68896484375, "actor_target_entropy": -3.0, "actor_entropy": 0.68531334400177, "alpha_loss": -0.19163915514945984, "alpha_value": 2.4615535992720274, "duration": 1.4529178142547607, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1517000}
{"episode_reward": 0.0, "episode": 15171.0, "batch_reward": 2.7605600357055664, "critic_loss": 12167.01171875, "actor_loss": -2883.237060546875, "actor_target_entropy": -3.0, "actor_entropy": 0.562848687171936, "alpha_loss": -0.6403236985206604, "alpha_value": 2.4514456704061054, "duration": 1.3991045951843262, "info_normalized_performance_mean": 0.007352605927735567, "info_normalized_performance_final": 0.008503401651978493, "info_performance_mean": 0.007352605927735567, "info_performance_final": 0.008503401651978493, "step": 1517500}
{"episode_reward": 14.705215419501158, "episode": 15176.0, "batch_reward": 1.6916649341583252, "critic_loss": 4205.09716796875, "actor_loss": -2731.97607421875, "actor_target_entropy": -3.0, "actor_entropy": 0.7254581451416016, "alpha_loss": 0.25052884221076965, "alpha_value": 2.4238462321524983, "duration": 1.6397366523742676, "info_normalized_performance_mean": 1.322751268162392e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 1.322751268162392e-05, "info_performance_final": 0.0, "step": 1518000}
{"episode_reward": 0.026455026455026454, "episode": 15181.0, "batch_reward": 1.496678352355957, "critic_loss": 10079.91796875, "actor_loss": -2946.09423828125, "actor_target_entropy": -3.0, "actor_entropy": 0.33090031147003174, "alpha_loss": -0.9817737340927124, "alpha_value": 2.3836390588273635, "duration": 1.380394458770752, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1518500}
{"episode_reward": 0.0, "episode": 15186.0, "batch_reward": 1.773049235343933, "critic_loss": 3890.226318359375, "actor_loss": -2845.53564453125, "actor_target_entropy": -3.0, "actor_entropy": 0.49795007705688477, "alpha_loss": 0.19245372712612152, "alpha_value": 2.3432730893113276, "duration": 1.4580919742584229, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1519000}
{"episode_reward": 0.0, "episode": 15191.0, "batch_reward": 2.042865037918091, "critic_loss": 5953.3583984375, "actor_loss": -2652.90234375, "actor_target_entropy": -3.0, "actor_entropy": 0.7974681854248047, "alpha_loss": 0.3829653859138489, "alpha_value": 2.338568659815853, "duration": 1.4273650646209717, "info_normalized_performance_mean": 7.964954420458525e-06, "info_normalized_performance_final": 0.0, "info_performance_mean": 7.964954420458525e-06, "info_performance_final": 0.0, "step": 1519500}
{"episode_reward": 0.01592990840302668, "episode": 15196.0, "batch_reward": 1.2216546535491943, "critic_loss": 5361.7275390625, "actor_loss": -2803.65625, "actor_target_entropy": -3.0, "actor_entropy": 0.16810326278209686, "alpha_loss": 0.3666069507598877, "alpha_value": 2.329520349291872, "step": 1520000}
{"duration": 18.407492876052856, "info_normalized_performance_mean": 1.9531249563442543e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 1.9531249563442543e-05, "info_performance_final": 0.0, "step": 1520000}
{"episode_reward": 0.0390625, "episode": 15201.0, "batch_reward": 2.149376392364502, "critic_loss": 10906.3203125, "actor_loss": -2531.38525390625, "actor_target_entropy": -3.0, "actor_entropy": 0.6203510761260986, "alpha_loss": 0.7595942616462708, "alpha_value": 2.325566852116811, "duration": 1.4987025260925293, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1520500}
{"episode_reward": 0.0, "episode": 15206.0, "batch_reward": 1.6583963632583618, "critic_loss": 5207.767578125, "actor_loss": -2565.043212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.6241604089736938, "alpha_loss": 0.7394148111343384, "alpha_value": 2.289767671787366, "duration": 1.475438117980957, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1521000}
{"episode_reward": 0.0, "episode": 15211.0, "batch_reward": 1.697185754776001, "critic_loss": 5425.4794921875, "actor_loss": -2634.04248046875, "actor_target_entropy": -3.0, "actor_entropy": 0.33720603585243225, "alpha_loss": -1.1697120666503906, "alpha_value": 2.287024705060584, "duration": 1.4106483459472656, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1521500}
{"episode_reward": 0.0, "episode": 15216.0, "batch_reward": 1.808318018913269, "critic_loss": 5800.953125, "actor_loss": -3207.59228515625, "actor_target_entropy": -3.0, "actor_entropy": 0.7787030935287476, "alpha_loss": 0.8811914324760437, "alpha_value": 2.3205831453171295, "duration": 1.5062172412872314, "info_normalized_performance_mean": 0.00013888889225199819, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.00013888889225199819, "info_performance_final": 0.0, "step": 1522000}
{"episode_reward": 0.2777777777777778, "episode": 15221.0, "batch_reward": 1.9661006927490234, "critic_loss": 4835.59228515625, "actor_loss": -2854.419921875, "actor_target_entropy": -3.0, "actor_entropy": 0.7598377466201782, "alpha_loss": -2.493381977081299, "alpha_value": 2.363637804426023, "duration": 1.4923467636108398, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1522500}
{"episode_reward": 0.0, "episode": 15226.0, "batch_reward": 1.9718308448791504, "critic_loss": 6469.3330078125, "actor_loss": -2729.80078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8007766008377075, "alpha_loss": -0.4618741273880005, "alpha_value": 2.422800531630886, "duration": 1.4725310802459717, "info_normalized_performance_mean": 0.08643314242362976, "info_normalized_performance_final": 0.10210622847080231, "info_performance_mean": 0.08643314242362976, "info_performance_final": 0.10210622847080231, "step": 1523000}
{"episode_reward": 172.86630036630052, "episode": 15231.0, "batch_reward": 1.2988277673721313, "critic_loss": 8539.16796875, "actor_loss": -2905.52392578125, "actor_target_entropy": -3.0, "actor_entropy": 0.5297069549560547, "alpha_loss": -0.6022642850875854, "alpha_value": 2.4625433021968295, "duration": 1.4479765892028809, "info_normalized_performance_mean": 0.30405375361442566, "info_normalized_performance_final": 0.3687423765659332, "info_performance_mean": 0.30405375361442566, "info_performance_final": 0.3687423765659332, "step": 1523500}
{"episode_reward": 608.1074481074482, "episode": 15236.0, "batch_reward": 1.2949581146240234, "critic_loss": 5966.7841796875, "actor_loss": -2863.425537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.5820685625076294, "alpha_loss": -1.3383355140686035, "alpha_value": 2.4977029281483065, "duration": 1.5559308528900146, "info_normalized_performance_mean": 0.07498510181903839, "info_normalized_performance_final": 0.0825892835855484, "info_performance_mean": 0.07498510181903839, "info_performance_final": 0.0825892835855484, "step": 1524000}
{"episode_reward": 149.970238095238, "episode": 15241.0, "batch_reward": 1.291912317276001, "critic_loss": 6020.6552734375, "actor_loss": -2771.134033203125, "actor_target_entropy": -3.0, "actor_entropy": 0.5746586918830872, "alpha_loss": -2.0621628761291504, "alpha_value": 2.5264640090779795, "duration": 1.4891951084136963, "info_normalized_performance_mean": 0.1527690887451172, "info_normalized_performance_final": 0.1653645783662796, "info_performance_mean": 0.1527690887451172, "info_performance_final": 0.1653645783662796, "step": 1524500}
{"episode_reward": 305.53819444444446, "episode": 15246.0, "batch_reward": 1.5352073907852173, "critic_loss": 7384.048828125, "actor_loss": -2968.27197265625, "actor_target_entropy": -3.0, "actor_entropy": 0.39159998297691345, "alpha_loss": -0.9250556826591492, "alpha_value": 2.5578458470307712, "duration": 1.534912109375, "info_normalized_performance_mean": 0.0445149689912796, "info_normalized_performance_final": 0.048828125, "info_performance_mean": 0.0445149689912796, "info_performance_final": 0.048828125, "step": 1525000}
{"episode_reward": 89.02994791666666, "episode": 15251.0, "batch_reward": 1.5535976886749268, "critic_loss": 13208.994140625, "actor_loss": -2691.261474609375, "actor_target_entropy": -3.0, "actor_entropy": 0.5641497373580933, "alpha_loss": -0.24343988299369812, "alpha_value": 2.5953208110557324, "duration": 1.5252857208251953, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1525500}
{"episode_reward": 0.0, "episode": 15256.0, "batch_reward": 1.1051017045974731, "critic_loss": 4594.236328125, "actor_loss": -2667.552001953125, "actor_target_entropy": -3.0, "actor_entropy": 0.9358168244361877, "alpha_loss": -0.03465673327445984, "alpha_value": 2.6309215666625407, "duration": 1.4511518478393555, "info_normalized_performance_mean": 0.40338096022605896, "info_normalized_performance_final": 0.44583332538604736, "info_performance_mean": 0.40338096022605896, "info_performance_final": 0.44583332538604736, "step": 1526000}
{"episode_reward": 806.7619047619039, "episode": 15261.0, "batch_reward": 1.1279351711273193, "critic_loss": 10903.1865234375, "actor_loss": -2730.36669921875, "actor_target_entropy": -3.0, "actor_entropy": 0.6793926954269409, "alpha_loss": -0.21795538067817688, "alpha_value": 2.688302417045593, "duration": 1.5563831329345703, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1526500}
{"episode_reward": 0.0, "episode": 15266.0, "batch_reward": 1.7701475620269775, "critic_loss": 4336.75390625, "actor_loss": -2781.34375, "actor_target_entropy": -3.0, "actor_entropy": 1.0751793384552002, "alpha_loss": -1.0783467292785645, "alpha_value": 2.7276564243347523, "duration": 1.4860866069793701, "info_normalized_performance_mean": 0.35452502965927124, "info_normalized_performance_final": 0.42625001072883606, "info_performance_mean": 0.35452502965927124, "info_performance_final": 0.42625001072883606, "step": 1527000}
{"episode_reward": 709.0499999999989, "episode": 15271.0, "batch_reward": 1.4637340307235718, "critic_loss": 10799.8515625, "actor_loss": -2852.35009765625, "actor_target_entropy": -3.0, "actor_entropy": 1.0425999164581299, "alpha_loss": -1.5368092060089111, "alpha_value": 2.7562510937166613, "duration": 1.5363073348999023, "info_normalized_performance_mean": 0.03205883130431175, "info_normalized_performance_final": 0.10196078568696976, "info_performance_mean": 0.03205883130431175, "info_performance_final": 0.10196078568696976, "step": 1527500}
{"episode_reward": 64.11764705882354, "episode": 15276.0, "batch_reward": 1.4283387660980225, "critic_loss": 5955.76953125, "actor_loss": -2847.56640625, "actor_target_entropy": -3.0, "actor_entropy": 0.5589083433151245, "alpha_loss": 0.24222175776958466, "alpha_value": 2.7767866213319676, "duration": 1.5069198608398438, "info_normalized_performance_mean": 0.39915502071380615, "info_normalized_performance_final": 0.4780748784542084, "info_performance_mean": 0.39915502071380615, "info_performance_final": 0.4780748784542084, "step": 1528000}
{"episode_reward": 798.3101604278058, "episode": 15281.0, "batch_reward": 1.334801435470581, "critic_loss": 6722.39404296875, "actor_loss": -2864.365478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0575358867645264, "alpha_loss": -1.5100204944610596, "alpha_value": 2.8282141563273466, "duration": 1.5349667072296143, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1528500}
{"episode_reward": 0.0, "episode": 15286.0, "batch_reward": 1.3895738124847412, "critic_loss": 5295.7626953125, "actor_loss": -2816.109619140625, "actor_target_entropy": -3.0, "actor_entropy": 1.2813787460327148, "alpha_loss": 0.37080979347229004, "alpha_value": 2.8749303308816536, "duration": 1.5565581321716309, "info_normalized_performance_mean": 0.39166802167892456, "info_normalized_performance_final": 0.4582299292087555, "info_performance_mean": 0.39166802167892456, "info_performance_final": 0.4582299292087555, "step": 1529000}
{"episode_reward": 783.336090432866, "episode": 15291.0, "batch_reward": 1.2345781326293945, "critic_loss": 7100.55078125, "actor_loss": -2910.838623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1461176872253418, "alpha_loss": 1.1180343627929688, "alpha_value": 2.9275498163206977, "duration": 1.560032844543457, "info_normalized_performance_mean": 0.051249999552965164, "info_normalized_performance_final": 0.06911765038967133, "info_performance_mean": 0.051249999552965164, "info_performance_final": 0.06911765038967133, "step": 1529500}
{"episode_reward": 102.49999999999983, "episode": 15296.0, "batch_reward": 1.5564208030700684, "critic_loss": 5788.70703125, "actor_loss": -2874.28759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.200150728225708, "alpha_loss": 0.375355064868927, "alpha_value": 2.9360306918020878, "step": 1530000}
{"duration": 19.03305435180664, "info_normalized_performance_mean": 0.0648428425192833, "info_normalized_performance_final": 0.07285714149475098, "info_performance_mean": 0.0648428425192833, "info_performance_final": 0.07285714149475098, "step": 1530000}
{"episode_reward": 129.68571428571417, "episode": 15301.0, "batch_reward": 1.4214497804641724, "critic_loss": 5693.6669921875, "actor_loss": -2989.393798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.446239709854126, "alpha_loss": 0.3116984963417053, "alpha_value": 2.9473957395193846, "duration": 1.530733346939087, "info_normalized_performance_mean": 0.009266968816518784, "info_normalized_performance_final": 0.009954751469194889, "info_performance_mean": 0.009266968816518784, "info_performance_final": 0.009954751469194889, "step": 1530500}
{"episode_reward": 18.533936651583677, "episode": 15306.0, "batch_reward": 1.8122819662094116, "critic_loss": 5372.56005859375, "actor_loss": -2903.5615234375, "actor_target_entropy": -3.0, "actor_entropy": 1.5289826393127441, "alpha_loss": 0.09098014235496521, "alpha_value": 2.942629029159169, "duration": 1.6184113025665283, "info_normalized_performance_mean": 0.1978103667497635, "info_normalized_performance_final": 0.30129870772361755, "info_performance_mean": 0.1978103667497635, "info_performance_final": 0.30129870772361755, "step": 1531000}
{"episode_reward": 395.6207792207801, "episode": 15311.0, "batch_reward": 1.221325397491455, "critic_loss": 3660.330078125, "actor_loss": -2899.912109375, "actor_target_entropy": -3.0, "actor_entropy": 1.288533329963684, "alpha_loss": 1.73347806930542, "alpha_value": 2.896134020418563, "duration": 1.4884495735168457, "info_normalized_performance_mean": 0.6189285516738892, "info_normalized_performance_final": 0.7559523582458496, "info_performance_mean": 0.6189285516738892, "info_performance_final": 0.7559523582458496, "step": 1531500}
{"episode_reward": 1237.857142857143, "episode": 15316.0, "batch_reward": 1.388978123664856, "critic_loss": 3839.894775390625, "actor_loss": -2815.08642578125, "actor_target_entropy": -3.0, "actor_entropy": 1.4875669479370117, "alpha_loss": 0.7377623319625854, "alpha_value": 2.8434959468151786, "duration": 1.4293904304504395, "info_normalized_performance_mean": 0.29939281940460205, "info_normalized_performance_final": 0.35178571939468384, "info_performance_mean": 0.29939281940460205, "info_performance_final": 0.35178571939468384, "step": 1532000}
{"episode_reward": 598.7857142857144, "episode": 15321.0, "batch_reward": 1.591040849685669, "critic_loss": 5000.6611328125, "actor_loss": -2841.2109375, "actor_target_entropy": -3.0, "actor_entropy": 1.281310796737671, "alpha_loss": 1.6812554597854614, "alpha_value": 2.7893981082513015, "duration": 1.5530500411987305, "info_normalized_performance_mean": 0.3126881718635559, "info_normalized_performance_final": 0.36000001430511475, "info_performance_mean": 0.3126881718635559, "info_performance_final": 0.36000001430511475, "step": 1532500}
{"episode_reward": 625.3761904761906, "episode": 15326.0, "batch_reward": 1.408396601676941, "critic_loss": 5152.01708984375, "actor_loss": -2919.86181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1454169750213623, "alpha_loss": 0.2703104019165039, "alpha_value": 2.747134731903606, "duration": 1.5258982181549072, "info_normalized_performance_mean": 0.5269073247909546, "info_normalized_performance_final": 0.6958398818969727, "info_performance_mean": 0.5269073247909546, "info_performance_final": 0.6958398818969727, "step": 1533000}
{"episode_reward": 1053.8147566718994, "episode": 15331.0, "batch_reward": 2.071106433868408, "critic_loss": 4004.727783203125, "actor_loss": -3043.282470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1799770593643188, "alpha_loss": -0.024708181619644165, "alpha_value": 2.689398845153894, "duration": 1.5765810012817383, "info_normalized_performance_mean": 0.6266106367111206, "info_normalized_performance_final": 0.7944711446762085, "info_performance_mean": 0.6266106367111206, "info_performance_final": 0.7944711446762085, "step": 1533500}
{"episode_reward": 1253.2211538461547, "episode": 15336.0, "batch_reward": 1.1855729818344116, "critic_loss": 2411.63134765625, "actor_loss": -2777.488037109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9064422845840454, "alpha_loss": 1.0385079383850098, "alpha_value": 2.628587346870336, "duration": 1.5398764610290527, "info_normalized_performance_mean": 0.6258928179740906, "info_normalized_performance_final": 0.7485119104385376, "info_performance_mean": 0.6258928179740906, "info_performance_final": 0.7485119104385376, "step": 1534000}
{"episode_reward": 1251.7857142857129, "episode": 15341.0, "batch_reward": 1.3819535970687866, "critic_loss": 3204.4873046875, "actor_loss": -2850.588623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.150930404663086, "alpha_loss": 1.3202179670333862, "alpha_value": 2.567751374671594, "duration": 1.4538688659667969, "info_normalized_performance_mean": 0.0006249999860301614, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0006249999860301614, "info_performance_final": 0.0, "step": 1534500}
{"episode_reward": 1.25, "episode": 15346.0, "batch_reward": 1.8988020420074463, "critic_loss": 3390.96923828125, "actor_loss": -2895.157470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3484306335449219, "alpha_loss": 0.20166808366775513, "alpha_value": 2.5095735601613955, "duration": 1.670564889907837, "info_normalized_performance_mean": 0.5130183696746826, "info_normalized_performance_final": 0.6369616985321045, "info_performance_mean": 0.5130183696746826, "info_performance_final": 0.6369616985321045, "step": 1535000}
{"episode_reward": 1026.0366826156317, "episode": 15351.0, "batch_reward": 1.1348538398742676, "critic_loss": 8895.7958984375, "actor_loss": -2875.22705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.052303433418274, "alpha_loss": 1.0773038864135742, "alpha_value": 2.4497233522249116, "duration": 1.6300079822540283, "info_normalized_performance_mean": 0.3432958126068115, "info_normalized_performance_final": 0.4735416769981384, "info_performance_mean": 0.3432958126068115, "info_performance_final": 0.4735416769981384, "step": 1535500}
{"episode_reward": 686.5916666666668, "episode": 15356.0, "batch_reward": 1.8872556686401367, "critic_loss": 2581.0283203125, "actor_loss": -2783.202392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.0036511421203613, "alpha_loss": 1.7254869937896729, "alpha_value": 2.3855016848345154, "duration": 1.5963201522827148, "info_normalized_performance_mean": 0.4086436927318573, "info_normalized_performance_final": 0.5137085318565369, "info_performance_mean": 0.4086436927318573, "info_performance_final": 0.5137085318565369, "step": 1536000}
{"episode_reward": 817.2871572871572, "episode": 15361.0, "batch_reward": 1.7891467809677124, "critic_loss": 4350.16064453125, "actor_loss": -2731.5595703125, "actor_target_entropy": -3.0, "actor_entropy": 0.7341053485870361, "alpha_loss": 0.37270432710647583, "alpha_value": 2.326798092743916, "duration": 1.4834139347076416, "info_normalized_performance_mean": 0.5697330236434937, "info_normalized_performance_final": 0.6864316463470459, "info_performance_mean": 0.5697330236434937, "info_performance_final": 0.6864316463470459, "step": 1536500}
{"episode_reward": 1139.465811965812, "episode": 15366.0, "batch_reward": 2.097580909729004, "critic_loss": 6007.23291015625, "actor_loss": -2656.8212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.263784646987915, "alpha_loss": 1.4723305702209473, "alpha_value": 2.261293334855715, "duration": 1.536180019378662, "info_normalized_performance_mean": 0.1879854053258896, "info_normalized_performance_final": 0.21296297013759613, "info_performance_mean": 0.1879854053258896, "info_performance_final": 0.21296297013759613, "step": 1537000}
{"episode_reward": 375.9708193041521, "episode": 15371.0, "batch_reward": 1.4516688585281372, "critic_loss": 2919.0185546875, "actor_loss": -2516.921875, "actor_target_entropy": -3.0, "actor_entropy": 1.2764403820037842, "alpha_loss": 2.0256054401397705, "alpha_value": 2.2007941692089457, "duration": 1.6280925273895264, "info_normalized_performance_mean": 0.6745700240135193, "info_normalized_performance_final": 0.7731481194496155, "info_performance_mean": 0.6745700240135193, "info_performance_final": 0.7731481194496155, "step": 1537500}
{"episode_reward": 1349.140211640212, "episode": 15376.0, "batch_reward": 1.773929476737976, "critic_loss": 2540.148681640625, "actor_loss": -2581.522705078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8123829364776611, "alpha_loss": 0.4856899380683899, "alpha_value": 2.15757396864998, "duration": 1.470710277557373, "info_normalized_performance_mean": 0.20669597387313843, "info_normalized_performance_final": 0.23046875, "info_performance_mean": 0.20669597387313843, "info_performance_final": 0.23046875, "step": 1538000}
{"episode_reward": 413.39192708333337, "episode": 15381.0, "batch_reward": 1.7881231307983398, "critic_loss": 2997.09228515625, "actor_loss": -2618.630126953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1321732997894287, "alpha_loss": 1.6042569875717163, "alpha_value": 2.1078939833356882, "duration": 1.4667630195617676, "info_normalized_performance_mean": 0.5891554355621338, "info_normalized_performance_final": 0.6899092793464661, "info_performance_mean": 0.5891554355621338, "info_performance_final": 0.6899092793464661, "step": 1538500}
{"episode_reward": 1178.3106575963739, "episode": 15386.0, "batch_reward": 1.9304453134536743, "critic_loss": 2605.9345703125, "actor_loss": -2565.650146484375, "actor_target_entropy": -3.0, "actor_entropy": 0.9166843891143799, "alpha_loss": 0.3740646243095398, "alpha_value": 2.0646154716491227, "duration": 1.5207419395446777, "info_normalized_performance_mean": 0.12672725319862366, "info_normalized_performance_final": 0.13689839839935303, "info_performance_mean": 0.12672725319862366, "info_performance_final": 0.13689839839935303, "step": 1539000}
{"episode_reward": 253.45454545454584, "episode": 15391.0, "batch_reward": 1.5973674058914185, "critic_loss": 2545.71337890625, "actor_loss": -2568.61328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8803411722183228, "alpha_loss": 0.9300714135169983, "alpha_value": 2.023589025981237, "duration": 1.480881690979004, "info_normalized_performance_mean": 0.3882714807987213, "info_normalized_performance_final": 0.42081448435783386, "info_performance_mean": 0.3882714807987213, "info_performance_final": 0.42081448435783386, "step": 1539500}
{"episode_reward": 776.5429864253404, "episode": 15396.0, "batch_reward": 1.9090999364852905, "critic_loss": 2135.17919921875, "actor_loss": -2457.109130859375, "actor_target_entropy": -3.0, "actor_entropy": 1.169468641281128, "alpha_loss": 0.6826911568641663, "alpha_value": 1.9898277026717932, "step": 1540000}
{"duration": 18.920663356781006, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1540000}
{"episode_reward": 0.0, "episode": 15401.0, "batch_reward": 1.610802173614502, "critic_loss": 3236.95458984375, "actor_loss": -2549.49853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.3475592136383057, "alpha_loss": 0.33596229553222656, "alpha_value": 1.960895210039707, "duration": 1.5076477527618408, "info_normalized_performance_mean": 0.5056435465812683, "info_normalized_performance_final": 0.5490580797195435, "info_performance_mean": 0.5056435465812683, "info_performance_final": 0.5490580797195435, "step": 1540500}
{"episode_reward": 1011.2872841444279, "episode": 15406.0, "batch_reward": 1.9198784828186035, "critic_loss": 2640.053466796875, "actor_loss": -2427.37353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.4191172122955322, "alpha_loss": 0.676539421081543, "alpha_value": 1.9486117625708081, "duration": 1.6281423568725586, "info_normalized_performance_mean": 0.6380887031555176, "info_normalized_performance_final": 0.7070105671882629, "info_performance_mean": 0.6380887031555176, "info_performance_final": 0.7070105671882629, "step": 1541000}
{"episode_reward": 1276.177248677249, "episode": 15411.0, "batch_reward": 2.2956244945526123, "critic_loss": 2508.35498046875, "actor_loss": -2486.89697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.258190393447876, "alpha_loss": 0.23706598579883575, "alpha_value": 1.9459115847376733, "duration": 1.3793108463287354, "info_normalized_performance_mean": 0.12589283287525177, "info_normalized_performance_final": 0.1339285671710968, "info_performance_mean": 0.12589283287525177, "info_performance_final": 0.1339285671710968, "step": 1541500}
{"episode_reward": 251.78571428571377, "episode": 15416.0, "batch_reward": 1.464869499206543, "critic_loss": 2383.68408203125, "actor_loss": -2352.01953125, "actor_target_entropy": -3.0, "actor_entropy": 1.2895022630691528, "alpha_loss": -0.79076087474823, "alpha_value": 1.9324795064758118, "duration": 1.7000722885131836, "info_normalized_performance_mean": 0.3964824676513672, "info_normalized_performance_final": 0.48691460490226746, "info_performance_mean": 0.3964824676513672, "info_performance_final": 0.48691460490226746, "step": 1542000}
{"episode_reward": 792.9648760330588, "episode": 15421.0, "batch_reward": 2.0858898162841797, "critic_loss": 2648.10400390625, "actor_loss": -2443.98876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.1805137395858765, "alpha_loss": -1.0535132884979248, "alpha_value": 1.9179674979387726, "duration": 1.7719168663024902, "info_normalized_performance_mean": 0.526336669921875, "info_normalized_performance_final": 0.6119123697280884, "info_performance_mean": 0.526336669921875, "info_performance_final": 0.6119123697280884, "step": 1542500}
{"episode_reward": 1052.6736111111086, "episode": 15426.0, "batch_reward": 2.20151948928833, "critic_loss": 2511.559814453125, "actor_loss": -2393.13427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3849363327026367, "alpha_loss": -0.3286018371582031, "alpha_value": 1.90565938846592, "duration": 1.5053448677062988, "info_normalized_performance_mean": 0.26840171217918396, "info_normalized_performance_final": 0.3095703125, "info_performance_mean": 0.26840171217918396, "info_performance_final": 0.3095703125, "step": 1543000}
{"episode_reward": 536.8033854166667, "episode": 15431.0, "batch_reward": 1.9120030403137207, "critic_loss": 2285.517578125, "actor_loss": -2275.375, "actor_target_entropy": -3.0, "actor_entropy": 1.4030143022537231, "alpha_loss": 1.3900599479675293, "alpha_value": 1.893116396561246, "duration": 1.7496883869171143, "info_normalized_performance_mean": 0.5188989043235779, "info_normalized_performance_final": 0.5995370149612427, "info_performance_mean": 0.5188989043235779, "info_performance_final": 0.5995370149612427, "step": 1543500}
{"episode_reward": 1037.7980324074085, "episode": 15436.0, "batch_reward": 2.5137665271759033, "critic_loss": 3288.942138671875, "actor_loss": -2372.76220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0982049703598022, "alpha_loss": 0.3142293393611908, "alpha_value": 1.8695593110419606, "duration": 1.5116257667541504, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1544000}
{"episode_reward": 0.0, "episode": 15441.0, "batch_reward": 2.2608609199523926, "critic_loss": 5560.5625, "actor_loss": -2275.24609375, "actor_target_entropy": -3.0, "actor_entropy": 1.5424413681030273, "alpha_loss": 1.7275493144989014, "alpha_value": 1.8476351015065533, "duration": 1.565680742263794, "info_normalized_performance_mean": 0.249204620718956, "info_normalized_performance_final": 0.30508071184158325, "info_performance_mean": 0.249204620718956, "info_performance_final": 0.30508071184158325, "step": 1544500}
{"episode_reward": 498.40930674263916, "episode": 15446.0, "batch_reward": 1.6696536540985107, "critic_loss": 3170.0576171875, "actor_loss": -2427.9150390625, "actor_target_entropy": -3.0, "actor_entropy": 1.4420181512832642, "alpha_loss": -0.03490641713142395, "alpha_value": 1.8214540413293767, "duration": 1.499070167541504, "info_normalized_performance_mean": 0.6429402828216553, "info_normalized_performance_final": 0.6832386255264282, "info_performance_mean": 0.6429402828216553, "info_performance_final": 0.6832386255264282, "step": 1545000}
{"episode_reward": 1285.8806818181831, "episode": 15451.0, "batch_reward": 2.2040932178497314, "critic_loss": 2248.779296875, "actor_loss": -2357.08203125, "actor_target_entropy": -3.0, "actor_entropy": 1.3520762920379639, "alpha_loss": 0.6518064141273499, "alpha_value": 1.7986291252763993, "duration": 1.4759178161621094, "info_normalized_performance_mean": 3.61990969395265e-05, "info_normalized_performance_final": 0.0, "info_performance_mean": 3.61990969395265e-05, "info_performance_final": 0.0, "step": 1545500}
{"episode_reward": 0.07239819004524888, "episode": 15456.0, "batch_reward": 1.9966461658477783, "critic_loss": 2696.881103515625, "actor_loss": -2304.121337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.1610095500946045, "alpha_loss": 0.33806824684143066, "alpha_value": 1.7724326058609219, "duration": 1.4791924953460693, "info_normalized_performance_mean": 0.3288281261920929, "info_normalized_performance_final": 0.3654513955116272, "info_performance_mean": 0.3288281261920929, "info_performance_final": 0.3654513955116272, "step": 1546000}
{"episode_reward": 657.6562500000006, "episode": 15461.0, "batch_reward": 2.3462109565734863, "critic_loss": 2362.03173828125, "actor_loss": -2317.59033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1465778350830078, "alpha_loss": 0.9086761474609375, "alpha_value": 1.751217903747548, "duration": 1.4441113471984863, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1546500}
{"episode_reward": 0.0, "episode": 15466.0, "batch_reward": 2.3094420433044434, "critic_loss": 2235.595703125, "actor_loss": -2350.2548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.1942853927612305, "alpha_loss": 0.38403743505477905, "alpha_value": 1.717048103467272, "duration": 1.4260079860687256, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1547000}
{"episode_reward": 0.0, "episode": 15471.0, "batch_reward": 2.53892183303833, "critic_loss": 2644.96337890625, "actor_loss": -2278.2705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.042186975479126, "alpha_loss": -0.25750550627708435, "alpha_value": 1.6912639902992073, "duration": 1.6257379055023193, "info_normalized_performance_mean": 0.20910124480724335, "info_normalized_performance_final": 0.23519283533096313, "info_performance_mean": 0.20910124480724335, "info_performance_final": 0.23519283533096313, "step": 1547500}
{"episode_reward": 418.20247933884247, "episode": 15476.0, "batch_reward": 2.7693533897399902, "critic_loss": 2404.6220703125, "actor_loss": -2302.057373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.063634991645813, "alpha_loss": 0.43521571159362793, "alpha_value": 1.6627547893146941, "duration": 1.4087717533111572, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1548000}
{"episode_reward": 0.0, "episode": 15481.0, "batch_reward": 2.8135828971862793, "critic_loss": 1499.050537109375, "actor_loss": -2308.12158203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1334507465362549, "alpha_loss": 0.7656773328781128, "alpha_value": 1.6307651657003666, "duration": 1.5929195880889893, "info_normalized_performance_mean": 0.7686536312103271, "info_normalized_performance_final": 0.9058823585510254, "info_performance_mean": 0.7686536312103271, "info_performance_final": 0.9058823585510254, "step": 1548500}
{"episode_reward": 1537.3071895424807, "episode": 15486.0, "batch_reward": 2.201371431350708, "critic_loss": 3650.55859375, "actor_loss": -2235.66162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3047959804534912, "alpha_loss": 0.21824969351291656, "alpha_value": 1.6029132044241967, "duration": 1.4520628452301025, "info_normalized_performance_mean": 0.3545660078525543, "info_normalized_performance_final": 0.390625, "info_performance_mean": 0.3545660078525543, "info_performance_final": 0.390625, "step": 1549000}
{"episode_reward": 709.1319444444445, "episode": 15491.0, "batch_reward": 1.8648954629898071, "critic_loss": 2541.920654296875, "actor_loss": -2226.5888671875, "actor_target_entropy": -3.0, "actor_entropy": 0.7362262606620789, "alpha_loss": 0.684059739112854, "alpha_value": 1.5785388462047116, "duration": 1.5164096355438232, "info_normalized_performance_mean": 0.39736610651016235, "info_normalized_performance_final": 0.46737638115882874, "info_performance_mean": 0.39736610651016235, "info_performance_final": 0.46737638115882874, "step": 1549500}
{"episode_reward": 794.7321428571412, "episode": 15496.0, "batch_reward": 2.198674440383911, "critic_loss": 2296.153564453125, "actor_loss": -2300.05615234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8636902570724487, "alpha_loss": 0.7108173370361328, "alpha_value": 1.5639307589293598, "step": 1550000}
{"duration": 18.821474075317383, "info_normalized_performance_mean": 0.6272222399711609, "info_normalized_performance_final": 0.7624008059501648, "info_performance_mean": 0.6272222399711609, "info_performance_final": 0.7624008059501648, "step": 1550000}
{"episode_reward": 1254.4444444444453, "episode": 15501.0, "batch_reward": 2.513028383255005, "critic_loss": 2304.94921875, "actor_loss": -2287.00537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.0586895942687988, "alpha_loss": 0.2543753385543823, "alpha_value": 1.5396664265169027, "duration": 1.6135718822479248, "info_normalized_performance_mean": 0.36213618516921997, "info_normalized_performance_final": 0.42989417910575867, "info_performance_mean": 0.36213618516921997, "info_performance_final": 0.42989417910575867, "step": 1550500}
{"episode_reward": 724.2724867724879, "episode": 15506.0, "batch_reward": 2.6372737884521484, "critic_loss": 28254.208984375, "actor_loss": -2158.259521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.077579140663147, "alpha_loss": 0.7129706740379333, "alpha_value": 1.5094411368181768, "duration": 1.479550838470459, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1551000}
{"episode_reward": 0.0, "episode": 15511.0, "batch_reward": 2.59263014793396, "critic_loss": 2574.438232421875, "actor_loss": -2216.60498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.3194847106933594, "alpha_loss": 1.0529688596725464, "alpha_value": 1.4941790816487122, "duration": 1.4624261856079102, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1551500}
{"episode_reward": 0.0, "episode": 15516.0, "batch_reward": 2.483269214630127, "critic_loss": 2613.9326171875, "actor_loss": -2334.781982421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8178963661193848, "alpha_loss": -0.46831804513931274, "alpha_value": 1.4971031832500947, "duration": 1.6956486701965332, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1552000}
{"episode_reward": 0.0, "episode": 15521.0, "batch_reward": 1.9701557159423828, "critic_loss": 4724.40771484375, "actor_loss": -2265.94482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0408458709716797, "alpha_loss": -0.2703791856765747, "alpha_value": 1.5223805278101155, "duration": 1.5517449378967285, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1552500}
{"episode_reward": 0.0, "episode": 15526.0, "batch_reward": 2.3121562004089355, "critic_loss": 2675.53271484375, "actor_loss": -2394.505126953125, "actor_target_entropy": -3.0, "actor_entropy": 1.177910327911377, "alpha_loss": -0.43565499782562256, "alpha_value": 1.568378133615415, "duration": 1.745579719543457, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1553000}
{"episode_reward": 0.0, "episode": 15531.0, "batch_reward": 2.6000280380249023, "critic_loss": 2988.9228515625, "actor_loss": -2403.7421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3557292222976685, "alpha_loss": 0.6687948703765869, "alpha_value": 1.5989351291155312, "duration": 1.5904407501220703, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1553500}
{"episode_reward": 0.0, "episode": 15536.0, "batch_reward": 1.7342963218688965, "critic_loss": 4585.93115234375, "actor_loss": -2485.44873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.468443751335144, "alpha_loss": -1.0865650177001953, "alpha_value": 1.6210352973708588, "duration": 1.7175672054290771, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1554000}
{"episode_reward": 0.0, "episode": 15541.0, "batch_reward": 2.2753477096557617, "critic_loss": 2584.68896484375, "actor_loss": -2424.202880859375, "actor_target_entropy": -3.0, "actor_entropy": 1.5368707180023193, "alpha_loss": -0.10890708863735199, "alpha_value": 1.6310350078698002, "duration": 1.6244192123413086, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1554500}
{"episode_reward": 0.0, "episode": 15546.0, "batch_reward": 2.323712110519409, "critic_loss": 3807.977783203125, "actor_loss": -2459.6552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.5670742988586426, "alpha_loss": -0.3961019814014435, "alpha_value": 1.6470808481630175, "duration": 1.532531976699829, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1555000}
{"episode_reward": 0.0, "episode": 15551.0, "batch_reward": 2.312887191772461, "critic_loss": 3922.021484375, "actor_loss": -2479.89501953125, "actor_target_entropy": -3.0, "actor_entropy": 1.3617050647735596, "alpha_loss": -0.16533148288726807, "alpha_value": 1.6767046929934024, "duration": 1.5568974018096924, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1555500}
{"episode_reward": 0.0, "episode": 15556.0, "batch_reward": 2.502992868423462, "critic_loss": 2279.2861328125, "actor_loss": -2441.751220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.575385332107544, "alpha_loss": -0.6580525040626526, "alpha_value": 1.7025166240789376, "duration": 1.5895543098449707, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1556000}
{"episode_reward": 0.0, "episode": 15561.0, "batch_reward": 2.231727361679077, "critic_loss": 2246.41845703125, "actor_loss": -2395.450439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.3800160884857178, "alpha_loss": -0.5245397090911865, "alpha_value": 1.7338713264947823, "duration": 1.5346200466156006, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1556500}
{"episode_reward": 0.0, "episode": 15566.0, "batch_reward": 2.0416641235351562, "critic_loss": 3182.56201171875, "actor_loss": -2459.2294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4122521877288818, "alpha_loss": -0.8482778072357178, "alpha_value": 1.7435698630453111, "duration": 1.5726876258850098, "info_normalized_performance_mean": 0.05115833133459091, "info_normalized_performance_final": 0.0625, "info_performance_mean": 0.05115833133459091, "info_performance_final": 0.0625, "step": 1557000}
{"episode_reward": 102.31666666666666, "episode": 15571.0, "batch_reward": 2.180633783340454, "critic_loss": 3158.222412109375, "actor_loss": -2433.79345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.7884469032287598, "alpha_loss": -0.5430248975753784, "alpha_value": 1.716292205597582, "duration": 1.4770524501800537, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1557500}
{"episode_reward": 0.0, "episode": 15576.0, "batch_reward": 2.861147165298462, "critic_loss": 1520.444580078125, "actor_loss": -2332.376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.9305894374847412, "alpha_loss": 0.3213908076286316, "alpha_value": 1.6823537327840343, "duration": 1.5949864387512207, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1558000}
{"episode_reward": 0.0, "episode": 15581.0, "batch_reward": 3.057460308074951, "critic_loss": 1568.6260986328125, "actor_loss": -2332.9306640625, "actor_target_entropy": -3.0, "actor_entropy": 1.6297409534454346, "alpha_loss": 1.2986888885498047, "alpha_value": 1.6274828248734254, "duration": 1.5014517307281494, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1558500}
{"episode_reward": 0.0, "episode": 15586.0, "batch_reward": 2.236368179321289, "critic_loss": 2024.533935546875, "actor_loss": -2332.424560546875, "actor_target_entropy": -3.0, "actor_entropy": 1.724120020866394, "alpha_loss": 0.8169103860855103, "alpha_value": 1.5776689145731126, "duration": 1.527841329574585, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1559000}
{"episode_reward": 0.0, "episode": 15591.0, "batch_reward": 2.5636730194091797, "critic_loss": 1819.00634765625, "actor_loss": -2227.6240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.7328767776489258, "alpha_loss": 1.89065420627594, "alpha_value": 1.527548199337768, "duration": 1.490588903427124, "info_normalized_performance_mean": 0.002868589712306857, "info_normalized_performance_final": 0.008547008968889713, "info_performance_mean": 0.002868589712306857, "info_performance_final": 0.008547008968889713, "step": 1559500}
{"episode_reward": 5.737179487179489, "episode": 15596.0, "batch_reward": 2.4639225006103516, "critic_loss": 1440.224609375, "actor_loss": -2193.68115234375, "actor_target_entropy": -3.0, "actor_entropy": 1.498130202293396, "alpha_loss": 1.3490748405456543, "alpha_value": 1.4840499707799442, "step": 1560000}
{"duration": 19.128746271133423, "info_normalized_performance_mean": 0.12199998646974564, "info_normalized_performance_final": 0.1709090918302536, "info_performance_mean": 0.12199998646974564, "info_performance_final": 0.1709090918302536, "step": 1560000}
{"episode_reward": 243.99999999999966, "episode": 15601.0, "batch_reward": 3.4841196537017822, "critic_loss": 2478.53759765625, "actor_loss": -2203.71435546875, "actor_target_entropy": -3.0, "actor_entropy": 1.5852231979370117, "alpha_loss": 1.1534099578857422, "alpha_value": 1.4398763370705472, "duration": 1.4992742538452148, "info_normalized_performance_mean": 0.07152777910232544, "info_normalized_performance_final": 0.1770833283662796, "info_performance_mean": 0.07152777910232544, "info_performance_final": 0.1770833283662796, "step": 1560500}
{"episode_reward": 143.05555555555557, "episode": 15606.0, "batch_reward": 1.7619335651397705, "critic_loss": 1682.8485107421875, "actor_loss": -2083.364990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.7856416702270508, "alpha_loss": 1.5196107625961304, "alpha_value": 1.3967816089855143, "duration": 1.5591676235198975, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1561000}
{"episode_reward": 0.0, "episode": 15611.0, "batch_reward": 2.645549774169922, "critic_loss": 1994.6416015625, "actor_loss": -2074.3037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.5396062135696411, "alpha_loss": 1.1836249828338623, "alpha_value": 1.3531927727466413, "duration": 1.4505724906921387, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1561500}
{"episode_reward": 0.0, "episode": 15616.0, "batch_reward": 2.3296220302581787, "critic_loss": 2488.80419921875, "actor_loss": -2069.242431640625, "actor_target_entropy": -3.0, "actor_entropy": 1.7361888885498047, "alpha_loss": 1.682985544204712, "alpha_value": 1.3135737082417018, "duration": 1.5709319114685059, "info_normalized_performance_mean": 0.019978610798716545, "info_normalized_performance_final": 0.14759358763694763, "info_performance_mean": 0.019978610798716545, "info_performance_final": 0.14759358763694763, "step": 1562000}
{"episode_reward": 39.9572192513369, "episode": 15621.0, "batch_reward": 2.3144490718841553, "critic_loss": 1433.479248046875, "actor_loss": -2037.273193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6762840747833252, "alpha_loss": 1.5465441942214966, "alpha_value": 1.27856204101166, "duration": 1.4829349517822266, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1562500}
{"episode_reward": 0.0, "episode": 15626.0, "batch_reward": 1.9747625589370728, "critic_loss": 3245.235107421875, "actor_loss": -1951.8995361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.5138635635375977, "alpha_loss": 0.9046275019645691, "alpha_value": 1.2499440993501336, "duration": 1.5453851222991943, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1563000}
{"episode_reward": 0.0, "episode": 15631.0, "batch_reward": 2.560904026031494, "critic_loss": 1538.98486328125, "actor_loss": -1914.753662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.6009521484375, "alpha_loss": 1.194283366203308, "alpha_value": 1.2249599632750743, "duration": 1.5982661247253418, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1563500}
{"episode_reward": 0.0, "episode": 15636.0, "batch_reward": 1.4167293310165405, "critic_loss": 1363.06201171875, "actor_loss": -1958.124755859375, "actor_target_entropy": -3.0, "actor_entropy": 1.289542317390442, "alpha_loss": 0.857563853263855, "alpha_value": 1.2018226181808822, "duration": 1.531280755996704, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1564000}
{"episode_reward": 0.0, "episode": 15641.0, "batch_reward": 2.3961052894592285, "critic_loss": 2049.998779296875, "actor_loss": -1968.5927734375, "actor_target_entropy": -3.0, "actor_entropy": 1.263108491897583, "alpha_loss": 0.6671807765960693, "alpha_value": 1.1795497084078594, "duration": 1.5957539081573486, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1564500}
{"episode_reward": 0.0, "episode": 15646.0, "batch_reward": 3.1128346920013428, "critic_loss": 1153.287109375, "actor_loss": -1908.09423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.6144864559173584, "alpha_loss": 0.8469980955123901, "alpha_value": 1.1554612509042144, "duration": 1.5617265701293945, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1565000}
{"episode_reward": 0.0, "episode": 15651.0, "batch_reward": 2.856872797012329, "critic_loss": 1110.3270263671875, "actor_loss": -1871.677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.5354220867156982, "alpha_loss": 0.25792816281318665, "alpha_value": 1.1346099784103683, "duration": 1.5497305393218994, "info_normalized_performance_mean": 0.002685714280232787, "info_normalized_performance_final": 0.027142856270074844, "info_performance_mean": 0.002685714280232787, "info_performance_final": 0.027142856270074844, "step": 1565500}
{"episode_reward": 5.371428571428571, "episode": 15656.0, "batch_reward": 1.8070350885391235, "critic_loss": 1753.6029052734375, "actor_loss": -1890.9962158203125, "actor_target_entropy": -3.0, "actor_entropy": 1.5486291646957397, "alpha_loss": 0.6529524326324463, "alpha_value": 1.118469656189255, "duration": 1.5915050506591797, "info_normalized_performance_mean": 0.1349206417798996, "info_normalized_performance_final": 0.3405483365058899, "info_performance_mean": 0.1349206417798996, "info_performance_final": 0.3405483365058899, "step": 1566000}
{"episode_reward": 269.84126984127, "episode": 15661.0, "batch_reward": 1.814121127128601, "critic_loss": 2805.951171875, "actor_loss": -1746.411865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.630301833152771, "alpha_loss": 0.590277373790741, "alpha_value": 1.1034278694106727, "duration": 1.6163153648376465, "info_normalized_performance_mean": 0.18408069014549255, "info_normalized_performance_final": 0.3432539701461792, "info_performance_mean": 0.18408069014549255, "info_performance_final": 0.3432539701461792, "step": 1566500}
{"episode_reward": 368.16137566137525, "episode": 15666.0, "batch_reward": 2.457307815551758, "critic_loss": 3078.6845703125, "actor_loss": -1831.527587890625, "actor_target_entropy": -3.0, "actor_entropy": 1.7100214958190918, "alpha_loss": 0.5552998781204224, "alpha_value": 1.0915597031979054, "duration": 1.4980628490447998, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1567000}
{"episode_reward": 0.0, "episode": 15671.0, "batch_reward": 1.859145164489746, "critic_loss": 2323.345947265625, "actor_loss": -1848.885498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.403903603553772, "alpha_loss": 0.1915556639432907, "alpha_value": 1.0854223580499063, "duration": 1.4725139141082764, "info_normalized_performance_mean": 0.37535643577575684, "info_normalized_performance_final": 0.4365234375, "info_performance_mean": 0.37535643577575684, "info_performance_final": 0.4365234375, "step": 1567500}
{"episode_reward": 750.712890625, "episode": 15676.0, "batch_reward": 2.640615463256836, "critic_loss": 1049.8284912109375, "actor_loss": -1739.1787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.680847406387329, "alpha_loss": -0.24710460007190704, "alpha_value": 1.0907658384016454, "duration": 1.567145824432373, "info_normalized_performance_mean": 0.2502025365829468, "info_normalized_performance_final": 0.32475000619888306, "info_performance_mean": 0.2502025365829468, "info_performance_final": 0.32475000619888306, "step": 1568000}
{"episode_reward": 500.4050000000003, "episode": 15681.0, "batch_reward": 2.408247947692871, "critic_loss": 1569.565185546875, "actor_loss": -1788.7825927734375, "actor_target_entropy": -3.0, "actor_entropy": 1.3141732215881348, "alpha_loss": -0.3924764394760132, "alpha_value": 1.0959475510519372, "duration": 1.5606541633605957, "info_normalized_performance_mean": 0.11818300187587738, "info_normalized_performance_final": 0.3673202693462372, "info_performance_mean": 0.11818300187587738, "info_performance_final": 0.3673202693462372, "step": 1568500}
{"episode_reward": 236.3660130718953, "episode": 15686.0, "batch_reward": 2.4412789344787598, "critic_loss": 3326.78662109375, "actor_loss": -1725.8515625, "actor_target_entropy": -3.0, "actor_entropy": 1.498569369316101, "alpha_loss": 0.7554199695587158, "alpha_value": 1.0861112355210325, "duration": 1.4345917701721191, "info_normalized_performance_mean": 0.056347399950027466, "info_normalized_performance_final": 0.06331168860197067, "info_performance_mean": 0.056347399950027466, "info_performance_final": 0.06331168860197067, "step": 1569000}
{"episode_reward": 112.6948051948053, "episode": 15691.0, "batch_reward": 2.0870203971862793, "critic_loss": 1249.124267578125, "actor_loss": -1632.778076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.5385723114013672, "alpha_loss": 0.18957701325416565, "alpha_value": 1.069758108546598, "duration": 1.4383790493011475, "info_normalized_performance_mean": 0.2586989998817444, "info_normalized_performance_final": 0.3176020383834839, "info_performance_mean": 0.2586989998817444, "info_performance_final": 0.3176020383834839, "step": 1569500}
{"episode_reward": 517.3979591836727, "episode": 15696.0, "batch_reward": 2.2663354873657227, "critic_loss": 1354.54931640625, "actor_loss": -1684.8858642578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7115569114685059, "alpha_loss": 0.8361660838127136, "alpha_value": 1.0545276193944566, "step": 1570000}
{"duration": 18.424105644226074, "info_normalized_performance_mean": 0.5814374685287476, "info_normalized_performance_final": 0.6387500166893005, "info_performance_mean": 0.5814374685287476, "info_performance_final": 0.6387500166893005, "step": 1570000}
{"episode_reward": 1162.8749999999995, "episode": 15701.0, "batch_reward": 2.3959360122680664, "critic_loss": 1245.334228515625, "actor_loss": -1711.4447021484375, "actor_target_entropy": -3.0, "actor_entropy": 1.518207311630249, "alpha_loss": 0.5013325214385986, "alpha_value": 1.0356926761829495, "duration": 1.5228536128997803, "info_normalized_performance_mean": 0.20420165359973907, "info_normalized_performance_final": 0.21848739683628082, "info_performance_mean": 0.20420165359973907, "info_performance_final": 0.21848739683628082, "step": 1570500}
{"episode_reward": 408.4033613445386, "episode": 15706.0, "batch_reward": 3.4070425033569336, "critic_loss": 1202.58837890625, "actor_loss": -1770.446044921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4495339393615723, "alpha_loss": 0.5680386424064636, "alpha_value": 1.016954670294582, "duration": 1.4143693447113037, "info_normalized_performance_mean": 0.3994999825954437, "info_normalized_performance_final": 0.5678571462631226, "info_performance_mean": 0.3994999825954437, "info_performance_final": 0.5678571462631226, "step": 1571000}
{"episode_reward": 799.0000000000003, "episode": 15711.0, "batch_reward": 2.0813188552856445, "critic_loss": 2002.310546875, "actor_loss": -1675.20361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.5838825702667236, "alpha_loss": 0.4967373013496399, "alpha_value": 0.9975524317874895, "duration": 1.5432994365692139, "info_normalized_performance_mean": 0.30717170238494873, "info_normalized_performance_final": 0.39915281534194946, "info_performance_mean": 0.30717170238494873, "info_performance_final": 0.39915281534194946, "step": 1571500}
{"episode_reward": 614.3434343434335, "episode": 15716.0, "batch_reward": 3.0469350814819336, "critic_loss": 1697.947021484375, "actor_loss": -1616.828857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.7856452465057373, "alpha_loss": 0.9703947305679321, "alpha_value": 0.9797824435045395, "duration": 1.4647960662841797, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1572000}
{"episode_reward": 0.0, "episode": 15721.0, "batch_reward": 2.117687702178955, "critic_loss": 1194.6591796875, "actor_loss": -1691.6453857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3721330165863037, "alpha_loss": -0.08534727245569229, "alpha_value": 0.9636716490444301, "duration": 1.3906362056732178, "info_normalized_performance_mean": 0.23573730885982513, "info_normalized_performance_final": 0.2646484375, "info_performance_mean": 0.23573730885982513, "info_performance_final": 0.2646484375, "step": 1572500}
{"episode_reward": 471.474609375, "episode": 15726.0, "batch_reward": 2.5925369262695312, "critic_loss": 1069.10546875, "actor_loss": -1657.7119140625, "actor_target_entropy": -3.0, "actor_entropy": 1.4606053829193115, "alpha_loss": 0.42046207189559937, "alpha_value": 0.9444075401211466, "duration": 1.4277141094207764, "info_normalized_performance_mean": 0.02160000056028366, "info_normalized_performance_final": 0.02666666731238365, "info_performance_mean": 0.02160000056028366, "info_performance_final": 0.02666666731238365, "step": 1573000}
{"episode_reward": 43.2, "episode": 15731.0, "batch_reward": 3.276817798614502, "critic_loss": 941.844970703125, "actor_loss": -1600.5225830078125, "actor_target_entropy": -3.0, "actor_entropy": 1.516510009765625, "alpha_loss": 0.1158398687839508, "alpha_value": 0.9260441746252625, "duration": 1.5843043327331543, "info_normalized_performance_mean": 0.33008572459220886, "info_normalized_performance_final": 0.4446153938770294, "info_performance_mean": 0.33008572459220886, "info_performance_final": 0.4446153938770294, "step": 1573500}
{"episode_reward": 660.1714285714277, "episode": 15736.0, "batch_reward": 3.3638062477111816, "critic_loss": 1254.896728515625, "actor_loss": -1568.699462890625, "actor_target_entropy": -3.0, "actor_entropy": 1.2198047637939453, "alpha_loss": 0.13637368381023407, "alpha_value": 0.9125872310861077, "duration": 1.402618646621704, "info_normalized_performance_mean": 0.29295140504837036, "info_normalized_performance_final": 0.3107638955116272, "info_performance_mean": 0.29295140504837036, "info_performance_final": 0.3107638955116272, "step": 1574000}
{"episode_reward": 585.9027777777779, "episode": 15741.0, "batch_reward": 1.8561601638793945, "critic_loss": 1017.646728515625, "actor_loss": -1609.288818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.0872890949249268, "alpha_loss": -0.606275200843811, "alpha_value": 0.9021647183543167, "duration": 1.4823806285858154, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1574500}
{"episode_reward": 0.0, "episode": 15746.0, "batch_reward": 2.88273286819458, "critic_loss": 964.5938110351562, "actor_loss": -1552.4588623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.4585168361663818, "alpha_loss": 0.24713656306266785, "alpha_value": 0.8934009168576682, "duration": 1.4926550388336182, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1575000}
{"episode_reward": 0.0, "episode": 15751.0, "batch_reward": 3.9965968132019043, "critic_loss": 909.2365112304688, "actor_loss": -1558.59521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.5012493133544922, "alpha_loss": -0.07428327202796936, "alpha_value": 0.8835736139923177, "duration": 1.5529940128326416, "info_normalized_performance_mean": 0.28318408131599426, "info_normalized_performance_final": 0.3477272689342499, "info_performance_mean": 0.28318408131599426, "info_performance_final": 0.3477272689342499, "step": 1575500}
{"episode_reward": 566.3681818181815, "episode": 15756.0, "batch_reward": 3.278179407119751, "critic_loss": 644.45166015625, "actor_loss": -1539.63916015625, "actor_target_entropy": -3.0, "actor_entropy": 1.2949868440628052, "alpha_loss": 0.5732994079589844, "alpha_value": 0.8791971232627278, "duration": 1.6066348552703857, "info_normalized_performance_mean": 0.6841309070587158, "info_normalized_performance_final": 0.7169230580329895, "info_performance_mean": 0.6841309070587158, "info_performance_final": 0.7169230580329895, "step": 1576000}
{"episode_reward": 1368.2615384615394, "episode": 15761.0, "batch_reward": 3.028503179550171, "critic_loss": 1055.431396484375, "actor_loss": -1508.1904296875, "actor_target_entropy": -3.0, "actor_entropy": 1.8129335641860962, "alpha_loss": 0.09784705936908722, "alpha_value": 0.8722981738428697, "duration": 1.481285810470581, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1576500}
{"episode_reward": 0.0, "episode": 15766.0, "batch_reward": 2.549619436264038, "critic_loss": 1011.778564453125, "actor_loss": -1493.275390625, "actor_target_entropy": -3.0, "actor_entropy": 0.8979653120040894, "alpha_loss": -0.41159504652023315, "alpha_value": 0.8692714703175436, "duration": 1.563316822052002, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1577000}
{"episode_reward": 0.0, "episode": 15771.0, "batch_reward": 2.7651402950286865, "critic_loss": 1644.0555419921875, "actor_loss": -1438.840576171875, "actor_target_entropy": -3.0, "actor_entropy": 1.8456621170043945, "alpha_loss": 0.1878657042980194, "alpha_value": 0.8670657391382297, "duration": 1.64739990234375, "info_normalized_performance_mean": 0.4582539498806, "info_normalized_performance_final": 0.5476190447807312, "info_performance_mean": 0.4582539498806, "info_performance_final": 0.5476190447807312, "step": 1577500}
{"episode_reward": 916.5079365079372, "episode": 15776.0, "batch_reward": 3.9828577041625977, "critic_loss": 1015.9198608398438, "actor_loss": -1556.6871337890625, "actor_target_entropy": -3.0, "actor_entropy": 1.3676362037658691, "alpha_loss": 0.04919266700744629, "alpha_value": 0.8608736762960874, "duration": 1.4394001960754395, "info_normalized_performance_mean": 0.4219270348548889, "info_normalized_performance_final": 0.4466145932674408, "info_performance_mean": 0.4219270348548889, "info_performance_final": 0.4466145932674408, "step": 1578000}
{"episode_reward": 843.8541666666656, "episode": 15781.0, "batch_reward": 3.451907157897949, "critic_loss": 1193.8634033203125, "actor_loss": -1458.81787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.9092751741409302, "alpha_loss": 0.3521089553833008, "alpha_value": 0.8617235054289782, "duration": 1.601593255996704, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1578500}
{"episode_reward": 0.0, "episode": 15786.0, "batch_reward": 3.2330031394958496, "critic_loss": 1151.39453125, "actor_loss": -1534.2703857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.5550310611724854, "alpha_loss": -0.19664430618286133, "alpha_value": 0.8630881167651532, "duration": 1.5982167720794678, "info_normalized_performance_mean": 0.38723617792129517, "info_normalized_performance_final": 0.43263888359069824, "info_performance_mean": 0.38723617792129517, "info_performance_final": 0.43263888359069824, "step": 1579000}
{"episode_reward": 774.4722222222234, "episode": 15791.0, "batch_reward": 2.526296615600586, "critic_loss": 787.4354248046875, "actor_loss": -1423.7210693359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2579082250595093, "alpha_loss": 0.030160270631313324, "alpha_value": 0.8631785459019149, "duration": 1.530250072479248, "info_normalized_performance_mean": 0.5973357558250427, "info_normalized_performance_final": 0.7236160635948181, "info_performance_mean": 0.5973357558250427, "info_performance_final": 0.7236160635948181, "step": 1579500}
{"episode_reward": 1194.671445639186, "episode": 15796.0, "batch_reward": 3.567964553833008, "critic_loss": 4070.87890625, "actor_loss": -1464.951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.604222297668457, "alpha_loss": 0.3596627116203308, "alpha_value": 0.8594865912206072, "step": 1580000}
{"duration": 18.29569363594055, "info_normalized_performance_mean": 0.4487142264842987, "info_normalized_performance_final": 0.513671875, "info_performance_mean": 0.4487142264842987, "info_performance_final": 0.513671875, "step": 1580000}
{"episode_reward": 897.4283854166666, "episode": 15801.0, "batch_reward": 3.8344807624816895, "critic_loss": 1428.574951171875, "actor_loss": -1474.130859375, "actor_target_entropy": -3.0, "actor_entropy": 1.9341789484024048, "alpha_loss": 0.27777186036109924, "alpha_value": 0.8514847280156015, "duration": 1.612311601638794, "info_normalized_performance_mean": 0.5115238428115845, "info_normalized_performance_final": 0.5746031999588013, "info_performance_mean": 0.5115238428115845, "info_performance_final": 0.5746031999588013, "step": 1580500}
{"episode_reward": 1023.0476190476192, "episode": 15806.0, "batch_reward": 3.043069362640381, "critic_loss": 897.4366455078125, "actor_loss": -1371.064208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.6567597389221191, "alpha_loss": 0.09500385820865631, "alpha_value": 0.8519407142749076, "duration": 1.479790210723877, "info_normalized_performance_mean": 0.6743972301483154, "info_normalized_performance_final": 0.7321428656578064, "info_performance_mean": 0.6743972301483154, "info_performance_final": 0.7321428656578064, "step": 1581000}
{"episode_reward": 1348.7946428571413, "episode": 15811.0, "batch_reward": 3.488776445388794, "critic_loss": 853.73681640625, "actor_loss": -1394.1201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.6945469379425049, "alpha_loss": 0.2381024956703186, "alpha_value": 0.8476181383843095, "duration": 1.5162262916564941, "info_normalized_performance_mean": 0.402843177318573, "info_normalized_performance_final": 0.45980390906333923, "info_performance_mean": 0.402843177318573, "info_performance_final": 0.45980390906333923, "step": 1581500}
{"episode_reward": 805.6862745098051, "episode": 15816.0, "batch_reward": 3.2716617584228516, "critic_loss": 2393.3466796875, "actor_loss": -1358.1800537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.6343785524368286, "alpha_loss": 0.23848003149032593, "alpha_value": 0.847626893620149, "duration": 1.456160068511963, "info_normalized_performance_mean": 0.3112308979034424, "info_normalized_performance_final": 0.35522958636283875, "info_performance_mean": 0.3112308979034424, "info_performance_final": 0.35522958636283875, "step": 1582000}
{"episode_reward": 622.4617346938777, "episode": 15821.0, "batch_reward": 3.049961566925049, "critic_loss": 1167.9134521484375, "actor_loss": -1387.352294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.8063877820968628, "alpha_loss": 0.2318461835384369, "alpha_value": 0.8375075038034357, "duration": 1.6143608093261719, "info_normalized_performance_mean": 0.6033499836921692, "info_normalized_performance_final": 0.6863636374473572, "info_performance_mean": 0.6033499836921692, "info_performance_final": 0.6863636374473572, "step": 1582500}
{"episode_reward": 1206.7000000000014, "episode": 15826.0, "batch_reward": 3.246321201324463, "critic_loss": 629.7996215820312, "actor_loss": -1343.869384765625, "actor_target_entropy": -3.0, "actor_entropy": 1.4880597591400146, "alpha_loss": 0.25977298617362976, "alpha_value": 0.8320080242782069, "duration": 1.5619421005249023, "info_normalized_performance_mean": 0.4891665577888489, "info_normalized_performance_final": 0.5990195870399475, "info_performance_mean": 0.4891665577888489, "info_performance_final": 0.5990195870399475, "step": 1583000}
{"episode_reward": 978.3333333333342, "episode": 15831.0, "batch_reward": 3.01932954788208, "critic_loss": 1299.805419921875, "actor_loss": -1372.369384765625, "actor_target_entropy": -3.0, "actor_entropy": 1.3239028453826904, "alpha_loss": -0.13957929611206055, "alpha_value": 0.8259376248694653, "duration": 1.5829486846923828, "info_normalized_performance_mean": 0.6889410614967346, "info_normalized_performance_final": 0.8500000238418579, "info_performance_mean": 0.6889410614967346, "info_performance_final": 0.8500000238418579, "step": 1583500}
{"episode_reward": 1377.8823529411766, "episode": 15836.0, "batch_reward": 3.105193853378296, "critic_loss": 1350.345458984375, "actor_loss": -1411.982666015625, "actor_target_entropy": -3.0, "actor_entropy": 1.564523458480835, "alpha_loss": 0.17476414144039154, "alpha_value": 0.8271675482224388, "duration": 1.6687302589416504, "info_normalized_performance_mean": 0.6005300283432007, "info_normalized_performance_final": 0.6959999799728394, "info_performance_mean": 0.6005300283432007, "info_performance_final": 0.6959999799728394, "step": 1584000}
{"episode_reward": 1201.0599999999997, "episode": 15841.0, "batch_reward": 2.4099204540252686, "critic_loss": 1602.73828125, "actor_loss": -1288.5740966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.8251078128814697, "alpha_loss": 0.09414876997470856, "alpha_value": 0.8228740672956893, "duration": 1.6174769401550293, "info_normalized_performance_mean": 0.40261879563331604, "info_normalized_performance_final": 0.5252083539962769, "info_performance_mean": 0.40261879563331604, "info_performance_final": 0.5252083539962769, "step": 1584500}
{"episode_reward": 805.2375000000015, "episode": 15846.0, "batch_reward": 3.6118040084838867, "critic_loss": 819.404541015625, "actor_loss": -1330.286865234375, "actor_target_entropy": -3.0, "actor_entropy": 1.883358359336853, "alpha_loss": 0.43825480341911316, "alpha_value": 0.8226640950289303, "duration": 1.8794529438018799, "info_normalized_performance_mean": 0.6184820532798767, "info_normalized_performance_final": 0.7910787463188171, "info_performance_mean": 0.6184820532798767, "info_performance_final": 0.7910787463188171, "step": 1585000}
{"episode_reward": 1236.9640418752863, "episode": 15851.0, "batch_reward": 3.963639497756958, "critic_loss": 990.3233032226562, "actor_loss": -1364.6181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.88052499294281, "alpha_loss": 0.3006835877895355, "alpha_value": 0.8202034424737384, "duration": 1.5308892726898193, "info_normalized_performance_mean": 0.6505919098854065, "info_normalized_performance_final": 0.7755101919174194, "info_performance_mean": 0.6505919098854065, "info_performance_final": 0.7755101919174194, "step": 1585500}
{"episode_reward": 1301.1836734693895, "episode": 15856.0, "batch_reward": 3.2978463172912598, "critic_loss": 1284.70849609375, "actor_loss": -1407.0438232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.5583350658416748, "alpha_loss": -0.631403386592865, "alpha_value": 0.8284992268478868, "duration": 1.6412920951843262, "info_normalized_performance_mean": 0.5062807202339172, "info_normalized_performance_final": 0.61307692527771, "info_performance_mean": 0.5062807202339172, "info_performance_final": 0.61307692527771, "step": 1586000}
{"episode_reward": 1012.5615384615363, "episode": 15861.0, "batch_reward": 2.785695791244507, "critic_loss": 555.989013671875, "actor_loss": -1297.645751953125, "actor_target_entropy": -3.0, "actor_entropy": 1.5463194847106934, "alpha_loss": -0.0197107195854187, "alpha_value": 0.8349002162303563, "duration": 1.5942351818084717, "info_normalized_performance_mean": 0.26545819640159607, "info_normalized_performance_final": 0.3276353180408478, "info_performance_mean": 0.26545819640159607, "info_performance_final": 0.3276353180408478, "step": 1586500}
{"episode_reward": 530.9164292497638, "episode": 15866.0, "batch_reward": 4.050013065338135, "critic_loss": 2948.9404296875, "actor_loss": -1403.250244140625, "actor_target_entropy": -3.0, "actor_entropy": 1.468424677848816, "alpha_loss": -0.1753798872232437, "alpha_value": 0.8379454441606533, "duration": 1.514603614807129, "info_normalized_performance_mean": 0.4020320177078247, "info_normalized_performance_final": 0.4310160279273987, "info_performance_mean": 0.4020320177078247, "info_performance_final": 0.4310160279273987, "step": 1587000}
{"episode_reward": 804.0641711229949, "episode": 15871.0, "batch_reward": 3.6046926975250244, "critic_loss": 799.6456298828125, "actor_loss": -1357.53173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.4038848876953125, "alpha_loss": -0.1728413999080658, "alpha_value": 0.8349845309013213, "duration": 1.4746947288513184, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1587500}
{"episode_reward": 0.0, "episode": 15876.0, "batch_reward": 3.2816076278686523, "critic_loss": 722.6094970703125, "actor_loss": -1326.998779296875, "actor_target_entropy": -3.0, "actor_entropy": 1.804511308670044, "alpha_loss": 0.23075959086418152, "alpha_value": 0.8311812974799715, "duration": 1.6394338607788086, "info_normalized_performance_mean": 0.5936574339866638, "info_normalized_performance_final": 0.704365074634552, "info_performance_mean": 0.5936574339866638, "info_performance_final": 0.704365074634552, "step": 1588000}
{"episode_reward": 1187.3148148148148, "episode": 15881.0, "batch_reward": 3.4198875427246094, "critic_loss": 850.59814453125, "actor_loss": -1349.988525390625, "actor_target_entropy": -3.0, "actor_entropy": 1.6655409336090088, "alpha_loss": -0.12368524074554443, "alpha_value": 0.8345323887304457, "duration": 1.6078989505767822, "info_normalized_performance_mean": 0.5840363502502441, "info_normalized_performance_final": 0.6418181657791138, "info_performance_mean": 0.5840363502502441, "info_performance_final": 0.6418181657791138, "step": 1588500}
{"episode_reward": 1168.0727272727274, "episode": 15886.0, "batch_reward": 4.129734039306641, "critic_loss": 1174.083984375, "actor_loss": -1273.9908447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.5991647243499756, "alpha_loss": 0.44575226306915283, "alpha_value": 0.8431322253759588, "duration": 1.5083444118499756, "info_normalized_performance_mean": 0.12817272543907166, "info_normalized_performance_final": 0.13636364042758942, "info_performance_mean": 0.12817272543907166, "info_performance_final": 0.13636364042758942, "step": 1589000}
{"episode_reward": 256.3454545454543, "episode": 15891.0, "batch_reward": 2.7338204383850098, "critic_loss": 3304.31982421875, "actor_loss": -1326.3724365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.512170672416687, "alpha_loss": -0.20696260035037994, "alpha_value": 0.8441639335514125, "duration": 1.6449530124664307, "info_normalized_performance_mean": 0.5875794291496277, "info_normalized_performance_final": 0.7129629850387573, "info_performance_mean": 0.5875794291496277, "info_performance_final": 0.7129629850387573, "step": 1589500}
{"episode_reward": 1175.1587301587301, "episode": 15896.0, "batch_reward": 3.6388134956359863, "critic_loss": 661.9832763671875, "actor_loss": -1294.7425537109375, "actor_target_entropy": -3.0, "actor_entropy": 1.8249197006225586, "alpha_loss": 0.08330811560153961, "alpha_value": 0.8501891457211372, "step": 1590000}
{"duration": 19.35325574874878, "info_normalized_performance_mean": 0.34902679920196533, "info_normalized_performance_final": 0.37112298607826233, "info_performance_mean": 0.34902679920196533, "info_performance_final": 0.37112298607826233, "step": 1590000}
{"episode_reward": 698.0534759358285, "episode": 15901.0, "batch_reward": 3.166269063949585, "critic_loss": 2035.4617919921875, "actor_loss": -1410.5968017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.469404697418213, "alpha_loss": -0.29324182868003845, "alpha_value": 0.8595170969003625, "duration": 1.4998867511749268, "info_normalized_performance_mean": 0.38949406147003174, "info_normalized_performance_final": 0.46352940797805786, "info_performance_mean": 0.38949406147003174, "info_performance_final": 0.46352940797805786, "step": 1590500}
{"episode_reward": 778.9882352941167, "episode": 15906.0, "batch_reward": 3.7163379192352295, "critic_loss": 2953.2314453125, "actor_loss": -1383.4052734375, "actor_target_entropy": -3.0, "actor_entropy": 1.557368278503418, "alpha_loss": -0.27337831258773804, "alpha_value": 0.8633010991349621, "duration": 1.467391014099121, "info_normalized_performance_mean": 0.7148178219795227, "info_normalized_performance_final": 0.7630208134651184, "info_performance_mean": 0.7148178219795227, "info_performance_final": 0.7630208134651184, "step": 1591000}
{"episode_reward": 1429.6354166666677, "episode": 15911.0, "batch_reward": 4.307518005371094, "critic_loss": 2302.3212890625, "actor_loss": -1421.5360107421875, "actor_target_entropy": -3.0, "actor_entropy": 1.3733882904052734, "alpha_loss": -0.23036052286624908, "alpha_value": 0.8647440173822492, "duration": 1.4918849468231201, "info_normalized_performance_mean": 0.5208398699760437, "info_normalized_performance_final": 0.68359375, "info_performance_mean": 0.5208398699760437, "info_performance_final": 0.68359375, "step": 1591500}
{"episode_reward": 1041.6796875, "episode": 15916.0, "batch_reward": 3.658651828765869, "critic_loss": 1285.5775146484375, "actor_loss": -1330.4176025390625, "actor_target_entropy": -3.0, "actor_entropy": 1.6625233888626099, "alpha_loss": 0.2104281336069107, "alpha_value": 0.8657094824614691, "duration": 1.5624785423278809, "info_normalized_performance_mean": 0.011142859235405922, "info_normalized_performance_final": 0.02857142873108387, "info_performance_mean": 0.011142859235405922, "info_performance_final": 0.02857142873108387, "step": 1592000}
{"episode_reward": 22.2857142857143, "episode": 15921.0, "batch_reward": 2.861222743988037, "critic_loss": 1368.8363037109375, "actor_loss": -1482.9388427734375, "actor_target_entropy": -3.0, "actor_entropy": 1.5826057195663452, "alpha_loss": -0.4498549699783325, "alpha_value": 0.858294662089313, "duration": 1.411592960357666, "info_normalized_performance_mean": 0.19296425580978394, "info_normalized_performance_final": 0.2142857164144516, "info_performance_mean": 0.19296425580978394, "info_performance_final": 0.2142857164144516, "step": 1592500}
{"episode_reward": 385.92857142857105, "episode": 15926.0, "batch_reward": 3.9391536712646484, "critic_loss": 1555.18408203125, "actor_loss": -1291.609130859375, "actor_target_entropy": -3.0, "actor_entropy": 1.7069731950759888, "alpha_loss": 0.5541363954544067, "alpha_value": 0.8532601036551142, "duration": 1.607961893081665, "info_normalized_performance_mean": 0.39912697672843933, "info_normalized_performance_final": 0.469696968793869, "info_performance_mean": 0.39912697672843933, "info_performance_final": 0.469696968793869, "step": 1593000}
{"episode_reward": 798.2539682539675, "episode": 15931.0, "batch_reward": 3.512010097503662, "critic_loss": 2677.3759765625, "actor_loss": -1377.4150390625, "actor_target_entropy": -3.0, "actor_entropy": 1.2630553245544434, "alpha_loss": 0.17843373119831085, "alpha_value": 0.8529347205543955, "duration": 1.5969762802124023, "info_normalized_performance_mean": 0.47839686274528503, "info_normalized_performance_final": 0.6666666865348816, "info_performance_mean": 0.47839686274528503, "info_performance_final": 0.6666666865348816, "step": 1593500}
{"episode_reward": 956.7936507936519, "episode": 15936.0, "batch_reward": 4.542171001434326, "critic_loss": 1848.94482421875, "actor_loss": -1350.9808349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.598577857017517, "alpha_loss": 0.4151654839515686, "alpha_value": 0.8475341667622015, "duration": 1.5272960662841797, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1594000}
{"episode_reward": 0.0, "episode": 15941.0, "batch_reward": 3.3256373405456543, "critic_loss": 1596.61376953125, "actor_loss": -1430.613525390625, "actor_target_entropy": -3.0, "actor_entropy": 1.4408998489379883, "alpha_loss": -0.5490341186523438, "alpha_value": 0.8556736180769502, "duration": 1.450875997543335, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1594500}
{"episode_reward": 0.0, "episode": 15946.0, "batch_reward": 3.8850834369659424, "critic_loss": 1260.652099609375, "actor_loss": -1452.834228515625, "actor_target_entropy": -3.0, "actor_entropy": 1.4082649946212769, "alpha_loss": -0.4155347943305969, "alpha_value": 0.8863978858115683, "duration": 1.5388858318328857, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1595000}
{"episode_reward": 0.0, "episode": 15951.0, "batch_reward": 4.155311584472656, "critic_loss": 4235.80517578125, "actor_loss": -1705.047607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.418119192123413, "alpha_loss": -0.9873809814453125, "alpha_value": 0.9124482962413972, "duration": 1.4410266876220703, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1595500}
{"episode_reward": 0.0, "episode": 15956.0, "batch_reward": 4.2394490242004395, "critic_loss": 2301.25146484375, "actor_loss": -1631.497314453125, "actor_target_entropy": -3.0, "actor_entropy": 1.502099633216858, "alpha_loss": -0.15343281626701355, "alpha_value": 0.9340786218146525, "duration": 1.6115362644195557, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1596000}
{"episode_reward": 0.0, "episode": 15961.0, "batch_reward": 4.053781509399414, "critic_loss": 3625.85986328125, "actor_loss": -1796.48876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.4911234378814697, "alpha_loss": -0.7224351167678833, "alpha_value": 0.9635023921887674, "duration": 1.526428461074829, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1596500}
{"episode_reward": 0.0, "episode": 15966.0, "batch_reward": 2.952402114868164, "critic_loss": 6719.45849609375, "actor_loss": -1885.476806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.2728363275527954, "alpha_loss": -1.3630003929138184, "alpha_value": 0.992390862063016, "duration": 1.588219404220581, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1597000}
{"episode_reward": 0.0, "episode": 15971.0, "batch_reward": 3.9691038131713867, "critic_loss": 8184.0361328125, "actor_loss": -1795.1595458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3910136222839355, "alpha_loss": -0.22438231110572815, "alpha_value": 1.01440366701305, "duration": 1.5805182456970215, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1597500}
{"episode_reward": 0.0, "episode": 15976.0, "batch_reward": 4.329839706420898, "critic_loss": 2831.3310546875, "actor_loss": -1776.556396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.9250390529632568, "alpha_loss": -0.21265026926994324, "alpha_value": 1.03570694760908, "duration": 1.5488293170928955, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1598000}
{"episode_reward": 0.0, "episode": 15981.0, "batch_reward": 3.95395565032959, "critic_loss": 2898.48779296875, "actor_loss": -1826.220458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.155347228050232, "alpha_loss": 0.5126819610595703, "alpha_value": 1.0470161972333676, "duration": 1.4548969268798828, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1598500}
{"episode_reward": 0.0, "episode": 15986.0, "batch_reward": 4.093480110168457, "critic_loss": 1958.12890625, "actor_loss": -1870.18359375, "actor_target_entropy": -3.0, "actor_entropy": 1.088820219039917, "alpha_loss": -0.5107206106185913, "alpha_value": 1.0637241134023534, "duration": 1.5213813781738281, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1599000}
{"episode_reward": 0.0, "episode": 15991.0, "batch_reward": 3.751636028289795, "critic_loss": 2932.47802734375, "actor_loss": -2085.30810546875, "actor_target_entropy": -3.0, "actor_entropy": 1.5297991037368774, "alpha_loss": -1.1261012554168701, "alpha_value": 1.089513335620884, "duration": 1.5170071125030518, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1599500}
{"episode_reward": 0.0, "episode": 15996.0, "batch_reward": 4.577770233154297, "critic_loss": 2743.70751953125, "actor_loss": -2354.921630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.5415570735931396, "alpha_loss": -1.1430697441101074, "alpha_value": 1.122073511940465, "step": 1600000}
{"duration": 18.853333711624146, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1600000}
{"episode_reward": 0.0, "episode": 16001.0, "batch_reward": 3.4889721870422363, "critic_loss": 3192.901611328125, "actor_loss": -2050.80810546875, "actor_target_entropy": -3.0, "actor_entropy": 1.8982360363006592, "alpha_loss": -1.0630897283554077, "alpha_value": 1.157324484261738, "duration": 1.5660550594329834, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1600500}
{"episode_reward": 0.0, "episode": 16006.0, "batch_reward": 3.4155163764953613, "critic_loss": 6373.67724609375, "actor_loss": -2283.057373046875, "actor_target_entropy": -3.0, "actor_entropy": 2.039876937866211, "alpha_loss": -0.06859360635280609, "alpha_value": 1.1937987029467256, "duration": 1.5574281215667725, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1601000}
{"episode_reward": 0.0, "episode": 16011.0, "batch_reward": 3.738712787628174, "critic_loss": 2939.85888671875, "actor_loss": -2164.759765625, "actor_target_entropy": -3.0, "actor_entropy": 1.9076035022735596, "alpha_loss": -0.8566243648529053, "alpha_value": 1.2303751414511865, "duration": 1.5240530967712402, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1601500}
{"episode_reward": 0.0, "episode": 16016.0, "batch_reward": 3.7732741832733154, "critic_loss": 3660.53955078125, "actor_loss": -2102.792724609375, "actor_target_entropy": -3.0, "actor_entropy": 1.806344985961914, "alpha_loss": -0.8943608403205872, "alpha_value": 1.2635816307904095, "duration": 1.5294275283813477, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1602000}
{"episode_reward": 0.0, "episode": 16021.0, "batch_reward": 4.057390213012695, "critic_loss": 8607.080078125, "actor_loss": -2104.7607421875, "actor_target_entropy": -3.0, "actor_entropy": 2.0464744567871094, "alpha_loss": -0.8007513284683228, "alpha_value": 1.3016974860322008, "duration": 1.549177885055542, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1602500}
{"episode_reward": 0.0, "episode": 16026.0, "batch_reward": 3.7663581371307373, "critic_loss": 4554.2724609375, "actor_loss": -2292.310546875, "actor_target_entropy": -3.0, "actor_entropy": 2.0444719791412354, "alpha_loss": -0.8580780029296875, "alpha_value": 1.3286860252565897, "duration": 1.5324907302856445, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1603000}
{"episode_reward": 0.0, "episode": 16031.0, "batch_reward": 4.229989528656006, "critic_loss": 4568.5380859375, "actor_loss": -2241.355224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.8268498182296753, "alpha_loss": -0.8705732226371765, "alpha_value": 1.3585071932824242, "duration": 1.673837423324585, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1603500}
{"episode_reward": 0.0, "episode": 16036.0, "batch_reward": 3.985915422439575, "critic_loss": 4283.16455078125, "actor_loss": -2152.571533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.7641122341156006, "alpha_loss": -0.44190242886543274, "alpha_value": 1.3774230603063002, "duration": 1.5066401958465576, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1604000}
{"episode_reward": 0.0, "episode": 16041.0, "batch_reward": 3.7566490173339844, "critic_loss": 4468.2138671875, "actor_loss": -2296.418701171875, "actor_target_entropy": -3.0, "actor_entropy": 1.697765588760376, "alpha_loss": -0.396289587020874, "alpha_value": 1.3939104454620954, "duration": 1.4194810390472412, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1604500}
{"episode_reward": 0.0, "episode": 16046.0, "batch_reward": 3.6740431785583496, "critic_loss": 2798.056640625, "actor_loss": -2442.397705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.7743473052978516, "alpha_loss": 0.1602577269077301, "alpha_value": 1.3995194811023772, "duration": 1.5646693706512451, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1605000}
{"episode_reward": 0.0, "episode": 16051.0, "batch_reward": 4.1972784996032715, "critic_loss": 10301.2099609375, "actor_loss": -2288.056884765625, "actor_target_entropy": -3.0, "actor_entropy": 1.9094009399414062, "alpha_loss": 0.07441408932209015, "alpha_value": 1.4143999306513162, "duration": 1.5039207935333252, "info_normalized_performance_mean": 0.010150001384317875, "info_normalized_performance_final": 0.011666666716337204, "info_performance_mean": 0.010150001384317875, "info_performance_final": 0.011666666716337204, "step": 1605500}
{"episode_reward": 20.29999999999999, "episode": 16056.0, "batch_reward": 3.689920425415039, "critic_loss": 4221.47802734375, "actor_loss": -2208.705322265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6124775409698486, "alpha_loss": 0.4131278395652771, "alpha_value": 1.418912130415227, "duration": 1.4398624897003174, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1606000}
{"episode_reward": 0.0, "episode": 16061.0, "batch_reward": 3.507293462753296, "critic_loss": 2849.368896484375, "actor_loss": -2244.311767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.958836555480957, "alpha_loss": -0.6328915357589722, "alpha_value": 1.421170723449955, "duration": 1.4580457210540771, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1606500}
{"episode_reward": 0.0, "episode": 16066.0, "batch_reward": 4.099604606628418, "critic_loss": 4346.6162109375, "actor_loss": -2430.162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.8948355913162231, "alpha_loss": 0.00024278461933135986, "alpha_value": 1.4279822442280163, "duration": 1.5571105480194092, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1607000}
{"episode_reward": 0.0, "episode": 16071.0, "batch_reward": 3.8281357288360596, "critic_loss": 2958.70703125, "actor_loss": -2277.39013671875, "actor_target_entropy": -3.0, "actor_entropy": 1.8727781772613525, "alpha_loss": 0.12030518054962158, "alpha_value": 1.4385666603073253, "duration": 1.5074388980865479, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1607500}
{"episode_reward": 0.0, "episode": 16076.0, "batch_reward": 4.174587249755859, "critic_loss": 8364.4921875, "actor_loss": -2240.755859375, "actor_target_entropy": -3.0, "actor_entropy": 1.7805116176605225, "alpha_loss": -0.8908675909042358, "alpha_value": 1.449849840054085, "duration": 1.4854583740234375, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1608000}
{"episode_reward": 0.0, "episode": 16081.0, "batch_reward": 3.132824420928955, "critic_loss": 5885.9853515625, "actor_loss": -2421.064697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.6045794486999512, "alpha_loss": -0.19851353764533997, "alpha_value": 1.4581369682206597, "duration": 1.4870266914367676, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1608500}
{"episode_reward": 0.0, "episode": 16086.0, "batch_reward": 4.010590076446533, "critic_loss": 2138.134033203125, "actor_loss": -2261.15966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.7986335754394531, "alpha_loss": 0.4277024269104004, "alpha_value": 1.4574185761628067, "duration": 1.4360229969024658, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1609000}
{"episode_reward": 0.0, "episode": 16091.0, "batch_reward": 4.4401702880859375, "critic_loss": 5083.705078125, "actor_loss": -2102.50830078125, "actor_target_entropy": -3.0, "actor_entropy": 1.5563479661941528, "alpha_loss": -0.08604276925325394, "alpha_value": 1.440239786080017, "duration": 1.5632643699645996, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1609500}
{"episode_reward": 0.0, "episode": 16096.0, "batch_reward": 3.2566092014312744, "critic_loss": 4529.25732421875, "actor_loss": -2375.987060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.872388482093811, "alpha_loss": -0.07439305633306503, "alpha_value": 1.4300277920846094, "step": 1610000}
{"duration": 18.88335871696472, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1610000}
{"episode_reward": 0.0, "episode": 16101.0, "batch_reward": 3.242009401321411, "critic_loss": 3437.87939453125, "actor_loss": -2329.61572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.7831125259399414, "alpha_loss": 0.5789361000061035, "alpha_value": 1.4162920326890944, "duration": 1.489011526107788, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1610500}
{"episode_reward": 0.0, "episode": 16106.0, "batch_reward": 3.784742593765259, "critic_loss": 2610.576171875, "actor_loss": -2268.588623046875, "actor_target_entropy": -3.0, "actor_entropy": 2.033050298690796, "alpha_loss": 0.7788692116737366, "alpha_value": 1.3995922262495923, "duration": 1.5502283573150635, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1611000}
{"episode_reward": 0.0, "episode": 16111.0, "batch_reward": 3.67319655418396, "critic_loss": 4457.98779296875, "actor_loss": -2270.005859375, "actor_target_entropy": -3.0, "actor_entropy": 1.6389667987823486, "alpha_loss": 0.5327783823013306, "alpha_value": 1.3788473307156264, "duration": 1.4866011142730713, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1611500}
{"episode_reward": 0.0, "episode": 16116.0, "batch_reward": 3.094404697418213, "critic_loss": 5803.09814453125, "actor_loss": -2182.218994140625, "actor_target_entropy": -3.0, "actor_entropy": 1.4628422260284424, "alpha_loss": -0.808219850063324, "alpha_value": 1.3629055004118524, "duration": 1.51621413230896, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1612000}
{"episode_reward": 0.0, "episode": 16121.0, "batch_reward": 3.678136110305786, "critic_loss": 3195.5009765625, "actor_loss": -2288.69384765625, "actor_target_entropy": -3.0, "actor_entropy": 2.031869649887085, "alpha_loss": 0.4995603561401367, "alpha_value": 1.3474532499050416, "duration": 1.4548709392547607, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1612500}
{"episode_reward": 0.0, "episode": 16126.0, "batch_reward": 3.857577085494995, "critic_loss": 11743.5537109375, "actor_loss": -2290.488037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.9348583221435547, "alpha_loss": 0.3067527413368225, "alpha_value": 1.3265670296201897, "duration": 1.5466959476470947, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1613000}
{"episode_reward": 0.0, "episode": 16131.0, "batch_reward": 4.619448661804199, "critic_loss": 3287.303466796875, "actor_loss": -2265.66943359375, "actor_target_entropy": -3.0, "actor_entropy": 1.6664462089538574, "alpha_loss": 0.7730690836906433, "alpha_value": 1.3131542053608403, "duration": 1.5562331676483154, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1613500}
{"episode_reward": 0.0, "episode": 16136.0, "batch_reward": 3.446995258331299, "critic_loss": 4549.4775390625, "actor_loss": -2236.2529296875, "actor_target_entropy": -3.0, "actor_entropy": 1.4703789949417114, "alpha_loss": 0.19036772847175598, "alpha_value": 1.295188325087317, "duration": 1.5808744430541992, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1614000}
{"episode_reward": 0.0, "episode": 16141.0, "batch_reward": 4.066298961639404, "critic_loss": 22407.37890625, "actor_loss": -2128.44775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.756714940071106, "alpha_loss": 0.5129605531692505, "alpha_value": 1.2744600134841975, "duration": 1.5030548572540283, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1614500}
{"episode_reward": 0.0, "episode": 16146.0, "batch_reward": 3.3752102851867676, "critic_loss": 4329.6708984375, "actor_loss": -2198.024169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6043521165847778, "alpha_loss": 0.3413422703742981, "alpha_value": 1.2487291403172434, "duration": 1.4653174877166748, "info_normalized_performance_mean": 0.0187611635774374, "info_normalized_performance_final": 0.02287946455180645, "info_performance_mean": 0.0187611635774374, "info_performance_final": 0.02287946455180645, "step": 1615000}
{"episode_reward": 37.522321428571395, "episode": 16151.0, "batch_reward": 3.272881507873535, "critic_loss": 2628.6845703125, "actor_loss": -2246.532958984375, "actor_target_entropy": -3.0, "actor_entropy": 1.750760555267334, "alpha_loss": 0.0789719820022583, "alpha_value": 1.2228431361590817, "duration": 1.526026725769043, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1615500}
{"episode_reward": 0.0, "episode": 16156.0, "batch_reward": 3.9833641052246094, "critic_loss": 3161.845458984375, "actor_loss": -2107.3515625, "actor_target_entropy": -3.0, "actor_entropy": 1.5228855609893799, "alpha_loss": 0.8246428370475769, "alpha_value": 1.2017474484138497, "duration": 1.4885170459747314, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1616000}
{"episode_reward": 0.0, "episode": 16161.0, "batch_reward": 3.9227232933044434, "critic_loss": 2566.005615234375, "actor_loss": -2094.91015625, "actor_target_entropy": -3.0, "actor_entropy": 1.220818281173706, "alpha_loss": 0.26390743255615234, "alpha_value": 1.1814924757885346, "duration": 1.630016803741455, "info_normalized_performance_mean": 0.0004665978194680065, "info_normalized_performance_final": 0.0015495867701247334, "info_performance_mean": 0.0004665978194680065, "info_performance_final": 0.0015495867701247334, "step": 1616500}
{"episode_reward": 0.9331955922865008, "episode": 16166.0, "batch_reward": 3.5522263050079346, "critic_loss": 4966.29931640625, "actor_loss": -2139.26806640625, "actor_target_entropy": -3.0, "actor_entropy": 1.5226680040359497, "alpha_loss": 0.4488217532634735, "alpha_value": 1.161721586468479, "duration": 1.5188767910003662, "info_normalized_performance_mean": 0.007028387859463692, "info_normalized_performance_final": 0.01007326040416956, "info_performance_mean": 0.007028387859463692, "info_performance_final": 0.01007326040416956, "step": 1617000}
{"episode_reward": 14.056776556776539, "episode": 16171.0, "batch_reward": 4.377130508422852, "critic_loss": 3973.50732421875, "actor_loss": -2001.2635498046875, "actor_target_entropy": -3.0, "actor_entropy": 1.7100622653961182, "alpha_loss": 0.5037696361541748, "alpha_value": 1.1432055781094919, "duration": 1.5495436191558838, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1617500}
{"episode_reward": 0.0, "episode": 16176.0, "batch_reward": 3.481265068054199, "critic_loss": 1852.2275390625, "actor_loss": -2079.95703125, "actor_target_entropy": -3.0, "actor_entropy": 1.791837215423584, "alpha_loss": 0.691275954246521, "alpha_value": 1.125781073872786, "duration": 1.4722046852111816, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1618000}
{"episode_reward": 0.0, "episode": 16181.0, "batch_reward": 2.4257140159606934, "critic_loss": 2832.52783203125, "actor_loss": -2039.852294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.6152288913726807, "alpha_loss": 0.6683454513549805, "alpha_value": 1.102799845333537, "duration": 1.5032708644866943, "info_normalized_performance_mean": 0.10519097000360489, "info_normalized_performance_final": 0.1128472238779068, "info_performance_mean": 0.10519097000360489, "info_performance_final": 0.1128472238779068, "step": 1618500}
{"episode_reward": 210.38194444444483, "episode": 16186.0, "batch_reward": 2.8213725090026855, "critic_loss": 4370.0810546875, "actor_loss": -1989.0089111328125, "actor_target_entropy": -3.0, "actor_entropy": 1.4501415491104126, "alpha_loss": 0.26961222290992737, "alpha_value": 1.0876648722151059, "duration": 1.7030203342437744, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1619000}
{"episode_reward": 0.0, "episode": 16191.0, "batch_reward": 3.4486565589904785, "critic_loss": 2253.78466796875, "actor_loss": -1923.8291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.6275949478149414, "alpha_loss": 0.1540379524230957, "alpha_value": 1.0694129084248523, "duration": 1.4200623035430908, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1619500}
{"episode_reward": 0.0, "episode": 16196.0, "batch_reward": 3.466987133026123, "critic_loss": 2614.16845703125, "actor_loss": -1897.987060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.7966198921203613, "alpha_loss": 0.25087934732437134, "alpha_value": 1.053370447684707, "step": 1620000}
{"duration": 18.84139847755432, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1620000}
{"episode_reward": 0.0, "episode": 16201.0, "batch_reward": 3.7446537017822266, "critic_loss": 2138.84912109375, "actor_loss": -1945.142333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.4624710083007812, "alpha_loss": -0.005907289683818817, "alpha_value": 1.0379863786429577, "duration": 1.4447782039642334, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1620500}
{"episode_reward": 0.0, "episode": 16206.0, "batch_reward": 3.371230125427246, "critic_loss": 2011.904296875, "actor_loss": -2003.48681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.626849889755249, "alpha_loss": 0.17611584067344666, "alpha_value": 1.0245255187003888, "duration": 1.5263407230377197, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1621000}
{"episode_reward": 0.0, "episode": 16211.0, "batch_reward": 3.306074380874634, "critic_loss": 3070.3681640625, "actor_loss": -1917.55419921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4375752210617065, "alpha_loss": 0.050249069929122925, "alpha_value": 1.0094667490385518, "duration": 1.507080078125, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1621500}
{"episode_reward": 0.0, "episode": 16216.0, "batch_reward": 2.4517195224761963, "critic_loss": 2116.55712890625, "actor_loss": -1874.805908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.7246941328048706, "alpha_loss": 0.6095361709594727, "alpha_value": 0.9920011206637147, "duration": 1.5326731204986572, "info_normalized_performance_mean": 0.14661933481693268, "info_normalized_performance_final": 0.25852271914482117, "info_performance_mean": 0.14661933481693268, "info_performance_final": 0.25852271914482117, "step": 1622000}
{"episode_reward": 293.2386363636362, "episode": 16221.0, "batch_reward": 3.367183208465576, "critic_loss": 2504.673095703125, "actor_loss": -1815.2132568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.4259233474731445, "alpha_loss": 0.09172998368740082, "alpha_value": 0.9801249793937358, "duration": 1.4432506561279297, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1622500}
{"episode_reward": 0.0, "episode": 16226.0, "batch_reward": 3.9789061546325684, "critic_loss": 2458.999755859375, "actor_loss": -1806.7943115234375, "actor_target_entropy": -3.0, "actor_entropy": 1.3642429113388062, "alpha_loss": 0.2681707739830017, "alpha_value": 0.9647380631405906, "duration": 1.6288087368011475, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1623000}
{"episode_reward": 0.0, "episode": 16231.0, "batch_reward": 3.754274845123291, "critic_loss": 1955.5916748046875, "actor_loss": -1862.5908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.8619210720062256, "alpha_loss": -0.1372186690568924, "alpha_value": 0.9546886496384912, "duration": 1.4346036911010742, "info_normalized_performance_mean": 0.034084249287843704, "info_normalized_performance_final": 0.03907204046845436, "info_performance_mean": 0.034084249287843704, "info_performance_final": 0.03907204046845436, "step": 1623500}
{"episode_reward": 68.16849816849806, "episode": 16236.0, "batch_reward": 3.063427448272705, "critic_loss": 1125.951904296875, "actor_loss": -1766.831787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.7015643119812012, "alpha_loss": 0.40476351976394653, "alpha_value": 0.9499239919023598, "duration": 1.5784125328063965, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1624000}
{"episode_reward": 0.0, "episode": 16241.0, "batch_reward": 3.5899980068206787, "critic_loss": 2154.170166015625, "actor_loss": -1694.821533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.7211101055145264, "alpha_loss": 0.12057466804981232, "alpha_value": 0.9428585868142567, "duration": 1.4966800212860107, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1624500}
{"episode_reward": 0.0, "episode": 16246.0, "batch_reward": 4.098405838012695, "critic_loss": 2024.5389404296875, "actor_loss": -1724.288818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.8079042434692383, "alpha_loss": 0.32258307933807373, "alpha_value": 0.9365777126760721, "duration": 1.500136375427246, "info_normalized_performance_mean": 0.025719132274389267, "info_normalized_performance_final": 0.028703704476356506, "info_performance_mean": 0.025719132274389267, "info_performance_final": 0.028703704476356506, "step": 1625000}
{"episode_reward": 51.43827160493831, "episode": 16251.0, "batch_reward": 3.5368056297302246, "critic_loss": 4299.966796875, "actor_loss": -1698.7529296875, "actor_target_entropy": -3.0, "actor_entropy": 1.5950465202331543, "alpha_loss": 0.009884707629680634, "alpha_value": 0.9386337024307496, "duration": 1.4667046070098877, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1625500}
{"episode_reward": 0.0, "episode": 16256.0, "batch_reward": 2.7243831157684326, "critic_loss": 1381.5155029296875, "actor_loss": -1702.712646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.402053713798523, "alpha_loss": -0.056119970977306366, "alpha_value": 0.9374933878422184, "duration": 1.500328779220581, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1626000}
{"episode_reward": 0.0, "episode": 16261.0, "batch_reward": 3.6254920959472656, "critic_loss": 2437.537109375, "actor_loss": -1722.881103515625, "actor_target_entropy": -3.0, "actor_entropy": 1.499426245689392, "alpha_loss": 0.2635727524757385, "alpha_value": 0.9292482770004254, "duration": 1.635993242263794, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1626500}
{"episode_reward": 0.0, "episode": 16266.0, "batch_reward": 3.2845101356506348, "critic_loss": 2296.61376953125, "actor_loss": -1688.396728515625, "actor_target_entropy": -3.0, "actor_entropy": 1.5805585384368896, "alpha_loss": 0.11733017861843109, "alpha_value": 0.9229294538491464, "duration": 1.5118353366851807, "info_normalized_performance_mean": 0.21499352157115936, "info_normalized_performance_final": 0.2522786557674408, "info_performance_mean": 0.21499352157115936, "info_performance_final": 0.2522786557674408, "step": 1627000}
{"episode_reward": 429.98697916666714, "episode": 16271.0, "batch_reward": 2.835498094558716, "critic_loss": 1392.31201171875, "actor_loss": -1668.9854736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.4869015216827393, "alpha_loss": 0.21359390020370483, "alpha_value": 0.9082624816925904, "duration": 1.4597508907318115, "info_normalized_performance_mean": 0.07413831353187561, "info_normalized_performance_final": 0.08503401279449463, "info_performance_mean": 0.07413831353187561, "info_performance_final": 0.08503401279449463, "step": 1627500}
{"episode_reward": 148.27664399092967, "episode": 16276.0, "batch_reward": 4.1483917236328125, "critic_loss": 4096.494140625, "actor_loss": -1603.081298828125, "actor_target_entropy": -3.0, "actor_entropy": 1.6234740018844604, "alpha_loss": 0.3165145218372345, "alpha_value": 0.9018890959278096, "duration": 1.4492390155792236, "info_normalized_performance_mean": 0.21375848352909088, "info_normalized_performance_final": 0.24773243069648743, "info_performance_mean": 0.21375848352909088, "info_performance_final": 0.24773243069648743, "step": 1628000}
{"episode_reward": 427.51700680272165, "episode": 16281.0, "batch_reward": 3.5194878578186035, "critic_loss": 2054.293701171875, "actor_loss": -1708.694580078125, "actor_target_entropy": -3.0, "actor_entropy": 1.9824976921081543, "alpha_loss": -0.07285777479410172, "alpha_value": 0.8984138118897976, "duration": 1.59779691696167, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1628500}
{"episode_reward": 0.0, "episode": 16286.0, "batch_reward": 3.4040098190307617, "critic_loss": 2274.01904296875, "actor_loss": -1731.2841796875, "actor_target_entropy": -3.0, "actor_entropy": 1.6289477348327637, "alpha_loss": -0.5835983753204346, "alpha_value": 0.9025448478661419, "duration": 1.503519058227539, "info_normalized_performance_mean": 0.039253246039152145, "info_normalized_performance_final": 0.09090909361839294, "info_performance_mean": 0.039253246039152145, "info_performance_final": 0.09090909361839294, "step": 1629000}
{"episode_reward": 78.50649350649348, "episode": 16291.0, "batch_reward": 3.8057188987731934, "critic_loss": 2060.84130859375, "actor_loss": -1624.606689453125, "actor_target_entropy": -3.0, "actor_entropy": 1.6296701431274414, "alpha_loss": -0.07261361181735992, "alpha_value": 0.9128878290129566, "duration": 1.4109160900115967, "info_normalized_performance_mean": 0.033562492579221725, "info_normalized_performance_final": 0.03750000149011612, "info_performance_mean": 0.033562492579221725, "info_performance_final": 0.03750000149011612, "step": 1629500}
{"episode_reward": 67.125, "episode": 16296.0, "batch_reward": 4.587982177734375, "critic_loss": 1604.82080078125, "actor_loss": -1644.873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.9333422183990479, "alpha_loss": 0.6902409791946411, "alpha_value": 0.926473111709411, "step": 1630000}
{"duration": 18.669631481170654, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1630000}
{"episode_reward": 0.0, "episode": 16301.0, "batch_reward": 3.28031063079834, "critic_loss": 2629.486328125, "actor_loss": -1626.2540283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.472668170928955, "alpha_loss": 0.013381093740463257, "alpha_value": 0.941547002835655, "duration": 1.5746595859527588, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1630500}
{"episode_reward": 0.0, "episode": 16306.0, "batch_reward": 3.498776435852051, "critic_loss": 4060.0458984375, "actor_loss": -1590.6217041015625, "actor_target_entropy": -3.0, "actor_entropy": 1.6827812194824219, "alpha_loss": -0.29264578223228455, "alpha_value": 0.962451853860434, "duration": 1.5231873989105225, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1631000}
{"episode_reward": 0.0, "episode": 16311.0, "batch_reward": 2.534961700439453, "critic_loss": 3982.751220703125, "actor_loss": -1690.468017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.5739728212356567, "alpha_loss": -1.0977766513824463, "alpha_value": 0.991534538134863, "duration": 1.5835180282592773, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1631500}
{"episode_reward": 0.0, "episode": 16316.0, "batch_reward": 3.0843448638916016, "critic_loss": 6422.1240234375, "actor_loss": -1686.172119140625, "actor_target_entropy": -3.0, "actor_entropy": 1.6270849704742432, "alpha_loss": -0.6614658832550049, "alpha_value": 1.0213324366874512, "duration": 1.5548853874206543, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1632000}
{"episode_reward": 0.0, "episode": 16321.0, "batch_reward": 3.6352314949035645, "critic_loss": 3883.27197265625, "actor_loss": -1686.709228515625, "actor_target_entropy": -3.0, "actor_entropy": 2.029970645904541, "alpha_loss": -1.0265668630599976, "alpha_value": 1.0589563686394914, "duration": 1.4904744625091553, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1632500}
{"episode_reward": 0.0, "episode": 16326.0, "batch_reward": 2.8681023120880127, "critic_loss": 2160.93603515625, "actor_loss": -1778.9583740234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4256341457366943, "alpha_loss": -0.975011944770813, "alpha_value": 1.0940405809011056, "duration": 1.456831932067871, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1633000}
{"episode_reward": 0.0, "episode": 16331.0, "batch_reward": 2.762009859085083, "critic_loss": 4520.0361328125, "actor_loss": -1658.1641845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.5104362964630127, "alpha_loss": -0.9477234482765198, "alpha_value": 1.129665625088113, "duration": 1.4693140983581543, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1633500}
{"episode_reward": 0.0, "episode": 16336.0, "batch_reward": 2.9795238971710205, "critic_loss": 1976.69873046875, "actor_loss": -1743.554931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.6595858335494995, "alpha_loss": -1.2722384929656982, "alpha_value": 1.1642795404239161, "duration": 1.5385322570800781, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1634000}
{"episode_reward": 0.0, "episode": 16341.0, "batch_reward": 3.3417415618896484, "critic_loss": 3142.860107421875, "actor_loss": -1750.4088134765625, "actor_target_entropy": -3.0, "actor_entropy": 1.6453003883361816, "alpha_loss": -0.5802180171012878, "alpha_value": 1.193474500225596, "duration": 1.417065143585205, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1634500}
{"episode_reward": 0.0, "episode": 16346.0, "batch_reward": 2.7530925273895264, "critic_loss": 3566.916259765625, "actor_loss": -1730.289794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.8265767097473145, "alpha_loss": -0.61070716381073, "alpha_value": 1.2130803515107118, "duration": 1.4118893146514893, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1635000}
{"episode_reward": 0.0, "episode": 16351.0, "batch_reward": 2.7146315574645996, "critic_loss": 4562.4580078125, "actor_loss": -1844.00439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.6426069736480713, "alpha_loss": 0.057945385575294495, "alpha_value": 1.2214221712554456, "duration": 1.5759856700897217, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1635500}
{"episode_reward": 0.0, "episode": 16356.0, "batch_reward": 2.8899002075195312, "critic_loss": 1943.7413330078125, "actor_loss": -1758.79248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.825352430343628, "alpha_loss": 0.414052814245224, "alpha_value": 1.2262309053780955, "duration": 1.4563801288604736, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1636000}
{"episode_reward": 0.0, "episode": 16361.0, "batch_reward": 3.3739113807678223, "critic_loss": 3095.697265625, "actor_loss": -1809.3353271484375, "actor_target_entropy": -3.0, "actor_entropy": 1.2868796586990356, "alpha_loss": -0.8881070613861084, "alpha_value": 1.2372182959503164, "duration": 1.5366113185882568, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1636500}
{"episode_reward": 0.0, "episode": 16366.0, "batch_reward": 3.1164793968200684, "critic_loss": 3086.69775390625, "actor_loss": -1891.8560791015625, "actor_target_entropy": -3.0, "actor_entropy": 2.027714967727661, "alpha_loss": -0.12916895747184753, "alpha_value": 1.2498492381341644, "duration": 1.5322163105010986, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1637000}
{"episode_reward": 0.0, "episode": 16371.0, "batch_reward": 3.28240966796875, "critic_loss": 6736.22900390625, "actor_loss": -1869.259521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.6787296533584595, "alpha_loss": -0.6328911781311035, "alpha_value": 1.2630283871137475, "duration": 1.579435110092163, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1637500}
{"episode_reward": 0.0, "episode": 16376.0, "batch_reward": 2.693875312805176, "critic_loss": 2574.22119140625, "actor_loss": -1913.7236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.8894822597503662, "alpha_loss": -0.5417559742927551, "alpha_value": 1.2903908799532038, "duration": 1.4994213581085205, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1638000}
{"episode_reward": 0.0, "episode": 16381.0, "batch_reward": 3.2047300338745117, "critic_loss": 2745.56787109375, "actor_loss": -1871.2886962890625, "actor_target_entropy": -3.0, "actor_entropy": 1.7239253520965576, "alpha_loss": -0.16785505414009094, "alpha_value": 1.3191167711915175, "duration": 1.3818309307098389, "info_normalized_performance_mean": 0.1533106565475464, "info_normalized_performance_final": 0.16609977185726166, "info_performance_mean": 0.1533106565475464, "info_performance_final": 0.16609977185726166, "step": 1638500}
{"episode_reward": 306.6213151927439, "episode": 16386.0, "batch_reward": 2.7569520473480225, "critic_loss": 3445.41552734375, "actor_loss": -1815.740966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.6050918102264404, "alpha_loss": -0.39545708894729614, "alpha_value": 1.3479909045765401, "duration": 1.5151920318603516, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1639000}
{"episode_reward": 0.0, "episode": 16391.0, "batch_reward": 3.3471460342407227, "critic_loss": 2741.447998046875, "actor_loss": -1897.477783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.7695417404174805, "alpha_loss": 0.4942772090435028, "alpha_value": 1.3740818382065487, "duration": 1.4854435920715332, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1639500}
{"episode_reward": 0.0, "episode": 16396.0, "batch_reward": 3.470432758331299, "critic_loss": 2431.152587890625, "actor_loss": -1909.962646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1819133758544922, "alpha_loss": -0.2149817943572998, "alpha_value": 1.386151365125597, "step": 1640000}
{"duration": 18.959370613098145, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1640000}
{"episode_reward": 0.0, "episode": 16401.0, "batch_reward": 3.594147205352783, "critic_loss": 1941.8212890625, "actor_loss": -1861.92626953125, "actor_target_entropy": -3.0, "actor_entropy": 1.4943010807037354, "alpha_loss": 0.1398373544216156, "alpha_value": 1.385837536444598, "duration": 1.5047781467437744, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1640500}
{"episode_reward": 0.0, "episode": 16406.0, "batch_reward": 2.554492950439453, "critic_loss": 2510.286865234375, "actor_loss": -1971.18310546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4135208129882812, "alpha_loss": 0.3096972107887268, "alpha_value": 1.368901892831493, "duration": 1.4581093788146973, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1641000}
{"episode_reward": 0.0, "episode": 16411.0, "batch_reward": 2.555969715118408, "critic_loss": 1709.884033203125, "actor_loss": -1824.8548583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.5232597589492798, "alpha_loss": 0.545353889465332, "alpha_value": 1.334543315875207, "duration": 1.5581450462341309, "info_normalized_performance_mean": 0.11508186161518097, "info_normalized_performance_final": 0.130952388048172, "info_performance_mean": 0.11508186161518097, "info_performance_final": 0.130952388048172, "step": 1641500}
{"episode_reward": 230.16369047619057, "episode": 16416.0, "batch_reward": 2.260483741760254, "critic_loss": 1813.3096923828125, "actor_loss": -1940.8118896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4182071685791016, "alpha_loss": 1.2716574668884277, "alpha_value": 1.299217266303361, "duration": 1.4844098091125488, "info_normalized_performance_mean": 0.0028954085428267717, "info_normalized_performance_final": 0.0031887756194919348, "info_performance_mean": 0.0028954085428267717, "info_performance_final": 0.0031887756194919348, "step": 1642000}
{"episode_reward": 5.790816326530608, "episode": 16421.0, "batch_reward": 2.781014919281006, "critic_loss": 1595.0943603515625, "actor_loss": -1866.44482421875, "actor_target_entropy": -3.0, "actor_entropy": 1.7809345722198486, "alpha_loss": 0.6731467843055725, "alpha_value": 1.272342038402548, "duration": 1.5584008693695068, "info_normalized_performance_mean": 0.05323982238769531, "info_normalized_performance_final": 0.05791855230927467, "info_performance_mean": 0.05323982238769531, "info_performance_final": 0.05791855230927467, "step": 1642500}
{"episode_reward": 106.4796380090497, "episode": 16426.0, "batch_reward": 2.2270891666412354, "critic_loss": 1353.04296875, "actor_loss": -1942.163330078125, "actor_target_entropy": -3.0, "actor_entropy": 1.4098392724990845, "alpha_loss": 0.6985502243041992, "alpha_value": 1.247740361699074, "duration": 1.4940240383148193, "info_normalized_performance_mean": 0.17419250309467316, "info_normalized_performance_final": 0.19358289241790771, "info_performance_mean": 0.17419250309467316, "info_performance_final": 0.19358289241790771, "step": 1643000}
{"episode_reward": 348.38502673796813, "episode": 16431.0, "batch_reward": 2.489114761352539, "critic_loss": 1365.027587890625, "actor_loss": -1867.5894775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5612869262695312, "alpha_loss": 0.6157470941543579, "alpha_value": 1.2223744733423287, "duration": 1.4812381267547607, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1643500}
{"episode_reward": 0.0, "episode": 16436.0, "batch_reward": 2.336261034011841, "critic_loss": 1631.2288818359375, "actor_loss": -1817.5804443359375, "actor_target_entropy": -3.0, "actor_entropy": 2.1122453212738037, "alpha_loss": 0.666497528553009, "alpha_value": 1.1928189926919204, "duration": 1.5313398838043213, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1644000}
{"episode_reward": 0.0, "episode": 16441.0, "batch_reward": 2.456434965133667, "critic_loss": 1016.0170288085938, "actor_loss": -1862.1904296875, "actor_target_entropy": -3.0, "actor_entropy": 1.691462755203247, "alpha_loss": 0.32579734921455383, "alpha_value": 1.1609579416823996, "duration": 1.4120988845825195, "info_normalized_performance_mean": 0.1894192099571228, "info_normalized_performance_final": 0.20580808818340302, "info_performance_mean": 0.1894192099571228, "info_performance_final": 0.20580808818340302, "step": 1644500}
{"episode_reward": 378.83838383838327, "episode": 16446.0, "batch_reward": 3.1848785877227783, "critic_loss": 1172.6839599609375, "actor_loss": -1802.97021484375, "actor_target_entropy": -3.0, "actor_entropy": 1.9097334146499634, "alpha_loss": 0.3726612329483032, "alpha_value": 1.1328243733981394, "duration": 1.5145173072814941, "info_normalized_performance_mean": 0.0024470589123666286, "info_normalized_performance_final": 0.030588235706090927, "info_performance_mean": 0.0024470589123666286, "info_performance_final": 0.030588235706090927, "step": 1645000}
{"episode_reward": 4.894117647058824, "episode": 16451.0, "batch_reward": 3.383500337600708, "critic_loss": 964.3002319335938, "actor_loss": -1774.24658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.9993057250976562, "alpha_loss": 1.4522249698638916, "alpha_value": 1.1050187232432234, "duration": 1.5640065670013428, "info_normalized_performance_mean": 0.1544286012649536, "info_normalized_performance_final": 0.1785714328289032, "info_performance_mean": 0.1544286012649536, "info_performance_final": 0.1785714328289032, "step": 1645500}
{"episode_reward": 308.857142857143, "episode": 16456.0, "batch_reward": 2.5876104831695557, "critic_loss": 962.328125, "actor_loss": -1750.29541015625, "actor_target_entropy": -3.0, "actor_entropy": 2.246201753616333, "alpha_loss": 1.4042607545852661, "alpha_value": 1.0752962306884737, "duration": 1.4376277923583984, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1646000}
{"episode_reward": 0.0, "episode": 16461.0, "batch_reward": 2.4244208335876465, "critic_loss": 1263.3695068359375, "actor_loss": -1756.9520263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.5888043642044067, "alpha_loss": 0.6997222900390625, "alpha_value": 1.0466789447815377, "duration": 1.473762035369873, "info_normalized_performance_mean": 0.06622500717639923, "info_normalized_performance_final": 0.07124999910593033, "info_performance_mean": 0.06622500717639923, "info_performance_final": 0.07124999910593033, "step": 1646500}
{"episode_reward": 132.44999999999987, "episode": 16466.0, "batch_reward": 2.0139245986938477, "critic_loss": 902.4869384765625, "actor_loss": -1746.568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.8448772430419922, "alpha_loss": 0.8470203876495361, "alpha_value": 1.0182957977634464, "duration": 1.4691176414489746, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1647000}
{"episode_reward": 0.0, "episode": 16471.0, "batch_reward": 2.2495927810668945, "critic_loss": 914.985107421875, "actor_loss": -1713.8631591796875, "actor_target_entropy": -3.0, "actor_entropy": 1.9087165594100952, "alpha_loss": 0.8843595385551453, "alpha_value": 0.9937579171342039, "duration": 1.521827220916748, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1647500}
{"episode_reward": 0.0, "episode": 16476.0, "batch_reward": 2.96333646774292, "critic_loss": 1419.4820556640625, "actor_loss": -1665.783203125, "actor_target_entropy": -3.0, "actor_entropy": 2.143812417984009, "alpha_loss": 0.9360640048980713, "alpha_value": 0.9747583749445052, "duration": 1.5821301937103271, "info_normalized_performance_mean": 0.11964286863803864, "info_normalized_performance_final": 0.2182539701461792, "info_performance_mean": 0.11964286863803864, "info_performance_final": 0.2182539701461792, "step": 1648000}
{"episode_reward": 239.2857142857143, "episode": 16481.0, "batch_reward": 2.0839602947235107, "critic_loss": 954.788818359375, "actor_loss": -1724.43017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.8570477962493896, "alpha_loss": 0.3666173219680786, "alpha_value": 0.961403256633439, "duration": 1.4774832725524902, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1648500}
{"episode_reward": 0.0, "episode": 16486.0, "batch_reward": 2.34190034866333, "critic_loss": 1735.53271484375, "actor_loss": -1651.296875, "actor_target_entropy": -3.0, "actor_entropy": 1.6366311311721802, "alpha_loss": 0.27692317962646484, "alpha_value": 0.9530719535163331, "duration": 1.3902065753936768, "info_normalized_performance_mean": 0.1450694352388382, "info_normalized_performance_final": 0.1723484843969345, "info_performance_mean": 0.1450694352388382, "info_performance_final": 0.1723484843969345, "step": 1649000}
{"episode_reward": 290.1388888888886, "episode": 16491.0, "batch_reward": 2.269834041595459, "critic_loss": 1593.920166015625, "actor_loss": -1678.318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.7089015245437622, "alpha_loss": -0.47444480657577515, "alpha_value": 0.9523624149407567, "duration": 1.5410537719726562, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1649500}
{"episode_reward": 0.0, "episode": 16496.0, "batch_reward": 2.2786865234375, "critic_loss": 1444.26416015625, "actor_loss": -1649.1533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.8392858505249023, "alpha_loss": -0.4332365393638611, "alpha_value": 0.9569138869241672, "step": 1650000}
{"duration": 18.058831691741943, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1650000}
{"episode_reward": 0.0, "episode": 16501.0, "batch_reward": 2.0154573917388916, "critic_loss": 1309.1051025390625, "actor_loss": -1681.711181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.4756190776824951, "alpha_loss": -0.6748175621032715, "alpha_value": 0.9657068497154209, "duration": 1.4894850254058838, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1650500}
{"episode_reward": 0.0, "episode": 16506.0, "batch_reward": 1.9523110389709473, "critic_loss": 1032.7802734375, "actor_loss": -1733.69189453125, "actor_target_entropy": -3.0, "actor_entropy": 1.787976622581482, "alpha_loss": -0.45075762271881104, "alpha_value": 0.977039123806793, "duration": 1.434676170349121, "info_normalized_performance_mean": 0.030104169622063637, "info_normalized_performance_final": 0.0338541679084301, "info_performance_mean": 0.030104169622063637, "info_performance_final": 0.0338541679084301, "step": 1651000}
{"episode_reward": 60.208333333333414, "episode": 16511.0, "batch_reward": 1.8620980978012085, "critic_loss": 1269.37646484375, "actor_loss": -1676.176513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3661795854568481, "alpha_loss": -0.636088490486145, "alpha_value": 0.9900767495767836, "duration": 1.4833433628082275, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1651500}
{"episode_reward": 0.0, "episode": 16516.0, "batch_reward": 2.4433231353759766, "critic_loss": 1731.97314453125, "actor_loss": -1733.297607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.274885654449463, "alpha_loss": -0.5532941818237305, "alpha_value": 1.0018717913440687, "duration": 1.4931910037994385, "info_normalized_performance_mean": 0.0003168402472510934, "info_normalized_performance_final": 0.0004340277810115367, "info_performance_mean": 0.0003168402472510934, "info_performance_final": 0.0004340277810115367, "step": 1652000}
{"episode_reward": 0.6336805555555566, "episode": 16521.0, "batch_reward": 1.618698239326477, "critic_loss": 1927.706298828125, "actor_loss": -1738.2371826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.9291203022003174, "alpha_loss": 0.07829824090003967, "alpha_value": 1.0136320707959525, "duration": 1.47025465965271, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1652500}
{"episode_reward": 0.0, "episode": 16526.0, "batch_reward": 1.684435486793518, "critic_loss": 963.326904296875, "actor_loss": -1708.642333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.7854723930358887, "alpha_loss": 0.10964739322662354, "alpha_value": 1.0226630855727477, "duration": 1.5019960403442383, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1653000}
{"episode_reward": 0.0, "episode": 16531.0, "batch_reward": 1.9938441514968872, "critic_loss": 1692.6639404296875, "actor_loss": -1724.7867431640625, "actor_target_entropy": -3.0, "actor_entropy": 1.7003581523895264, "alpha_loss": -0.5620553493499756, "alpha_value": 1.0301877905859038, "duration": 1.4924428462982178, "info_normalized_performance_mean": 0.22568179666996002, "info_normalized_performance_final": 0.30844154953956604, "info_performance_mean": 0.22568179666996002, "info_performance_final": 0.30844154953956604, "step": 1653500}
{"episode_reward": 451.3636363636358, "episode": 16536.0, "batch_reward": 2.5395305156707764, "critic_loss": 1221.22021484375, "actor_loss": -1689.03466796875, "actor_target_entropy": -3.0, "actor_entropy": 1.7916135787963867, "alpha_loss": -0.34905070066452026, "alpha_value": 1.0305902777234823, "duration": 1.45829439163208, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1654000}
{"episode_reward": 0.0, "episode": 16541.0, "batch_reward": 1.8215770721435547, "critic_loss": 1599.418701171875, "actor_loss": -1714.212158203125, "actor_target_entropy": -3.0, "actor_entropy": 1.9916654825210571, "alpha_loss": 0.20349770784378052, "alpha_value": 1.0213431724028035, "duration": 1.3916263580322266, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1654500}
{"episode_reward": 0.0, "episode": 16546.0, "batch_reward": 1.5686123371124268, "critic_loss": 1254.1036376953125, "actor_loss": -1675.94140625, "actor_target_entropy": -3.0, "actor_entropy": 1.670914888381958, "alpha_loss": -0.008742637932300568, "alpha_value": 1.0027264801190043, "duration": 1.510451078414917, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1655000}
{"episode_reward": 0.0, "episode": 16551.0, "batch_reward": 2.28902530670166, "critic_loss": 1421.3623046875, "actor_loss": -1690.760009765625, "actor_target_entropy": -3.0, "actor_entropy": 1.6107852458953857, "alpha_loss": 0.555404543876648, "alpha_value": 0.9784139911858383, "duration": 1.5372982025146484, "info_normalized_performance_mean": 0.3405773937702179, "info_normalized_performance_final": 0.4974114000797272, "info_performance_mean": 0.3405773937702179, "info_performance_final": 0.4974114000797272, "step": 1655500}
{"episode_reward": 681.1549183592191, "episode": 16556.0, "batch_reward": 1.86014986038208, "critic_loss": 1208.3447265625, "actor_loss": -1689.092529296875, "actor_target_entropy": -3.0, "actor_entropy": 1.528498888015747, "alpha_loss": 0.6817596554756165, "alpha_value": 0.9572654108051839, "duration": 1.4588079452514648, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1656000}
{"episode_reward": 0.0, "episode": 16561.0, "batch_reward": 1.9031943082809448, "critic_loss": 1368.660888671875, "actor_loss": -1677.5443115234375, "actor_target_entropy": -3.0, "actor_entropy": 1.752288818359375, "alpha_loss": -0.21903161704540253, "alpha_value": 0.9362785105251246, "duration": 1.4512104988098145, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1656500}
{"episode_reward": 0.0, "episode": 16566.0, "batch_reward": 1.9686651229858398, "critic_loss": 1050.734619140625, "actor_loss": -1651.418212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.6978988647460938, "alpha_loss": -0.11522947251796722, "alpha_value": 0.911014412617158, "duration": 1.4519753456115723, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1657000}
{"episode_reward": 0.0, "episode": 16571.0, "batch_reward": 1.9832216501235962, "critic_loss": 1072.62158203125, "actor_loss": -1608.9521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.7070680856704712, "alpha_loss": 0.6534364223480225, "alpha_value": 0.887419379217596, "duration": 1.435030460357666, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1657500}
{"episode_reward": 0.0, "episode": 16576.0, "batch_reward": 1.980591058731079, "critic_loss": 2381.4248046875, "actor_loss": -1650.476318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3596627712249756, "alpha_loss": 0.2857246696949005, "alpha_value": 0.8685261435828774, "duration": 1.4212560653686523, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1658000}
{"episode_reward": 0.0, "episode": 16581.0, "batch_reward": 2.3767342567443848, "critic_loss": 1256.08935546875, "actor_loss": -1571.38818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.642322301864624, "alpha_loss": 0.3814452886581421, "alpha_value": 0.8516188793375628, "duration": 1.7212557792663574, "info_normalized_performance_mean": 0.22594617307186127, "info_normalized_performance_final": 0.2873263955116272, "info_performance_mean": 0.22594617307186127, "info_performance_final": 0.2873263955116272, "step": 1658500}
{"episode_reward": 451.8923611111109, "episode": 16586.0, "batch_reward": 2.0823886394500732, "critic_loss": 1366.535888671875, "actor_loss": -1561.707763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.6755144596099854, "alpha_loss": -0.09833934903144836, "alpha_value": 0.8373431937478112, "duration": 1.4751670360565186, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1659000}
{"episode_reward": 0.0, "episode": 16591.0, "batch_reward": 2.475613594055176, "critic_loss": 1042.9345703125, "actor_loss": -1622.133544921875, "actor_target_entropy": -3.0, "actor_entropy": 2.262938976287842, "alpha_loss": 0.44992685317993164, "alpha_value": 0.8265817080931068, "duration": 1.4264123439788818, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1659500}
{"episode_reward": 0.0, "episode": 16596.0, "batch_reward": 1.670567274093628, "critic_loss": 824.3626708984375, "actor_loss": -1553.655517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.5193569660186768, "alpha_loss": -0.12600301206111908, "alpha_value": 0.8167329339537773, "step": 1660000}
{"duration": 19.125473737716675, "info_normalized_performance_mean": 0.25135207176208496, "info_normalized_performance_final": 0.3020833432674408, "info_performance_mean": 0.25135207176208496, "info_performance_final": 0.3020833432674408, "step": 1660000}
{"episode_reward": 502.70416666666745, "episode": 16601.0, "batch_reward": 2.3974595069885254, "critic_loss": 2324.6650390625, "actor_loss": -1542.1168212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.4646518230438232, "alpha_loss": 0.021983377635478973, "alpha_value": 0.804762779730821, "duration": 1.4878950119018555, "info_normalized_performance_mean": 0.3882443606853485, "info_normalized_performance_final": 0.4322222173213959, "info_performance_mean": 0.3882443606853485, "info_performance_final": 0.4322222173213959, "step": 1660500}
{"episode_reward": 776.4888888888872, "episode": 16606.0, "batch_reward": 2.2828755378723145, "critic_loss": 495.48583984375, "actor_loss": -1550.255859375, "actor_target_entropy": -3.0, "actor_entropy": 1.6205260753631592, "alpha_loss": 0.7799646854400635, "alpha_value": 0.7918733609747309, "duration": 1.5873346328735352, "info_normalized_performance_mean": 0.053290918469429016, "info_normalized_performance_final": 0.058701299130916595, "info_performance_mean": 0.053290918469429016, "info_performance_final": 0.058701299130916595, "step": 1661000}
{"episode_reward": 106.58181818181836, "episode": 16611.0, "batch_reward": 3.01778507232666, "critic_loss": 760.00634765625, "actor_loss": -1568.349365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.6636133193969727, "alpha_loss": 0.35548168420791626, "alpha_value": 0.7811649117011871, "duration": 1.4811890125274658, "info_normalized_performance_mean": 0.000637254910543561, "info_normalized_performance_final": 0.0009803922148421407, "info_performance_mean": 0.000637254910543561, "info_performance_final": 0.0009803922148421407, "step": 1661500}
{"episode_reward": 1.2745098039215683, "episode": 16616.0, "batch_reward": 3.031770706176758, "critic_loss": 616.6904907226562, "actor_loss": -1544.97509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.9791733026504517, "alpha_loss": 0.38512909412384033, "alpha_value": 0.7704409681878267, "duration": 1.5582621097564697, "info_normalized_performance_mean": 0.20815326273441315, "info_normalized_performance_final": 0.24389609694480896, "info_performance_mean": 0.20815326273441315, "info_performance_final": 0.24389609694480896, "step": 1662000}
{"episode_reward": 416.3064935064927, "episode": 16621.0, "batch_reward": 1.998488426208496, "critic_loss": 650.1982421875, "actor_loss": -1474.952880859375, "actor_target_entropy": -3.0, "actor_entropy": 1.6967332363128662, "alpha_loss": 0.2031865417957306, "alpha_value": 0.7623415599227908, "duration": 1.4949369430541992, "info_normalized_performance_mean": 0.12656137347221375, "info_normalized_performance_final": 0.17811354994773865, "info_performance_mean": 0.12656137347221375, "info_performance_final": 0.17811354994773865, "step": 1662500}
{"episode_reward": 253.12271062271085, "episode": 16626.0, "batch_reward": 3.0396718978881836, "critic_loss": 990.8412475585938, "actor_loss": -1489.76611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.977942705154419, "alpha_loss": 0.18816392123699188, "alpha_value": 0.7576419818218204, "duration": 1.460012674331665, "info_normalized_performance_mean": 0.5689177513122559, "info_normalized_performance_final": 0.6950231194496155, "info_performance_mean": 0.5689177513122559, "info_performance_final": 0.6950231194496155, "step": 1663000}
{"episode_reward": 1137.8356481481474, "episode": 16631.0, "batch_reward": 2.589797019958496, "critic_loss": 848.8314208984375, "actor_loss": -1525.3089599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.6269018650054932, "alpha_loss": 0.13161525130271912, "alpha_value": 0.7519534696549962, "duration": 1.5807769298553467, "info_normalized_performance_mean": 0.4187149107456207, "info_normalized_performance_final": 0.47671157121658325, "info_performance_mean": 0.4187149107456207, "info_performance_final": 0.47671157121658325, "step": 1663500}
{"episode_reward": 837.4298540965223, "episode": 16636.0, "batch_reward": 2.7516627311706543, "critic_loss": 1081.54443359375, "actor_loss": -1486.593505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.7511873245239258, "alpha_loss": 0.19389624893665314, "alpha_value": 0.7470734885925224, "duration": 1.4859497547149658, "info_normalized_performance_mean": 0.02690933644771576, "info_normalized_performance_final": 0.04532967135310173, "info_performance_mean": 0.02690933644771576, "info_performance_final": 0.04532967135310173, "step": 1664000}
{"episode_reward": 53.81868131868135, "episode": 16641.0, "batch_reward": 2.1616291999816895, "critic_loss": 775.9747314453125, "actor_loss": -1478.058837890625, "actor_target_entropy": -3.0, "actor_entropy": 1.9077339172363281, "alpha_loss": 0.4910687804222107, "alpha_value": 0.7392020826344481, "duration": 1.5114197731018066, "info_normalized_performance_mean": 0.49344807863235474, "info_normalized_performance_final": 0.6122449040412903, "info_performance_mean": 0.49344807863235474, "info_performance_final": 0.6122449040412903, "step": 1664500}
{"episode_reward": 986.8962585033994, "episode": 16646.0, "batch_reward": 3.0852718353271484, "critic_loss": 690.0901489257812, "actor_loss": -1510.064453125, "actor_target_entropy": -3.0, "actor_entropy": 2.336735248565674, "alpha_loss": 0.21238934993743896, "alpha_value": 0.7355950053085398, "duration": 1.4363698959350586, "info_normalized_performance_mean": 0.4919515550136566, "info_normalized_performance_final": 0.545918345451355, "info_performance_mean": 0.4919515550136566, "info_performance_final": 0.545918345451355, "step": 1665000}
{"episode_reward": 983.9030612244909, "episode": 16651.0, "batch_reward": 3.179189443588257, "critic_loss": 815.1988525390625, "actor_loss": -1483.19921875, "actor_target_entropy": -3.0, "actor_entropy": 1.8353426456451416, "alpha_loss": 0.17698711156845093, "alpha_value": 0.7307954730175854, "duration": 1.4651858806610107, "info_normalized_performance_mean": 0.5354166626930237, "info_normalized_performance_final": 0.6180555820465088, "info_performance_mean": 0.5354166626930237, "info_performance_final": 0.6180555820465088, "step": 1665500}
{"episode_reward": 1070.8333333333317, "episode": 16656.0, "batch_reward": 2.675752878189087, "critic_loss": 797.885498046875, "actor_loss": -1503.26025390625, "actor_target_entropy": -3.0, "actor_entropy": 1.8400486707687378, "alpha_loss": -0.29385504126548767, "alpha_value": 0.7260139257291397, "duration": 1.4735701084136963, "info_normalized_performance_mean": 0.12496031075716019, "info_normalized_performance_final": 0.289682537317276, "info_performance_mean": 0.12496031075716019, "info_performance_final": 0.289682537317276, "step": 1666000}
{"episode_reward": 249.92063492063477, "episode": 16661.0, "batch_reward": 2.1214404106140137, "critic_loss": 877.9819946289062, "actor_loss": -1512.209716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.8321452140808105, "alpha_loss": 0.17143647372722626, "alpha_value": 0.7173100805745145, "duration": 1.4966650009155273, "info_normalized_performance_mean": 0.15781250596046448, "info_normalized_performance_final": 0.17656250298023224, "info_performance_mean": 0.15781250596046448, "info_performance_final": 0.17656250298023224, "step": 1666500}
{"episode_reward": 315.625, "episode": 16666.0, "batch_reward": 2.6974072456359863, "critic_loss": 532.88232421875, "actor_loss": -1477.935302734375, "actor_target_entropy": -3.0, "actor_entropy": 1.9746394157409668, "alpha_loss": 0.254386305809021, "alpha_value": 0.7106279995524609, "duration": 1.684831142425537, "info_normalized_performance_mean": 0.46907439827919006, "info_normalized_performance_final": 0.5660654902458191, "info_performance_mean": 0.46907439827919006, "info_performance_final": 0.5660654902458191, "step": 1667000}
{"episode_reward": 938.1486934118495, "episode": 16671.0, "batch_reward": 2.3007705211639404, "critic_loss": 1019.8255615234375, "actor_loss": -1448.8056640625, "actor_target_entropy": -3.0, "actor_entropy": 2.111168384552002, "alpha_loss": -0.11506485939025879, "alpha_value": 0.7041717062281351, "duration": 1.849945306777954, "info_normalized_performance_mean": 0.47096726298332214, "info_normalized_performance_final": 0.5680473446846008, "info_performance_mean": 0.47096726298332214, "info_performance_final": 0.5680473446846008, "step": 1667500}
{"episode_reward": 941.9344560764681, "episode": 16676.0, "batch_reward": 2.40728759765625, "critic_loss": 594.7618408203125, "actor_loss": -1433.530517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7450764179229736, "alpha_loss": 0.015120282769203186, "alpha_value": 0.7028365283082443, "duration": 1.5560188293457031, "info_normalized_performance_mean": 0.13226081430912018, "info_normalized_performance_final": 0.2121913582086563, "info_performance_mean": 0.13226081430912018, "info_performance_final": 0.2121913582086563, "step": 1668000}
{"episode_reward": 264.5216049382714, "episode": 16681.0, "batch_reward": 2.0066239833831787, "critic_loss": 805.9574584960938, "actor_loss": -1457.5999755859375, "actor_target_entropy": -3.0, "actor_entropy": 2.1033833026885986, "alpha_loss": -0.028987467288970947, "alpha_value": 0.7036765047507881, "duration": 1.7555689811706543, "info_normalized_performance_mean": 0.2971964180469513, "info_normalized_performance_final": 0.32867133617401123, "info_performance_mean": 0.2971964180469513, "info_performance_final": 0.32867133617401123, "step": 1668500}
{"episode_reward": 594.3928798474251, "episode": 16686.0, "batch_reward": 2.655636787414551, "critic_loss": 666.6737060546875, "actor_loss": -1461.564453125, "actor_target_entropy": -3.0, "actor_entropy": 1.8123650550842285, "alpha_loss": -0.06336433440446854, "alpha_value": 0.7180040430532492, "duration": 1.6030123233795166, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1669000}
{"episode_reward": 0.0, "episode": 16691.0, "batch_reward": 2.642395496368408, "critic_loss": 1180.5140380859375, "actor_loss": -1489.7080078125, "actor_target_entropy": -3.0, "actor_entropy": 2.130439043045044, "alpha_loss": -0.5356141924858093, "alpha_value": 0.7393332006670684, "duration": 1.5882813930511475, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1669500}
{"episode_reward": 0.0, "episode": 16696.0, "batch_reward": 2.741100311279297, "critic_loss": 804.462890625, "actor_loss": -1513.01318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.8159358501434326, "alpha_loss": -0.40465760231018066, "alpha_value": 0.7626904227625648, "step": 1670000}
{"duration": 18.67757511138916, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1670000}
{"episode_reward": 0.0, "episode": 16701.0, "batch_reward": 2.716671943664551, "critic_loss": 1117.1334228515625, "actor_loss": -1501.7666015625, "actor_target_entropy": -3.0, "actor_entropy": 1.9961954355239868, "alpha_loss": -0.06266127526760101, "alpha_value": 0.7778746942232738, "duration": 1.5352551937103271, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1670500}
{"episode_reward": 0.0, "episode": 16706.0, "batch_reward": 1.567878246307373, "critic_loss": 692.66357421875, "actor_loss": -1491.6075439453125, "actor_target_entropy": -3.0, "actor_entropy": 2.1486968994140625, "alpha_loss": 0.11484944820404053, "alpha_value": 0.7847925670713866, "duration": 1.5351805686950684, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1671000}
{"episode_reward": 0.0, "episode": 16711.0, "batch_reward": 1.9704266786575317, "critic_loss": 773.7163696289062, "actor_loss": -1499.1734619140625, "actor_target_entropy": -3.0, "actor_entropy": 2.165559768676758, "alpha_loss": -0.07400746643543243, "alpha_value": 0.7844294685729611, "duration": 1.524214506149292, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1671500}
{"episode_reward": 0.0, "episode": 16716.0, "batch_reward": 1.8036441802978516, "critic_loss": 816.6942138671875, "actor_loss": -1527.279052734375, "actor_target_entropy": -3.0, "actor_entropy": 2.2182955741882324, "alpha_loss": 0.5668837428092957, "alpha_value": 0.7757003973691033, "duration": 1.57112455368042, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1672000}
{"episode_reward": 0.0, "episode": 16721.0, "batch_reward": 1.7346305847167969, "critic_loss": 582.7491455078125, "actor_loss": -1467.6162109375, "actor_target_entropy": -3.0, "actor_entropy": 2.0272130966186523, "alpha_loss": 0.03269791230559349, "alpha_value": 0.767988466446849, "duration": 1.530517816543579, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1672500}
{"episode_reward": 0.0, "episode": 16726.0, "batch_reward": 2.606179714202881, "critic_loss": 660.4775390625, "actor_loss": -1477.80517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.7441900968551636, "alpha_loss": -0.37382790446281433, "alpha_value": 0.7607438111964847, "duration": 1.654233694076538, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1673000}
{"episode_reward": 0.0, "episode": 16731.0, "batch_reward": 1.432530164718628, "critic_loss": 714.466064453125, "actor_loss": -1459.9375, "actor_target_entropy": -3.0, "actor_entropy": 2.082260847091675, "alpha_loss": -0.1425626575946808, "alpha_value": 0.7579465246768348, "duration": 1.6155483722686768, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1673500}
{"episode_reward": 0.0, "episode": 16736.0, "batch_reward": 2.616549015045166, "critic_loss": 520.8477172851562, "actor_loss": -1452.1251220703125, "actor_target_entropy": -3.0, "actor_entropy": 2.047827959060669, "alpha_loss": 0.40531396865844727, "alpha_value": 0.7469275229943135, "duration": 1.4435930252075195, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1674000}
{"episode_reward": 0.0, "episode": 16741.0, "batch_reward": 2.430543899536133, "critic_loss": 1092.7958984375, "actor_loss": -1431.944091796875, "actor_target_entropy": -3.0, "actor_entropy": 1.8735687732696533, "alpha_loss": 0.09365352988243103, "alpha_value": 0.7299793378375318, "duration": 1.5543763637542725, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1674500}
{"episode_reward": 0.0, "episode": 16746.0, "batch_reward": 2.3945698738098145, "critic_loss": 703.9219970703125, "actor_loss": -1424.725830078125, "actor_target_entropy": -3.0, "actor_entropy": 2.175808906555176, "alpha_loss": 0.1804906129837036, "alpha_value": 0.7129056824116242, "duration": 1.4922599792480469, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1675000}
{"episode_reward": 0.0, "episode": 16751.0, "batch_reward": 1.8512485027313232, "critic_loss": 339.47882080078125, "actor_loss": -1340.366943359375, "actor_target_entropy": -3.0, "actor_entropy": 2.0810484886169434, "alpha_loss": 0.12451932579278946, "alpha_value": 0.6975909934979672, "duration": 1.4863307476043701, "info_normalized_performance_mean": 0.3333752155303955, "info_normalized_performance_final": 0.45408162474632263, "info_performance_mean": 0.3333752155303955, "info_performance_final": 0.45408162474632263, "step": 1675500}
{"episode_reward": 666.7503924646775, "episode": 16756.0, "batch_reward": 1.8057124614715576, "critic_loss": 494.4390563964844, "actor_loss": -1351.0693359375, "actor_target_entropy": -3.0, "actor_entropy": 2.298661231994629, "alpha_loss": 0.6169575452804565, "alpha_value": 0.6790654522342287, "duration": 1.5363550186157227, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1676000}
{"episode_reward": 0.0, "episode": 16761.0, "batch_reward": 1.5106520652770996, "critic_loss": 446.92364501953125, "actor_loss": -1360.57373046875, "actor_target_entropy": -3.0, "actor_entropy": 2.3879125118255615, "alpha_loss": 0.42334890365600586, "alpha_value": 0.6624839630596616, "duration": 1.537583351135254, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1676500}
{"episode_reward": 0.0, "episode": 16766.0, "batch_reward": 1.0157110691070557, "critic_loss": 542.9598388671875, "actor_loss": -1325.2386474609375, "actor_target_entropy": -3.0, "actor_entropy": 2.201873302459717, "alpha_loss": 0.4511336088180542, "alpha_value": 0.6475234674618329, "duration": 1.570652723312378, "info_normalized_performance_mean": 0.42005783319473267, "info_normalized_performance_final": 0.5127314925193787, "info_performance_mean": 0.42005783319473267, "info_performance_final": 0.5127314925193787, "step": 1677000}
{"episode_reward": 840.1157407407418, "episode": 16771.0, "batch_reward": 2.3614914417266846, "critic_loss": 790.0631103515625, "actor_loss": -1320.90625, "actor_target_entropy": -3.0, "actor_entropy": 2.029157876968384, "alpha_loss": 0.6355937719345093, "alpha_value": 0.6336719056591501, "duration": 1.4806504249572754, "info_normalized_performance_mean": 0.2638818323612213, "info_normalized_performance_final": 0.32818183302879333, "info_performance_mean": 0.2638818323612213, "info_performance_final": 0.32818183302879333, "step": 1677500}
{"episode_reward": 527.7636363636366, "episode": 16776.0, "batch_reward": 1.8899729251861572, "critic_loss": 738.3112182617188, "actor_loss": -1300.412109375, "actor_target_entropy": -3.0, "actor_entropy": 2.2142603397369385, "alpha_loss": 0.3959847092628479, "alpha_value": 0.6232968909536001, "duration": 1.429619312286377, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1678000}
{"episode_reward": 0.0, "episode": 16781.0, "batch_reward": 1.581991195678711, "critic_loss": 462.25799560546875, "actor_loss": -1229.6805419921875, "actor_target_entropy": -3.0, "actor_entropy": 2.055455207824707, "alpha_loss": 0.09468896687030792, "alpha_value": 0.6116758666166145, "duration": 1.5733668804168701, "info_normalized_performance_mean": 0.19064155220985413, "info_normalized_performance_final": 0.25330686569213867, "info_performance_mean": 0.19064155220985413, "info_performance_final": 0.25330686569213867, "step": 1678500}
{"episode_reward": 381.28306878306904, "episode": 16786.0, "batch_reward": 1.6253700256347656, "critic_loss": 1002.3719482421875, "actor_loss": -1260.5445556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.824463129043579, "alpha_loss": -0.10845526307821274, "alpha_value": 0.603451786263742, "duration": 1.5307390689849854, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1679000}
{"episode_reward": 0.0, "episode": 16791.0, "batch_reward": 2.023120164871216, "critic_loss": 426.6689453125, "actor_loss": -1244.869140625, "actor_target_entropy": -3.0, "actor_entropy": 2.3267338275909424, "alpha_loss": 0.782016932964325, "alpha_value": 0.5929904603892087, "duration": 1.5472757816314697, "info_normalized_performance_mean": 0.0035294117406010628, "info_normalized_performance_final": 0.003921568859368563, "info_performance_mean": 0.0035294117406010628, "info_performance_final": 0.003921568859368563, "step": 1679500}
{"episode_reward": 7.0588235294117565, "episode": 16796.0, "batch_reward": 2.1920249462127686, "critic_loss": 503.84844970703125, "actor_loss": -1246.8250732421875, "actor_target_entropy": -3.0, "actor_entropy": 1.8468924760818481, "alpha_loss": 0.22189463675022125, "alpha_value": 0.5814622883796198, "step": 1680000}
{"duration": 18.56903600692749, "info_normalized_performance_mean": 0.585178554058075, "info_normalized_performance_final": 0.7678571343421936, "info_performance_mean": 0.585178554058075, "info_performance_final": 0.7678571343421936, "step": 1680000}
{"episode_reward": 1170.3571428571438, "episode": 16801.0, "batch_reward": 2.127591371536255, "critic_loss": 885.9591064453125, "actor_loss": -1220.31396484375, "actor_target_entropy": -3.0, "actor_entropy": 2.401762008666992, "alpha_loss": 0.46886369585990906, "alpha_value": 0.5682351694699245, "duration": 1.5400402545928955, "info_normalized_performance_mean": 0.49933287501335144, "info_normalized_performance_final": 0.6534537076950073, "info_performance_mean": 0.49933287501335144, "info_performance_final": 0.6534537076950073, "step": 1680500}
{"episode_reward": 998.6656200941916, "episode": 16806.0, "batch_reward": 2.288146495819092, "critic_loss": 638.1572265625, "actor_loss": -1212.228515625, "actor_target_entropy": -3.0, "actor_entropy": 2.346047878265381, "alpha_loss": 0.3313308656215668, "alpha_value": 0.553921286536049, "duration": 1.4952993392944336, "info_normalized_performance_mean": 0.1820320338010788, "info_normalized_performance_final": 0.19679144024848938, "info_performance_mean": 0.1820320338010788, "info_performance_final": 0.19679144024848938, "step": 1681000}
{"episode_reward": 364.06417112299476, "episode": 16811.0, "batch_reward": 2.1729931831359863, "critic_loss": 493.2879333496094, "actor_loss": -1192.2691650390625, "actor_target_entropy": -3.0, "actor_entropy": 2.3717691898345947, "alpha_loss": 0.6777938604354858, "alpha_value": 0.5403977186483544, "duration": 1.484724521636963, "info_normalized_performance_mean": 0.17856650054454803, "info_normalized_performance_final": 0.5203372836112976, "info_performance_mean": 0.17856650054454803, "info_performance_final": 0.5203372836112976, "step": 1681500}
{"episode_reward": 357.1329365079364, "episode": 16816.0, "batch_reward": 1.9264575242996216, "critic_loss": 753.0062255859375, "actor_loss": -1149.72900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.7374801635742188, "alpha_loss": 0.13743489980697632, "alpha_value": 0.528440940616699, "duration": 1.5677688121795654, "info_normalized_performance_mean": 0.3628949820995331, "info_normalized_performance_final": 0.5583791136741638, "info_performance_mean": 0.3628949820995331, "info_performance_final": 0.5583791136741638, "step": 1682000}
{"episode_reward": 725.7898351648342, "episode": 16821.0, "batch_reward": 2.139547824859619, "critic_loss": 463.0050964355469, "actor_loss": -1153.0772705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.935971736907959, "alpha_loss": 0.1490030139684677, "alpha_value": 0.5186336858828472, "duration": 1.5625669956207275, "info_normalized_performance_mean": 0.02711399644613266, "info_normalized_performance_final": 0.052669551223516464, "info_performance_mean": 0.02711399644613266, "info_performance_final": 0.052669551223516464, "step": 1682500}
{"episode_reward": 54.22799422799422, "episode": 16826.0, "batch_reward": 2.259927272796631, "critic_loss": 1022.7877807617188, "actor_loss": -1185.040771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.706594467163086, "alpha_loss": 0.16734875738620758, "alpha_value": 0.5099560790114187, "duration": 1.4353129863739014, "info_normalized_performance_mean": 0.17891722917556763, "info_normalized_performance_final": 0.19954648613929749, "info_performance_mean": 0.17891722917556763, "info_performance_final": 0.19954648613929749, "step": 1683000}
{"episode_reward": 357.83446712018156, "episode": 16831.0, "batch_reward": 2.1191673278808594, "critic_loss": 449.96484375, "actor_loss": -1121.291259765625, "actor_target_entropy": -3.0, "actor_entropy": 2.0314769744873047, "alpha_loss": 0.22349631786346436, "alpha_value": 0.5029040956716697, "duration": 1.5197515487670898, "info_normalized_performance_mean": 0.41078099608421326, "info_normalized_performance_final": 0.47880691289901733, "info_performance_mean": 0.41078099608421326, "info_performance_final": 0.47880691289901733, "step": 1683500}
{"episode_reward": 821.5620094191507, "episode": 16836.0, "batch_reward": 2.0895023345947266, "critic_loss": 469.2262878417969, "actor_loss": -1125.739990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.7993335723876953, "alpha_loss": 0.03800394386053085, "alpha_value": 0.49666280672280555, "duration": 1.6142759323120117, "info_normalized_performance_mean": 0.4162277281284332, "info_normalized_performance_final": 0.4955357015132904, "info_performance_mean": 0.4162277281284332, "info_performance_final": 0.4955357015132904, "step": 1684000}
{"episode_reward": 832.4553571428585, "episode": 16841.0, "batch_reward": 1.4274911880493164, "critic_loss": 997.8251342773438, "actor_loss": -1064.80712890625, "actor_target_entropy": -3.0, "actor_entropy": 2.3680782318115234, "alpha_loss": 0.17496027052402496, "alpha_value": 0.4909353214041595, "duration": 1.4205477237701416, "info_normalized_performance_mean": 0.5088542103767395, "info_normalized_performance_final": 0.5963541865348816, "info_performance_mean": 0.5088542103767395, "info_performance_final": 0.5963541865348816, "step": 1684500}
{"episode_reward": 1017.7083333333346, "episode": 16846.0, "batch_reward": 1.9147119522094727, "critic_loss": 576.856689453125, "actor_loss": -1079.5328369140625, "actor_target_entropy": -3.0, "actor_entropy": 2.336785316467285, "alpha_loss": 0.15910860896110535, "alpha_value": 0.4898081483145101, "duration": 1.491865634918213, "info_normalized_performance_mean": 0.05467262119054794, "info_normalized_performance_final": 0.0892857164144516, "info_performance_mean": 0.05467262119054794, "info_performance_final": 0.0892857164144516, "step": 1685000}
{"episode_reward": 109.3452380952381, "episode": 16851.0, "batch_reward": 2.2667903900146484, "critic_loss": 548.7230834960938, "actor_loss": -1082.973388671875, "actor_target_entropy": -3.0, "actor_entropy": 2.3574295043945312, "alpha_loss": 0.35010480880737305, "alpha_value": 0.4882410613928956, "duration": 1.5037691593170166, "info_normalized_performance_mean": 0.46531596779823303, "info_normalized_performance_final": 0.6208791136741638, "info_performance_mean": 0.46531596779823303, "info_performance_final": 0.6208791136741638, "step": 1685500}
{"episode_reward": 930.6318681318666, "episode": 16856.0, "batch_reward": 1.1872363090515137, "critic_loss": 909.1033935546875, "actor_loss": -1033.197265625, "actor_target_entropy": -3.0, "actor_entropy": 2.161885976791382, "alpha_loss": 0.22089451551437378, "alpha_value": 0.4908930569495494, "duration": 1.5950160026550293, "info_normalized_performance_mean": 0.27323073148727417, "info_normalized_performance_final": 0.36527472734451294, "info_performance_mean": 0.27323073148727417, "info_performance_final": 0.36527472734451294, "step": 1686000}
{"episode_reward": 546.4615384615381, "episode": 16861.0, "batch_reward": 2.002223014831543, "critic_loss": 754.9970703125, "actor_loss": -1062.505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.814802885055542, "alpha_loss": -0.18515267968177795, "alpha_value": 0.4951165408905604, "duration": 1.4456806182861328, "info_normalized_performance_mean": 0.014203297905623913, "info_normalized_performance_final": 0.015109890140593052, "info_performance_mean": 0.014203297905623913, "info_performance_final": 0.015109890140593052, "step": 1686500}
{"episode_reward": 28.40659340659345, "episode": 16866.0, "batch_reward": 2.4646902084350586, "critic_loss": 597.8809814453125, "actor_loss": -1106.0008544921875, "actor_target_entropy": -3.0, "actor_entropy": 1.5348093509674072, "alpha_loss": -0.3602362275123596, "alpha_value": 0.5060242134983476, "duration": 1.5526301860809326, "info_normalized_performance_mean": 0.411438524723053, "info_normalized_performance_final": 0.4642857015132904, "info_performance_mean": 0.411438524723053, "info_performance_final": 0.4642857015132904, "step": 1687000}
{"episode_reward": 822.8769841269855, "episode": 16871.0, "batch_reward": 2.158745288848877, "critic_loss": 770.2806396484375, "actor_loss": -1046.46337890625, "actor_target_entropy": -3.0, "actor_entropy": 2.3374619483947754, "alpha_loss": -0.07770926505327225, "alpha_value": 0.519146345055925, "duration": 1.5282349586486816, "info_normalized_performance_mean": 0.26294758915901184, "info_normalized_performance_final": 0.30992797017097473, "info_performance_mean": 0.26294758915901184, "info_performance_final": 0.30992797017097473, "step": 1687500}
{"episode_reward": 525.8950617283951, "episode": 16876.0, "batch_reward": 2.0668892860412598, "critic_loss": 602.1585693359375, "actor_loss": -1035.6651611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.8792495727539062, "alpha_loss": -0.259964257478714, "alpha_value": 0.5279079355664872, "duration": 1.6967508792877197, "info_normalized_performance_mean": 0.4919416010379791, "info_normalized_performance_final": 0.5795833468437195, "info_performance_mean": 0.4919416010379791, "info_performance_final": 0.5795833468437195, "step": 1688000}
{"episode_reward": 983.8833333333339, "episode": 16881.0, "batch_reward": 2.1908254623413086, "critic_loss": 579.2147216796875, "actor_loss": -1033.999267578125, "actor_target_entropy": -3.0, "actor_entropy": 1.9784419536590576, "alpha_loss": 0.04086193069815636, "alpha_value": 0.5371351080086397, "duration": 1.500748872756958, "info_normalized_performance_mean": 0.3610974848270416, "info_normalized_performance_final": 0.4017857015132904, "info_performance_mean": 0.3610974848270416, "info_performance_final": 0.4017857015132904, "step": 1688500}
{"episode_reward": 722.1949404761914, "episode": 16886.0, "batch_reward": 2.2195792198181152, "critic_loss": 550.7522583007812, "actor_loss": -1037.017822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.8923423290252686, "alpha_loss": 0.13324913382530212, "alpha_value": 0.5465054174843778, "duration": 1.5329062938690186, "info_normalized_performance_mean": 0.0420493520796299, "info_normalized_performance_final": 0.0574025958776474, "info_performance_mean": 0.0420493520796299, "info_performance_final": 0.0574025958776474, "step": 1689000}
{"episode_reward": 84.09870129870122, "episode": 16891.0, "batch_reward": 1.8307329416275024, "critic_loss": 694.544189453125, "actor_loss": -1016.7987060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.696138858795166, "alpha_loss": -0.31451350450515747, "alpha_value": 0.55107285671787, "duration": 1.5103814601898193, "info_normalized_performance_mean": 0.40277934074401855, "info_normalized_performance_final": 0.4615384638309479, "info_performance_mean": 0.40277934074401855, "info_performance_final": 0.4615384638309479, "step": 1689500}
{"episode_reward": 805.5586080586096, "episode": 16896.0, "batch_reward": 2.540146827697754, "critic_loss": 477.0594482421875, "actor_loss": -1037.725830078125, "actor_target_entropy": -3.0, "actor_entropy": 2.08817720413208, "alpha_loss": -0.1032634824514389, "alpha_value": 0.5575751832181022, "step": 1690000}
{"duration": 18.27362084388733, "info_normalized_performance_mean": 0.35965269804000854, "info_normalized_performance_final": 0.45023149251937866, "info_performance_mean": 0.35965269804000854, "info_performance_final": 0.45023149251937866, "step": 1690000}
{"episode_reward": 719.305555555557, "episode": 16901.0, "batch_reward": 1.534848690032959, "critic_loss": 535.3179931640625, "actor_loss": -993.72802734375, "actor_target_entropy": -3.0, "actor_entropy": 2.1651365756988525, "alpha_loss": 0.16504062712192535, "alpha_value": 0.5609934522278537, "duration": 1.380481481552124, "info_normalized_performance_mean": 0.15746033191680908, "info_normalized_performance_final": 0.3156288266181946, "info_performance_mean": 0.15746033191680908, "info_performance_final": 0.3156288266181946, "step": 1690500}
{"episode_reward": 314.9206349206348, "episode": 16906.0, "batch_reward": 1.358719825744629, "critic_loss": 754.2145385742188, "actor_loss": -998.1952514648438, "actor_target_entropy": -3.0, "actor_entropy": 1.6346238851547241, "alpha_loss": -0.29383671283721924, "alpha_value": 0.562142299961691, "duration": 1.6215567588806152, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1691000}
{"episode_reward": 0.0, "episode": 16911.0, "batch_reward": 1.6659040451049805, "critic_loss": 625.740478515625, "actor_loss": -987.6905517578125, "actor_target_entropy": -3.0, "actor_entropy": 2.0035364627838135, "alpha_loss": -0.28407829999923706, "alpha_value": 0.5648028187679432, "duration": 1.4550974369049072, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1691500}
{"episode_reward": 0.0, "episode": 16916.0, "batch_reward": 1.790503740310669, "critic_loss": 825.9508056640625, "actor_loss": -1006.7843017578125, "actor_target_entropy": -3.0, "actor_entropy": 2.239424705505371, "alpha_loss": 0.2814394533634186, "alpha_value": 0.5675015389239502, "duration": 1.4549555778503418, "info_normalized_performance_mean": 0.3662261962890625, "info_normalized_performance_final": 0.3909502327442169, "info_performance_mean": 0.3662261962890625, "info_performance_final": 0.3909502327442169, "step": 1692000}
{"episode_reward": 732.4524886877812, "episode": 16921.0, "batch_reward": 1.7480113506317139, "critic_loss": 429.8761901855469, "actor_loss": -1026.336669921875, "actor_target_entropy": -3.0, "actor_entropy": 2.0661163330078125, "alpha_loss": -0.1735142320394516, "alpha_value": 0.5695576562226632, "duration": 1.459810733795166, "info_normalized_performance_mean": 0.3408110737800598, "info_normalized_performance_final": 0.39444443583488464, "info_performance_mean": 0.3408110737800598, "info_performance_final": 0.39444443583488464, "step": 1692500}
{"episode_reward": 681.6222222222235, "episode": 16926.0, "batch_reward": 1.484154224395752, "critic_loss": 691.3358764648438, "actor_loss": -948.8685302734375, "actor_target_entropy": -3.0, "actor_entropy": 2.2247209548950195, "alpha_loss": -0.25293684005737305, "alpha_value": 0.5756102821039019, "duration": 1.5534696578979492, "info_normalized_performance_mean": 0.34447914361953735, "info_normalized_performance_final": 0.4019097089767456, "info_performance_mean": 0.34447914361953735, "info_performance_final": 0.4019097089767456, "step": 1693000}
{"episode_reward": 688.958333333334, "episode": 16931.0, "batch_reward": 1.4890451431274414, "critic_loss": 658.1077880859375, "actor_loss": -995.4720458984375, "actor_target_entropy": -3.0, "actor_entropy": 2.4450325965881348, "alpha_loss": 0.13844925165176392, "alpha_value": 0.5831168760149336, "duration": 1.445802927017212, "info_normalized_performance_mean": 0.03347042202949524, "info_normalized_performance_final": 0.036075036972761154, "info_performance_mean": 0.03347042202949524, "info_performance_final": 0.036075036972761154, "step": 1693500}
{"episode_reward": 66.94083694083706, "episode": 16936.0, "batch_reward": 1.2324917316436768, "critic_loss": 598.1701049804688, "actor_loss": -980.81591796875, "actor_target_entropy": -3.0, "actor_entropy": 2.335111618041992, "alpha_loss": -0.1790197491645813, "alpha_value": 0.5894846541525512, "duration": 1.6294362545013428, "info_normalized_performance_mean": 0.6169829368591309, "info_normalized_performance_final": 0.7106481194496155, "info_performance_mean": 0.6169829368591309, "info_performance_final": 0.7106481194496155, "step": 1694000}
{"episode_reward": 1233.9660493827164, "episode": 16941.0, "batch_reward": 1.9604487419128418, "critic_loss": 1116.790283203125, "actor_loss": -965.76806640625, "actor_target_entropy": -3.0, "actor_entropy": 2.248175621032715, "alpha_loss": -0.13532878458499908, "alpha_value": 0.5932926974983598, "duration": 1.6121537685394287, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1694500}
{"episode_reward": 0.0, "episode": 16946.0, "batch_reward": 1.5899804830551147, "critic_loss": 531.9507446289062, "actor_loss": -962.6776123046875, "actor_target_entropy": -3.0, "actor_entropy": 2.0180108547210693, "alpha_loss": 0.24467980861663818, "alpha_value": 0.595962075322287, "duration": 1.5542755126953125, "info_normalized_performance_mean": 0.4645918905735016, "info_normalized_performance_final": 0.5294784307479858, "info_performance_mean": 0.4645918905735016, "info_performance_final": 0.5294784307479858, "step": 1695000}
{"episode_reward": 929.1836734693865, "episode": 16951.0, "batch_reward": 1.5856409072875977, "critic_loss": 514.62255859375, "actor_loss": -967.167236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.7239129543304443, "alpha_loss": -0.721359372138977, "alpha_value": 0.5973547050252113, "duration": 1.6032218933105469, "info_normalized_performance_mean": 0.6512560844421387, "info_normalized_performance_final": 0.7364197373390198, "info_performance_mean": 0.6512560844421387, "info_performance_final": 0.7364197373390198, "step": 1695500}
{"episode_reward": 1302.5123456790136, "episode": 16956.0, "batch_reward": 1.7126989364624023, "critic_loss": 480.88299560546875, "actor_loss": -978.984130859375, "actor_target_entropy": -3.0, "actor_entropy": 1.9392824172973633, "alpha_loss": -0.31743544340133667, "alpha_value": 0.6025583073246099, "duration": 1.5276525020599365, "info_normalized_performance_mean": 0.5913645029067993, "info_normalized_performance_final": 0.7197802066802979, "info_performance_mean": 0.5913645029067993, "info_performance_final": 0.7197802066802979, "step": 1696000}
{"episode_reward": 1182.7289377289383, "episode": 16961.0, "batch_reward": 1.542349100112915, "critic_loss": 764.3597412109375, "actor_loss": -933.5917358398438, "actor_target_entropy": -3.0, "actor_entropy": 2.535917282104492, "alpha_loss": 0.023764172568917274, "alpha_value": 0.6107732371430001, "duration": 1.4692234992980957, "info_normalized_performance_mean": 0.046875011175870895, "info_normalized_performance_final": 0.05781250074505806, "info_performance_mean": 0.046875011175870895, "info_performance_final": 0.05781250074505806, "step": 1696500}
{"episode_reward": 93.75, "episode": 16966.0, "batch_reward": 1.888902187347412, "critic_loss": 484.12359619140625, "actor_loss": -971.6123046875, "actor_target_entropy": -3.0, "actor_entropy": 2.54091215133667, "alpha_loss": 0.4235513210296631, "alpha_value": 0.6196498120326358, "duration": 1.4094245433807373, "info_normalized_performance_mean": 0.1997656226158142, "info_normalized_performance_final": 0.2109375, "info_performance_mean": 0.1997656226158142, "info_performance_final": 0.2109375, "step": 1697000}
{"episode_reward": 399.53125, "episode": 16971.0, "batch_reward": 2.1450767517089844, "critic_loss": 876.5431518554688, "actor_loss": -1001.0802001953125, "actor_target_entropy": -3.0, "actor_entropy": 2.2724368572235107, "alpha_loss": -0.1881844401359558, "alpha_value": 0.6248155054617544, "duration": 1.5806009769439697, "info_normalized_performance_mean": 0.4473627507686615, "info_normalized_performance_final": 0.5843137502670288, "info_performance_mean": 0.4473627507686615, "info_performance_final": 0.5843137502670288, "step": 1697500}
{"episode_reward": 894.7254901960803, "episode": 16976.0, "batch_reward": 1.998576283454895, "critic_loss": 1154.78564453125, "actor_loss": -955.40966796875, "actor_target_entropy": -3.0, "actor_entropy": 2.3085765838623047, "alpha_loss": -0.34963199496269226, "alpha_value": 0.6364667551811475, "duration": 1.473799705505371, "info_normalized_performance_mean": 0.6112815737724304, "info_normalized_performance_final": 0.6748737096786499, "info_performance_mean": 0.6112815737724304, "info_performance_final": 0.6748737096786499, "step": 1698000}
{"episode_reward": 1222.5631313131314, "episode": 16981.0, "batch_reward": 2.265280246734619, "critic_loss": 709.24951171875, "actor_loss": -1002.0732421875, "actor_target_entropy": -3.0, "actor_entropy": 2.1323437690734863, "alpha_loss": -0.21458858251571655, "alpha_value": 0.6491995119592645, "duration": 1.431060791015625, "info_normalized_performance_mean": 0.45124998688697815, "info_normalized_performance_final": 0.4791666567325592, "info_performance_mean": 0.45124998688697815, "info_performance_final": 0.4791666567325592, "step": 1698500}
{"episode_reward": 902.5000000000011, "episode": 16986.0, "batch_reward": 1.7575523853302002, "critic_loss": 1075.6126708984375, "actor_loss": -942.0823974609375, "actor_target_entropy": -3.0, "actor_entropy": 2.0696024894714355, "alpha_loss": 0.10749699175357819, "alpha_value": 0.6592850406902019, "duration": 1.4302978515625, "info_normalized_performance_mean": 0.29835712909698486, "info_normalized_performance_final": 0.40714284777641296, "info_performance_mean": 0.29835712909698486, "info_performance_final": 0.40714284777641296, "step": 1699000}
{"episode_reward": 596.714285714286, "episode": 16991.0, "batch_reward": 1.9312713146209717, "critic_loss": 803.2598266601562, "actor_loss": -1005.5008544921875, "actor_target_entropy": -3.0, "actor_entropy": 2.247032642364502, "alpha_loss": -0.40752601623535156, "alpha_value": 0.6642276194115873, "duration": 1.5821197032928467, "info_normalized_performance_mean": 0.49464988708496094, "info_normalized_performance_final": 0.6399999856948853, "info_performance_mean": 0.49464988708496094, "info_performance_final": 0.6399999856948853, "step": 1699500}
{"episode_reward": 989.2999999999986, "episode": 16996.0, "batch_reward": 1.9606980085372925, "critic_loss": 386.1000671386719, "actor_loss": -994.5765380859375, "actor_target_entropy": -3.0, "actor_entropy": 2.0828330516815186, "alpha_loss": -0.16985614597797394, "alpha_value": 0.6662009779335998, "step": 1700000}
{"duration": 19.933233737945557, "info_normalized_performance_mean": 0.6638168096542358, "info_normalized_performance_final": 0.7857142686843872, "info_performance_mean": 0.6638168096542358, "info_performance_final": 0.7857142686843872, "step": 1700000}
{"episode_reward": 1327.6339285714303, "episode": 17001.0, "batch_reward": 2.2018561363220215, "critic_loss": 436.046875, "actor_loss": -949.8731689453125, "actor_target_entropy": -3.0, "actor_entropy": 2.250736713409424, "alpha_loss": 0.3148145377635956, "alpha_value": 0.6648591980563234, "duration": 1.6161017417907715, "info_normalized_performance_mean": 0.4587429165840149, "info_normalized_performance_final": 0.5984415411949158, "info_performance_mean": 0.4587429165840149, "info_performance_final": 0.5984415411949158, "step": 1700500}
{"episode_reward": 917.4857142857137, "episode": 17006.0, "batch_reward": 2.593900442123413, "critic_loss": 403.40301513671875, "actor_loss": -1037.070556640625, "actor_target_entropy": -3.0, "actor_entropy": 2.653945207595825, "alpha_loss": 0.08198528736829758, "alpha_value": 0.6616141855076278, "duration": 1.4895625114440918, "info_normalized_performance_mean": 0.6728998422622681, "info_normalized_performance_final": 0.7400000095367432, "info_performance_mean": 0.6728998422622681, "info_performance_final": 0.7400000095367432, "step": 1701000}
{"episode_reward": 1345.7999999999977, "episode": 17011.0, "batch_reward": 2.2268567085266113, "critic_loss": 1084.3671875, "actor_loss": -984.688232421875, "actor_target_entropy": -3.0, "actor_entropy": 2.127531051635742, "alpha_loss": -0.05797576904296875, "alpha_value": 0.6568468358018824, "duration": 1.434838056564331, "info_normalized_performance_mean": 0.4697383642196655, "info_normalized_performance_final": 0.5405982732772827, "info_performance_mean": 0.4697383642196655, "info_performance_final": 0.5405982732772827, "step": 1701500}
{"episode_reward": 939.4764957264963, "episode": 17016.0, "batch_reward": 1.908187747001648, "critic_loss": 482.7960205078125, "actor_loss": -976.47705078125, "actor_target_entropy": -3.0, "actor_entropy": 2.1423139572143555, "alpha_loss": 0.43480947613716125, "alpha_value": 0.646418359092289, "duration": 1.6139607429504395, "info_normalized_performance_mean": 0.6253834366798401, "info_normalized_performance_final": 0.7308333516120911, "info_performance_mean": 0.6253834366798401, "info_performance_final": 0.7308333516120911, "step": 1702000}
{"episode_reward": 1250.7666666666655, "episode": 17021.0, "batch_reward": 1.7313827276229858, "critic_loss": 468.4581298828125, "actor_loss": -960.66943359375, "actor_target_entropy": -3.0, "actor_entropy": 2.438192367553711, "alpha_loss": 0.09995236992835999, "alpha_value": 0.6335994564047595, "duration": 1.4867966175079346, "info_normalized_performance_mean": 0.4974602460861206, "info_normalized_performance_final": 0.5776643753051758, "info_performance_mean": 0.4974602460861206, "info_performance_final": 0.5776643753051758, "step": 1702500}
{"episode_reward": 994.920634920634, "episode": 17026.0, "batch_reward": 1.9895304441452026, "critic_loss": 513.7958984375, "actor_loss": -968.07421875, "actor_target_entropy": -3.0, "actor_entropy": 2.3954362869262695, "alpha_loss": -0.010073132812976837, "alpha_value": 0.6270365634693691, "duration": 1.6138746738433838, "info_normalized_performance_mean": 0.4457460641860962, "info_normalized_performance_final": 0.5730158686637878, "info_performance_mean": 0.4457460641860962, "info_performance_final": 0.5730158686637878, "step": 1703000}
{"episode_reward": 891.4920634920638, "episode": 17031.0, "batch_reward": 2.1029646396636963, "critic_loss": 361.483642578125, "actor_loss": -972.8442993164062, "actor_target_entropy": -3.0, "actor_entropy": 2.042339324951172, "alpha_loss": 0.13027127087116241, "alpha_value": 0.6191379121962645, "duration": 1.6134624481201172, "info_normalized_performance_mean": 0.6479805707931519, "info_normalized_performance_final": 0.8236331343650818, "info_performance_mean": 0.6479805707931519, "info_performance_final": 0.8236331343650818, "step": 1703500}
{"episode_reward": 1295.9611992945336, "episode": 17036.0, "batch_reward": 2.157614231109619, "critic_loss": 392.57208251953125, "actor_loss": -991.322998046875, "actor_target_entropy": -3.0, "actor_entropy": 2.2995853424072266, "alpha_loss": 0.005864597856998444, "alpha_value": 0.6139102447654443, "duration": 1.5943360328674316, "info_normalized_performance_mean": 0.3643397390842438, "info_normalized_performance_final": 0.4356217384338379, "info_performance_mean": 0.3643397390842438, "info_performance_final": 0.4356217384338379, "step": 1704000}
{"episode_reward": 728.6793493245099, "episode": 17041.0, "batch_reward": 2.984208106994629, "critic_loss": 998.7764892578125, "actor_loss": -981.1192626953125, "actor_target_entropy": -3.0, "actor_entropy": 2.289377450942993, "alpha_loss": 0.36445116996765137, "alpha_value": 0.6064433269890067, "duration": 1.455099105834961, "info_normalized_performance_mean": 0.43978816270828247, "info_normalized_performance_final": 0.5270588397979736, "info_performance_mean": 0.43978816270828247, "info_performance_final": 0.5270588397979736, "step": 1704500}
{"episode_reward": 879.5764705882344, "episode": 17046.0, "batch_reward": 2.545206308364868, "critic_loss": 1215.21728515625, "actor_loss": -981.9451293945312, "actor_target_entropy": -3.0, "actor_entropy": 1.8659881353378296, "alpha_loss": -0.24239835143089294, "alpha_value": 0.603671310433739, "duration": 1.5920829772949219, "info_normalized_performance_mean": 0.582990288734436, "info_normalized_performance_final": 0.6274510025978088, "info_performance_mean": 0.582990288734436, "info_performance_final": 0.6274510025978088, "step": 1705000}
{"episode_reward": 1165.9803921568605, "episode": 17051.0, "batch_reward": 1.6349952220916748, "critic_loss": 857.7163696289062, "actor_loss": -995.9457397460938, "actor_target_entropy": -3.0, "actor_entropy": 2.067318916320801, "alpha_loss": -0.16165634989738464, "alpha_value": 0.6094367040522398, "duration": 1.5496149063110352, "info_normalized_performance_mean": 0.4818744957447052, "info_normalized_performance_final": 0.5849462151527405, "info_performance_mean": 0.4818744957447052, "info_performance_final": 0.5849462151527405, "step": 1705500}
{"episode_reward": 963.749103942654, "episode": 17056.0, "batch_reward": 2.2054824829101562, "critic_loss": 589.2967529296875, "actor_loss": -995.9453735351562, "actor_target_entropy": -3.0, "actor_entropy": 2.222942352294922, "alpha_loss": 0.17275318503379822, "alpha_value": 0.6151736235265165, "duration": 1.4835658073425293, "info_normalized_performance_mean": 0.5669387578964233, "info_normalized_performance_final": 0.6638321876525879, "info_performance_mean": 0.5669387578964233, "info_performance_final": 0.6638321876525879, "step": 1706000}
{"episode_reward": 1133.8775510204093, "episode": 17061.0, "batch_reward": 2.86098051071167, "critic_loss": 430.5374755859375, "actor_loss": -1033.042236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.8928004503250122, "alpha_loss": -0.46312689781188965, "alpha_value": 0.6153979450961812, "duration": 1.4753780364990234, "info_normalized_performance_mean": 0.5008593797683716, "info_normalized_performance_final": 0.5625, "info_performance_mean": 0.5008593797683716, "info_performance_final": 0.5625, "step": 1706500}
{"episode_reward": 1001.71875, "episode": 17066.0, "batch_reward": 2.5926804542541504, "critic_loss": 348.57440185546875, "actor_loss": -1046.8785400390625, "actor_target_entropy": -3.0, "actor_entropy": 2.019446849822998, "alpha_loss": 0.09114595502614975, "alpha_value": 0.616181402085357, "duration": 1.4791715145111084, "info_normalized_performance_mean": 0.09997060894966125, "info_normalized_performance_final": 0.11568627506494522, "info_performance_mean": 0.09997060894966125, "info_performance_final": 0.11568627506494522, "step": 1707000}
{"episode_reward": 199.94117647058818, "episode": 17071.0, "batch_reward": 2.5305442810058594, "critic_loss": 275.9181213378906, "actor_loss": -1009.9620361328125, "actor_target_entropy": -3.0, "actor_entropy": 2.2062597274780273, "alpha_loss": 0.04472201317548752, "alpha_value": 0.6142015397476507, "duration": 1.5895631313323975, "info_normalized_performance_mean": 0.6315625905990601, "info_normalized_performance_final": 0.7462499737739563, "info_performance_mean": 0.6315625905990601, "info_performance_final": 0.7462499737739563, "step": 1707500}
{"episode_reward": 1263.124999999998, "episode": 17076.0, "batch_reward": 2.787540912628174, "critic_loss": 547.21337890625, "actor_loss": -1025.9385986328125, "actor_target_entropy": -3.0, "actor_entropy": 2.1103124618530273, "alpha_loss": 0.30458396673202515, "alpha_value": 0.6077142310181252, "duration": 1.5128941535949707, "info_normalized_performance_mean": 0.4356200098991394, "info_normalized_performance_final": 0.5322420597076416, "info_performance_mean": 0.4356200098991394, "info_performance_final": 0.5322420597076416, "step": 1708000}
{"episode_reward": 871.2400793650812, "episode": 17081.0, "batch_reward": 1.9546406269073486, "critic_loss": 725.60107421875, "actor_loss": -973.2335205078125, "actor_target_entropy": -3.0, "actor_entropy": 1.6945244073867798, "alpha_loss": -0.019954446703195572, "alpha_value": 0.5994434857822009, "duration": 1.676513910293579, "info_normalized_performance_mean": 0.35882386565208435, "info_normalized_performance_final": 0.4389701187610626, "info_performance_mean": 0.35882386565208435, "info_performance_final": 0.4389701187610626, "step": 1708500}
{"episode_reward": 717.6478067387168, "episode": 17086.0, "batch_reward": 2.3443589210510254, "critic_loss": 434.32086181640625, "actor_loss": -990.0882568359375, "actor_target_entropy": -3.0, "actor_entropy": 1.9495930671691895, "alpha_loss": 0.01953934133052826, "alpha_value": 0.591381615797178, "duration": 1.4619088172912598, "info_normalized_performance_mean": 0.35501471161842346, "info_normalized_performance_final": 0.4264705777168274, "info_performance_mean": 0.35501471161842346, "info_performance_final": 0.4264705777168274, "step": 1709000}
{"episode_reward": 710.0294117647045, "episode": 17091.0, "batch_reward": 3.5413572788238525, "critic_loss": 453.75732421875, "actor_loss": -1063.2647705078125, "actor_target_entropy": -3.0, "actor_entropy": 1.9725489616394043, "alpha_loss": 0.463070273399353, "alpha_value": 0.5885146276482797, "duration": 1.4843993186950684, "info_normalized_performance_mean": 0.5323724150657654, "info_normalized_performance_final": 0.6019607782363892, "info_performance_mean": 0.5323724150657654, "info_performance_final": 0.6019607782363892, "step": 1709500}
{"episode_reward": 1064.7450980392139, "episode": 17096.0, "batch_reward": 2.556647300720215, "critic_loss": 851.1676025390625, "actor_loss": -1020.2957763671875, "actor_target_entropy": -3.0, "actor_entropy": 1.8124492168426514, "alpha_loss": 0.16433587670326233, "alpha_value": 0.5851986300303789, "step": 1710000}
{"duration": 18.690391063690186, "info_normalized_performance_mean": 0.3117539882659912, "info_normalized_performance_final": 0.36791443824768066, "info_performance_mean": 0.3117539882659912, "info_performance_final": 0.36791443824768066, "step": 1710000}
{"episode_reward": 623.5080213903748, "episode": 17101.0, "batch_reward": 3.6742019653320312, "critic_loss": 570.6705322265625, "actor_loss": -1085.591064453125, "actor_target_entropy": -3.0, "actor_entropy": 1.9514334201812744, "alpha_loss": -0.30824267864227295, "alpha_value": 0.5849385409113006, "duration": 1.5787250995635986, "info_normalized_performance_mean": 0.516598105430603, "info_normalized_performance_final": 0.6460784077644348, "info_performance_mean": 0.516598105430603, "info_performance_final": 0.6460784077644348, "step": 1710500}
{"episode_reward": 1033.196078431371, "episode": 17106.0, "batch_reward": 3.2542905807495117, "critic_loss": 1081.939208984375, "actor_loss": -1064.489990234375, "actor_target_entropy": -3.0, "actor_entropy": 2.0565848350524902, "alpha_loss": -0.11494007706642151, "alpha_value": 0.5879399164547174, "duration": 1.616401195526123, "info_normalized_performance_mean": 0.42947086691856384, "info_normalized_performance_final": 0.5158730149269104, "info_performance_mean": 0.42947086691856384, "info_performance_final": 0.5158730149269104, "step": 1711000}
{"episode_reward": 858.9417989417999, "episode": 17111.0, "batch_reward": 3.4856338500976562, "critic_loss": 541.62890625, "actor_loss": -1059.618896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.77236008644104, "alpha_loss": -0.21392092108726501, "alpha_value": 0.5974645479795774, "duration": 1.5593008995056152, "info_normalized_performance_mean": 0.2719636559486389, "info_normalized_performance_final": 0.37220779061317444, "info_performance_mean": 0.2719636559486389, "info_performance_final": 0.37220779061317444, "step": 1711500}
{"episode_reward": 543.9272727272725, "episode": 17116.0, "batch_reward": 3.5145158767700195, "critic_loss": 614.689697265625, "actor_loss": -1086.429931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.911051630973816, "alpha_loss": -0.20650076866149902, "alpha_value": 0.6053359503657049, "duration": 1.50285005569458, "info_normalized_performance_mean": 0.6187882423400879, "info_normalized_performance_final": 0.7181122303009033, "info_performance_mean": 0.6187882423400879, "info_performance_final": 0.7181122303009033, "step": 1712000}
{"episode_reward": 1237.5765306122448, "episode": 17121.0, "batch_reward": 3.4599485397338867, "critic_loss": 532.66357421875, "actor_loss": -1073.2286376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.9327538013458252, "alpha_loss": -0.09998825937509537, "alpha_value": 0.6131350640458555, "duration": 1.624619483947754, "info_normalized_performance_mean": 0.2791566550731659, "info_normalized_performance_final": 0.3769936263561249, "info_performance_mean": 0.2791566550731659, "info_performance_final": 0.3769936263561249, "step": 1712500}
{"episode_reward": 558.313397129186, "episode": 17126.0, "batch_reward": 2.7455430030822754, "critic_loss": 780.2578735351562, "actor_loss": -1054.1173095703125, "actor_target_entropy": -3.0, "actor_entropy": 1.8695898056030273, "alpha_loss": -0.20741905272006989, "alpha_value": 0.6198243552616283, "duration": 1.5652673244476318, "info_normalized_performance_mean": 0.4586392939090729, "info_normalized_performance_final": 0.5540364384651184, "info_performance_mean": 0.4586392939090729, "info_performance_final": 0.5540364384651184, "step": 1713000}
{"episode_reward": 917.2786458333322, "episode": 17131.0, "batch_reward": 3.732574462890625, "critic_loss": 631.765869140625, "actor_loss": -1065.1357421875, "actor_target_entropy": -3.0, "actor_entropy": 2.187443256378174, "alpha_loss": 0.12164149433374405, "alpha_value": 0.6279587861772127, "duration": 1.6149346828460693, "info_normalized_performance_mean": 0.4950333535671234, "info_normalized_performance_final": 0.6297619342803955, "info_performance_mean": 0.4950333535671234, "info_performance_final": 0.6297619342803955, "step": 1713500}
{"episode_reward": 990.0666666666658, "episode": 17136.0, "batch_reward": 3.3761308193206787, "critic_loss": 888.27783203125, "actor_loss": -1105.53173828125, "actor_target_entropy": -3.0, "actor_entropy": 1.9272856712341309, "alpha_loss": 0.024871423840522766, "alpha_value": 0.6368269184020958, "duration": 1.4173672199249268, "info_normalized_performance_mean": 0.23884765803813934, "info_normalized_performance_final": 0.3125, "info_performance_mean": 0.23884765803813934, "info_performance_final": 0.3125, "step": 1714000}
{"episode_reward": 477.6953125, "episode": 17141.0, "batch_reward": 3.772207260131836, "critic_loss": 626.114013671875, "actor_loss": -1116.355712890625, "actor_target_entropy": -3.0, "actor_entropy": 2.3459627628326416, "alpha_loss": 0.11711207032203674, "alpha_value": 0.6470475809383645, "duration": 1.5839276313781738, "info_normalized_performance_mean": 0.3764670193195343, "info_normalized_performance_final": 0.421875, "info_performance_mean": 0.3764670193195343, "info_performance_final": 0.421875, "step": 1714500}
{"episode_reward": 752.9340277777778, "episode": 17146.0, "batch_reward": 2.657518148422241, "critic_loss": 1188.073974609375, "actor_loss": -1113.8695068359375, "actor_target_entropy": -3.0, "actor_entropy": 2.1443309783935547, "alpha_loss": -0.38402581214904785, "alpha_value": 0.6575597288437005, "duration": 1.367999792098999, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1715000}
{"episode_reward": 0.0, "episode": 17151.0, "batch_reward": 3.958873987197876, "critic_loss": 807.2044677734375, "actor_loss": -1133.6700439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.989577054977417, "alpha_loss": -0.24187253415584564, "alpha_value": 0.66705546832489, "duration": 1.4417195320129395, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1715500}
{"episode_reward": 0.0, "episode": 17156.0, "batch_reward": 3.6628289222717285, "critic_loss": 1021.9055786132812, "actor_loss": -1130.6510009765625, "actor_target_entropy": -3.0, "actor_entropy": 2.1636204719543457, "alpha_loss": -0.5280171632766724, "alpha_value": 0.6891525750637865, "duration": 1.6345787048339844, "info_normalized_performance_mean": 0.4214952886104584, "info_normalized_performance_final": 0.5147619247436523, "info_performance_mean": 0.4214952886104584, "info_performance_final": 0.5147619247436523, "step": 1716000}
{"episode_reward": 842.9904761904768, "episode": 17161.0, "batch_reward": 3.1820974349975586, "critic_loss": 723.4739990234375, "actor_loss": -1149.689208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.9857696294784546, "alpha_loss": -0.5729186534881592, "alpha_value": 0.6999437423207446, "duration": 1.409015417098999, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1716500}
{"episode_reward": 0.0, "episode": 17166.0, "batch_reward": 3.5484461784362793, "critic_loss": 626.34326171875, "actor_loss": -1165.599853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.9866397380828857, "alpha_loss": -0.16478459537029266, "alpha_value": 0.7086129121128731, "duration": 1.460508108139038, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1717000}
{"episode_reward": 0.0, "episode": 17171.0, "batch_reward": 4.224063873291016, "critic_loss": 846.4310913085938, "actor_loss": -1251.564697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.8054457902908325, "alpha_loss": -0.16262966394424438, "alpha_value": 0.7091756243421934, "duration": 1.4615516662597656, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1717500}
{"episode_reward": 0.0, "episode": 17176.0, "batch_reward": 4.084681034088135, "critic_loss": 1198.163818359375, "actor_loss": -1195.5224609375, "actor_target_entropy": -3.0, "actor_entropy": 2.0648794174194336, "alpha_loss": -0.07342563569545746, "alpha_value": 0.7030308056087853, "duration": 1.5341761112213135, "info_normalized_performance_mean": 0.19306938350200653, "info_normalized_performance_final": 0.314434677362442, "info_performance_mean": 0.19306938350200653, "info_performance_final": 0.314434677362442, "step": 1718000}
{"episode_reward": 386.1388074291301, "episode": 17181.0, "batch_reward": 3.285062313079834, "critic_loss": 506.04217529296875, "actor_loss": -1162.119140625, "actor_target_entropy": -3.0, "actor_entropy": 2.3437275886535645, "alpha_loss": 0.47496506571769714, "alpha_value": 0.689547295000858, "duration": 1.5048089027404785, "info_normalized_performance_mean": 0.0018948414362967014, "info_normalized_performance_final": 0.0069444444961845875, "info_performance_mean": 0.0018948414362967014, "info_performance_final": 0.0069444444961845875, "step": 1718500}
{"episode_reward": 3.7896825396825387, "episode": 17186.0, "batch_reward": 2.850499153137207, "critic_loss": 1161.894287109375, "actor_loss": -1204.640625, "actor_target_entropy": -3.0, "actor_entropy": 2.159623146057129, "alpha_loss": 0.33921515941619873, "alpha_value": 0.671962070490139, "duration": 1.4397940635681152, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1719000}
{"episode_reward": 0.0, "episode": 17191.0, "batch_reward": 3.69679856300354, "critic_loss": 498.3133239746094, "actor_loss": -1188.71240234375, "actor_target_entropy": -3.0, "actor_entropy": 2.117116928100586, "alpha_loss": 0.6879512071609497, "alpha_value": 0.6530984239978372, "duration": 1.5456416606903076, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1719500}
{"episode_reward": 0.0, "episode": 17196.0, "batch_reward": 3.5703258514404297, "critic_loss": 1167.3843994140625, "actor_loss": -1151.817626953125, "actor_target_entropy": -3.0, "actor_entropy": 2.135709524154663, "alpha_loss": 0.7001588940620422, "alpha_value": 0.6359348328000707, "step": 1720000}
{"duration": 18.87002468109131, "info_normalized_performance_mean": 0.045555561780929565, "info_normalized_performance_final": 0.0694444477558136, "info_performance_mean": 0.045555561780929565, "info_performance_final": 0.0694444477558136, "step": 1720000}
{"episode_reward": 91.11111111111097, "episode": 17201.0, "batch_reward": 3.8377647399902344, "critic_loss": 975.4217529296875, "actor_loss": -1131.15625, "actor_target_entropy": -3.0, "actor_entropy": 2.2483253479003906, "alpha_loss": 0.6999201774597168, "alpha_value": 0.6181792618027917, "duration": 1.4889521598815918, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1720500}
{"episode_reward": 0.0, "episode": 17206.0, "batch_reward": 3.017247200012207, "critic_loss": 1239.5867919921875, "actor_loss": -1092.218017578125, "actor_target_entropy": -3.0, "actor_entropy": 2.1847095489501953, "alpha_loss": 0.519096851348877, "alpha_value": 0.6039139322297647, "duration": 1.4789721965789795, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1721000}
{"episode_reward": 0.0, "episode": 17211.0, "batch_reward": 3.8520519733428955, "critic_loss": 803.1634521484375, "actor_loss": -1133.724853515625, "actor_target_entropy": -3.0, "actor_entropy": 2.35595703125, "alpha_loss": 0.4083775281906128, "alpha_value": 0.5912504472406485, "duration": 1.6137080192565918, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1721500}
{"episode_reward": 0.0, "episode": 17216.0, "batch_reward": 5.093284606933594, "critic_loss": 424.6822509765625, "actor_loss": -1135.123779296875, "actor_target_entropy": -3.0, "actor_entropy": 2.2464375495910645, "alpha_loss": 0.4075624644756317, "alpha_value": 0.5783773465080903, "duration": 1.4823627471923828, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1722000}
{"episode_reward": 0.0, "episode": 17221.0, "batch_reward": 3.355499744415283, "critic_loss": 530.2462158203125, "actor_loss": -1149.197021484375, "actor_target_entropy": -3.0, "actor_entropy": 2.0624547004699707, "alpha_loss": 0.5977041125297546, "alpha_value": 0.5678954355508254, "duration": 1.4389097690582275, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1722500}
{"episode_reward": 0.0, "episode": 17226.0, "batch_reward": 3.508209466934204, "critic_loss": 603.580078125, "actor_loss": -1103.0478515625, "actor_target_entropy": -3.0, "actor_entropy": 2.317392349243164, "alpha_loss": -0.05448237061500549, "alpha_value": 0.5608892153269132, "duration": 1.599658727645874, "info_normalized_performance_mean": 0.7823430895805359, "info_normalized_performance_final": 0.9205882549285889, "info_performance_mean": 0.7823430895805359, "info_performance_final": 0.9205882549285889, "step": 1723000}
{"episode_reward": 1564.686274509806, "episode": 17231.0, "batch_reward": 3.0799055099487305, "critic_loss": 431.9866943359375, "actor_loss": -1063.930908203125, "actor_target_entropy": -3.0, "actor_entropy": 2.139681816101074, "alpha_loss": 0.020318545401096344, "alpha_value": 0.5560801038885811, "duration": 1.5620629787445068, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1723500}
{"episode_reward": 0.0, "episode": 17236.0, "batch_reward": 3.5018980503082275, "critic_loss": 382.962158203125, "actor_loss": -1039.650634765625, "actor_target_entropy": -3.0, "actor_entropy": 2.3118433952331543, "alpha_loss": 0.3624202609062195, "alpha_value": 0.5501450052711627, "duration": 1.6108627319335938, "info_normalized_performance_mean": 0.3507576882839203, "info_normalized_performance_final": 0.4109615385532379, "info_performance_mean": 0.3507576882839203, "info_performance_final": 0.4109615385532379, "step": 1724000}
{"episode_reward": 701.5153846153842, "episode": 17241.0, "batch_reward": 3.812455415725708, "critic_loss": 1070.312744140625, "actor_loss": -1087.052001953125, "actor_target_entropy": -3.0, "actor_entropy": 2.147554636001587, "alpha_loss": 0.07757619023323059, "alpha_value": 0.5443111052937157, "duration": 1.4181673526763916, "info_normalized_performance_mean": 0.13126049935817719, "info_normalized_performance_final": 0.17983193695545197, "info_performance_mean": 0.13126049935817719, "info_performance_final": 0.17983193695545197, "step": 1724500}
{"episode_reward": 262.5210084033614, "episode": 17246.0, "batch_reward": 3.9591941833496094, "critic_loss": 674.8556518554688, "actor_loss": -1079.6021728515625, "actor_target_entropy": -3.0, "actor_entropy": 2.2629504203796387, "alpha_loss": 0.1433253288269043, "alpha_value": 0.5397151256956523, "duration": 1.4978229999542236, "info_normalized_performance_mean": 0.6529688239097595, "info_normalized_performance_final": 0.7767857313156128, "info_performance_mean": 0.6529688239097595, "info_performance_final": 0.7767857313156128, "step": 1725000}
{"episode_reward": 1305.9374999999982, "episode": 17251.0, "batch_reward": 3.8600363731384277, "critic_loss": 273.9269104003906, "actor_loss": -1052.98779296875, "actor_target_entropy": -3.0, "actor_entropy": 2.336344003677368, "alpha_loss": 0.1262737661600113, "alpha_value": 0.533395228037771, "duration": 1.5347509384155273, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1725500}
{"episode_reward": 0.0, "episode": 17256.0, "batch_reward": 3.514907121658325, "critic_loss": 471.9754638671875, "actor_loss": -1026.718505859375, "actor_target_entropy": -3.0, "actor_entropy": 2.149618625640869, "alpha_loss": 0.138477623462677, "alpha_value": 0.5252017858014755, "duration": 1.555053949356079, "info_normalized_performance_mean": 0.4716137647628784, "info_normalized_performance_final": 0.5740740895271301, "info_performance_mean": 0.4716137647628784, "info_performance_final": 0.5740740895271301, "step": 1726000}
{"episode_reward": 943.2275132275148, "episode": 17261.0, "batch_reward": 3.2634787559509277, "critic_loss": 326.876220703125, "actor_loss": -1011.08251953125, "actor_target_entropy": -3.0, "actor_entropy": 2.1833972930908203, "alpha_loss": 0.08560732752084732, "alpha_value": 0.5182338598766798, "duration": 1.4662630558013916, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1726500}
{"episode_reward": 0.0, "episode": 17266.0, "batch_reward": 3.953843593597412, "critic_loss": 446.90570068359375, "actor_loss": -1077.005615234375, "actor_target_entropy": -3.0, "actor_entropy": 2.4782843589782715, "alpha_loss": 0.17360618710517883, "alpha_value": 0.5112479434025942, "duration": 1.6319379806518555, "info_normalized_performance_mean": 0.14532570540905, "info_normalized_performance_final": 0.1855158656835556, "info_performance_mean": 0.14532570540905, "info_performance_final": 0.1855158656835556, "step": 1727000}
{"episode_reward": 290.6514550264554, "episode": 17271.0, "batch_reward": 3.1614410877227783, "critic_loss": 1338.439453125, "actor_loss": -1017.2708129882812, "actor_target_entropy": -3.0, "actor_entropy": 2.126366138458252, "alpha_loss": 0.17917276918888092, "alpha_value": 0.5055477518828891, "duration": 1.77354097366333, "info_normalized_performance_mean": 0.533814013004303, "info_normalized_performance_final": 0.646672785282135, "info_performance_mean": 0.533814013004303, "info_performance_final": 0.646672785282135, "step": 1727500}
{"episode_reward": 1067.6282051282033, "episode": 17276.0, "batch_reward": 3.474903106689453, "critic_loss": 525.1289672851562, "actor_loss": -1013.6009521484375, "actor_target_entropy": -3.0, "actor_entropy": 2.2262210845947266, "alpha_loss": 0.04438108205795288, "alpha_value": 0.5008123975151914, "duration": 1.489361047744751, "info_normalized_performance_mean": 0.6809217929840088, "info_normalized_performance_final": 0.7869352698326111, "info_performance_mean": 0.6809217929840088, "info_performance_final": 0.7869352698326111, "step": 1728000}
{"episode_reward": 1361.843711843712, "episode": 17281.0, "batch_reward": 3.969865560531616, "critic_loss": 634.6634521484375, "actor_loss": -1079.935302734375, "actor_target_entropy": -3.0, "actor_entropy": 2.1091458797454834, "alpha_loss": 0.2147943079471588, "alpha_value": 0.49652346693536026, "duration": 1.4812934398651123, "info_normalized_performance_mean": 0.5815179347991943, "info_normalized_performance_final": 0.6642857193946838, "info_performance_mean": 0.5815179347991943, "info_performance_final": 0.6642857193946838, "step": 1728500}
{"episode_reward": 1163.0357142857154, "episode": 17286.0, "batch_reward": 4.350487232208252, "critic_loss": 652.359130859375, "actor_loss": -1049.123291015625, "actor_target_entropy": -3.0, "actor_entropy": 2.185851812362671, "alpha_loss": 0.4340806305408478, "alpha_value": 0.48860843692069095, "duration": 1.6735560894012451, "info_normalized_performance_mean": 0.5504381656646729, "info_normalized_performance_final": 0.6530952453613281, "info_performance_mean": 0.5504381656646729, "info_performance_final": 0.6530952453613281, "step": 1729000}
{"episode_reward": 1100.8761904761914, "episode": 17291.0, "batch_reward": 4.008636474609375, "critic_loss": 358.44219970703125, "actor_loss": -988.17041015625, "actor_target_entropy": -3.0, "actor_entropy": 2.3308048248291016, "alpha_loss": 0.31084126234054565, "alpha_value": 0.48169825986652753, "duration": 1.645613431930542, "info_normalized_performance_mean": 0.4767460525035858, "info_normalized_performance_final": 0.5923520922660828, "info_performance_mean": 0.4767460525035858, "info_performance_final": 0.5923520922660828, "step": 1729500}
{"episode_reward": 953.4920634920642, "episode": 17296.0, "batch_reward": 4.364017486572266, "critic_loss": 571.9021606445312, "actor_loss": -1041.96728515625, "actor_target_entropy": -3.0, "actor_entropy": 2.3508636951446533, "alpha_loss": 0.2855343222618103, "alpha_value": 0.47533972825987586, "step": 1730000}
{"duration": 18.88908886909485, "info_normalized_performance_mean": 0.2822863459587097, "info_normalized_performance_final": 0.3504273593425751, "info_performance_mean": 0.2822863459587097, "info_performance_final": 0.3504273593425751, "step": 1730000}
{"episode_reward": 564.5726495726498, "episode": 17301.0, "batch_reward": 4.8726701736450195, "critic_loss": 277.2204895019531, "actor_loss": -1050.148193359375, "actor_target_entropy": -3.0, "actor_entropy": 2.1689553260803223, "alpha_loss": -0.1177486851811409, "alpha_value": 0.47418388789060345, "duration": 1.5041556358337402, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1730500}
{"episode_reward": 0.0, "episode": 17306.0, "batch_reward": 4.722007751464844, "critic_loss": 733.2883911132812, "actor_loss": -1032.5416259765625, "actor_target_entropy": -3.0, "actor_entropy": 2.3110194206237793, "alpha_loss": 0.09929697960615158, "alpha_value": 0.47207674091902335, "duration": 1.5684089660644531, "info_normalized_performance_mean": 0.5407066345214844, "info_normalized_performance_final": 0.6693891882896423, "info_performance_mean": 0.5407066345214844, "info_performance_final": 0.6693891882896423, "step": 1731000}
{"episode_reward": 1081.413352272728, "episode": 17311.0, "batch_reward": 4.574368000030518, "critic_loss": 1054.8531494140625, "actor_loss": -1011.3145751953125, "actor_target_entropy": -3.0, "actor_entropy": 2.3092923164367676, "alpha_loss": 0.03503311052918434, "alpha_value": 0.47016687227049225, "duration": 1.5882375240325928, "info_normalized_performance_mean": 0.4583272933959961, "info_normalized_performance_final": 0.5254545211791992, "info_performance_mean": 0.4583272933959961, "info_performance_final": 0.5254545211791992, "step": 1731500}
{"episode_reward": 916.6545454545449, "episode": 17316.0, "batch_reward": 4.338222980499268, "critic_loss": 410.850341796875, "actor_loss": -1063.7152099609375, "actor_target_entropy": -3.0, "actor_entropy": 2.23077654838562, "alpha_loss": 0.28987550735473633, "alpha_value": 0.46298556152958015, "duration": 1.616741418838501, "info_normalized_performance_mean": 0.7105644345283508, "info_normalized_performance_final": 0.8183421492576599, "info_performance_mean": 0.7105644345283508, "info_performance_final": 0.8183421492576599, "step": 1732000}
{"episode_reward": 1421.1287477954131, "episode": 17321.0, "batch_reward": 5.142478942871094, "critic_loss": 1513.0999755859375, "actor_loss": -1061.1060791015625, "actor_target_entropy": -3.0, "actor_entropy": 2.2749686241149902, "alpha_loss": 0.20703575015068054, "alpha_value": 0.4610751444184946, "duration": 1.4299664497375488, "info_normalized_performance_mean": 0.2103571742773056, "info_normalized_performance_final": 0.2410714328289032, "info_performance_mean": 0.2103571742773056, "info_performance_final": 0.2410714328289032, "step": 1732500}
{"episode_reward": 420.71428571428544, "episode": 17326.0, "batch_reward": 4.541081428527832, "critic_loss": 1345.91162109375, "actor_loss": -1016.8987426757812, "actor_target_entropy": -3.0, "actor_entropy": 2.7476303577423096, "alpha_loss": 0.30446282029151917, "alpha_value": 0.45659361335126286, "duration": 1.5429933071136475, "info_normalized_performance_mean": 0.48975056409835815, "info_normalized_performance_final": 0.5847355723381042, "info_performance_mean": 0.48975056409835815, "info_performance_final": 0.5847355723381042, "step": 1733000}
{"episode_reward": 979.5012019230769, "episode": 17331.0, "batch_reward": 5.5661516189575195, "critic_loss": 554.2353515625, "actor_loss": -1081.5562744140625, "actor_target_entropy": -3.0, "actor_entropy": 2.203892230987549, "alpha_loss": -0.07067994028329849, "alpha_value": 0.4538190079677126, "duration": 1.4763009548187256, "info_normalized_performance_mean": 0.3015933930873871, "info_normalized_performance_final": 0.40705129504203796, "info_performance_mean": 0.3015933930873871, "info_performance_final": 0.40705129504203796, "step": 1733500}
{"episode_reward": 603.1868131868129, "episode": 17336.0, "batch_reward": 4.396258354187012, "critic_loss": 581.8579711914062, "actor_loss": -1007.7095947265625, "actor_target_entropy": -3.0, "actor_entropy": 2.3863844871520996, "alpha_loss": 0.21600966155529022, "alpha_value": 0.4526809743151244, "duration": 1.548285722732544, "info_normalized_performance_mean": 0.6149999499320984, "info_normalized_performance_final": 0.7242857217788696, "info_performance_mean": 0.6149999499320984, "info_performance_final": 0.7242857217788696, "step": 1734000}
{"episode_reward": 1229.999999999999, "episode": 17341.0, "batch_reward": 4.1886420249938965, "critic_loss": 358.60467529296875, "actor_loss": -1003.9661254882812, "actor_target_entropy": -3.0, "actor_entropy": 2.0265698432922363, "alpha_loss": 0.09679027646780014, "alpha_value": 0.4501190339794604, "duration": 1.6434972286224365, "info_normalized_performance_mean": 0.5877580046653748, "info_normalized_performance_final": 0.7175925970077515, "info_performance_mean": 0.5877580046653748, "info_performance_final": 0.7175925970077515, "step": 1734500}
{"episode_reward": 1175.5158730158737, "episode": 17346.0, "batch_reward": 4.065220832824707, "critic_loss": 385.2972106933594, "actor_loss": -1018.52099609375, "actor_target_entropy": -3.0, "actor_entropy": 2.1238627433776855, "alpha_loss": 0.050284769386053085, "alpha_value": 0.44288831301341947, "duration": 1.7165725231170654, "info_normalized_performance_mean": 0.33718451857566833, "info_normalized_performance_final": 0.40740740299224854, "info_performance_mean": 0.33718451857566833, "info_performance_final": 0.40740740299224854, "step": 1735000}
{"episode_reward": 674.3692129629629, "episode": 17351.0, "batch_reward": 4.693955421447754, "critic_loss": 241.53369140625, "actor_loss": -982.341552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.8335230350494385, "alpha_loss": -0.038516752421855927, "alpha_value": 0.43685474871651336, "duration": 1.6685967445373535, "info_normalized_performance_mean": 0.3581266403198242, "info_normalized_performance_final": 0.44258373975753784, "info_performance_mean": 0.3581266403198242, "info_performance_final": 0.44258373975753784, "step": 1735500}
{"episode_reward": 716.2532204637464, "episode": 17356.0, "batch_reward": 5.188800811767578, "critic_loss": 281.9454345703125, "actor_loss": -1064.66748046875, "actor_target_entropy": -3.0, "actor_entropy": 2.4197821617126465, "alpha_loss": 0.2118239402770996, "alpha_value": 0.43841601410976067, "duration": 1.5277485847473145, "info_normalized_performance_mean": 0.8892707824707031, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.8892707824707031, "info_performance_final": 1.0, "step": 1736000}
{"episode_reward": 1778.5416666666665, "episode": 17361.0, "batch_reward": 4.808896064758301, "critic_loss": 267.63818359375, "actor_loss": -1026.36767578125, "actor_target_entropy": -3.0, "actor_entropy": 2.0193886756896973, "alpha_loss": 0.03227374702692032, "alpha_value": 0.43704091752591384, "duration": 1.4576127529144287, "info_normalized_performance_mean": 0.6123273372650146, "info_normalized_performance_final": 0.7470238208770752, "info_performance_mean": 0.6123273372650146, "info_performance_final": 0.7470238208770752, "step": 1736500}
{"episode_reward": 1224.65476190476, "episode": 17366.0, "batch_reward": 4.679248809814453, "critic_loss": 471.19830322265625, "actor_loss": -1015.8724975585938, "actor_target_entropy": -3.0, "actor_entropy": 2.0242106914520264, "alpha_loss": -0.022148288786411285, "alpha_value": 0.435468695279436, "duration": 1.5946059226989746, "info_normalized_performance_mean": 0.48229163885116577, "info_normalized_performance_final": 0.5367063283920288, "info_performance_mean": 0.48229163885116577, "info_performance_final": 0.5367063283920288, "step": 1737000}
{"episode_reward": 964.5833333333336, "episode": 17371.0, "batch_reward": 4.735089302062988, "critic_loss": 379.2514343261719, "actor_loss": -1027.4241943359375, "actor_target_entropy": -3.0, "actor_entropy": 2.680572271347046, "alpha_loss": -0.010975092649459839, "alpha_value": 0.44082347772172276, "duration": 1.596743106842041, "info_normalized_performance_mean": 0.5052552819252014, "info_normalized_performance_final": 0.6172839403152466, "info_performance_mean": 0.5052552819252014, "info_performance_final": 0.6172839403152466, "step": 1737500}
{"episode_reward": 1010.5106621773282, "episode": 17376.0, "batch_reward": 4.274928092956543, "critic_loss": 1884.1646728515625, "actor_loss": -1002.2591552734375, "actor_target_entropy": -3.0, "actor_entropy": 2.2388510704040527, "alpha_loss": 0.027616634964942932, "alpha_value": 0.43789483608412, "duration": 1.459665060043335, "info_normalized_performance_mean": 0.46375998854637146, "info_normalized_performance_final": 0.5199999809265137, "info_performance_mean": 0.46375998854637146, "info_performance_final": 0.5199999809265137, "step": 1738000}
{"episode_reward": 927.5199999999987, "episode": 17381.0, "batch_reward": 4.281761169433594, "critic_loss": 600.7783813476562, "actor_loss": -1056.46728515625, "actor_target_entropy": -3.0, "actor_entropy": 2.279608726501465, "alpha_loss": -0.1308681219816208, "alpha_value": 0.43440451581698797, "duration": 1.5607223510742188, "info_normalized_performance_mean": 0.7031729221343994, "info_normalized_performance_final": 0.7939560413360596, "info_performance_mean": 0.7031729221343994, "info_performance_final": 0.7939560413360596, "step": 1738500}
{"episode_reward": 1406.3461538461527, "episode": 17386.0, "batch_reward": 5.439393997192383, "critic_loss": 590.0401000976562, "actor_loss": -1054.7366943359375, "actor_target_entropy": -3.0, "actor_entropy": 1.94425368309021, "alpha_loss": 0.30156436562538147, "alpha_value": 0.42908243266468593, "duration": 1.5264108180999756, "info_normalized_performance_mean": 0.31126755475997925, "info_normalized_performance_final": 0.3903551697731018, "info_performance_mean": 0.31126755475997925, "info_performance_final": 0.3903551697731018, "step": 1739000}
{"episode_reward": 622.535027696319, "episode": 17391.0, "batch_reward": 4.708506107330322, "critic_loss": 515.0116577148438, "actor_loss": -990.5292358398438, "actor_target_entropy": -3.0, "actor_entropy": 2.2233870029449463, "alpha_loss": 0.3988226652145386, "alpha_value": 0.42078451931011407, "duration": 1.5420362949371338, "info_normalized_performance_mean": 0.759870171546936, "info_normalized_performance_final": 0.8668830990791321, "info_performance_mean": 0.759870171546936, "info_performance_final": 0.8668830990791321, "step": 1739500}
{"episode_reward": 1519.7402597402586, "episode": 17396.0, "batch_reward": 4.63865852355957, "critic_loss": 750.54736328125, "actor_loss": -1014.4873046875, "actor_target_entropy": -3.0, "actor_entropy": 2.478125810623169, "alpha_loss": 0.312719464302063, "alpha_value": 0.41514913359420974, "step": 1740000}
{"duration": 18.950807332992554, "info_normalized_performance_mean": 0.7330355644226074, "info_normalized_performance_final": 0.9214285612106323, "info_performance_mean": 0.7330355644226074, "info_performance_final": 0.9214285612106323, "step": 1740000}
{"episode_reward": 1466.0714285714264, "episode": 17401.0, "batch_reward": 4.3026123046875, "critic_loss": 1097.5604248046875, "actor_loss": -1005.2630615234375, "actor_target_entropy": -3.0, "actor_entropy": 2.1969218254089355, "alpha_loss": -0.10331399738788605, "alpha_value": 0.41134879598305896, "duration": 1.6356992721557617, "info_normalized_performance_mean": 0.541599690914154, "info_normalized_performance_final": 0.6584821343421936, "info_performance_mean": 0.541599690914154, "info_performance_final": 0.6584821343421936, "step": 1740500}
{"episode_reward": 1083.1994047619046, "episode": 17406.0, "batch_reward": 4.7825727462768555, "critic_loss": 468.9555969238281, "actor_loss": -998.6817016601562, "actor_target_entropy": -3.0, "actor_entropy": 2.0497512817382812, "alpha_loss": -0.1276800036430359, "alpha_value": 0.40813021866854965, "duration": 1.5580484867095947, "info_normalized_performance_mean": 0.8431717157363892, "info_normalized_performance_final": 0.910937488079071, "info_performance_mean": 0.8431717157363892, "info_performance_final": 0.910937488079071, "step": 1741000}
{"episode_reward": 1686.34375, "episode": 17411.0, "batch_reward": 5.300121307373047, "critic_loss": 270.8118896484375, "actor_loss": -1032.7542724609375, "actor_target_entropy": -3.0, "actor_entropy": 2.1399483680725098, "alpha_loss": -0.14232611656188965, "alpha_value": 0.4088795900211397, "duration": 1.4713070392608643, "info_normalized_performance_mean": 0.7626786828041077, "info_normalized_performance_final": 0.8392857313156128, "info_performance_mean": 0.7626786828041077, "info_performance_final": 0.8392857313156128, "step": 1741500}
{"episode_reward": 1525.3571428571424, "episode": 17416.0, "batch_reward": 5.316215515136719, "critic_loss": 506.75982666015625, "actor_loss": -1039.966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.9808812141418457, "alpha_loss": -0.0052603911608457565, "alpha_value": 0.41051112900035247, "duration": 1.5167162418365479, "info_normalized_performance_mean": 0.4176586866378784, "info_normalized_performance_final": 0.46560847759246826, "info_performance_mean": 0.4176586866378784, "info_performance_final": 0.46560847759246826, "step": 1742000}
{"episode_reward": 835.3174603174607, "episode": 17421.0, "batch_reward": 5.241231441497803, "critic_loss": 805.299560546875, "actor_loss": -998.843994140625, "actor_target_entropy": -3.0, "actor_entropy": 2.400057077407837, "alpha_loss": -0.1948765516281128, "alpha_value": 0.40998424293948416, "duration": 1.493908405303955, "info_normalized_performance_mean": 0.4437912106513977, "info_normalized_performance_final": 0.5343406796455383, "info_performance_mean": 0.4437912106513977, "info_performance_final": 0.5343406796455383, "step": 1742500}
{"episode_reward": 887.582417582418, "episode": 17426.0, "batch_reward": 4.736538887023926, "critic_loss": 349.00927734375, "actor_loss": -1012.7296142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.9823037385940552, "alpha_loss": -0.03326642885804176, "alpha_value": 0.4123705343226887, "duration": 1.414414644241333, "info_normalized_performance_mean": 0.14701171219348907, "info_normalized_performance_final": 0.15234375, "info_performance_mean": 0.14701171219348907, "info_performance_final": 0.15234375, "step": 1743000}
{"episode_reward": 294.0234375, "episode": 17431.0, "batch_reward": 5.02290153503418, "critic_loss": 1119.217529296875, "actor_loss": -1033.5771484375, "actor_target_entropy": -3.0, "actor_entropy": 2.0374326705932617, "alpha_loss": -0.09241023659706116, "alpha_value": 0.4180487753129887, "duration": 1.6119623184204102, "info_normalized_performance_mean": 0.5706428289413452, "info_normalized_performance_final": 0.6722221970558167, "info_performance_mean": 0.5706428289413452, "info_performance_final": 0.6722221970558167, "step": 1743500}
{"episode_reward": 1141.2857142857142, "episode": 17436.0, "batch_reward": 5.685715675354004, "critic_loss": 706.2109375, "actor_loss": -1006.48876953125, "actor_target_entropy": -3.0, "actor_entropy": 2.1469454765319824, "alpha_loss": 0.39606285095214844, "alpha_value": 0.4185970751523432, "duration": 1.4694948196411133, "info_normalized_performance_mean": 0.5204120874404907, "info_normalized_performance_final": 0.595695972442627, "info_performance_mean": 0.5204120874404907, "info_performance_final": 0.595695972442627, "step": 1744000}
{"episode_reward": 1040.8241758241754, "episode": 17441.0, "batch_reward": 5.592596054077148, "critic_loss": 307.5012512207031, "actor_loss": -1039.4039306640625, "actor_target_entropy": -3.0, "actor_entropy": 1.8673646450042725, "alpha_loss": -0.0003444477915763855, "alpha_value": 0.4185473281108547, "duration": 1.4935941696166992, "info_normalized_performance_mean": 0.6052486896514893, "info_normalized_performance_final": 0.6817601919174194, "info_performance_mean": 0.6052486896514893, "info_performance_final": 0.6817601919174194, "step": 1744500}
{"episode_reward": 1210.4974489795932, "episode": 17446.0, "batch_reward": 5.65879487991333, "critic_loss": 973.22998046875, "actor_loss": -1094.563232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.9975171089172363, "alpha_loss": 0.2867615520954132, "alpha_value": 0.4196988512432979, "duration": 1.5087602138519287, "info_normalized_performance_mean": 0.25204822421073914, "info_normalized_performance_final": 0.313973069190979, "info_performance_mean": 0.25204822421073914, "info_performance_final": 0.313973069190979, "step": 1745000}
{"episode_reward": 504.0965207631868, "episode": 17451.0, "batch_reward": 5.2795281410217285, "critic_loss": 1958.16015625, "actor_loss": -1005.9512329101562, "actor_target_entropy": -3.0, "actor_entropy": 1.9248394966125488, "alpha_loss": -0.11092229932546616, "alpha_value": 0.4185354192630459, "duration": 1.6619806289672852, "info_normalized_performance_mean": 0.5643959641456604, "info_normalized_performance_final": 0.7318580746650696, "info_performance_mean": 0.5643959641456604, "info_performance_final": 0.7318580746650696, "step": 1745500}
{"episode_reward": 1128.7918660287075, "episode": 17456.0, "batch_reward": 5.126420021057129, "critic_loss": 320.8406982421875, "actor_loss": -1025.721435546875, "actor_target_entropy": -3.0, "actor_entropy": 1.7670245170593262, "alpha_loss": -0.2547624707221985, "alpha_value": 0.41456912096015974, "duration": 1.4372477531433105, "info_normalized_performance_mean": 0.3248639702796936, "info_normalized_performance_final": 0.35147392749786377, "info_performance_mean": 0.3248639702796936, "info_performance_final": 0.35147392749786377, "step": 1746000}
{"episode_reward": 649.7278911564622, "episode": 17461.0, "batch_reward": 5.9530487060546875, "critic_loss": 628.7880859375, "actor_loss": -998.3193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.9321835041046143, "alpha_loss": 0.09445705264806747, "alpha_value": 0.4142116124126421, "duration": 1.5897002220153809, "info_normalized_performance_mean": 0.6418358683586121, "info_normalized_performance_final": 0.8243727684020996, "info_performance_mean": 0.6418358683586121, "info_performance_final": 0.8243727684020996, "step": 1746500}
{"episode_reward": 1283.6718438868984, "episode": 17466.0, "batch_reward": 5.013430118560791, "critic_loss": 430.2216491699219, "actor_loss": -1032.5748291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.8752979040145874, "alpha_loss": -0.137837216258049, "alpha_value": 0.41662404785889434, "duration": 1.4919040203094482, "info_normalized_performance_mean": 0.4320351481437683, "info_normalized_performance_final": 0.502734363079071, "info_performance_mean": 0.4320351481437683, "info_performance_final": 0.502734363079071, "step": 1747000}
{"episode_reward": 864.0703125, "episode": 17471.0, "batch_reward": 5.059152126312256, "critic_loss": 445.4642333984375, "actor_loss": -1002.9488525390625, "actor_target_entropy": -3.0, "actor_entropy": 2.089046001434326, "alpha_loss": -0.09098019450902939, "alpha_value": 0.41621712855251636, "duration": 1.616358757019043, "info_normalized_performance_mean": 0.49686747789382935, "info_normalized_performance_final": 0.6031168699264526, "info_performance_mean": 0.49686747789382935, "info_performance_final": 0.6031168699264526, "step": 1747500}
{"episode_reward": 993.7350649350649, "episode": 17476.0, "batch_reward": 5.2662763595581055, "critic_loss": 387.581298828125, "actor_loss": -992.5003662109375, "actor_target_entropy": -3.0, "actor_entropy": 2.2353100776672363, "alpha_loss": -0.07956445962190628, "alpha_value": 0.4138310336070607, "duration": 1.5763826370239258, "info_normalized_performance_mean": 0.676175057888031, "info_normalized_performance_final": 0.8837500214576721, "info_performance_mean": 0.676175057888031, "info_performance_final": 0.8837500214576721, "step": 1748000}
{"episode_reward": 1352.3499999999983, "episode": 17481.0, "batch_reward": 5.954331874847412, "critic_loss": 811.8717041015625, "actor_loss": -1028.361572265625, "actor_target_entropy": -3.0, "actor_entropy": 1.9415943622589111, "alpha_loss": 0.05084128677845001, "alpha_value": 0.4137051448651701, "duration": 1.5359148979187012, "info_normalized_performance_mean": 0.7825399041175842, "info_normalized_performance_final": 0.8399999737739563, "info_performance_mean": 0.7825399041175842, "info_performance_final": 0.8399999737739563, "step": 1748500}
{"episode_reward": 1565.0799999999974, "episode": 17486.0, "batch_reward": 5.688709259033203, "critic_loss": 313.4472351074219, "actor_loss": -1058.851806640625, "actor_target_entropy": -3.0, "actor_entropy": 2.0749731063842773, "alpha_loss": 0.04633648321032524, "alpha_value": 0.4118538695521506, "duration": 1.5314736366271973, "info_normalized_performance_mean": 0.5642857551574707, "info_normalized_performance_final": 0.7023809552192688, "info_performance_mean": 0.5642857551574707, "info_performance_final": 0.7023809552192688, "step": 1749000}
{"episode_reward": 1128.571428571428, "episode": 17491.0, "batch_reward": 6.33102560043335, "critic_loss": 689.197265625, "actor_loss": -1120.7664794921875, "actor_target_entropy": -3.0, "actor_entropy": 2.046941041946411, "alpha_loss": -0.09516371041536331, "alpha_value": 0.40619327869633715, "duration": 1.5268595218658447, "info_normalized_performance_mean": 0.5280651450157166, "info_normalized_performance_final": 0.6440345644950867, "info_performance_mean": 0.5280651450157166, "info_performance_final": 0.6440345644950867, "step": 1749500}
{"episode_reward": 1056.130298273155, "episode": 17496.0, "batch_reward": 5.800051689147949, "critic_loss": 483.35089111328125, "actor_loss": -1090.6202392578125, "actor_target_entropy": -3.0, "actor_entropy": 2.2320921421051025, "alpha_loss": -0.17256301641464233, "alpha_value": 0.4042576621358972, "step": 1750000}
{"duration": 18.957768201828003, "info_normalized_performance_mean": 0.4446665942668915, "info_normalized_performance_final": 0.5370833277702332, "info_performance_mean": 0.4446665942668915, "info_performance_final": 0.5370833277702332, "step": 1750000}
{"episode_reward": 889.3333333333337, "episode": 17501.0, "batch_reward": 5.30020809173584, "critic_loss": 831.2330322265625, "actor_loss": -1054.424560546875, "actor_target_entropy": -3.0, "actor_entropy": 2.0464282035827637, "alpha_loss": -0.20686101913452148, "alpha_value": 0.40511490210744827, "duration": 1.5570125579833984, "info_normalized_performance_mean": 0.5953081846237183, "info_normalized_performance_final": 0.7200716733932495, "info_performance_mean": 0.5953081846237183, "info_performance_final": 0.7200716733932495, "step": 1750500}
{"episode_reward": 1190.616487455198, "episode": 17506.0, "batch_reward": 5.829983234405518, "critic_loss": 320.18243408203125, "actor_loss": -1075.59375, "actor_target_entropy": -3.0, "actor_entropy": 2.168591022491455, "alpha_loss": 0.12049557268619537, "alpha_value": 0.4027257702199589, "duration": 1.62996506690979, "info_normalized_performance_mean": 0.4840252995491028, "info_normalized_performance_final": 0.59375, "info_performance_mean": 0.4840252995491028, "info_performance_final": 0.59375, "step": 1751000}
{"episode_reward": 968.0505952380955, "episode": 17511.0, "batch_reward": 5.184188365936279, "critic_loss": 588.9695434570312, "actor_loss": -1033.928466796875, "actor_target_entropy": -3.0, "actor_entropy": 1.9263911247253418, "alpha_loss": -0.026362698525190353, "alpha_value": 0.4049741079326129, "duration": 1.699258804321289, "info_normalized_performance_mean": 0.4868125915527344, "info_normalized_performance_final": 0.6046205759048462, "info_performance_mean": 0.4868125915527344, "info_performance_final": 0.6046205759048462, "step": 1751500}
{"episode_reward": 973.6250939143495, "episode": 17516.0, "batch_reward": 5.984501838684082, "critic_loss": 313.20684814453125, "actor_loss": -1076.7437744140625, "actor_target_entropy": -3.0, "actor_entropy": 2.4182050228118896, "alpha_loss": -0.20100462436676025, "alpha_value": 0.4112447993149489, "duration": 1.711207628250122, "info_normalized_performance_mean": 0.25443679094314575, "info_normalized_performance_final": 0.31379732489585876, "info_performance_mean": 0.25443679094314575, "info_performance_final": 0.31379732489585876, "step": 1752000}
{"episode_reward": 508.87362637362673, "episode": 17521.0, "batch_reward": 6.113999366760254, "critic_loss": 385.7717590332031, "actor_loss": -1129.657470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.8027927875518799, "alpha_loss": 0.020272016525268555, "alpha_value": 0.4108914719841015, "duration": 1.542588233947754, "info_normalized_performance_mean": 0.653218686580658, "info_normalized_performance_final": 0.8402343988418579, "info_performance_mean": 0.653218686580658, "info_performance_final": 0.8402343988418579, "step": 1752500}
{"episode_reward": 1306.4375, "episode": 17526.0, "batch_reward": 6.73089599609375, "critic_loss": 370.84161376953125, "actor_loss": -1130.900634765625, "actor_target_entropy": -3.0, "actor_entropy": 2.3534650802612305, "alpha_loss": 0.3391895294189453, "alpha_value": 0.4066595792223726, "duration": 1.5896944999694824, "info_normalized_performance_mean": 0.7844333052635193, "info_normalized_performance_final": 0.8377777934074402, "info_performance_mean": 0.7844333052635193, "info_performance_final": 0.8377777934074402, "step": 1753000}
{"episode_reward": 1568.8666666666647, "episode": 17531.0, "batch_reward": 5.806718826293945, "critic_loss": 240.6691436767578, "actor_loss": -1010.5527954101562, "actor_target_entropy": -3.0, "actor_entropy": 2.0178821086883545, "alpha_loss": 0.07269388437271118, "alpha_value": 0.40543777198638553, "duration": 1.4561264514923096, "info_normalized_performance_mean": 0.5683929324150085, "info_normalized_performance_final": 0.6071428656578064, "info_performance_mean": 0.5683929324150085, "info_performance_final": 0.6071428656578064, "step": 1753500}
{"episode_reward": 1136.785714285713, "episode": 17536.0, "batch_reward": 5.839994430541992, "critic_loss": 297.5866394042969, "actor_loss": -1088.8809814453125, "actor_target_entropy": -3.0, "actor_entropy": 2.0235965251922607, "alpha_loss": 0.08586561679840088, "alpha_value": 0.40372218903741997, "duration": 1.6089835166931152, "info_normalized_performance_mean": 0.5348478555679321, "info_normalized_performance_final": 0.6904761791229248, "info_performance_mean": 0.5348478555679321, "info_performance_final": 0.6904761791229248, "step": 1754000}
{"episode_reward": 1069.6957671957682, "episode": 17541.0, "batch_reward": 5.842887878417969, "critic_loss": 628.6272583007812, "actor_loss": -1095.85888671875, "actor_target_entropy": -3.0, "actor_entropy": 2.4120538234710693, "alpha_loss": -0.42496737837791443, "alpha_value": 0.4009539134665379, "duration": 1.55487060546875, "info_normalized_performance_mean": 0.7847442626953125, "info_normalized_performance_final": 0.8920454382896423, "info_performance_mean": 0.7847442626953125, "info_performance_final": 0.8920454382896423, "step": 1754500}
{"episode_reward": 1569.4886363636351, "episode": 17546.0, "batch_reward": 6.110486030578613, "critic_loss": 306.95947265625, "actor_loss": -1104.671875, "actor_target_entropy": -3.0, "actor_entropy": 2.070688247680664, "alpha_loss": 0.20509248971939087, "alpha_value": 0.4025841492408018, "duration": 1.5464799404144287, "info_normalized_performance_mean": 0.3988220989704132, "info_normalized_performance_final": 0.47626203298568726, "info_performance_mean": 0.3988220989704132, "info_performance_final": 0.47626203298568726, "step": 1755000}
{"episode_reward": 797.6442307692294, "episode": 17551.0, "batch_reward": 5.896283149719238, "critic_loss": 448.55108642578125, "actor_loss": -1080.1181640625, "actor_target_entropy": -3.0, "actor_entropy": 2.2378878593444824, "alpha_loss": -0.04513844847679138, "alpha_value": 0.4059382321269909, "duration": 1.4723396301269531, "info_normalized_performance_mean": 0.40601643919944763, "info_normalized_performance_final": 0.4890109896659851, "info_performance_mean": 0.40601643919944763, "info_performance_final": 0.4890109896659851, "step": 1755500}
{"episode_reward": 812.0329670329676, "episode": 17556.0, "batch_reward": 6.295751094818115, "critic_loss": 267.5240478515625, "actor_loss": -1091.079345703125, "actor_target_entropy": -3.0, "actor_entropy": 2.124462366104126, "alpha_loss": 0.06360656023025513, "alpha_value": 0.40371530529881106, "duration": 1.6436729431152344, "info_normalized_performance_mean": 0.5710780024528503, "info_normalized_performance_final": 0.6792327761650085, "info_performance_mean": 0.5710780024528503, "info_performance_final": 0.6792327761650085, "step": 1756000}
{"episode_reward": 1142.1560846560842, "episode": 17561.0, "batch_reward": 6.700754165649414, "critic_loss": 543.0247802734375, "actor_loss": -1154.5792236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.9748868942260742, "alpha_loss": -0.15579456090927124, "alpha_value": 0.4026998690272451, "duration": 1.4956824779510498, "info_normalized_performance_mean": 0.5320420861244202, "info_normalized_performance_final": 0.6259157657623291, "info_performance_mean": 0.5320420861244202, "info_performance_final": 0.6259157657623291, "step": 1756500}
{"episode_reward": 1064.0842490842474, "episode": 17566.0, "batch_reward": 6.369503021240234, "critic_loss": 1474.1004638671875, "actor_loss": -1073.0621337890625, "actor_target_entropy": -3.0, "actor_entropy": 2.29003643989563, "alpha_loss": 0.18599660694599152, "alpha_value": 0.40594550723909256, "duration": 1.4901866912841797, "info_normalized_performance_mean": 0.47929999232292175, "info_normalized_performance_final": 0.5199999809265137, "info_performance_mean": 0.47929999232292175, "info_performance_final": 0.5199999809265137, "step": 1757000}
{"episode_reward": 958.5999999999985, "episode": 17571.0, "batch_reward": 5.756405830383301, "critic_loss": 491.8297119140625, "actor_loss": -1075.0545654296875, "actor_target_entropy": -3.0, "actor_entropy": 1.8513602018356323, "alpha_loss": 0.20530176162719727, "alpha_value": 0.40781223991051724, "duration": 1.5724799633026123, "info_normalized_performance_mean": 0.6067999601364136, "info_normalized_performance_final": 0.6587499976158142, "info_performance_mean": 0.6067999601364136, "info_performance_final": 0.6587499976158142, "step": 1757500}
{"episode_reward": 1213.5999999999979, "episode": 17576.0, "batch_reward": 5.82058048248291, "critic_loss": 775.82421875, "actor_loss": -1078.0654296875, "actor_target_entropy": -3.0, "actor_entropy": 1.7364953756332397, "alpha_loss": -0.03019193932414055, "alpha_value": 0.4066049022731101, "duration": 1.7706928253173828, "info_normalized_performance_mean": 0.5866258144378662, "info_normalized_performance_final": 0.685473620891571, "info_performance_mean": 0.5866258144378662, "info_performance_final": 0.685473620891571, "step": 1758000}
{"episode_reward": 1173.2517482517474, "episode": 17581.0, "batch_reward": 7.0643720626831055, "critic_loss": 519.992431640625, "actor_loss": -1127.46875, "actor_target_entropy": -3.0, "actor_entropy": 2.3396525382995605, "alpha_loss": 0.29861781001091003, "alpha_value": 0.4088235871691469, "duration": 1.5107626914978027, "info_normalized_performance_mean": 0.26017650961875916, "info_normalized_performance_final": 0.34215685725212097, "info_performance_mean": 0.26017650961875916, "info_performance_final": 0.34215685725212097, "step": 1758500}
{"episode_reward": 520.3529411764713, "episode": 17586.0, "batch_reward": 6.257528305053711, "critic_loss": 773.9388427734375, "actor_loss": -1111.48779296875, "actor_target_entropy": -3.0, "actor_entropy": 2.1514880657196045, "alpha_loss": -0.003367781639099121, "alpha_value": 0.4060344459058567, "duration": 1.557300090789795, "info_normalized_performance_mean": 0.6968600749969482, "info_normalized_performance_final": 0.8735119104385376, "info_performance_mean": 0.6968600749969482, "info_performance_final": 0.8735119104385376, "step": 1759000}
{"episode_reward": 1393.720238095237, "episode": 17591.0, "batch_reward": 7.3450164794921875, "critic_loss": 296.68695068359375, "actor_loss": -1147.7308349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.958264708518982, "alpha_loss": 0.13093352317810059, "alpha_value": 0.4010677711205953, "duration": 1.4286038875579834, "info_normalized_performance_mean": 0.2937479019165039, "info_normalized_performance_final": 0.3478991687297821, "info_performance_mean": 0.2937479019165039, "info_performance_final": 0.3478991687297821, "step": 1759500}
{"episode_reward": 587.495798319327, "episode": 17596.0, "batch_reward": 6.401713848114014, "critic_loss": 381.8716125488281, "actor_loss": -1077.6199951171875, "actor_target_entropy": -3.0, "actor_entropy": 2.2763404846191406, "alpha_loss": 0.05123959481716156, "alpha_value": 0.3973694167440178, "step": 1760000}
{"duration": 19.60365080833435, "info_normalized_performance_mean": 0.30945447087287903, "info_normalized_performance_final": 0.36818182468414307, "info_performance_mean": 0.30945447087287903, "info_performance_final": 0.36818182468414307, "step": 1760000}
{"episode_reward": 618.9090909090912, "episode": 17601.0, "batch_reward": 6.813483715057373, "critic_loss": 322.5919189453125, "actor_loss": -1148.778564453125, "actor_target_entropy": -3.0, "actor_entropy": 2.1823554039001465, "alpha_loss": -0.021766001358628273, "alpha_value": 0.39404169048308724, "duration": 1.6062681674957275, "info_normalized_performance_mean": 0.49895042181015015, "info_normalized_performance_final": 0.6093294620513916, "info_performance_mean": 0.49895042181015015, "info_performance_final": 0.6093294620513916, "step": 1760500}
{"episode_reward": 997.900874635569, "episode": 17606.0, "batch_reward": 7.120182037353516, "critic_loss": 1167.35791015625, "actor_loss": -1144.515380859375, "actor_target_entropy": -3.0, "actor_entropy": 2.0664119720458984, "alpha_loss": -0.12631581723690033, "alpha_value": 0.3909062970421182, "duration": 1.652266502380371, "info_normalized_performance_mean": 0.471963495016098, "info_normalized_performance_final": 0.5586419701576233, "info_performance_mean": 0.471963495016098, "info_performance_final": 0.5586419701576233, "step": 1761000}
{"episode_reward": 943.9268755935433, "episode": 17611.0, "batch_reward": 6.809624671936035, "critic_loss": 549.698486328125, "actor_loss": -1123.27392578125, "actor_target_entropy": -3.0, "actor_entropy": 2.2499451637268066, "alpha_loss": 0.1581796258687973, "alpha_value": 0.38983494079055553, "duration": 1.4915826320648193, "info_normalized_performance_mean": 0.38848361372947693, "info_normalized_performance_final": 0.5320261716842651, "info_performance_mean": 0.38848361372947693, "info_performance_final": 0.5320261716842651, "step": 1761500}
{"episode_reward": 776.9673202614375, "episode": 17616.0, "batch_reward": 6.625768184661865, "critic_loss": 392.691162109375, "actor_loss": -1101.1376953125, "actor_target_entropy": -3.0, "actor_entropy": 2.369920253753662, "alpha_loss": -0.10558094829320908, "alpha_value": 0.3917700719152825, "duration": 1.7179434299468994, "info_normalized_performance_mean": 0.44532203674316406, "info_normalized_performance_final": 0.5462453961372375, "info_performance_mean": 0.44532203674316406, "info_performance_final": 0.5462453961372375, "step": 1762000}
{"episode_reward": 890.6440781440763, "episode": 17621.0, "batch_reward": 6.949340343475342, "critic_loss": 2625.2099609375, "actor_loss": -1146.7481689453125, "actor_target_entropy": -3.0, "actor_entropy": 2.4709434509277344, "alpha_loss": -0.10593003034591675, "alpha_value": 0.38884122640012164, "duration": 1.3953990936279297, "info_normalized_performance_mean": 0.13782662153244019, "info_normalized_performance_final": 0.16117216646671295, "info_performance_mean": 0.13782662153244019, "info_performance_final": 0.16117216646671295, "step": 1762500}
{"episode_reward": 275.6532356532352, "episode": 17626.0, "batch_reward": 7.043410778045654, "critic_loss": 472.6231689453125, "actor_loss": -1139.045166015625, "actor_target_entropy": -3.0, "actor_entropy": 2.5537753105163574, "alpha_loss": 0.21376341581344604, "alpha_value": 0.3874834895383451, "duration": 1.6087005138397217, "info_normalized_performance_mean": 0.3939351737499237, "info_normalized_performance_final": 0.5211640000343323, "info_performance_mean": 0.3939351737499237, "info_performance_final": 0.5211640000343323, "step": 1763000}
{"episode_reward": 787.8703703703702, "episode": 17631.0, "batch_reward": 7.613073348999023, "critic_loss": 629.920654296875, "actor_loss": -1154.7554931640625, "actor_target_entropy": -3.0, "actor_entropy": 2.033900260925293, "alpha_loss": -0.39292991161346436, "alpha_value": 0.38424498150850284, "duration": 1.443457841873169, "info_normalized_performance_mean": 0.578125, "info_normalized_performance_final": 0.685019850730896, "info_performance_mean": 0.578125, "info_performance_final": 0.685019850730896, "step": 1763500}
{"episode_reward": 1156.250000000001, "episode": 17636.0, "batch_reward": 7.008986473083496, "critic_loss": 529.1296997070312, "actor_loss": -1117.7908935546875, "actor_target_entropy": -3.0, "actor_entropy": 2.168776035308838, "alpha_loss": 0.18885314464569092, "alpha_value": 0.37885968487773336, "duration": 1.5007398128509521, "info_normalized_performance_mean": 0.3202213644981384, "info_normalized_performance_final": 0.3821614682674408, "info_performance_mean": 0.3202213644981384, "info_performance_final": 0.3821614682674408, "step": 1764000}
{"episode_reward": 640.4427083333333, "episode": 17641.0, "batch_reward": 6.1694769859313965, "critic_loss": 2672.44140625, "actor_loss": -1074.7406005859375, "actor_target_entropy": -3.0, "actor_entropy": 2.222194194793701, "alpha_loss": 0.23854371905326843, "alpha_value": 0.3712221698612434, "duration": 1.4525706768035889, "info_normalized_performance_mean": 0.443437397480011, "info_normalized_performance_final": 0.4671874940395355, "info_performance_mean": 0.443437397480011, "info_performance_final": 0.4671874940395355, "step": 1764500}
{"episode_reward": 886.875, "episode": 17646.0, "batch_reward": 7.376496315002441, "critic_loss": 489.9895935058594, "actor_loss": -1145.574951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.7439730167388916, "alpha_loss": 0.3011774718761444, "alpha_value": 0.36276935574625524, "duration": 1.4360830783843994, "info_normalized_performance_mean": 0.8546428084373474, "info_normalized_performance_final": 0.9071428775787354, "info_performance_mean": 0.8546428084373474, "info_performance_final": 0.9071428775787354, "step": 1765000}
{"episode_reward": 1709.2857142857126, "episode": 17651.0, "batch_reward": 6.94012975692749, "critic_loss": 858.36376953125, "actor_loss": -1102.640869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.7103028297424316, "alpha_loss": 0.07155501842498779, "alpha_value": 0.35508016767246137, "duration": 1.592879295349121, "info_normalized_performance_mean": 0.34445706009864807, "info_normalized_performance_final": 0.41357141733169556, "info_performance_mean": 0.34445706009864807, "info_performance_final": 0.41357141733169556, "step": 1765500}
{"episode_reward": 688.9142857142866, "episode": 17656.0, "batch_reward": 7.7177629470825195, "critic_loss": 874.8452758789062, "actor_loss": -1135.3642578125, "actor_target_entropy": -3.0, "actor_entropy": 2.049111843109131, "alpha_loss": 0.11314750462770462, "alpha_value": 0.3538891671930355, "duration": 1.4770853519439697, "info_normalized_performance_mean": 0.029374999925494194, "info_normalized_performance_final": 0.03125, "info_performance_mean": 0.029374999925494194, "info_performance_final": 0.03125, "step": 1766000}
{"episode_reward": 58.75, "episode": 17661.0, "batch_reward": 7.0619659423828125, "critic_loss": 1632.821533203125, "actor_loss": -1125.556640625, "actor_target_entropy": -3.0, "actor_entropy": 2.0625743865966797, "alpha_loss": 0.05928868055343628, "alpha_value": 0.35141353054097335, "duration": 1.4888951778411865, "info_normalized_performance_mean": 0.14325454831123352, "info_normalized_performance_final": 0.19272726774215698, "info_performance_mean": 0.14325454831123352, "info_performance_final": 0.19272726774215698, "step": 1766500}
{"episode_reward": 286.5090909090908, "episode": 17666.0, "batch_reward": 7.068005561828613, "critic_loss": 733.4712524414062, "actor_loss": -1139.099365234375, "actor_target_entropy": -3.0, "actor_entropy": 2.127089500427246, "alpha_loss": -0.15739990770816803, "alpha_value": 0.35002623816295253, "duration": 1.6342012882232666, "info_normalized_performance_mean": 0.6754966974258423, "info_normalized_performance_final": 0.7951739430427551, "info_performance_mean": 0.6754966974258423, "info_performance_final": 0.7951739430427551, "step": 1767000}
{"episode_reward": 1350.9932659932645, "episode": 17671.0, "batch_reward": 7.578871250152588, "critic_loss": 1427.242431640625, "actor_loss": -1134.99560546875, "actor_target_entropy": -3.0, "actor_entropy": 2.344982147216797, "alpha_loss": 0.037090398371219635, "alpha_value": 0.3491807930245897, "duration": 1.5133960247039795, "info_normalized_performance_mean": 0.32831570506095886, "info_normalized_performance_final": 0.41477271914482117, "info_performance_mean": 0.32831570506095886, "info_performance_final": 0.41477271914482117, "step": 1767500}
{"episode_reward": 656.6314935064933, "episode": 17676.0, "batch_reward": 7.413731575012207, "critic_loss": 1029.142822265625, "actor_loss": -1155.371337890625, "actor_target_entropy": -3.0, "actor_entropy": 2.0267508029937744, "alpha_loss": 0.042327046394348145, "alpha_value": 0.350168607109195, "duration": 1.5667588710784912, "info_normalized_performance_mean": 0.4857710301876068, "info_normalized_performance_final": 0.581632673740387, "info_performance_mean": 0.4857710301876068, "info_performance_final": 0.581632673740387, "step": 1768000}
{"episode_reward": 971.5419501133775, "episode": 17681.0, "batch_reward": 7.034743309020996, "critic_loss": 574.4325561523438, "actor_loss": -1112.0718994140625, "actor_target_entropy": -3.0, "actor_entropy": 2.1016132831573486, "alpha_loss": -0.15497548878192902, "alpha_value": 0.34686494587654715, "duration": 1.539243459701538, "info_normalized_performance_mean": 0.46677082777023315, "info_normalized_performance_final": 0.5698784589767456, "info_performance_mean": 0.46677082777023315, "info_performance_final": 0.5698784589767456, "step": 1768500}
{"episode_reward": 933.5416666666671, "episode": 17686.0, "batch_reward": 6.777078151702881, "critic_loss": 451.7292785644531, "actor_loss": -1087.516845703125, "actor_target_entropy": -3.0, "actor_entropy": 2.234740734100342, "alpha_loss": -0.022062040865421295, "alpha_value": 0.34809821697349946, "duration": 1.7244369983673096, "info_normalized_performance_mean": 0.6698246002197266, "info_normalized_performance_final": 0.7988436818122864, "info_performance_mean": 0.6698246002197266, "info_performance_final": 0.7988436818122864, "step": 1769000}
{"episode_reward": 1339.6491228070167, "episode": 17691.0, "batch_reward": 7.258238315582275, "critic_loss": 657.4642333984375, "actor_loss": -1136.510009765625, "actor_target_entropy": -3.0, "actor_entropy": 2.4187698364257812, "alpha_loss": 0.06278298050165176, "alpha_value": 0.3532812047051391, "duration": 1.472764015197754, "info_normalized_performance_mean": 0.4396311938762665, "info_normalized_performance_final": 0.5047096014022827, "info_performance_mean": 0.4396311938762665, "info_performance_final": 0.5047096014022827, "step": 1769500}
{"episode_reward": 879.2621664050218, "episode": 17696.0, "batch_reward": 7.214568138122559, "critic_loss": 756.990234375, "actor_loss": -1125.009033203125, "actor_target_entropy": -3.0, "actor_entropy": 2.1154093742370605, "alpha_loss": 0.037150442600250244, "alpha_value": 0.3530232970436945, "step": 1770000}
{"duration": 18.956382513046265, "info_normalized_performance_mean": 0.15489287674427032, "info_normalized_performance_final": 0.19761905074119568, "info_performance_mean": 0.15489287674427032, "info_performance_final": 0.19761905074119568, "step": 1770000}
{"episode_reward": 309.7857142857142, "episode": 17701.0, "batch_reward": 7.661986351013184, "critic_loss": 408.98187255859375, "actor_loss": -1141.5908203125, "actor_target_entropy": -3.0, "actor_entropy": 2.5923914909362793, "alpha_loss": 0.26519250869750977, "alpha_value": 0.3517474945046957, "duration": 1.497272253036499, "info_normalized_performance_mean": 0.618392825126648, "info_normalized_performance_final": 0.8769841194152832, "info_performance_mean": 0.618392825126648, "info_performance_final": 0.8769841194152832, "step": 1770500}
{"episode_reward": 1236.7857142857151, "episode": 17706.0, "batch_reward": 7.456967353820801, "critic_loss": 282.3981018066406, "actor_loss": -1123.7589111328125, "actor_target_entropy": -3.0, "actor_entropy": 2.170893430709839, "alpha_loss": -0.1669875979423523, "alpha_value": 0.3520511562399929, "duration": 1.4642400741577148, "info_normalized_performance_mean": 0.20378604531288147, "info_normalized_performance_final": 0.21875, "info_performance_mean": 0.20378604531288147, "info_performance_final": 0.21875, "step": 1771000}
{"episode_reward": 407.57211538461536, "episode": 17711.0, "batch_reward": 7.212777614593506, "critic_loss": 357.02178955078125, "actor_loss": -1112.143798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.7199037075042725, "alpha_loss": -0.14311063289642334, "alpha_value": 0.3507083817863025, "duration": 1.6022920608520508, "info_normalized_performance_mean": 0.5486195683479309, "info_normalized_performance_final": 0.659652054309845, "info_performance_mean": 0.5486195683479309, "info_performance_final": 0.659652054309845, "step": 1771500}
{"episode_reward": 1097.2390572390561, "episode": 17716.0, "batch_reward": 7.434292793273926, "critic_loss": 2064.51025390625, "actor_loss": -1144.577392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.9284956455230713, "alpha_loss": 0.17708070576190948, "alpha_value": 0.34977209362162076, "duration": 1.5281386375427246, "info_normalized_performance_mean": 0.9131054878234863, "info_normalized_performance_final": 0.96484375, "info_performance_mean": 0.9131054878234863, "info_performance_final": 0.96484375, "step": 1772000}
{"episode_reward": 1826.2109375, "episode": 17721.0, "batch_reward": 7.898128986358643, "critic_loss": 435.255126953125, "actor_loss": -1171.732666015625, "actor_target_entropy": -3.0, "actor_entropy": 2.159047842025757, "alpha_loss": 0.2758602499961853, "alpha_value": 0.34845884023287493, "duration": 1.7832977771759033, "info_normalized_performance_mean": 0.4471915364265442, "info_normalized_performance_final": 0.5483440160751343, "info_performance_mean": 0.4471915364265442, "info_performance_final": 0.5483440160751343, "step": 1772500}
{"episode_reward": 894.3830128205126, "episode": 17726.0, "batch_reward": 7.531733989715576, "critic_loss": 806.2796630859375, "actor_loss": -1137.05517578125, "actor_target_entropy": -3.0, "actor_entropy": 2.0832831859588623, "alpha_loss": 0.007193289697170258, "alpha_value": 0.34662226948258706, "duration": 1.5703558921813965, "info_normalized_performance_mean": 0.38904860615730286, "info_normalized_performance_final": 0.43541666865348816, "info_performance_mean": 0.38904860615730286, "info_performance_final": 0.43541666865348816, "step": 1773000}
{"episode_reward": 778.0972222222222, "episode": 17731.0, "batch_reward": 7.772322177886963, "critic_loss": 457.064208984375, "actor_loss": -1163.0653076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.7044553756713867, "alpha_loss": 0.1940019428730011, "alpha_value": 0.34596635605917375, "duration": 1.4498522281646729, "info_normalized_performance_mean": 0.24161456525325775, "info_normalized_performance_final": 0.2690972089767456, "info_performance_mean": 0.24161456525325775, "info_performance_final": 0.2690972089767456, "step": 1773500}
{"episode_reward": 483.2291666666675, "episode": 17736.0, "batch_reward": 6.8621368408203125, "critic_loss": 523.0238647460938, "actor_loss": -1134.2388916015625, "actor_target_entropy": -3.0, "actor_entropy": 1.9057856798171997, "alpha_loss": 0.020397871732711792, "alpha_value": 0.34565678440831965, "duration": 1.4755268096923828, "info_normalized_performance_mean": 0.31209999322891235, "info_normalized_performance_final": 0.38499999046325684, "info_performance_mean": 0.31209999322891235, "info_performance_final": 0.38499999046325684, "step": 1774000}
{"episode_reward": 624.2000000000003, "episode": 17741.0, "batch_reward": 7.903005599975586, "critic_loss": 2046.5826416015625, "actor_loss": -1128.9166259765625, "actor_target_entropy": -3.0, "actor_entropy": 2.1254868507385254, "alpha_loss": 0.11959198117256165, "alpha_value": 0.34771180055913925, "duration": 1.4692373275756836, "info_normalized_performance_mean": 0.4838712215423584, "info_normalized_performance_final": 0.5408163070678711, "info_performance_mean": 0.4838712215423584, "info_performance_final": 0.5408163070678711, "step": 1774500}
{"episode_reward": 967.7423469387769, "episode": 17746.0, "batch_reward": 8.17140007019043, "critic_loss": 844.6810913085938, "actor_loss": -1187.4676513671875, "actor_target_entropy": -3.0, "actor_entropy": 2.068958282470703, "alpha_loss": -0.09734201431274414, "alpha_value": 0.3483650698960233, "duration": 1.5011744499206543, "info_normalized_performance_mean": 0.6588767170906067, "info_normalized_performance_final": 0.8180708289146423, "info_performance_mean": 0.6588767170906067, "info_performance_final": 0.8180708289146423, "step": 1775000}
{"episode_reward": 1317.753357753356, "episode": 17751.0, "batch_reward": 8.140215873718262, "critic_loss": 386.50445556640625, "actor_loss": -1142.29150390625, "actor_target_entropy": -3.0, "actor_entropy": 2.239382266998291, "alpha_loss": 0.4010348916053772, "alpha_value": 0.3469930172963963, "duration": 1.449453592300415, "info_normalized_performance_mean": 0.34928572177886963, "info_normalized_performance_final": 0.4094387888908386, "info_performance_mean": 0.34928572177886963, "info_performance_final": 0.4094387888908386, "step": 1775500}
{"episode_reward": 698.5714285714289, "episode": 17756.0, "batch_reward": 7.316653251647949, "critic_loss": 404.63470458984375, "actor_loss": -1133.9918212890625, "actor_target_entropy": -3.0, "actor_entropy": 2.0980052947998047, "alpha_loss": -0.30772143602371216, "alpha_value": 0.3472051028049133, "duration": 1.5447595119476318, "info_normalized_performance_mean": 0.6742908954620361, "info_normalized_performance_final": 0.713942289352417, "info_performance_mean": 0.6742908954620361, "info_performance_final": 0.713942289352417, "step": 1776000}
{"episode_reward": 1348.5817307692325, "episode": 17761.0, "batch_reward": 8.21733570098877, "critic_loss": 1265.90673828125, "actor_loss": -1182.4527587890625, "actor_target_entropy": -3.0, "actor_entropy": 2.214625358581543, "alpha_loss": 0.04738088697195053, "alpha_value": 0.3452051228724858, "duration": 1.4220824241638184, "info_normalized_performance_mean": 0.00027472528745420277, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.00027472528745420277, "info_performance_final": 0.0, "step": 1776500}
{"episode_reward": 0.5494505494505494, "episode": 17766.0, "batch_reward": 7.027268409729004, "critic_loss": 1604.71728515625, "actor_loss": -1108.169189453125, "actor_target_entropy": -3.0, "actor_entropy": 1.5761945247650146, "alpha_loss": -0.18439826369285583, "alpha_value": 0.346577270654456, "duration": 1.623584508895874, "info_normalized_performance_mean": 0.5443791747093201, "info_normalized_performance_final": 0.6972789168357849, "info_performance_mean": 0.5443791747093201, "info_performance_final": 0.6972789168357849, "step": 1777000}
{"episode_reward": 1088.758503401361, "episode": 17771.0, "batch_reward": 8.997480392456055, "critic_loss": 2235.28857421875, "actor_loss": -1208.3702392578125, "actor_target_entropy": -3.0, "actor_entropy": 2.0464324951171875, "alpha_loss": 0.14913438260555267, "alpha_value": 0.352017643174753, "duration": 1.6217987537384033, "info_normalized_performance_mean": 0.501300036907196, "info_normalized_performance_final": 0.6083333492279053, "info_performance_mean": 0.501300036907196, "info_performance_final": 0.6083333492279053, "step": 1777500}
{"episode_reward": 1002.5999999999984, "episode": 17776.0, "batch_reward": 7.593193054199219, "critic_loss": 369.93463134765625, "actor_loss": -1147.8763427734375, "actor_target_entropy": -3.0, "actor_entropy": 2.2407710552215576, "alpha_loss": -0.07113601267337799, "alpha_value": 0.3557585452962449, "duration": 1.4805729389190674, "info_normalized_performance_mean": 0.49434030055999756, "info_normalized_performance_final": 0.59375, "info_performance_mean": 0.49434030055999756, "info_performance_final": 0.59375, "step": 1778000}
{"episode_reward": 988.6805555555555, "episode": 17781.0, "batch_reward": 7.86309814453125, "critic_loss": 433.72064208984375, "actor_loss": -1163.594970703125, "actor_target_entropy": -3.0, "actor_entropy": 2.077263355255127, "alpha_loss": 0.1293586641550064, "alpha_value": 0.3581257287710467, "duration": 1.4581446647644043, "info_normalized_performance_mean": 0.4783448278903961, "info_normalized_performance_final": 0.5387731194496155, "info_performance_mean": 0.4783448278903961, "info_performance_final": 0.5387731194496155, "step": 1778500}
{"episode_reward": 956.689814814813, "episode": 17786.0, "batch_reward": 7.135852813720703, "critic_loss": 1086.4197998046875, "actor_loss": -1128.3533935546875, "actor_target_entropy": -3.0, "actor_entropy": 1.6209831237792969, "alpha_loss": -0.08148857951164246, "alpha_value": 0.3602566398944815, "duration": 1.6302928924560547, "info_normalized_performance_mean": 0.7482545375823975, "info_normalized_performance_final": 0.8090909123420715, "info_performance_mean": 0.7482545375823975, "info_performance_final": 0.8090909123420715, "step": 1779000}
{"episode_reward": 1496.5090909090914, "episode": 17791.0, "batch_reward": 7.2544403076171875, "critic_loss": 852.3045654296875, "actor_loss": -1159.5870361328125, "actor_target_entropy": -3.0, "actor_entropy": 1.9534227848052979, "alpha_loss": -0.3384256362915039, "alpha_value": 0.3623768907629394, "duration": 1.7479567527770996, "info_normalized_performance_mean": 0.6742601990699768, "info_normalized_performance_final": 0.8095325827598572, "info_performance_mean": 0.6742601990699768, "info_performance_final": 0.8095325827598572, "step": 1779500}
{"episode_reward": 1348.520426941479, "episode": 17796.0, "batch_reward": 7.945054054260254, "critic_loss": 787.939453125, "actor_loss": -1171.876220703125, "actor_target_entropy": -3.0, "actor_entropy": 2.0327837467193604, "alpha_loss": -0.1682286560535431, "alpha_value": 0.3640345348321366, "step": 1780000}
{"duration": 19.032357692718506, "info_normalized_performance_mean": 0.6565788388252258, "info_normalized_performance_final": 0.7767857313156128, "info_performance_mean": 0.6565788388252258, "info_performance_final": 0.7767857313156128, "step": 1780000}
{"episode_reward": 1313.1574675324678, "episode": 17801.0, "batch_reward": 8.605968475341797, "critic_loss": 2250.0615234375, "actor_loss": -1191.369873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.849137306213379, "alpha_loss": -0.05556783825159073, "alpha_value": 0.36464724419264466, "duration": 1.6325969696044922, "info_normalized_performance_mean": 0.681837260723114, "info_normalized_performance_final": 0.8235294222831726, "info_performance_mean": 0.681837260723114, "info_performance_final": 0.8235294222831726, "step": 1780500}
{"episode_reward": 1363.6742081447978, "episode": 17806.0, "batch_reward": 7.336454391479492, "critic_loss": 835.807861328125, "actor_loss": -1133.076904296875, "actor_target_entropy": -3.0, "actor_entropy": 2.2162275314331055, "alpha_loss": -0.40066930651664734, "alpha_value": 0.368961104703965, "duration": 1.5266966819763184, "info_normalized_performance_mean": 0.5679435133934021, "info_normalized_performance_final": 0.7507849335670471, "info_performance_mean": 0.5679435133934021, "info_performance_final": 0.7507849335670471, "step": 1781000}
{"episode_reward": 1135.886970172684, "episode": 17811.0, "batch_reward": 8.228357315063477, "critic_loss": 1543.4979248046875, "actor_loss": -1166.500732421875, "actor_target_entropy": -3.0, "actor_entropy": 1.953732967376709, "alpha_loss": 0.004629109054803848, "alpha_value": 0.3731423556652587, "duration": 1.5598149299621582, "info_normalized_performance_mean": 0.47230470180511475, "info_normalized_performance_final": 0.5759856700897217, "info_performance_mean": 0.47230470180511475, "info_performance_final": 0.5759856700897217, "step": 1781500}
{"episode_reward": 944.6093189964139, "episode": 17816.0, "batch_reward": 7.557682037353516, "critic_loss": 342.225341796875, "actor_loss": -1154.432861328125, "actor_target_entropy": -3.0, "actor_entropy": 2.1743059158325195, "alpha_loss": 0.07315192371606827, "alpha_value": 0.37110960192014597, "duration": 1.5599396228790283, "info_normalized_performance_mean": 0.7233293056488037, "info_normalized_performance_final": 0.7728365659713745, "info_performance_mean": 0.7233293056488037, "info_performance_final": 0.7728365659713745, "step": 1782000}
{"episode_reward": 1446.6586538461509, "episode": 17821.0, "batch_reward": 8.052525520324707, "critic_loss": 541.7069091796875, "actor_loss": -1157.15869140625, "actor_target_entropy": -3.0, "actor_entropy": 2.243908405303955, "alpha_loss": 0.09700402617454529, "alpha_value": 0.3699357018097061, "duration": 1.4802875518798828, "info_normalized_performance_mean": 0.36737221479415894, "info_normalized_performance_final": 0.40909090638160706, "info_performance_mean": 0.36737221479415894, "info_performance_final": 0.40909090638160706, "step": 1782500}
{"episode_reward": 734.744318181817, "episode": 17826.0, "batch_reward": 7.476968765258789, "critic_loss": 2034.7882080078125, "actor_loss": -1137.77197265625, "actor_target_entropy": -3.0, "actor_entropy": 2.362624406814575, "alpha_loss": -0.11702114343643188, "alpha_value": 0.36945469583368196, "duration": 1.5009326934814453, "info_normalized_performance_mean": 0.41198861598968506, "info_normalized_performance_final": 0.47727271914482117, "info_performance_mean": 0.41198861598968506, "info_performance_final": 0.47727271914482117, "step": 1783000}
{"episode_reward": 823.977272727272, "episode": 17831.0, "batch_reward": 8.759882926940918, "critic_loss": 387.98291015625, "actor_loss": -1189.230224609375, "actor_target_entropy": -3.0, "actor_entropy": 2.0885000228881836, "alpha_loss": -0.08357750624418259, "alpha_value": 0.3708341091963537, "duration": 1.4216887950897217, "info_normalized_performance_mean": 0.42924994230270386, "info_normalized_performance_final": 0.4571428596973419, "info_performance_mean": 0.42924994230270386, "info_performance_final": 0.4571428596973419, "step": 1783500}
{"episode_reward": 858.4999999999995, "episode": 17836.0, "batch_reward": 8.452093124389648, "critic_loss": 3290.42333984375, "actor_loss": -1182.843505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.81947922706604, "alpha_loss": -0.3021230101585388, "alpha_value": 0.3745577058509144, "duration": 1.5528476238250732, "info_normalized_performance_mean": 0.43590372800827026, "info_normalized_performance_final": 0.5732620358467102, "info_performance_mean": 0.43590372800827026, "info_performance_final": 0.5732620358467102, "step": 1784000}
{"episode_reward": 871.8074866310163, "episode": 17841.0, "batch_reward": 7.936180114746094, "critic_loss": 818.7772216796875, "actor_loss": -1138.9736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.9754782915115356, "alpha_loss": 0.023222729563713074, "alpha_value": 0.37496460167064233, "duration": 1.528421401977539, "info_normalized_performance_mean": 0.39356622099876404, "info_normalized_performance_final": 0.564874529838562, "info_performance_mean": 0.39356622099876404, "info_performance_final": 0.564874529838562, "step": 1784500}
{"episode_reward": 787.132616487455, "episode": 17846.0, "batch_reward": 7.523583889007568, "critic_loss": 1050.814208984375, "actor_loss": -1137.009521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.9191486835479736, "alpha_loss": -0.006413627415895462, "alpha_value": 0.3746287779086385, "duration": 1.4701178073883057, "info_normalized_performance_mean": 0.3958052694797516, "info_normalized_performance_final": 0.42548078298568726, "info_performance_mean": 0.3958052694797516, "info_performance_final": 0.42548078298568726, "step": 1785000}
{"episode_reward": 791.6105769230753, "episode": 17851.0, "batch_reward": 8.227376937866211, "critic_loss": 549.54736328125, "actor_loss": -1206.160888671875, "actor_target_entropy": -3.0, "actor_entropy": 2.0764331817626953, "alpha_loss": -0.14665862917900085, "alpha_value": 0.3737197855592579, "duration": 1.6256208419799805, "info_normalized_performance_mean": 0.44797661900520325, "info_normalized_performance_final": 0.5594805479049683, "info_performance_mean": 0.44797661900520325, "info_performance_final": 0.5594805479049683, "step": 1785500}
{"episode_reward": 895.953246753246, "episode": 17856.0, "batch_reward": 8.29162883758545, "critic_loss": 711.67822265625, "actor_loss": -1176.839599609375, "actor_target_entropy": -3.0, "actor_entropy": 2.1642608642578125, "alpha_loss": 0.2062641978263855, "alpha_value": 0.37360612509193475, "duration": 1.587085247039795, "info_normalized_performance_mean": 0.9377042651176453, "info_normalized_performance_final": 0.9987980723381042, "info_performance_mean": 0.9377042651176453, "info_performance_final": 0.9987980723381042, "step": 1786000}
{"episode_reward": 1875.4086538461497, "episode": 17861.0, "batch_reward": 8.638914108276367, "critic_loss": 516.8306884765625, "actor_loss": -1190.364013671875, "actor_target_entropy": -3.0, "actor_entropy": 1.960767388343811, "alpha_loss": -0.16790658235549927, "alpha_value": 0.3714802319918437, "duration": 1.7000596523284912, "info_normalized_performance_mean": 0.31104424595832825, "info_normalized_performance_final": 0.3618881106376648, "info_performance_mean": 0.31104424595832825, "info_performance_final": 0.3618881106376648, "step": 1786500}
{"episode_reward": 622.0883661792753, "episode": 17866.0, "batch_reward": 8.408462524414062, "critic_loss": 440.8050537109375, "actor_loss": -1199.80224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.7793415784835815, "alpha_loss": -0.011940919794142246, "alpha_value": 0.3681220888714091, "duration": 1.5087733268737793, "info_normalized_performance_mean": 0.3819010555744171, "info_normalized_performance_final": 0.49609375, "info_performance_mean": 0.3819010555744171, "info_performance_final": 0.49609375, "step": 1787000}
{"episode_reward": 763.8020833333333, "episode": 17871.0, "batch_reward": 8.525217056274414, "critic_loss": 262.23931884765625, "actor_loss": -1186.974365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.943638563156128, "alpha_loss": -0.056965045630931854, "alpha_value": 0.36603961985566286, "duration": 1.4930047988891602, "info_normalized_performance_mean": 0.5014582872390747, "info_normalized_performance_final": 0.6223958134651184, "info_performance_mean": 0.5014582872390747, "info_performance_final": 0.6223958134651184, "step": 1787500}
{"episode_reward": 1002.9166666666655, "episode": 17876.0, "batch_reward": 8.351822853088379, "critic_loss": 1724.48291015625, "actor_loss": -1208.59033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.7236766815185547, "alpha_loss": 0.06769374012947083, "alpha_value": 0.3623443707529675, "duration": 1.5661876201629639, "info_normalized_performance_mean": 0.7351389527320862, "info_normalized_performance_final": 0.7934027910232544, "info_performance_mean": 0.7351389527320862, "info_performance_final": 0.7934027910232544, "step": 1788000}
{"episode_reward": 1470.27777777778, "episode": 17881.0, "batch_reward": 8.828702926635742, "critic_loss": 3415.112548828125, "actor_loss": -1204.005615234375, "actor_target_entropy": -3.0, "actor_entropy": 2.1100127696990967, "alpha_loss": 0.11853799223899841, "alpha_value": 0.3612939053289572, "duration": 1.7367525100708008, "info_normalized_performance_mean": 0.5973813533782959, "info_normalized_performance_final": 0.7419948577880859, "info_performance_mean": 0.5973813533782959, "info_performance_final": 0.7419948577880859, "step": 1788500}
{"episode_reward": 1194.7626058152362, "episode": 17886.0, "batch_reward": 8.016279220581055, "critic_loss": 481.80792236328125, "actor_loss": -1189.646240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.8911173343658447, "alpha_loss": 0.11141993850469589, "alpha_value": 0.35866643038120405, "duration": 1.4100103378295898, "info_normalized_performance_mean": 0.17473213374614716, "info_normalized_performance_final": 0.18928571045398712, "info_performance_mean": 0.17473213374614716, "info_performance_final": 0.18928571045398712, "step": 1789000}
{"episode_reward": 349.4642857142853, "episode": 17891.0, "batch_reward": 8.364364624023438, "critic_loss": 627.0125732421875, "actor_loss": -1174.1497802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.8411335945129395, "alpha_loss": 0.2140524983406067, "alpha_value": 0.3532933634728016, "duration": 1.650890588760376, "info_normalized_performance_mean": 0.3240964114665985, "info_normalized_performance_final": 0.37909460067749023, "info_performance_mean": 0.3240964114665985, "info_performance_final": 0.37909460067749023, "step": 1789500}
{"episode_reward": 648.192859771807, "episode": 17896.0, "batch_reward": 8.62121295928955, "critic_loss": 1010.66259765625, "actor_loss": -1204.776123046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5243760347366333, "alpha_loss": 0.05701131746172905, "alpha_value": 0.3461842842793414, "step": 1790000}
{"duration": 18.856375455856323, "info_normalized_performance_mean": 0.6460666060447693, "info_normalized_performance_final": 0.7409855723381042, "info_performance_mean": 0.6460666060447693, "info_performance_final": 0.7409855723381042, "step": 1790000}
{"episode_reward": 1292.1334134615372, "episode": 17901.0, "batch_reward": 7.412657737731934, "critic_loss": 4147.4951171875, "actor_loss": -1156.969970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.6667659282684326, "alpha_loss": -0.031175609678030014, "alpha_value": 0.34079930149168364, "duration": 1.7678699493408203, "info_normalized_performance_mean": 0.33192574977874756, "info_normalized_performance_final": 0.39329594373703003, "info_performance_mean": 0.33192574977874756, "info_performance_final": 0.39329594373703003, "step": 1790500}
{"episode_reward": 663.8514957264961, "episode": 17906.0, "batch_reward": 8.001835823059082, "critic_loss": 1384.816162109375, "actor_loss": -1197.27099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.6201226711273193, "alpha_loss": -0.2676152288913727, "alpha_value": 0.3334927979560061, "duration": 1.5376389026641846, "info_normalized_performance_mean": 0.7230033874511719, "info_normalized_performance_final": 0.7760416865348816, "info_performance_mean": 0.7230033874511719, "info_performance_final": 0.7760416865348816, "step": 1791000}
{"episode_reward": 1446.0069444444434, "episode": 17911.0, "batch_reward": 8.595993995666504, "critic_loss": 422.01910400390625, "actor_loss": -1180.633056640625, "actor_target_entropy": -3.0, "actor_entropy": 1.6399661302566528, "alpha_loss": -0.03830471634864807, "alpha_value": 0.3274278570953547, "duration": 1.3591737747192383, "info_normalized_performance_mean": 0.16884373128414154, "info_normalized_performance_final": 0.18125000596046448, "info_performance_mean": 0.16884373128414154, "info_performance_final": 0.18125000596046448, "step": 1791500}
{"episode_reward": 337.6875, "episode": 17916.0, "batch_reward": 9.107612609863281, "critic_loss": 216.01504516601562, "actor_loss": -1206.098388671875, "actor_target_entropy": -3.0, "actor_entropy": 2.061570644378662, "alpha_loss": 0.1481114625930786, "alpha_value": 0.3228744523028849, "duration": 1.6190438270568848, "info_normalized_performance_mean": 0.5389044284820557, "info_normalized_performance_final": 0.6381173133850098, "info_performance_mean": 0.5389044284820557, "info_performance_final": 0.6381173133850098, "step": 1792000}
{"episode_reward": 1077.8086419753083, "episode": 17921.0, "batch_reward": 8.226171493530273, "critic_loss": 695.228271484375, "actor_loss": -1175.1954345703125, "actor_target_entropy": -3.0, "actor_entropy": 1.8658065795898438, "alpha_loss": 0.19787544012069702, "alpha_value": 0.31601272732733793, "duration": 1.5092175006866455, "info_normalized_performance_mean": 0.14684920012950897, "info_normalized_performance_final": 0.21190476417541504, "info_performance_mean": 0.14684920012950897, "info_performance_final": 0.21190476417541504, "step": 1792500}
{"episode_reward": 293.69841269841277, "episode": 17926.0, "batch_reward": 8.657779693603516, "critic_loss": 1569.4580078125, "actor_loss": -1197.627685546875, "actor_target_entropy": -3.0, "actor_entropy": 1.2342243194580078, "alpha_loss": -0.03505232185125351, "alpha_value": 0.3091953631094445, "duration": 1.5356154441833496, "info_normalized_performance_mean": 0.8547601103782654, "info_normalized_performance_final": 0.9120000004768372, "info_performance_mean": 0.8547601103782654, "info_performance_final": 0.9120000004768372, "step": 1793000}
{"episode_reward": 1709.5200000000007, "episode": 17931.0, "batch_reward": 8.598504066467285, "critic_loss": 469.2008361816406, "actor_loss": -1200.2490234375, "actor_target_entropy": -3.0, "actor_entropy": 1.9653457403182983, "alpha_loss": 0.1281077265739441, "alpha_value": 0.30315304840759744, "duration": 1.456613540649414, "info_normalized_performance_mean": 0.6305468678474426, "info_normalized_performance_final": 0.6770833134651184, "info_performance_mean": 0.6305468678474426, "info_performance_final": 0.6770833134651184, "step": 1793500}
{"episode_reward": 1261.0937500000002, "episode": 17936.0, "batch_reward": 8.81450366973877, "critic_loss": 831.061767578125, "actor_loss": -1210.847412109375, "actor_target_entropy": -3.0, "actor_entropy": 2.1800754070281982, "alpha_loss": 0.3398866653442383, "alpha_value": 0.2983429730880368, "duration": 1.6318168640136719, "info_normalized_performance_mean": 0.5115439891815186, "info_normalized_performance_final": 0.6140060424804688, "info_performance_mean": 0.5115439891815186, "info_performance_final": 0.6140060424804688, "step": 1794000}
{"episode_reward": 1023.0879514750485, "episode": 17941.0, "batch_reward": 8.061491012573242, "critic_loss": 889.8136596679688, "actor_loss": -1158.1893310546875, "actor_target_entropy": -3.0, "actor_entropy": 1.9332865476608276, "alpha_loss": -0.10560456663370132, "alpha_value": 0.2968806097406114, "duration": 1.4619367122650146, "info_normalized_performance_mean": 0.3028993010520935, "info_normalized_performance_final": 0.3246527910232544, "info_performance_mean": 0.3028993010520935, "info_performance_final": 0.3246527910232544, "step": 1794500}
{"episode_reward": 605.7986111111103, "episode": 17946.0, "batch_reward": 8.213632583618164, "critic_loss": 387.92218017578125, "actor_loss": -1184.17822265625, "actor_target_entropy": -3.0, "actor_entropy": 1.830183982849121, "alpha_loss": 0.08759590983390808, "alpha_value": 0.292291811567461, "duration": 1.5580780506134033, "info_normalized_performance_mean": 0.6997833847999573, "info_normalized_performance_final": 0.7450000047683716, "info_performance_mean": 0.6997833847999573, "info_performance_final": 0.7450000047683716, "step": 1795000}
{"episode_reward": 1399.566666666668, "episode": 17951.0, "batch_reward": 8.650428771972656, "critic_loss": 938.6744995117188, "actor_loss": -1195.2354736328125, "actor_target_entropy": -3.0, "actor_entropy": 2.0547361373901367, "alpha_loss": 0.24590608477592468, "alpha_value": 0.28867974462566626, "duration": 1.467005729675293, "info_normalized_performance_mean": 0.24853172898292542, "info_normalized_performance_final": 0.2658730149269104, "info_performance_mean": 0.24853172898292542, "info_performance_final": 0.2658730149269104, "step": 1795500}
{"episode_reward": 497.06349206349165, "episode": 17956.0, "batch_reward": 9.344417572021484, "critic_loss": 966.8399047851562, "actor_loss": -1206.3619384765625, "actor_target_entropy": -3.0, "actor_entropy": 1.947875738143921, "alpha_loss": 0.07578405737876892, "alpha_value": 0.2855485009933585, "duration": 1.668485164642334, "info_normalized_performance_mean": 0.5427785515785217, "info_normalized_performance_final": 0.6747618913650513, "info_performance_mean": 0.5427785515785217, "info_performance_final": 0.6747618913650513, "step": 1796000}
{"episode_reward": 1085.5571428571427, "episode": 17961.0, "batch_reward": 9.324869155883789, "critic_loss": 556.4324951171875, "actor_loss": -1230.1650390625, "actor_target_entropy": -3.0, "actor_entropy": 1.8859350681304932, "alpha_loss": 0.3447112441062927, "alpha_value": 0.28122795169923814, "duration": 1.5568976402282715, "info_normalized_performance_mean": 0.2811249792575836, "info_normalized_performance_final": 0.47999998927116394, "info_performance_mean": 0.2811249792575836, "info_performance_final": 0.47999998927116394, "step": 1796500}
{"episode_reward": 562.2500000000005, "episode": 17966.0, "batch_reward": 7.928321838378906, "critic_loss": 635.1293334960938, "actor_loss": -1166.372802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.8402094841003418, "alpha_loss": 0.06752223521471024, "alpha_value": 0.27527852833948313, "duration": 1.5629703998565674, "info_normalized_performance_mean": 0.6424887776374817, "info_normalized_performance_final": 0.7994791865348816, "info_performance_mean": 0.6424887776374817, "info_performance_final": 0.7994791865348816, "step": 1797000}
{"episode_reward": 1284.9776785714284, "episode": 17971.0, "batch_reward": 8.456218719482422, "critic_loss": 521.205078125, "actor_loss": -1201.658203125, "actor_target_entropy": -3.0, "actor_entropy": 1.6032633781433105, "alpha_loss": -0.1261681616306305, "alpha_value": 0.271880987010705, "duration": 1.5021028518676758, "info_normalized_performance_mean": 0.30732640624046326, "info_normalized_performance_final": 0.3255208432674408, "info_performance_mean": 0.30732640624046326, "info_performance_final": 0.3255208432674408, "step": 1797500}
{"episode_reward": 614.6527777777778, "episode": 17976.0, "batch_reward": 9.346452713012695, "critic_loss": 757.80712890625, "actor_loss": -1201.3697509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.9050191640853882, "alpha_loss": 0.019361155107617378, "alpha_value": 0.26969432864056375, "duration": 1.819180965423584, "info_normalized_performance_mean": 0.6737393140792847, "info_normalized_performance_final": 0.7881944179534912, "info_performance_mean": 0.6737393140792847, "info_performance_final": 0.7881944179534912, "step": 1798000}
{"episode_reward": 1347.4786324786337, "episode": 17981.0, "batch_reward": 8.6264009475708, "critic_loss": 709.701416015625, "actor_loss": -1191.889404296875, "actor_target_entropy": -3.0, "actor_entropy": 1.9825084209442139, "alpha_loss": 0.0793316587805748, "alpha_value": 0.2682848059511998, "duration": 1.7936525344848633, "info_normalized_performance_mean": 0.5683316588401794, "info_normalized_performance_final": 0.6909722089767456, "info_performance_mean": 0.5683316588401794, "info_performance_final": 0.6909722089767456, "step": 1798500}
{"episode_reward": 1136.6633597883597, "episode": 17986.0, "batch_reward": 9.453130722045898, "critic_loss": 829.127197265625, "actor_loss": -1237.3017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.838256597518921, "alpha_loss": -0.04918278753757477, "alpha_value": 0.26735315005388904, "duration": 1.6344680786132812, "info_normalized_performance_mean": 0.5391921997070312, "info_normalized_performance_final": 0.7015584707260132, "info_performance_mean": 0.5391921997070312, "info_performance_final": 0.7015584707260132, "step": 1799000}
{"episode_reward": 1078.3844155844156, "episode": 17991.0, "batch_reward": 9.274462699890137, "critic_loss": 1163.6932373046875, "actor_loss": -1239.13623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.9009382724761963, "alpha_loss": 0.04860099405050278, "alpha_value": 0.2682218230610377, "duration": 1.4829034805297852, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1799500}
{"episode_reward": 0.0, "episode": 17996.0, "batch_reward": 9.527488708496094, "critic_loss": 485.24151611328125, "actor_loss": -1223.9793701171875, "actor_target_entropy": -3.0, "actor_entropy": 2.232638359069824, "alpha_loss": -0.037357889115810394, "alpha_value": 0.2693079698987785, "step": 1800000}
{"duration": 18.746528387069702, "info_normalized_performance_mean": 0.782682478427887, "info_normalized_performance_final": 0.8305882215499878, "info_performance_mean": 0.782682478427887, "info_performance_final": 0.8305882215499878, "step": 1800000}
{"episode_reward": 1565.36470588235, "episode": 18001.0, "batch_reward": 9.318700790405273, "critic_loss": 933.2760009765625, "actor_loss": -1208.064208984375, "actor_target_entropy": -3.0, "actor_entropy": 1.997342586517334, "alpha_loss": 0.011689817532896996, "alpha_value": 0.2708548540248523, "duration": 1.483098030090332, "info_normalized_performance_mean": 0.442823588848114, "info_normalized_performance_final": 0.5407366156578064, "info_performance_mean": 0.442823588848114, "info_performance_final": 0.5407366156578064, "step": 1800500}
{"episode_reward": 885.6473214285705, "episode": 18006.0, "batch_reward": 9.01066780090332, "critic_loss": 711.5438232421875, "actor_loss": -1217.205078125, "actor_target_entropy": -3.0, "actor_entropy": 1.8141825199127197, "alpha_loss": 0.01811499521136284, "alpha_value": 0.272149431333477, "duration": 1.5611159801483154, "info_normalized_performance_mean": 0.5492708683013916, "info_normalized_performance_final": 0.6705729365348816, "info_performance_mean": 0.5492708683013916, "info_performance_final": 0.6705729365348816, "step": 1801000}
{"episode_reward": 1098.5416666666674, "episode": 18011.0, "batch_reward": 8.872802734375, "critic_loss": 2791.15966796875, "actor_loss": -1179.473388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.3798129558563232, "alpha_loss": 0.04440956190228462, "alpha_value": 0.2712706571126403, "duration": 1.4193603992462158, "info_normalized_performance_mean": 0.09832943230867386, "info_normalized_performance_final": 0.10588235408067703, "info_performance_mean": 0.09832943230867386, "info_performance_final": 0.10588235408067703, "step": 1801500}
{"episode_reward": 196.65882352941216, "episode": 18016.0, "batch_reward": 9.08950424194336, "critic_loss": 338.37335205078125, "actor_loss": -1209.7650146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.6750009059906006, "alpha_loss": 0.0347612127661705, "alpha_value": 0.27385665450469976, "duration": 1.5080163478851318, "info_normalized_performance_mean": 0.4083615839481354, "info_normalized_performance_final": 0.5642856955528259, "info_performance_mean": 0.4083615839481354, "info_performance_final": 0.5642856955528259, "step": 1802000}
{"episode_reward": 816.7232142857155, "episode": 18021.0, "batch_reward": 9.68018913269043, "critic_loss": 635.148681640625, "actor_loss": -1213.0362548828125, "actor_target_entropy": -3.0, "actor_entropy": 2.002676486968994, "alpha_loss": 0.055868640542030334, "alpha_value": 0.27765275393670574, "duration": 1.4451351165771484, "info_normalized_performance_mean": 0.22240740060806274, "info_normalized_performance_final": 0.26851850748062134, "info_performance_mean": 0.22240740060806274, "info_performance_final": 0.26851850748062134, "step": 1802500}
{"episode_reward": 444.8148148148153, "episode": 18026.0, "batch_reward": 9.29037857055664, "critic_loss": 714.5518188476562, "actor_loss": -1214.8990478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.732277750968933, "alpha_loss": 0.05149099975824356, "alpha_value": 0.281807975367816, "duration": 1.5020475387573242, "info_normalized_performance_mean": 0.38967427611351013, "info_normalized_performance_final": 0.4631083309650421, "info_performance_mean": 0.38967427611351013, "info_performance_final": 0.4631083309650421, "step": 1803000}
{"episode_reward": 779.3485086342229, "episode": 18031.0, "batch_reward": 9.229325294494629, "critic_loss": 462.1343994140625, "actor_loss": -1221.195556640625, "actor_target_entropy": -3.0, "actor_entropy": 1.6161402463912964, "alpha_loss": 0.002882838249206543, "alpha_value": 0.2846197204662682, "duration": 1.5721793174743652, "info_normalized_performance_mean": 0.8071248531341553, "info_normalized_performance_final": 0.8737499713897705, "info_performance_mean": 0.8071248531341553, "info_performance_final": 0.8737499713897705, "step": 1803500}
{"episode_reward": 1614.249999999998, "episode": 18036.0, "batch_reward": 8.116158485412598, "critic_loss": 982.16650390625, "actor_loss": -1163.06787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.8140404224395752, "alpha_loss": 0.013020917773246765, "alpha_value": 0.2878086205312057, "duration": 1.539982557296753, "info_normalized_performance_mean": 0.6190420389175415, "info_normalized_performance_final": 0.6605042219161987, "info_performance_mean": 0.6190420389175415, "info_performance_final": 0.6605042219161987, "step": 1804000}
{"episode_reward": 1238.0840336134463, "episode": 18041.0, "batch_reward": 8.792003631591797, "critic_loss": 1509.2783203125, "actor_loss": -1196.009033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.8198606967926025, "alpha_loss": 0.06728550791740417, "alpha_value": 0.29079237028443855, "duration": 1.4790022373199463, "info_normalized_performance_mean": 0.5678355693817139, "info_normalized_performance_final": 0.6730324029922485, "info_performance_mean": 0.5678355693817139, "info_performance_final": 0.6730324029922485, "step": 1804500}
{"episode_reward": 1135.6712962962954, "episode": 18046.0, "batch_reward": 8.840811729431152, "critic_loss": 2762.28369140625, "actor_loss": -1215.5211181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.781538963317871, "alpha_loss": -0.09356410056352615, "alpha_value": 0.2956105327328117, "duration": 1.513932466506958, "info_normalized_performance_mean": 0.5228963494300842, "info_normalized_performance_final": 0.5859497785568237, "info_performance_mean": 0.5228963494300842, "info_performance_final": 0.5859497785568237, "step": 1805000}
{"episode_reward": 1045.7927786499222, "episode": 18051.0, "batch_reward": 9.132356643676758, "critic_loss": 345.2395935058594, "actor_loss": -1208.46533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.8848741054534912, "alpha_loss": -0.08750975131988525, "alpha_value": 0.3015793482278087, "duration": 1.7571368217468262, "info_normalized_performance_mean": 0.5382325649261475, "info_normalized_performance_final": 0.6538461446762085, "info_performance_mean": 0.5382325649261475, "info_performance_final": 0.6538461446762085, "step": 1805500}
{"episode_reward": 1076.4652014652013, "episode": 18056.0, "batch_reward": 8.102020263671875, "critic_loss": 3587.412109375, "actor_loss": -1174.2423095703125, "actor_target_entropy": -3.0, "actor_entropy": 1.8620833158493042, "alpha_loss": -0.09042100608348846, "alpha_value": 0.3078351788102712, "duration": 1.5462009906768799, "info_normalized_performance_mean": 0.8515498638153076, "info_normalized_performance_final": 0.9049999713897705, "info_performance_mean": 0.8515498638153076, "info_performance_final": 0.9049999713897705, "step": 1806000}
{"episode_reward": 1703.0999999999974, "episode": 18061.0, "batch_reward": 9.94009780883789, "critic_loss": 570.5287475585938, "actor_loss": -1290.7548828125, "actor_target_entropy": -3.0, "actor_entropy": 2.0028347969055176, "alpha_loss": -0.15911801159381866, "alpha_value": 0.3163780366531621, "duration": 1.6829774379730225, "info_normalized_performance_mean": 0.6198551058769226, "info_normalized_performance_final": 0.7621977925300598, "info_performance_mean": 0.6198551058769226, "info_performance_final": 0.7621977925300598, "step": 1806500}
{"episode_reward": 1239.709890109891, "episode": 18066.0, "batch_reward": 8.676884651184082, "critic_loss": 1035.4586181640625, "actor_loss": -1248.5152587890625, "actor_target_entropy": -3.0, "actor_entropy": 1.7168442010879517, "alpha_loss": -0.2114405781030655, "alpha_value": 0.3271989786280498, "duration": 1.3991565704345703, "info_normalized_performance_mean": 0.6012499332427979, "info_normalized_performance_final": 0.6464285850524902, "info_performance_mean": 0.6012499332427979, "info_performance_final": 0.6464285850524902, "step": 1807000}
{"episode_reward": 1202.4999999999995, "episode": 18071.0, "batch_reward": 8.621072769165039, "critic_loss": 1199.7342529296875, "actor_loss": -1234.6400146484375, "actor_target_entropy": -3.0, "actor_entropy": 1.915416955947876, "alpha_loss": -0.49900954961776733, "alpha_value": 0.3417462182915921, "duration": 1.6497514247894287, "info_normalized_performance_mean": 0.6011143326759338, "info_normalized_performance_final": 0.7950649261474609, "info_performance_mean": 0.6011143326759338, "info_performance_final": 0.7950649261474609, "step": 1807500}
{"episode_reward": 1202.2285714285715, "episode": 18076.0, "batch_reward": 9.263810157775879, "critic_loss": 2747.43505859375, "actor_loss": -1297.837890625, "actor_target_entropy": -3.0, "actor_entropy": 2.08491849899292, "alpha_loss": -0.7681323289871216, "alpha_value": 0.3541303914082657, "duration": 1.6799440383911133, "info_normalized_performance_mean": 0.6625623106956482, "info_normalized_performance_final": 0.7672916650772095, "info_performance_mean": 0.6625623106956482, "info_performance_final": 0.7672916650772095, "step": 1808000}
{"episode_reward": 1325.1249999999989, "episode": 18081.0, "batch_reward": 9.20331859588623, "critic_loss": 1899.322998046875, "actor_loss": -1297.4183349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.8813104629516602, "alpha_loss": -0.420412540435791, "alpha_value": 0.3651880873103919, "duration": 1.4726932048797607, "info_normalized_performance_mean": 0.5044140815734863, "info_normalized_performance_final": 0.576171875, "info_performance_mean": 0.5044140815734863, "info_performance_final": 0.576171875, "step": 1808500}
{"episode_reward": 1008.828125, "episode": 18086.0, "batch_reward": 8.635366439819336, "critic_loss": 6306.4013671875, "actor_loss": -1278.16748046875, "actor_target_entropy": -3.0, "actor_entropy": 1.9822813272476196, "alpha_loss": -0.16786937415599823, "alpha_value": 0.37442354719590615, "duration": 1.5036375522613525, "info_normalized_performance_mean": 0.36540359258651733, "info_normalized_performance_final": 0.4216141104698181, "info_performance_mean": 0.36540359258651733, "info_performance_final": 0.4216141104698181, "step": 1809000}
{"episode_reward": 730.8070500927647, "episode": 18091.0, "batch_reward": 9.157881736755371, "critic_loss": 925.9644165039062, "actor_loss": -1296.087158203125, "actor_target_entropy": -3.0, "actor_entropy": 2.102867841720581, "alpha_loss": -0.4601893424987793, "alpha_value": 0.38406745403777126, "duration": 1.499258041381836, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1809500}
{"episode_reward": 0.0, "episode": 18096.0, "batch_reward": 9.829792022705078, "critic_loss": 1145.17626953125, "actor_loss": -1362.3946533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.9102228879928589, "alpha_loss": -0.43959763646125793, "alpha_value": 0.39439698719215127, "step": 1810000}
{"duration": 18.97970151901245, "info_normalized_performance_mean": 0.4097959101200104, "info_normalized_performance_final": 0.4831240177154541, "info_performance_mean": 0.4097959101200104, "info_performance_final": 0.4831240177154541, "step": 1810000}
{"episode_reward": 819.5918367346943, "episode": 18101.0, "batch_reward": 8.577075004577637, "critic_loss": 1865.0887451171875, "actor_loss": -1295.0748291015625, "actor_target_entropy": -3.0, "actor_entropy": 1.8163591623306274, "alpha_loss": -0.2848846912384033, "alpha_value": 0.40322149600490975, "duration": 1.7591097354888916, "info_normalized_performance_mean": 0.3626995384693146, "info_normalized_performance_final": 0.43589743971824646, "info_performance_mean": 0.3626995384693146, "info_performance_final": 0.43589743971824646, "step": 1810500}
{"episode_reward": 725.3990795529257, "episode": 18106.0, "batch_reward": 8.404422760009766, "critic_loss": 9174.427734375, "actor_loss": -1322.221923828125, "actor_target_entropy": -3.0, "actor_entropy": 2.0597188472747803, "alpha_loss": -0.4432488679885864, "alpha_value": 0.4142886647350073, "duration": 1.6338679790496826, "info_normalized_performance_mean": 0.6557265520095825, "info_normalized_performance_final": 0.7758477926254272, "info_performance_mean": 0.6557265520095825, "info_performance_final": 0.7758477926254272, "step": 1811000}
{"episode_reward": 1311.4529914529912, "episode": 18111.0, "batch_reward": 8.553140640258789, "critic_loss": 3563.2529296875, "actor_loss": -1360.0743408203125, "actor_target_entropy": -3.0, "actor_entropy": 2.0312867164611816, "alpha_loss": -0.4396795332431793, "alpha_value": 0.42357171190911097, "duration": 1.7556543350219727, "info_normalized_performance_mean": 0.290054589509964, "info_normalized_performance_final": 0.34148839116096497, "info_performance_mean": 0.290054589509964, "info_performance_final": 0.34148839116096497, "step": 1811500}
{"episode_reward": 580.1092398725526, "episode": 18116.0, "batch_reward": 8.72158432006836, "critic_loss": 3815.27685546875, "actor_loss": -1362.3121337890625, "actor_target_entropy": -3.0, "actor_entropy": 2.1202783584594727, "alpha_loss": -0.20974159240722656, "alpha_value": 0.43167625481033034, "duration": 1.4252276420593262, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1812000}
{"episode_reward": 0.0, "episode": 18121.0, "batch_reward": 8.124013900756836, "critic_loss": 1061.7490234375, "actor_loss": -1332.516845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.5264697074890137, "alpha_loss": -0.14023621380329132, "alpha_value": 0.4383933471610935, "duration": 1.3711237907409668, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1812500}
{"episode_reward": 0.0, "episode": 18126.0, "batch_reward": 8.500197410583496, "critic_loss": 925.0782470703125, "actor_loss": -1418.47119140625, "actor_target_entropy": -3.0, "actor_entropy": 1.6861560344696045, "alpha_loss": -0.3539484143257141, "alpha_value": 0.44542019366512237, "duration": 1.6026501655578613, "info_normalized_performance_mean": 0.3570394814014435, "info_normalized_performance_final": 0.44118818640708923, "info_performance_mean": 0.3570394814014435, "info_performance_final": 0.44118818640708923, "step": 1813000}
{"episode_reward": 714.0789473684202, "episode": 18131.0, "batch_reward": 8.640606880187988, "critic_loss": 572.7194213867188, "actor_loss": -1403.2557373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.7213115692138672, "alpha_loss": -0.23960837721824646, "alpha_value": 0.45104857302285467, "duration": 1.3893663883209229, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1813500}
{"episode_reward": 0.0, "episode": 18136.0, "batch_reward": 9.1493501663208, "critic_loss": 1114.652587890625, "actor_loss": -1449.4708251953125, "actor_target_entropy": -3.0, "actor_entropy": 1.6332263946533203, "alpha_loss": -0.08967462927103043, "alpha_value": 0.45681207664414114, "duration": 1.484123945236206, "info_normalized_performance_mean": 0.5124514102935791, "info_normalized_performance_final": 0.6260822415351868, "info_performance_mean": 0.5124514102935791, "info_performance_final": 0.6260822415351868, "step": 1814000}
{"episode_reward": 1024.9025974025965, "episode": 18141.0, "batch_reward": 9.276061058044434, "critic_loss": 1448.6884765625, "actor_loss": -1437.50634765625, "actor_target_entropy": -3.0, "actor_entropy": 1.9169681072235107, "alpha_loss": -0.008787911385297775, "alpha_value": 0.4641790170962618, "duration": 1.4701347351074219, "info_normalized_performance_mean": 0.088375024497509, "info_normalized_performance_final": 0.10781250149011612, "info_performance_mean": 0.088375024497509, "info_performance_final": 0.10781250149011612, "step": 1814500}
{"episode_reward": 176.75, "episode": 18146.0, "batch_reward": 9.59385871887207, "critic_loss": 2885.25244140625, "actor_loss": -1487.019287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.696049690246582, "alpha_loss": 0.09705386310815811, "alpha_value": 0.4668021538503563, "duration": 1.3799192905426025, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1815000}
{"episode_reward": 0.0, "episode": 18151.0, "batch_reward": 8.273923873901367, "critic_loss": 1311.62353515625, "actor_loss": -1436.01513671875, "actor_target_entropy": -3.0, "actor_entropy": 1.5011563301086426, "alpha_loss": -0.05677217245101929, "alpha_value": 0.4708427068489566, "duration": 1.5768365859985352, "info_normalized_performance_mean": 0.2544404864311218, "info_normalized_performance_final": 0.30761903524398804, "info_performance_mean": 0.2544404864311218, "info_performance_final": 0.30761903524398804, "step": 1815500}
{"episode_reward": 508.88095238095246, "episode": 18156.0, "batch_reward": 9.316575050354004, "critic_loss": 1220.98486328125, "actor_loss": -1468.9012451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.620553970336914, "alpha_loss": 0.13855239748954773, "alpha_value": 0.47046533995214734, "duration": 1.5869770050048828, "info_normalized_performance_mean": 0.4931018054485321, "info_normalized_performance_final": 0.6355114579200745, "info_performance_mean": 0.4931018054485321, "info_performance_final": 0.6355114579200745, "step": 1816000}
{"episode_reward": 986.2034739454078, "episode": 18161.0, "batch_reward": 8.840588569641113, "critic_loss": 879.2388916015625, "actor_loss": -1462.8623046875, "actor_target_entropy": -3.0, "actor_entropy": 1.6764159202575684, "alpha_loss": 0.12230201065540314, "alpha_value": 0.4706899585480949, "duration": 1.4216794967651367, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1816500}
{"episode_reward": 0.0, "episode": 18166.0, "batch_reward": 8.653144836425781, "critic_loss": 917.6810913085938, "actor_loss": -1484.923828125, "actor_target_entropy": -3.0, "actor_entropy": 1.5263593196868896, "alpha_loss": -0.014105532318353653, "alpha_value": 0.4682697572701616, "duration": 1.466979742050171, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1817000}
{"episode_reward": 0.0, "episode": 18171.0, "batch_reward": 8.81611156463623, "critic_loss": 1522.544921875, "actor_loss": -1468.46923828125, "actor_target_entropy": -3.0, "actor_entropy": 1.7133467197418213, "alpha_loss": -0.07097498327493668, "alpha_value": 0.4700110337566807, "duration": 1.4259986877441406, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1817500}
{"episode_reward": 0.0, "episode": 18176.0, "batch_reward": 8.461963653564453, "critic_loss": 1780.62109375, "actor_loss": -1458.3751220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.671699047088623, "alpha_loss": -0.07516222447156906, "alpha_value": 0.47012441606304567, "duration": 1.4452626705169678, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1818000}
{"episode_reward": 0.0, "episode": 18181.0, "batch_reward": 9.358724594116211, "critic_loss": 1255.1671142578125, "actor_loss": -1562.678955078125, "actor_target_entropy": -3.0, "actor_entropy": 1.997319221496582, "alpha_loss": -0.008140146732330322, "alpha_value": 0.46996711411292597, "duration": 1.5151102542877197, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1818500}
{"episode_reward": 0.0, "episode": 18186.0, "batch_reward": 8.260736465454102, "critic_loss": 686.0428466796875, "actor_loss": -1447.158447265625, "actor_target_entropy": -3.0, "actor_entropy": 1.737619161605835, "alpha_loss": 0.14942236244678497, "alpha_value": 0.4716103227277856, "duration": 1.5177812576293945, "info_normalized_performance_mean": 0.36085301637649536, "info_normalized_performance_final": 0.3960784375667572, "info_performance_mean": 0.36085301637649536, "info_performance_final": 0.3960784375667572, "step": 1819000}
{"episode_reward": 721.7058823529404, "episode": 18191.0, "batch_reward": 8.562271118164062, "critic_loss": 1226.428955078125, "actor_loss": -1508.790771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.6233723163604736, "alpha_loss": 0.07364410161972046, "alpha_value": 0.4713102418286291, "duration": 1.4705631732940674, "info_normalized_performance_mean": 0.5615624785423279, "info_normalized_performance_final": 0.671875, "info_performance_mean": 0.5615624785423279, "info_performance_final": 0.671875, "step": 1819500}
{"episode_reward": 1123.125, "episode": 18196.0, "batch_reward": 9.29434585571289, "critic_loss": 2489.373291015625, "actor_loss": -1503.1240234375, "actor_target_entropy": -3.0, "actor_entropy": 2.2462422847747803, "alpha_loss": 0.28898173570632935, "alpha_value": 0.4728642571130487, "step": 1820000}
{"duration": 18.398189783096313, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1820000}
{"episode_reward": 0.0, "episode": 18201.0, "batch_reward": 8.456426620483398, "critic_loss": 3282.67236328125, "actor_loss": -1492.1650390625, "actor_target_entropy": -3.0, "actor_entropy": 1.922661304473877, "alpha_loss": 0.020954284816980362, "alpha_value": 0.47429371309596946, "duration": 1.4645652770996094, "info_normalized_performance_mean": 0.7704062461853027, "info_normalized_performance_final": 0.8531249761581421, "info_performance_mean": 0.7704062461853027, "info_performance_final": 0.8531249761581421, "step": 1820500}
{"episode_reward": 1540.8125, "episode": 18206.0, "batch_reward": 9.323433876037598, "critic_loss": 478.0292663574219, "actor_loss": -1532.328857421875, "actor_target_entropy": -3.0, "actor_entropy": 2.1022095680236816, "alpha_loss": 0.31659454107284546, "alpha_value": 0.47480517086950325, "duration": 1.507753849029541, "info_normalized_performance_mean": 0.27633047103881836, "info_normalized_performance_final": 0.41405022144317627, "info_performance_mean": 0.27633047103881836, "info_performance_final": 0.41405022144317627, "step": 1821000}
{"episode_reward": 552.6609105180526, "episode": 18211.0, "batch_reward": 8.592805862426758, "critic_loss": 2857.68359375, "actor_loss": -1501.582275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.5556946992874146, "alpha_loss": -0.29506438970565796, "alpha_value": 0.47282469051484727, "duration": 1.413708209991455, "info_normalized_performance_mean": 0.01724206656217575, "info_normalized_performance_final": 0.02182539738714695, "info_performance_mean": 0.01724206656217575, "info_performance_final": 0.02182539738714695, "step": 1821500}
{"episode_reward": 34.484126984126995, "episode": 18216.0, "batch_reward": 8.474855422973633, "critic_loss": 972.590576171875, "actor_loss": -1492.82421875, "actor_target_entropy": -3.0, "actor_entropy": 1.539555549621582, "alpha_loss": -0.01784653216600418, "alpha_value": 0.4743649904810915, "duration": 1.5242714881896973, "info_normalized_performance_mean": 0.17900390923023224, "info_normalized_performance_final": 0.33203125, "info_performance_mean": 0.17900390923023224, "info_performance_final": 0.33203125, "step": 1822000}
{"episode_reward": 358.0078124999998, "episode": 18221.0, "batch_reward": 9.496362686157227, "critic_loss": 914.9586181640625, "actor_loss": -1565.567626953125, "actor_target_entropy": -3.0, "actor_entropy": 2.050896406173706, "alpha_loss": 0.0687495619058609, "alpha_value": 0.4777286641059109, "duration": 1.4444854259490967, "info_normalized_performance_mean": 0.3424285650253296, "info_normalized_performance_final": 0.4392857253551483, "info_performance_mean": 0.3424285650253296, "info_performance_final": 0.4392857253551483, "step": 1822500}
{"episode_reward": 684.8571428571436, "episode": 18226.0, "batch_reward": 9.999025344848633, "critic_loss": 777.548828125, "actor_loss": -1564.665283203125, "actor_target_entropy": -3.0, "actor_entropy": 2.3218023777008057, "alpha_loss": -0.017434485256671906, "alpha_value": 0.49039341054470176, "duration": 1.7015845775604248, "info_normalized_performance_mean": 0.6214932203292847, "info_normalized_performance_final": 0.7388357520103455, "info_performance_mean": 0.6214932203292847, "info_performance_final": 0.7388357520103455, "step": 1823000}
{"episode_reward": 1242.9864433811815, "episode": 18231.0, "batch_reward": 8.026803016662598, "critic_loss": 1992.36181640625, "actor_loss": -1486.391845703125, "actor_target_entropy": -3.0, "actor_entropy": 1.5447890758514404, "alpha_loss": -0.2026951164007187, "alpha_value": 0.49653697568545113, "duration": 1.4912986755371094, "info_normalized_performance_mean": 0.2279750108718872, "info_normalized_performance_final": 0.24375000596046448, "info_performance_mean": 0.2279750108718872, "info_performance_final": 0.24375000596046448, "step": 1823500}
{"episode_reward": 455.95, "episode": 18236.0, "batch_reward": 9.009355545043945, "critic_loss": 943.6098022460938, "actor_loss": -1503.2305908203125, "actor_target_entropy": -3.0, "actor_entropy": 2.281357526779175, "alpha_loss": -0.05479384586215019, "alpha_value": 0.5006809468768881, "duration": 1.4633991718292236, "info_normalized_performance_mean": 0.4450238049030304, "info_normalized_performance_final": 0.5767857432365417, "info_performance_mean": 0.4450238049030304, "info_performance_final": 0.5767857432365417, "step": 1824000}
{"episode_reward": 890.0476190476206, "episode": 18241.0, "batch_reward": 8.795692443847656, "critic_loss": 561.89892578125, "actor_loss": -1477.165771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.9011162519454956, "alpha_loss": -0.045311376452445984, "alpha_value": 0.5092043734711433, "duration": 1.5050859451293945, "info_normalized_performance_mean": 0.6881824731826782, "info_normalized_performance_final": 0.7799744606018066, "info_performance_mean": 0.6881824731826782, "info_performance_final": 0.7799744606018066, "step": 1824500}
{"episode_reward": 1376.3647959183645, "episode": 18246.0, "batch_reward": 9.421327590942383, "critic_loss": 1009.8564453125, "actor_loss": -1548.6630859375, "actor_target_entropy": -3.0, "actor_entropy": 1.8099300861358643, "alpha_loss": -0.007367081940174103, "alpha_value": 0.5143434198438424, "duration": 1.5911941528320312, "info_normalized_performance_mean": 0.5166856646537781, "info_normalized_performance_final": 0.625194787979126, "info_performance_mean": 0.5166856646537781, "info_performance_final": 0.625194787979126, "step": 1825000}
{"episode_reward": 1033.3714285714275, "episode": 18251.0, "batch_reward": 8.142683029174805, "critic_loss": 1430.3648681640625, "actor_loss": -1449.737548828125, "actor_target_entropy": -3.0, "actor_entropy": 2.0317888259887695, "alpha_loss": -0.455917090177536, "alpha_value": 0.5203803766363058, "duration": 1.5775394439697266, "info_normalized_performance_mean": 0.6526923179626465, "info_normalized_performance_final": 0.8004807829856873, "info_performance_mean": 0.6526923179626465, "info_performance_final": 0.8004807829856873, "step": 1825500}
{"episode_reward": 1305.3846153846157, "episode": 18256.0, "batch_reward": 9.209647178649902, "critic_loss": 2895.541259765625, "actor_loss": -1480.57275390625, "actor_target_entropy": -3.0, "actor_entropy": 1.9234974384307861, "alpha_loss": 0.016230523586273193, "alpha_value": 0.5330649309334723, "duration": 1.4699256420135498, "info_normalized_performance_mean": 0.3856562077999115, "info_normalized_performance_final": 0.41718751192092896, "info_performance_mean": 0.3856562077999115, "info_performance_final": 0.41718751192092896, "step": 1826000}
{"episode_reward": 771.3125, "episode": 18261.0, "batch_reward": 8.713613510131836, "critic_loss": 1931.41943359375, "actor_loss": -1496.637451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.8666291236877441, "alpha_loss": -0.2540926933288574, "alpha_value": 0.5384636742762998, "duration": 1.5410940647125244, "info_normalized_performance_mean": 0.5221614241600037, "info_normalized_performance_final": 0.6263020634651184, "info_performance_mean": 0.5221614241600037, "info_performance_final": 0.6263020634651184, "step": 1826500}
{"episode_reward": 1044.3229166666654, "episode": 18266.0, "batch_reward": 9.702398300170898, "critic_loss": 1078.80712890625, "actor_loss": -1581.1014404296875, "actor_target_entropy": -3.0, "actor_entropy": 2.2278666496276855, "alpha_loss": 0.5409145355224609, "alpha_value": 0.5443381926123709, "duration": 1.681248664855957, "info_normalized_performance_mean": 0.784576416015625, "info_normalized_performance_final": 0.9097222089767456, "info_performance_mean": 0.784576416015625, "info_performance_final": 0.9097222089767456, "step": 1827000}
{"episode_reward": 1569.1527777777753, "episode": 18271.0, "batch_reward": 9.76961898803711, "critic_loss": 1013.2865600585938, "actor_loss": -1541.7779541015625, "actor_target_entropy": -3.0, "actor_entropy": 2.4430980682373047, "alpha_loss": 0.022061258554458618, "alpha_value": 0.5485916284702104, "duration": 1.4202525615692139, "info_normalized_performance_mean": 0.3665098547935486, "info_normalized_performance_final": 0.3960784375667572, "info_performance_mean": 0.3665098547935486, "info_performance_final": 0.3960784375667572, "step": 1827500}
{"episode_reward": 733.0196078431363, "episode": 18276.0, "batch_reward": 8.621444702148438, "critic_loss": 5928.294921875, "actor_loss": -1462.0318603515625, "actor_target_entropy": -3.0, "actor_entropy": 2.537432909011841, "alpha_loss": -0.25347864627838135, "alpha_value": 0.5494588626274285, "duration": 1.7355592250823975, "info_normalized_performance_mean": 0.34122809767723083, "info_normalized_performance_final": 0.41722550988197327, "info_performance_mean": 0.34122809767723083, "info_performance_final": 0.41722550988197327, "step": 1828000}
{"episode_reward": 682.456278763971, "episode": 18281.0, "batch_reward": 9.029630661010742, "critic_loss": 1619.605712890625, "actor_loss": -1488.4971923828125, "actor_target_entropy": -3.0, "actor_entropy": 2.2083232402801514, "alpha_loss": 0.38239389657974243, "alpha_value": 0.5511103066136991, "duration": 1.6315875053405762, "info_normalized_performance_mean": 0.7163955569267273, "info_normalized_performance_final": 0.8882275223731995, "info_performance_mean": 0.7163955569267273, "info_performance_final": 0.8882275223731995, "step": 1828500}
{"episode_reward": 1432.7910052910063, "episode": 18286.0, "batch_reward": 9.024456024169922, "critic_loss": 1157.233642578125, "actor_loss": -1516.9544677734375, "actor_target_entropy": -3.0, "actor_entropy": 2.34443998336792, "alpha_loss": 0.49070268869400024, "alpha_value": 0.5494268528332734, "duration": 1.4436101913452148, "info_normalized_performance_mean": 0.41516342759132385, "info_normalized_performance_final": 0.4431372582912445, "info_performance_mean": 0.41516342759132385, "info_performance_final": 0.4431372582912445, "step": 1829000}
{"episode_reward": 830.3267973856217, "episode": 18291.0, "batch_reward": 9.147468566894531, "critic_loss": 1455.6595458984375, "actor_loss": -1510.8118896484375, "actor_target_entropy": -3.0, "actor_entropy": 1.9467045068740845, "alpha_loss": -0.030221421271562576, "alpha_value": 0.5421859741395518, "duration": 1.620955228805542, "info_normalized_performance_mean": 0.48758330941200256, "info_normalized_performance_final": 0.6111904978752136, "info_performance_mean": 0.48758330941200256, "info_performance_final": 0.6111904978752136, "step": 1829500}
{"episode_reward": 975.1666666666666, "episode": 18296.0, "batch_reward": 9.560258865356445, "critic_loss": 358.7884521484375, "actor_loss": -1505.396728515625, "actor_target_entropy": -3.0, "actor_entropy": 2.1208767890930176, "alpha_loss": 0.29817402362823486, "alpha_value": 0.5369028618453884, "step": 1830000}
{"duration": 18.697492122650146, "info_normalized_performance_mean": 0.4814153015613556, "info_normalized_performance_final": 0.6395502686500549, "info_performance_mean": 0.4814153015613556, "info_performance_final": 0.6395502686500549, "step": 1830000}
{"episode_reward": 962.8306878306869, "episode": 18301.0, "batch_reward": 8.782325744628906, "critic_loss": 958.037841796875, "actor_loss": -1474.682373046875, "actor_target_entropy": -3.0, "actor_entropy": 2.2560296058654785, "alpha_loss": 0.23591339588165283, "alpha_value": 0.5318327963310745, "duration": 1.4175341129302979, "info_normalized_performance_mean": 0.626906156539917, "info_normalized_performance_final": 0.6781250238418579, "info_performance_mean": 0.626906156539917, "info_performance_final": 0.6781250238418579, "step": 1830500}
{"episode_reward": 1253.8125, "episode": 18306.0, "batch_reward": 9.147899627685547, "critic_loss": 836.3568725585938, "actor_loss": -1459.110107421875, "actor_target_entropy": -3.0, "actor_entropy": 2.167696475982666, "alpha_loss": 0.07037463039159775, "alpha_value": 0.5214752950867176, "duration": 1.5461726188659668, "info_normalized_performance_mean": 0.3652256727218628, "info_normalized_performance_final": 0.3984375, "info_performance_mean": 0.3652256727218628, "info_performance_final": 0.3984375, "step": 1831000}
{"episode_reward": 730.4513888888889, "episode": 18311.0, "batch_reward": 9.274495124816895, "critic_loss": 4438.0517578125, "actor_loss": -1517.988525390625, "actor_target_entropy": -3.0, "actor_entropy": 1.7243759632110596, "alpha_loss": -0.20646211504936218, "alpha_value": 0.5155649517643622, "duration": 1.6805312633514404, "info_normalized_performance_mean": 0.5978729128837585, "info_normalized_performance_final": 0.7106249928474426, "info_performance_mean": 0.5978729128837585, "info_performance_final": 0.7106249928474426, "step": 1831500}
{"episode_reward": 1195.7458333333334, "episode": 18316.0, "batch_reward": 8.698237419128418, "critic_loss": 842.8056640625, "actor_loss": -1438.9259033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.9031496047973633, "alpha_loss": 0.3081062436103821, "alpha_value": 0.5048646179655347, "duration": 1.4761476516723633, "info_normalized_performance_mean": 0.24551281332969666, "info_normalized_performance_final": 0.3145604431629181, "info_performance_mean": 0.24551281332969666, "info_performance_final": 0.3145604431629181, "step": 1832000}
{"episode_reward": 491.0256410256406, "episode": 18321.0, "batch_reward": 9.024324417114258, "critic_loss": 1806.3548583984375, "actor_loss": -1451.8287353515625, "actor_target_entropy": -3.0, "actor_entropy": 2.1474838256835938, "alpha_loss": 0.24205511808395386, "alpha_value": 0.49725657364977766, "duration": 1.4879977703094482, "info_normalized_performance_mean": 0.47485601902008057, "info_normalized_performance_final": 0.5848214030265808, "info_performance_mean": 0.47485601902008057, "info_performance_final": 0.5848214030265808, "step": 1832500}
{"episode_reward": 949.7123015873013, "episode": 18326.0, "batch_reward": 8.591765403747559, "critic_loss": 1056.510009765625, "actor_loss": -1430.078369140625, "actor_target_entropy": -3.0, "actor_entropy": 1.8918401002883911, "alpha_loss": 0.19561004638671875, "alpha_value": 0.4945472186096846, "duration": 1.6314270496368408, "info_normalized_performance_mean": 0.43658730387687683, "info_normalized_performance_final": 0.5191798806190491, "info_performance_mean": 0.43658730387687683, "info_performance_final": 0.5191798806190491, "step": 1833000}
{"episode_reward": 873.174603174603, "episode": 18331.0, "batch_reward": 9.060961723327637, "critic_loss": 905.5960693359375, "actor_loss": -1457.821044921875, "actor_target_entropy": -3.0, "actor_entropy": 1.9011642932891846, "alpha_loss": 0.06707218289375305, "alpha_value": 0.4938500164942329, "duration": 1.589742660522461, "info_normalized_performance_mean": 0.693450927734375, "info_normalized_performance_final": 0.8460784554481506, "info_performance_mean": 0.693450927734375, "info_performance_final": 0.8460784554481506, "step": 1833500}
{"episode_reward": 1386.901960784316, "episode": 18336.0, "batch_reward": 8.859721183776855, "critic_loss": 638.327392578125, "actor_loss": -1468.75439453125, "actor_target_entropy": -3.0, "actor_entropy": 2.124476671218872, "alpha_loss": -5.650520324707031e-05, "alpha_value": 0.4910525657475316, "duration": 1.4808423519134521, "info_normalized_performance_mean": 0.6279823184013367, "info_normalized_performance_final": 0.6776437759399414, "info_performance_mean": 0.6279823184013367, "info_performance_final": 0.6776437759399414, "step": 1834000}
{"episode_reward": 1255.9647495361778, "episode": 18341.0, "batch_reward": 8.168879508972168, "critic_loss": 864.9940185546875, "actor_loss": -1419.8875732421875, "actor_target_entropy": -3.0, "actor_entropy": 2.1836328506469727, "alpha_loss": -0.18441186845302582, "alpha_value": 0.4874395234634456, "duration": 1.4855008125305176, "info_normalized_performance_mean": 0.35211455821990967, "info_normalized_performance_final": 0.426870733499527, "info_performance_mean": 0.35211455821990967, "info_performance_final": 0.426870733499527, "step": 1834500}
{"episode_reward": 704.22902494331, "episode": 18346.0, "batch_reward": 9.172746658325195, "critic_loss": 752.2745971679688, "actor_loss": -1435.0216064453125, "actor_target_entropy": -3.0, "actor_entropy": 2.103221893310547, "alpha_loss": 0.11979874223470688, "alpha_value": 0.48131334538040565, "duration": 1.4963302612304688, "info_normalized_performance_mean": 0.523850679397583, "info_normalized_performance_final": 0.6410256624221802, "info_performance_mean": 0.523850679397583, "info_performance_final": 0.6410256624221802, "step": 1835000}
{"episode_reward": 1047.7014652014648, "episode": 18351.0, "batch_reward": 9.35564136505127, "critic_loss": 1480.53466796875, "actor_loss": -1441.31201171875, "actor_target_entropy": -3.0, "actor_entropy": 2.1659438610076904, "alpha_loss": 0.42878660559654236, "alpha_value": 0.47233313731786164, "duration": 1.580385446548462, "info_normalized_performance_mean": 0.3152674734592438, "info_normalized_performance_final": 0.390500009059906, "info_performance_mean": 0.3152674734592438, "info_performance_final": 0.390500009059906, "step": 1835500}
{"episode_reward": 630.5349999999995, "episode": 18356.0, "batch_reward": 8.942415237426758, "critic_loss": 1067.981201171875, "actor_loss": -1459.02783203125, "actor_target_entropy": -3.0, "actor_entropy": 2.3624982833862305, "alpha_loss": 0.23000721633434296, "alpha_value": 0.46496155388284544, "duration": 1.4745914936065674, "info_normalized_performance_mean": 0.42207032442092896, "info_normalized_performance_final": 0.458984375, "info_performance_mean": 0.42207032442092896, "info_performance_final": 0.458984375, "step": 1836000}
{"episode_reward": 844.140625, "episode": 18361.0, "batch_reward": 8.574811935424805, "critic_loss": 2280.84033203125, "actor_loss": -1409.23876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.7581136226654053, "alpha_loss": -0.0008039772510528564, "alpha_value": 0.46099068348012834, "duration": 1.576784372329712, "info_normalized_performance_mean": 0.4405291676521301, "info_normalized_performance_final": 0.4702380895614624, "info_performance_mean": 0.4405291676521301, "info_performance_final": 0.4702380895614624, "step": 1836500}
{"episode_reward": 881.0582010582024, "episode": 18366.0, "batch_reward": 8.752525329589844, "critic_loss": 806.2539672851562, "actor_loss": -1397.1953125, "actor_target_entropy": -3.0, "actor_entropy": 1.9989122152328491, "alpha_loss": 0.3822334408760071, "alpha_value": 0.4567403224684347, "duration": 1.529653549194336, "info_normalized_performance_mean": 0.7025297284126282, "info_normalized_performance_final": 0.7589285969734192, "info_performance_mean": 0.7025297284126282, "info_performance_final": 0.7589285969734192, "step": 1837000}
{"episode_reward": 1405.059523809522, "episode": 18371.0, "batch_reward": 10.21544075012207, "critic_loss": 727.4098510742188, "actor_loss": -1473.799072265625, "actor_target_entropy": -3.0, "actor_entropy": 2.049586296081543, "alpha_loss": 0.264308363199234, "alpha_value": 0.45026242259222476, "duration": 1.5522797107696533, "info_normalized_performance_mean": 0.8394445180892944, "info_normalized_performance_final": 0.8975694179534912, "info_performance_mean": 0.8394445180892944, "info_performance_final": 0.8975694179534912, "step": 1837500}
{"episode_reward": 1678.8888888888907, "episode": 18376.0, "batch_reward": 8.765466690063477, "critic_loss": 1366.014404296875, "actor_loss": -1406.872802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.8087029457092285, "alpha_loss": -0.09732308238744736, "alpha_value": 0.44753318721783614, "duration": 1.5015308856964111, "info_normalized_performance_mean": 0.427034467458725, "info_normalized_performance_final": 0.53125, "info_performance_mean": 0.427034467458725, "info_performance_final": 0.53125, "step": 1838000}
{"episode_reward": 854.0688775510203, "episode": 18381.0, "batch_reward": 8.872407913208008, "critic_loss": 509.5755615234375, "actor_loss": -1413.056396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.6260172128677368, "alpha_loss": 0.05704464390873909, "alpha_value": 0.4492130217560477, "duration": 1.606391429901123, "info_normalized_performance_mean": 0.2362135648727417, "info_normalized_performance_final": 0.29469335079193115, "info_performance_mean": 0.2362135648727417, "info_performance_final": 0.29469335079193115, "step": 1838500}
{"episode_reward": 472.427142235755, "episode": 18386.0, "batch_reward": 9.313689231872559, "critic_loss": 1254.0321044921875, "actor_loss": -1445.9537353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.9643211364746094, "alpha_loss": -0.013256743550300598, "alpha_value": 0.4477519215129692, "duration": 1.8013241291046143, "info_normalized_performance_mean": 0.31684115529060364, "info_normalized_performance_final": 0.3799499273300171, "info_performance_mean": 0.31684115529060364, "info_performance_final": 0.3799499273300171, "step": 1839000}
{"episode_reward": 633.6822940373246, "episode": 18391.0, "batch_reward": 10.246410369873047, "critic_loss": 1059.04248046875, "actor_loss": -1496.447998046875, "actor_target_entropy": -3.0, "actor_entropy": 2.1181623935699463, "alpha_loss": 0.006059102714061737, "alpha_value": 0.4459224821049845, "duration": 1.483851671218872, "info_normalized_performance_mean": 0.3649148643016815, "info_normalized_performance_final": 0.39346590638160706, "info_performance_mean": 0.3649148643016815, "info_performance_final": 0.39346590638160706, "step": 1839500}
{"episode_reward": 729.8295454545444, "episode": 18396.0, "batch_reward": 9.420278549194336, "critic_loss": 1840.502197265625, "actor_loss": -1442.849853515625, "actor_target_entropy": -3.0, "actor_entropy": 2.0915722846984863, "alpha_loss": 0.15189224481582642, "alpha_value": 0.4399036031612551, "step": 1840000}
{"duration": 19.30724287033081, "info_normalized_performance_mean": 0.8319198489189148, "info_normalized_performance_final": 0.9241071343421936, "info_performance_mean": 0.8319198489189148, "info_performance_final": 0.9241071343421936, "step": 1840000}
{"episode_reward": 1663.8392857142874, "episode": 18401.0, "batch_reward": 9.028818130493164, "critic_loss": 570.15869140625, "actor_loss": -1405.25, "actor_target_entropy": -3.0, "actor_entropy": 1.9308311939239502, "alpha_loss": 0.06279617547988892, "alpha_value": 0.43249042496067464, "duration": 1.47239351272583, "info_normalized_performance_mean": 0.4581911563873291, "info_normalized_performance_final": 0.489705890417099, "info_performance_mean": 0.4581911563873291, "info_performance_final": 0.489705890417099, "step": 1840500}
{"episode_reward": 916.3823529411751, "episode": 18406.0, "batch_reward": 9.637742042541504, "critic_loss": 765.5851440429688, "actor_loss": -1413.8465576171875, "actor_target_entropy": -3.0, "actor_entropy": 1.85541832447052, "alpha_loss": 0.23117204010486603, "alpha_value": 0.42590213360056606, "duration": 1.4513752460479736, "info_normalized_performance_mean": 0.3877902328968048, "info_normalized_performance_final": 0.4174107015132904, "info_performance_mean": 0.3877902328968048, "info_performance_final": 0.4174107015132904, "step": 1841000}
{"episode_reward": 775.5803571428584, "episode": 18411.0, "batch_reward": 9.330596923828125, "critic_loss": 1098.7890625, "actor_loss": -1401.0982666015625, "actor_target_entropy": -3.0, "actor_entropy": 1.8204096555709839, "alpha_loss": -0.11906230449676514, "alpha_value": 0.41984074905432084, "duration": 1.4728739261627197, "info_normalized_performance_mean": 0.33550265431404114, "info_normalized_performance_final": 0.420634925365448, "info_performance_mean": 0.33550265431404114, "info_performance_final": 0.420634925365448, "step": 1841500}
{"episode_reward": 671.005291005292, "episode": 18416.0, "batch_reward": 9.623414993286133, "critic_loss": 448.5330810546875, "actor_loss": -1403.605712890625, "actor_target_entropy": -3.0, "actor_entropy": 2.1103100776672363, "alpha_loss": 0.28359168767929077, "alpha_value": 0.41551942116585955, "duration": 1.426793098449707, "info_normalized_performance_mean": 0.4650000035762787, "info_normalized_performance_final": 0.5, "info_performance_mean": 0.4650000035762787, "info_performance_final": 0.5, "step": 1842000}
{"episode_reward": 930.0, "episode": 18421.0, "batch_reward": 9.62040901184082, "critic_loss": 834.8894653320312, "actor_loss": -1411.5718994140625, "actor_target_entropy": -3.0, "actor_entropy": 1.7951501607894897, "alpha_loss": 0.11974115669727325, "alpha_value": 0.41331075584168764, "duration": 1.722193717956543, "info_normalized_performance_mean": 0.5351911187171936, "info_normalized_performance_final": 0.6325757503509521, "info_performance_mean": 0.5351911187171936, "info_performance_final": 0.6325757503509521, "step": 1842500}
{"episode_reward": 1070.3822314049582, "episode": 18426.0, "batch_reward": 9.59345817565918, "critic_loss": 1688.196533203125, "actor_loss": -1424.30712890625, "actor_target_entropy": -3.0, "actor_entropy": 1.9019663333892822, "alpha_loss": -0.09721457958221436, "alpha_value": 0.41180584827343814, "duration": 1.7054097652435303, "info_normalized_performance_mean": 0.3822188973426819, "info_normalized_performance_final": 0.45353835821151733, "info_performance_mean": 0.3822188973426819, "info_performance_final": 0.45353835821151733, "step": 1843000}
{"episode_reward": 764.4378306878302, "episode": 18431.0, "batch_reward": 8.75433349609375, "critic_loss": 6200.189453125, "actor_loss": -1379.3751220703125, "actor_target_entropy": -3.0, "actor_entropy": 2.1043801307678223, "alpha_loss": -0.03298724442720413, "alpha_value": 0.40825767722262546, "duration": 1.5480718612670898, "info_normalized_performance_mean": 0.7440499067306519, "info_normalized_performance_final": 0.8100000023841858, "info_performance_mean": 0.7440499067306519, "info_performance_final": 0.8100000023841858, "step": 1843500}
{"episode_reward": 1488.1000000000024, "episode": 18436.0, "batch_reward": 9.743819236755371, "critic_loss": 613.5149536132812, "actor_loss": -1428.343017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.856239914894104, "alpha_loss": 0.08448648452758789, "alpha_value": 0.40413469820953807, "duration": 1.5317456722259521, "info_normalized_performance_mean": 0.6990001201629639, "info_normalized_performance_final": 0.9426470398902893, "info_performance_mean": 0.6990001201629639, "info_performance_final": 0.9426470398902893, "step": 1844000}
{"episode_reward": 1397.9999999999977, "episode": 18441.0, "batch_reward": 8.749734878540039, "critic_loss": 887.9201049804688, "actor_loss": -1319.229736328125, "actor_target_entropy": -3.0, "actor_entropy": 1.8722971677780151, "alpha_loss": 0.34933003783226013, "alpha_value": 0.3967625632407194, "duration": 1.6376280784606934, "info_normalized_performance_mean": 0.5650083422660828, "info_normalized_performance_final": 0.6916666626930237, "info_performance_mean": 0.5650083422660828, "info_performance_final": 0.6916666626930237, "step": 1844500}
{"episode_reward": 1130.0166666666669, "episode": 18446.0, "batch_reward": 9.835115432739258, "critic_loss": 798.5449829101562, "actor_loss": -1426.34765625, "actor_target_entropy": -3.0, "actor_entropy": 1.812814474105835, "alpha_loss": 0.009138032793998718, "alpha_value": 0.3890454456360793, "duration": 1.6486904621124268, "info_normalized_performance_mean": 0.3006439805030823, "info_normalized_performance_final": 0.374601274728775, "info_performance_mean": 0.3006439805030823, "info_performance_final": 0.374601274728775, "step": 1845000}
{"episode_reward": 601.2878787878775, "episode": 18451.0, "batch_reward": 9.209155082702637, "critic_loss": 1623.7138671875, "actor_loss": -1361.131591796875, "actor_target_entropy": -3.0, "actor_entropy": 2.1561412811279297, "alpha_loss": 0.25605034828186035, "alpha_value": 0.38099579259312555, "duration": 1.5276131629943848, "info_normalized_performance_mean": 0.642881453037262, "info_normalized_performance_final": 0.7820616960525513, "info_performance_mean": 0.642881453037262, "info_performance_final": 0.7820616960525513, "step": 1845500}
{"episode_reward": 1285.7629870129856, "episode": 18456.0, "batch_reward": 9.602513313293457, "critic_loss": 1324.03466796875, "actor_loss": -1392.0382080078125, "actor_target_entropy": -3.0, "actor_entropy": 1.623163104057312, "alpha_loss": -0.07426498830318451, "alpha_value": 0.3755502727750147, "duration": 1.4873003959655762, "info_normalized_performance_mean": 0.48520827293395996, "info_normalized_performance_final": 0.6848958134651184, "info_performance_mean": 0.48520827293395996, "info_performance_final": 0.6848958134651184, "step": 1846000}
{"episode_reward": 970.4166666666666, "episode": 18461.0, "batch_reward": 9.003348350524902, "critic_loss": 584.1253662109375, "actor_loss": -1358.1297607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.7033052444458008, "alpha_loss": -0.0828966423869133, "alpha_value": 0.3720992037897797, "duration": 1.6539008617401123, "info_normalized_performance_mean": 0.45101669430732727, "info_normalized_performance_final": 0.5745238065719604, "info_performance_mean": 0.45101669430732727, "info_performance_final": 0.5745238065719604, "step": 1846500}
{"episode_reward": 902.0333333333339, "episode": 18466.0, "batch_reward": 8.887179374694824, "critic_loss": 1049.3931884765625, "actor_loss": -1331.5792236328125, "actor_target_entropy": -3.0, "actor_entropy": 1.9389653205871582, "alpha_loss": -0.14482805132865906, "alpha_value": 0.3701385555709573, "duration": 1.6003081798553467, "info_normalized_performance_mean": 0.6093153357505798, "info_normalized_performance_final": 0.64682537317276, "info_performance_mean": 0.6093153357505798, "info_performance_final": 0.64682537317276, "step": 1847000}
{"episode_reward": 1218.6309523809534, "episode": 18471.0, "batch_reward": 9.481239318847656, "critic_loss": 1003.1322631835938, "actor_loss": -1405.7310791015625, "actor_target_entropy": -3.0, "actor_entropy": 1.6244029998779297, "alpha_loss": 0.005098909139633179, "alpha_value": 0.36856604681013133, "duration": 1.7433431148529053, "info_normalized_performance_mean": 0.3909600079059601, "info_normalized_performance_final": 0.48382171988487244, "info_performance_mean": 0.3909600079059601, "info_performance_final": 0.48382171988487244, "step": 1847500}
{"episode_reward": 781.9200244200252, "episode": 18476.0, "batch_reward": 8.25498104095459, "critic_loss": 938.9763793945312, "actor_loss": -1334.298583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.5861022472381592, "alpha_loss": -0.188859760761261, "alpha_value": 0.36596136139199686, "duration": 1.5927667617797852, "info_normalized_performance_mean": 0.5357638597488403, "info_normalized_performance_final": 0.5694444179534912, "info_performance_mean": 0.5357638597488403, "info_performance_final": 0.5694444179534912, "step": 1848000}
{"episode_reward": 1071.5277777777794, "episode": 18481.0, "batch_reward": 9.148262023925781, "critic_loss": 1969.957763671875, "actor_loss": -1365.6220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.5382676124572754, "alpha_loss": 0.14682671427726746, "alpha_value": 0.36429730964496604, "duration": 1.5673363208770752, "info_normalized_performance_mean": 0.6129297018051147, "info_normalized_performance_final": 0.752734363079071, "info_performance_mean": 0.6129297018051147, "info_performance_final": 0.752734363079071, "step": 1848500}
{"episode_reward": 1225.859375, "episode": 18486.0, "batch_reward": 9.066951751708984, "critic_loss": 1535.77587890625, "actor_loss": -1371.40478515625, "actor_target_entropy": -3.0, "actor_entropy": 1.8625584840774536, "alpha_loss": 0.08496913313865662, "alpha_value": 0.3623329309885418, "duration": 1.5467324256896973, "info_normalized_performance_mean": 0.45486393570899963, "info_normalized_performance_final": 0.5204081535339355, "info_performance_mean": 0.45486393570899963, "info_performance_final": 0.5204081535339355, "step": 1849000}
{"episode_reward": 909.7278911564638, "episode": 18491.0, "batch_reward": 9.310234069824219, "critic_loss": 2757.32470703125, "actor_loss": -1351.279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.6882660388946533, "alpha_loss": 0.035150058567523956, "alpha_value": 0.35960505572328716, "duration": 1.486241102218628, "info_normalized_performance_mean": 0.7057271003723145, "info_normalized_performance_final": 0.8405612111091614, "info_performance_mean": 0.7057271003723145, "info_performance_final": 0.8405612111091614, "step": 1849500}
{"episode_reward": 1411.454081632653, "episode": 18496.0, "batch_reward": 8.080652236938477, "critic_loss": 1780.34814453125, "actor_loss": -1312.9573974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.395259976387024, "alpha_loss": -0.18690864741802216, "alpha_value": 0.357088212828798, "step": 1850000}
{"duration": 19.430940866470337, "info_normalized_performance_mean": 0.894014298915863, "info_normalized_performance_final": 0.9627403616905212, "info_performance_mean": 0.894014298915863, "info_performance_final": 0.9627403616905212, "step": 1850000}
{"episode_reward": 1788.0288461538444, "episode": 18501.0, "batch_reward": 10.23637866973877, "critic_loss": 792.3331909179688, "actor_loss": -1397.252685546875, "actor_target_entropy": -3.0, "actor_entropy": 1.7671738862991333, "alpha_loss": -0.06045324355363846, "alpha_value": 0.35815661297963897, "duration": 1.5256824493408203, "info_normalized_performance_mean": 0.5211370587348938, "info_normalized_performance_final": 0.6358506679534912, "info_performance_mean": 0.5211370587348938, "info_performance_final": 0.6358506679534912, "step": 1850500}
{"episode_reward": 1042.2743055555568, "episode": 18506.0, "batch_reward": 8.56213092803955, "critic_loss": 754.11572265625, "actor_loss": -1310.1671142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.319921851158142, "alpha_loss": 0.026294570416212082, "alpha_value": 0.3553829569721289, "duration": 1.4639885425567627, "info_normalized_performance_mean": 0.6401302218437195, "info_normalized_performance_final": 0.7265625, "info_performance_mean": 0.6401302218437195, "info_performance_final": 0.7265625, "step": 1851000}
{"episode_reward": 1280.2604166666665, "episode": 18511.0, "batch_reward": 8.927811622619629, "critic_loss": 896.59912109375, "actor_loss": -1334.420166015625, "actor_target_entropy": -3.0, "actor_entropy": 1.749833345413208, "alpha_loss": 0.0878724679350853, "alpha_value": 0.3555704262721251, "duration": 1.6353142261505127, "info_normalized_performance_mean": 0.5776178240776062, "info_normalized_performance_final": 0.7051066160202026, "info_performance_mean": 0.5776178240776062, "info_performance_final": 0.7051066160202026, "step": 1851500}
{"episode_reward": 1155.2356902356887, "episode": 18516.0, "batch_reward": 8.814107894897461, "critic_loss": 490.32342529296875, "actor_loss": -1370.345458984375, "actor_target_entropy": -3.0, "actor_entropy": 1.409617304801941, "alpha_loss": -0.1761418879032135, "alpha_value": 0.3540948253529769, "duration": 1.452221155166626, "info_normalized_performance_mean": 0.5088617205619812, "info_normalized_performance_final": 0.5892857313156128, "info_performance_mean": 0.5088617205619812, "info_performance_final": 0.5892857313156128, "step": 1852000}
{"episode_reward": 1017.7232142857162, "episode": 18521.0, "batch_reward": 8.99319076538086, "critic_loss": 722.7665405273438, "actor_loss": -1372.697509765625, "actor_target_entropy": -3.0, "actor_entropy": 1.5858073234558105, "alpha_loss": 0.1253458559513092, "alpha_value": 0.3490266712543283, "duration": 1.6280772686004639, "info_normalized_performance_mean": 0.5536804795265198, "info_normalized_performance_final": 0.6722221970558167, "info_performance_mean": 0.5536804795265198, "info_performance_final": 0.6722221970558167, "step": 1852500}
{"episode_reward": 1107.361111111111, "episode": 18526.0, "batch_reward": 9.202659606933594, "critic_loss": 1907.751953125, "actor_loss": -1324.274169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3968700170516968, "alpha_loss": -0.04523596540093422, "alpha_value": 0.34600169513104156, "duration": 1.5362741947174072, "info_normalized_performance_mean": 0.5271791219711304, "info_normalized_performance_final": 0.6860215067863464, "info_performance_mean": 0.5271791219711304, "info_performance_final": 0.6860215067863464, "step": 1853000}
{"episode_reward": 1054.3584229390692, "episode": 18531.0, "batch_reward": 8.697271347045898, "critic_loss": 1552.5247802734375, "actor_loss": -1319.371826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.600583553314209, "alpha_loss": 0.12645487487316132, "alpha_value": 0.3423296413534941, "duration": 1.6562392711639404, "info_normalized_performance_mean": 0.009093406610190868, "info_normalized_performance_final": 0.013278388418257236, "info_performance_mean": 0.009093406610190868, "info_performance_final": 0.013278388418257236, "step": 1853500}
{"episode_reward": 18.186813186813218, "episode": 18536.0, "batch_reward": 8.971040725708008, "critic_loss": 1190.201171875, "actor_loss": -1352.4278564453125, "actor_target_entropy": -3.0, "actor_entropy": 1.3038843870162964, "alpha_loss": 0.09235872328281403, "alpha_value": 0.33761852852462165, "duration": 1.5042729377746582, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1854000}
{"episode_reward": 0.0, "episode": 18541.0, "batch_reward": 8.702667236328125, "critic_loss": 757.7741088867188, "actor_loss": -1339.936767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.3275070190429688, "alpha_loss": -0.03237654268741608, "alpha_value": 0.3343910872027467, "duration": 1.4930484294891357, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1854500}
{"episode_reward": 0.0, "episode": 18546.0, "batch_reward": 10.13211441040039, "critic_loss": 1544.80126953125, "actor_loss": -1395.5751953125, "actor_target_entropy": -3.0, "actor_entropy": 1.7886966466903687, "alpha_loss": 0.20292434096336365, "alpha_value": 0.3331974524715571, "duration": 1.5333542823791504, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1855000}
{"episode_reward": 0.0, "episode": 18551.0, "batch_reward": 8.40477180480957, "critic_loss": 586.2579956054688, "actor_loss": -1308.987548828125, "actor_target_entropy": -3.0, "actor_entropy": 1.398643970489502, "alpha_loss": -0.21392875909805298, "alpha_value": 0.33075908875997956, "duration": 1.5404675006866455, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1855500}
{"episode_reward": 0.0, "episode": 18556.0, "batch_reward": 8.90201187133789, "critic_loss": 784.9173583984375, "actor_loss": -1335.408203125, "actor_target_entropy": -3.0, "actor_entropy": 1.482142448425293, "alpha_loss": -0.04990183934569359, "alpha_value": 0.3302850434301944, "duration": 1.574307918548584, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1856000}
{"episode_reward": 0.0, "episode": 18561.0, "batch_reward": 9.023399353027344, "critic_loss": 1455.847412109375, "actor_loss": -1342.172119140625, "actor_target_entropy": -3.0, "actor_entropy": 1.160530924797058, "alpha_loss": 0.01820085197687149, "alpha_value": 0.32803878016614413, "duration": 1.6299762725830078, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1856500}
{"episode_reward": 0.0, "episode": 18566.0, "batch_reward": 7.784357070922852, "critic_loss": 633.57568359375, "actor_loss": -1387.9974365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2719886302947998, "alpha_loss": -0.012619435787200928, "alpha_value": 0.3276625908076608, "duration": 1.5588994026184082, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1857000}
{"episode_reward": 0.0, "episode": 18571.0, "batch_reward": 9.013586044311523, "critic_loss": 1586.8944091796875, "actor_loss": -1368.82373046875, "actor_target_entropy": -3.0, "actor_entropy": 1.5429704189300537, "alpha_loss": 0.07884758710861206, "alpha_value": 0.32849799114205547, "duration": 1.498664140701294, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1857500}
{"episode_reward": 0.0, "episode": 18576.0, "batch_reward": 8.176192283630371, "critic_loss": 804.3275756835938, "actor_loss": -1355.919921875, "actor_target_entropy": -3.0, "actor_entropy": 1.580726981163025, "alpha_loss": -0.1586298942565918, "alpha_value": 0.32806627442561526, "duration": 1.5230116844177246, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1858000}
{"episode_reward": 0.0, "episode": 18581.0, "batch_reward": 8.889404296875, "critic_loss": 1297.89501953125, "actor_loss": -1332.6529541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.4105521440505981, "alpha_loss": 0.12546801567077637, "alpha_value": 0.32759904199736545, "duration": 1.5285139083862305, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1858500}
{"episode_reward": 0.0, "episode": 18586.0, "batch_reward": 8.560054779052734, "critic_loss": 2641.30322265625, "actor_loss": -1326.279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3944169282913208, "alpha_loss": -0.06721514463424683, "alpha_value": 0.3287740124074948, "duration": 1.5509111881256104, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1859000}
{"episode_reward": 0.0, "episode": 18591.0, "batch_reward": 8.666360855102539, "critic_loss": 2242.500732421875, "actor_loss": -1331.265380859375, "actor_target_entropy": -3.0, "actor_entropy": 1.7251538038253784, "alpha_loss": 0.1669032871723175, "alpha_value": 0.32779596999365246, "duration": 1.4721550941467285, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1859500}
{"episode_reward": 0.0, "episode": 18596.0, "batch_reward": 9.066326141357422, "critic_loss": 1556.8707275390625, "actor_loss": -1352.8907470703125, "actor_target_entropy": -3.0, "actor_entropy": 1.935847282409668, "alpha_loss": 0.12033297121524811, "alpha_value": 0.3269804190264963, "step": 1860000}
{"duration": 18.44595980644226, "info_normalized_performance_mean": 0.6926271319389343, "info_normalized_performance_final": 0.7581818103790283, "info_performance_mean": 0.6926271319389343, "info_performance_final": 0.7581818103790283, "step": 1860000}
{"episode_reward": 1385.2545454545464, "episode": 18601.0, "batch_reward": 8.688579559326172, "critic_loss": 1837.76171875, "actor_loss": -1318.931640625, "actor_target_entropy": -3.0, "actor_entropy": 1.4428954124450684, "alpha_loss": -0.08528018742799759, "alpha_value": 0.3245564099355828, "duration": 1.528879165649414, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1860500}
{"episode_reward": 0.0, "episode": 18606.0, "batch_reward": 8.133291244506836, "critic_loss": 576.1849975585938, "actor_loss": -1299.0086669921875, "actor_target_entropy": -3.0, "actor_entropy": 1.1430692672729492, "alpha_loss": -0.17174775898456573, "alpha_value": 0.3242655927385041, "duration": 1.5331411361694336, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1861000}
{"episode_reward": 0.0, "episode": 18611.0, "batch_reward": 8.841767311096191, "critic_loss": 1463.374267578125, "actor_loss": -1317.67333984375, "actor_target_entropy": -3.0, "actor_entropy": 1.4213659763336182, "alpha_loss": 0.04529615864157677, "alpha_value": 0.3210781873357699, "duration": 1.574578046798706, "info_normalized_performance_mean": 0.7981569766998291, "info_normalized_performance_final": 0.8571428656578064, "info_performance_mean": 0.7981569766998291, "info_performance_final": 0.8571428656578064, "step": 1861500}
{"episode_reward": 1596.314285714284, "episode": 18616.0, "batch_reward": 9.875114440917969, "critic_loss": 762.3897705078125, "actor_loss": -1359.727783203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4219894409179688, "alpha_loss": -0.10679817199707031, "alpha_value": 0.3163868255194507, "duration": 1.530670404434204, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1862000}
{"episode_reward": 0.0, "episode": 18621.0, "batch_reward": 9.305912017822266, "critic_loss": 455.7628173828125, "actor_loss": -1314.212646484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1603128910064697, "alpha_loss": 0.05679745227098465, "alpha_value": 0.3142113537104273, "duration": 1.3742690086364746, "info_normalized_performance_mean": 0.20999999344348907, "info_normalized_performance_final": 0.22812500596046448, "info_performance_mean": 0.20999999344348907, "info_performance_final": 0.22812500596046448, "step": 1862500}
{"episode_reward": 420.0, "episode": 18626.0, "batch_reward": 7.411664009094238, "critic_loss": 632.777587890625, "actor_loss": -1258.66796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8951205015182495, "alpha_loss": -0.030324997380375862, "alpha_value": 0.31108041487234306, "duration": 1.5110712051391602, "info_normalized_performance_mean": 0.10417646169662476, "info_normalized_performance_final": 0.11323529481887817, "info_performance_mean": 0.10417646169662476, "info_performance_final": 0.11323529481887817, "step": 1863000}
{"episode_reward": 208.35294117647015, "episode": 18631.0, "batch_reward": 9.019606590270996, "critic_loss": 1256.8472900390625, "actor_loss": -1335.097412109375, "actor_target_entropy": -3.0, "actor_entropy": 0.8161418437957764, "alpha_loss": -0.10250429809093475, "alpha_value": 0.30899436562210775, "duration": 1.4796669483184814, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1863500}
{"episode_reward": 0.0, "episode": 18636.0, "batch_reward": 8.713724136352539, "critic_loss": 912.7975463867188, "actor_loss": -1285.7694091796875, "actor_target_entropy": -3.0, "actor_entropy": 0.8412668704986572, "alpha_loss": -0.1263446807861328, "alpha_value": 0.3095013927690587, "duration": 1.4840490818023682, "info_normalized_performance_mean": 0.2678954601287842, "info_normalized_performance_final": 0.35947713255882263, "info_performance_mean": 0.2678954601287842, "info_performance_final": 0.35947713255882263, "step": 1864000}
{"episode_reward": 535.7908496732031, "episode": 18641.0, "batch_reward": 8.293567657470703, "critic_loss": 925.172119140625, "actor_loss": -1269.16015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1022992134094238, "alpha_loss": 0.04136095941066742, "alpha_value": 0.3098557367396827, "duration": 1.6075677871704102, "info_normalized_performance_mean": 0.3245590627193451, "info_normalized_performance_final": 0.579365074634552, "info_performance_mean": 0.3245590627193451, "info_performance_final": 0.579365074634552, "step": 1864500}
{"episode_reward": 649.1181657848321, "episode": 18646.0, "batch_reward": 8.24155330657959, "critic_loss": 714.3660888671875, "actor_loss": -1291.186279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.1490341424942017, "alpha_loss": -0.11771167814731598, "alpha_value": 0.3073309227786894, "duration": 1.6323583126068115, "info_normalized_performance_mean": 0.5847381353378296, "info_normalized_performance_final": 0.7579365372657776, "info_performance_mean": 0.5847381353378296, "info_performance_final": 0.7579365372657776, "step": 1865000}
{"episode_reward": 1169.476190476189, "episode": 18651.0, "batch_reward": 8.107616424560547, "critic_loss": 674.2584838867188, "actor_loss": -1251.3988037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.204723596572876, "alpha_loss": -0.2944025993347168, "alpha_value": 0.306557272961259, "duration": 1.7387542724609375, "info_normalized_performance_mean": 0.6202686429023743, "info_normalized_performance_final": 0.73037189245224, "info_performance_mean": 0.6202686429023743, "info_performance_final": 0.73037189245224, "step": 1865500}
{"episode_reward": 1240.5371900826447, "episode": 18656.0, "batch_reward": 9.062492370605469, "critic_loss": 707.001708984375, "actor_loss": -1274.598388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.4721183776855469, "alpha_loss": 0.06506340205669403, "alpha_value": 0.3084083913676676, "duration": 1.6172657012939453, "info_normalized_performance_mean": 0.6213529706001282, "info_normalized_performance_final": 0.7411764860153198, "info_performance_mean": 0.6213529706001282, "info_performance_final": 0.7411764860153198, "step": 1866000}
{"episode_reward": 1242.7058823529417, "episode": 18661.0, "batch_reward": 8.203774452209473, "critic_loss": 2752.44921875, "actor_loss": -1233.8436279296875, "actor_target_entropy": -3.0, "actor_entropy": 1.3117377758026123, "alpha_loss": -0.16590307652950287, "alpha_value": 0.31022955520477874, "duration": 1.6462652683258057, "info_normalized_performance_mean": 0.7637103199958801, "info_normalized_performance_final": 0.9193121790885925, "info_performance_mean": 0.7637103199958801, "info_performance_final": 0.9193121790885925, "step": 1866500}
{"episode_reward": 1527.4206349206363, "episode": 18666.0, "batch_reward": 8.793983459472656, "critic_loss": 671.3359375, "actor_loss": -1274.0093994140625, "actor_target_entropy": -3.0, "actor_entropy": 1.3229937553405762, "alpha_loss": -0.03950608894228935, "alpha_value": 0.31109368735352455, "duration": 1.4367024898529053, "info_normalized_performance_mean": 0.28496670722961426, "info_normalized_performance_final": 0.3050000071525574, "info_performance_mean": 0.28496670722961426, "info_performance_final": 0.3050000071525574, "step": 1867000}
{"episode_reward": 569.9333333333343, "episode": 18671.0, "batch_reward": 8.839444160461426, "critic_loss": 2017.021484375, "actor_loss": -1289.059326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8358351588249207, "alpha_loss": -0.20611804723739624, "alpha_value": 0.31465920566855954, "duration": 1.4777629375457764, "info_normalized_performance_mean": 0.6544728875160217, "info_normalized_performance_final": 0.771541953086853, "info_performance_mean": 0.6544728875160217, "info_performance_final": 0.771541953086853, "step": 1867500}
{"episode_reward": 1308.9455782312898, "episode": 18676.0, "batch_reward": 8.988797187805176, "critic_loss": 1265.84228515625, "actor_loss": -1304.4403076171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3127171993255615, "alpha_loss": -0.07428853213787079, "alpha_value": 0.3179370856344817, "duration": 1.7237920761108398, "info_normalized_performance_mean": 0.5813723206520081, "info_normalized_performance_final": 0.6845729947090149, "info_performance_mean": 0.5813723206520081, "info_performance_final": 0.6845729947090149, "step": 1868000}
{"episode_reward": 1162.7444903581277, "episode": 18681.0, "batch_reward": 7.9746575355529785, "critic_loss": 804.9938354492188, "actor_loss": -1234.8045654296875, "actor_target_entropy": -3.0, "actor_entropy": 1.383894443511963, "alpha_loss": -0.11397771537303925, "alpha_value": 0.32087788559672364, "duration": 1.6670184135437012, "info_normalized_performance_mean": 0.6970347762107849, "info_normalized_performance_final": 0.78125, "info_performance_mean": 0.6970347762107849, "info_performance_final": 0.78125, "step": 1868500}
{"episode_reward": 1394.0694444444446, "episode": 18686.0, "batch_reward": 8.208120346069336, "critic_loss": 975.047119140625, "actor_loss": -1250.0517578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2765800952911377, "alpha_loss": 0.11592007428407669, "alpha_value": 0.3222332067376042, "duration": 1.53566312789917, "info_normalized_performance_mean": 0.41050830483436584, "info_normalized_performance_final": 0.5226458311080933, "info_performance_mean": 0.41050830483436584, "info_performance_final": 0.5226458311080933, "step": 1869000}
{"episode_reward": 821.0166177908098, "episode": 18691.0, "batch_reward": 8.491998672485352, "critic_loss": 623.8096313476562, "actor_loss": -1212.003662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3216164112091064, "alpha_loss": -0.08780166506767273, "alpha_value": 0.32634827193460103, "duration": 1.6507012844085693, "info_normalized_performance_mean": 0.5698639154434204, "info_normalized_performance_final": 0.8426870703697205, "info_performance_mean": 0.5698639154434204, "info_performance_final": 0.8426870703697205, "step": 1869500}
{"episode_reward": 1139.7278911564629, "episode": 18696.0, "batch_reward": 8.268917083740234, "critic_loss": 1630.1668701171875, "actor_loss": -1204.0523681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.653602123260498, "alpha_loss": -0.21479174494743347, "alpha_value": 0.33323583974994947, "step": 1870000}
{"duration": 18.477267026901245, "info_normalized_performance_mean": 0.5913437008857727, "info_normalized_performance_final": 0.637499988079071, "info_performance_mean": 0.5913437008857727, "info_performance_final": 0.637499988079071, "step": 1870000}
{"episode_reward": 1182.6875, "episode": 18701.0, "batch_reward": 9.687561988830566, "critic_loss": 580.7750854492188, "actor_loss": -1307.365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.4318740367889404, "alpha_loss": -0.0804649069905281, "alpha_value": 0.34234644806896825, "duration": 1.5055699348449707, "info_normalized_performance_mean": 0.11046703159809113, "info_normalized_performance_final": 0.19093406200408936, "info_performance_mean": 0.11046703159809113, "info_performance_final": 0.19093406200408936, "step": 1870500}
{"episode_reward": 220.93406593406576, "episode": 18706.0, "batch_reward": 7.383324146270752, "critic_loss": 636.2489013671875, "actor_loss": -1168.362060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.3218693733215332, "alpha_loss": 0.012651484459638596, "alpha_value": 0.3459640597302266, "duration": 1.6708533763885498, "info_normalized_performance_mean": 0.4520646333694458, "info_normalized_performance_final": 0.5452083349227905, "info_performance_mean": 0.4520646333694458, "info_performance_final": 0.5452083349227905, "step": 1871000}
{"episode_reward": 904.1291666666672, "episode": 18711.0, "batch_reward": 7.703719139099121, "critic_loss": 431.92169189453125, "actor_loss": -1208.52294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.2487051486968994, "alpha_loss": -0.006973793730139732, "alpha_value": 0.3473931733598299, "duration": 1.5773348808288574, "info_normalized_performance_mean": 0.9053173065185547, "info_normalized_performance_final": 0.97817462682724, "info_performance_mean": 0.9053173065185547, "info_performance_final": 0.97817462682724, "step": 1871500}
{"episode_reward": 1810.6349206349196, "episode": 18716.0, "batch_reward": 9.148801803588867, "critic_loss": 1312.14208984375, "actor_loss": -1218.414794921875, "actor_target_entropy": -3.0, "actor_entropy": 1.4443072080612183, "alpha_loss": 0.05193830281496048, "alpha_value": 0.3512092129763748, "duration": 1.4609789848327637, "info_normalized_performance_mean": 0.1560937464237213, "info_normalized_performance_final": 0.2265625, "info_performance_mean": 0.1560937464237213, "info_performance_final": 0.2265625, "step": 1872000}
{"episode_reward": 312.1875, "episode": 18721.0, "batch_reward": 8.259420394897461, "critic_loss": 2708.908935546875, "actor_loss": -1224.644287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3196417093276978, "alpha_loss": 0.0850459486246109, "alpha_value": 0.35304106875355223, "duration": 1.5628228187561035, "info_normalized_performance_mean": 0.0037896824069321156, "info_normalized_performance_final": 0.0337301604449749, "info_performance_mean": 0.0037896824069321156, "info_performance_final": 0.0337301604449749, "step": 1872500}
{"episode_reward": 7.57936507936508, "episode": 18726.0, "batch_reward": 8.419378280639648, "critic_loss": 1386.678466796875, "actor_loss": -1207.8629150390625, "actor_target_entropy": -3.0, "actor_entropy": 1.4632595777511597, "alpha_loss": 0.16388554871082306, "alpha_value": 0.35198433564488557, "duration": 1.5454905033111572, "info_normalized_performance_mean": 0.767087996006012, "info_normalized_performance_final": 0.8296703100204468, "info_performance_mean": 0.767087996006012, "info_performance_final": 0.8296703100204468, "step": 1873000}
{"episode_reward": 1534.1758241758246, "episode": 18731.0, "batch_reward": 8.750265121459961, "critic_loss": 743.4193115234375, "actor_loss": -1229.3699951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.3876101970672607, "alpha_loss": -0.03275793790817261, "alpha_value": 0.349422462188493, "duration": 1.5057568550109863, "info_normalized_performance_mean": 0.5786507725715637, "info_normalized_performance_final": 0.7125850319862366, "info_performance_mean": 0.5786507725715637, "info_performance_final": 0.7125850319862366, "step": 1873500}
{"episode_reward": 1157.3015873015847, "episode": 18736.0, "batch_reward": 8.629022598266602, "critic_loss": 1054.703125, "actor_loss": -1258.49951171875, "actor_target_entropy": -3.0, "actor_entropy": 1.4358835220336914, "alpha_loss": -0.057726893573999405, "alpha_value": 0.34792756855071666, "duration": 1.5749447345733643, "info_normalized_performance_mean": 0.4520336985588074, "info_normalized_performance_final": 0.488095223903656, "info_performance_mean": 0.4520336985588074, "info_performance_final": 0.488095223903656, "step": 1874000}
{"episode_reward": 904.0674603174624, "episode": 18741.0, "batch_reward": 8.942886352539062, "critic_loss": 706.8511962890625, "actor_loss": -1249.799072265625, "actor_target_entropy": -3.0, "actor_entropy": 1.1939456462860107, "alpha_loss": 0.20980247855186462, "alpha_value": 0.3480522929574495, "duration": 1.4827144145965576, "info_normalized_performance_mean": 0.4227655827999115, "info_normalized_performance_final": 0.5590659379959106, "info_performance_mean": 0.4227655827999115, "info_performance_final": 0.5590659379959106, "step": 1874500}
{"episode_reward": 845.5311355311344, "episode": 18746.0, "batch_reward": 8.718944549560547, "critic_loss": 1438.35400390625, "actor_loss": -1248.53662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.4103918075561523, "alpha_loss": 0.25912874937057495, "alpha_value": 0.34918301405293595, "duration": 1.5498955249786377, "info_normalized_performance_mean": 0.7686523199081421, "info_normalized_performance_final": 0.830078125, "info_performance_mean": 0.7686523199081421, "info_performance_final": 0.830078125, "step": 1875000}
{"episode_reward": 1537.3046875, "episode": 18751.0, "batch_reward": 9.605536460876465, "critic_loss": 1111.277099609375, "actor_loss": -1265.3580322265625, "actor_target_entropy": -3.0, "actor_entropy": 1.7927684783935547, "alpha_loss": 0.23498260974884033, "alpha_value": 0.34811080912759207, "duration": 1.480679988861084, "info_normalized_performance_mean": 0.40442851185798645, "info_normalized_performance_final": 0.5351190567016602, "info_performance_mean": 0.40442851185798645, "info_performance_final": 0.5351190567016602, "step": 1875500}
{"episode_reward": 808.8571428571431, "episode": 18756.0, "batch_reward": 8.251391410827637, "critic_loss": 1359.163330078125, "actor_loss": -1208.98876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.9034730195999146, "alpha_loss": -0.023603349924087524, "alpha_value": 0.35026757997192176, "duration": 1.6680219173431396, "info_normalized_performance_mean": 0.6051786541938782, "info_normalized_performance_final": 0.7314285635948181, "info_performance_mean": 0.6051786541938782, "info_performance_final": 0.7314285635948181, "step": 1876000}
{"episode_reward": 1210.3571428571406, "episode": 18761.0, "batch_reward": 8.24211311340332, "critic_loss": 1757.402587890625, "actor_loss": -1211.878662109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2322279214859009, "alpha_loss": 0.024657651782035828, "alpha_value": 0.34879403617731125, "duration": 1.537729263305664, "info_normalized_performance_mean": 0.6429342031478882, "info_normalized_performance_final": 0.7966721057891846, "info_performance_mean": 0.6429342031478882, "info_performance_final": 0.7966721057891846, "step": 1876500}
{"episode_reward": 1285.868506493506, "episode": 18766.0, "batch_reward": 7.878326416015625, "critic_loss": 723.8040771484375, "actor_loss": -1241.03857421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9520377516746521, "alpha_loss": -0.06105142831802368, "alpha_value": 0.346460040963038, "duration": 1.7569584846496582, "info_normalized_performance_mean": 0.40997254848480225, "info_normalized_performance_final": 0.49969473481178284, "info_performance_mean": 0.40997254848480225, "info_performance_final": 0.49969473481178284, "step": 1877000}
{"episode_reward": 819.9450549450545, "episode": 18771.0, "batch_reward": 8.161598205566406, "critic_loss": 1171.990478515625, "actor_loss": -1236.018310546875, "actor_target_entropy": -3.0, "actor_entropy": 1.3438780307769775, "alpha_loss": -0.1292133629322052, "alpha_value": 0.3453202811625418, "duration": 1.4562067985534668, "info_normalized_performance_mean": 0.4228520095348358, "info_normalized_performance_final": 0.5030612349510193, "info_performance_mean": 0.4228520095348358, "info_performance_final": 0.5030612349510193, "step": 1877500}
{"episode_reward": 845.7040816326521, "episode": 18776.0, "batch_reward": 8.345085144042969, "critic_loss": 1085.7640380859375, "actor_loss": -1218.86376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.311715841293335, "alpha_loss": 0.11902469396591187, "alpha_value": 0.3422776007398352, "duration": 1.5398647785186768, "info_normalized_performance_mean": 0.5361002087593079, "info_normalized_performance_final": 0.6272786259651184, "info_performance_mean": 0.5361002087593079, "info_performance_final": 0.6272786259651184, "step": 1878000}
{"episode_reward": 1072.2005208333323, "episode": 18781.0, "batch_reward": 8.578889846801758, "critic_loss": 1051.76953125, "actor_loss": -1256.540283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.1488282680511475, "alpha_loss": 0.08824540674686432, "alpha_value": 0.3400708809678046, "duration": 1.4882194995880127, "info_normalized_performance_mean": 0.45507577061653137, "info_normalized_performance_final": 0.5649350881576538, "info_performance_mean": 0.45507577061653137, "info_performance_final": 0.5649350881576538, "step": 1878500}
{"episode_reward": 910.1515151515147, "episode": 18786.0, "batch_reward": 8.33382797241211, "critic_loss": 878.376708984375, "actor_loss": -1208.833740234375, "actor_target_entropy": -3.0, "actor_entropy": 1.5001145601272583, "alpha_loss": -0.21833057701587677, "alpha_value": 0.3413452213161206, "duration": 1.4368033409118652, "info_normalized_performance_mean": 0.47010719776153564, "info_normalized_performance_final": 0.5464285612106323, "info_performance_mean": 0.47010719776153564, "info_performance_final": 0.5464285612106323, "step": 1879000}
{"episode_reward": 940.2142857142866, "episode": 18791.0, "batch_reward": 9.299686431884766, "critic_loss": 1384.91748046875, "actor_loss": -1271.595703125, "actor_target_entropy": -3.0, "actor_entropy": 1.4599533081054688, "alpha_loss": 0.11506025493144989, "alpha_value": 0.34158830066896695, "duration": 1.5387964248657227, "info_normalized_performance_mean": 0.5965590476989746, "info_normalized_performance_final": 0.7379807829856873, "info_performance_mean": 0.5965590476989746, "info_performance_final": 0.7379807829856873, "step": 1879500}
{"episode_reward": 1193.118131868132, "episode": 18796.0, "batch_reward": 7.812035083770752, "critic_loss": 1203.3583984375, "actor_loss": -1207.3431396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1147631406784058, "alpha_loss": -0.1629418432712555, "alpha_value": 0.33980284321091586, "step": 1880000}
{"duration": 19.425071239471436, "info_normalized_performance_mean": 0.717750072479248, "info_normalized_performance_final": 0.7749999761581421, "info_performance_mean": 0.717750072479248, "info_performance_final": 0.7749999761581421, "step": 1880000}
{"episode_reward": 1435.5, "episode": 18801.0, "batch_reward": 8.650941848754883, "critic_loss": 662.4462280273438, "actor_loss": -1226.4849853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.3133896589279175, "alpha_loss": 0.055351343005895615, "alpha_value": 0.3385201222379191, "duration": 1.6036155223846436, "info_normalized_performance_mean": 0.8432286977767944, "info_normalized_performance_final": 0.8985714316368103, "info_performance_mean": 0.8432286977767944, "info_performance_final": 0.8985714316368103, "step": 1880500}
{"episode_reward": 1686.4571428571405, "episode": 18806.0, "batch_reward": 7.932168960571289, "critic_loss": 2298.268798828125, "actor_loss": -1195.6455078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2121944427490234, "alpha_loss": 0.004539325833320618, "alpha_value": 0.3390880755817151, "duration": 1.5207133293151855, "info_normalized_performance_mean": 0.48240411281585693, "info_normalized_performance_final": 0.5717329382896423, "info_performance_mean": 0.48240411281585693, "info_performance_final": 0.5717329382896423, "step": 1881000}
{"episode_reward": 964.8082386363644, "episode": 18811.0, "batch_reward": 8.356646537780762, "critic_loss": 1086.03662109375, "actor_loss": -1229.554443359375, "actor_target_entropy": -3.0, "actor_entropy": 1.5586302280426025, "alpha_loss": 0.2740631103515625, "alpha_value": 0.33742867192429843, "duration": 1.6414494514465332, "info_normalized_performance_mean": 0.5850540399551392, "info_normalized_performance_final": 0.7085905075073242, "info_performance_mean": 0.5850540399551392, "info_performance_final": 0.7085905075073242, "step": 1881500}
{"episode_reward": 1170.1080246913575, "episode": 18816.0, "batch_reward": 7.773141860961914, "critic_loss": 716.0130004882812, "actor_loss": -1193.309326171875, "actor_target_entropy": -3.0, "actor_entropy": 1.434969186782837, "alpha_loss": -0.17541833221912384, "alpha_value": 0.3360223286758822, "duration": 1.4622867107391357, "info_normalized_performance_mean": 0.16730771958827972, "info_normalized_performance_final": 0.19963370263576508, "info_performance_mean": 0.16730771958827972, "info_performance_final": 0.19963370263576508, "step": 1882000}
{"episode_reward": 334.6153846153842, "episode": 18821.0, "batch_reward": 9.16740894317627, "critic_loss": 438.7077331542969, "actor_loss": -1290.1080322265625, "actor_target_entropy": -3.0, "actor_entropy": 0.9977763891220093, "alpha_loss": 0.05822628736495972, "alpha_value": 0.3336603688601797, "duration": 1.5378508567810059, "info_normalized_performance_mean": 0.0, "info_normalized_performance_final": 0.0, "info_performance_mean": 0.0, "info_performance_final": 0.0, "step": 1882500}
{"episode_reward": 0.0, "episode": 18826.0, "batch_reward": 8.121810913085938, "critic_loss": 1162.4095458984375, "actor_loss": -1224.811767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1730844974517822, "alpha_loss": -0.09608948975801468, "alpha_value": 0.33296617215423935, "duration": 1.5742852687835693, "info_normalized_performance_mean": 0.4890299141407013, "info_normalized_performance_final": 0.5529100298881531, "info_performance_mean": 0.4890299141407013, "info_performance_final": 0.5529100298881531, "step": 1883000}
{"episode_reward": 978.0599647266293, "episode": 18831.0, "batch_reward": 8.611488342285156, "critic_loss": 994.7196044921875, "actor_loss": -1206.7412109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3805081844329834, "alpha_loss": 0.1635315716266632, "alpha_value": 0.33508224310732987, "duration": 1.5210564136505127, "info_normalized_performance_mean": 0.3480035364627838, "info_normalized_performance_final": 0.457706093788147, "info_performance_mean": 0.3480035364627838, "info_performance_final": 0.457706093788147, "step": 1883500}
{"episode_reward": 696.0071684587824, "episode": 18836.0, "batch_reward": 8.428812980651855, "critic_loss": 604.116455078125, "actor_loss": -1231.8509521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.4093310832977295, "alpha_loss": -0.019100409001111984, "alpha_value": 0.336756304286828, "duration": 1.4925355911254883, "info_normalized_performance_mean": 0.21447500586509705, "info_normalized_performance_final": 0.2541666626930237, "info_performance_mean": 0.21447500586509705, "info_performance_final": 0.2541666626930237, "step": 1884000}
{"episode_reward": 428.94999999999953, "episode": 18841.0, "batch_reward": 7.808319091796875, "critic_loss": 1584.927734375, "actor_loss": -1178.68505859375, "actor_target_entropy": -3.0, "actor_entropy": 1.669657826423645, "alpha_loss": -0.056029312312603, "alpha_value": 0.34311049537588856, "duration": 1.6881532669067383, "info_normalized_performance_mean": 0.6185145378112793, "info_normalized_performance_final": 0.7091666460037231, "info_performance_mean": 0.6185145378112793, "info_performance_final": 0.7091666460037231, "step": 1884500}
{"episode_reward": 1237.0291666666658, "episode": 18846.0, "batch_reward": 9.493406295776367, "critic_loss": 1559.302001953125, "actor_loss": -1265.2099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.4122166633605957, "alpha_loss": -0.039416536688804626, "alpha_value": 0.34828140099182897, "duration": 1.4801371097564697, "info_normalized_performance_mean": 0.24634476006031036, "info_normalized_performance_final": 0.2695707082748413, "info_performance_mean": 0.24634476006031036, "info_performance_final": 0.2695707082748413, "step": 1885000}
{"episode_reward": 492.6893939393943, "episode": 18851.0, "batch_reward": 7.796756744384766, "critic_loss": 752.4819946289062, "actor_loss": -1181.26611328125, "actor_target_entropy": -3.0, "actor_entropy": 1.0237681865692139, "alpha_loss": -0.1416100263595581, "alpha_value": 0.3508625495569504, "duration": 1.7490742206573486, "info_normalized_performance_mean": 0.4736233651638031, "info_normalized_performance_final": 0.5906593203544617, "info_performance_mean": 0.4736233651638031, "info_performance_final": 0.5906593203544617, "step": 1885500}
{"episode_reward": 947.2466422466413, "episode": 18856.0, "batch_reward": 8.174495697021484, "critic_loss": 783.0846557617188, "actor_loss": -1161.9197998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.4427694082260132, "alpha_loss": 0.05135120451450348, "alpha_value": 0.3557408755280061, "duration": 1.5079312324523926, "info_normalized_performance_mean": 0.7849687337875366, "info_normalized_performance_final": 0.9375, "info_performance_mean": 0.7849687337875366, "info_performance_final": 0.9375, "step": 1886000}
{"episode_reward": 1569.9375, "episode": 18861.0, "batch_reward": 8.748432159423828, "critic_loss": 1241.7454833984375, "actor_loss": -1279.828857421875, "actor_target_entropy": -3.0, "actor_entropy": 1.0657682418823242, "alpha_loss": -0.20826423168182373, "alpha_value": 0.3609567524175507, "duration": 1.5479736328125, "info_normalized_performance_mean": 0.3018939197063446, "info_normalized_performance_final": 0.39590346813201904, "info_performance_mean": 0.3018939197063446, "info_performance_final": 0.39590346813201904, "step": 1886500}
{"episode_reward": 603.7878787878788, "episode": 18866.0, "batch_reward": 8.208131790161133, "critic_loss": 1076.339599609375, "actor_loss": -1216.30419921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3054687976837158, "alpha_loss": -0.10456305742263794, "alpha_value": 0.3681745925175107, "duration": 1.4974846839904785, "info_normalized_performance_mean": 0.06312217563390732, "info_normalized_performance_final": 0.06787330657243729, "info_performance_mean": 0.06312217563390732, "info_performance_final": 0.06787330657243729, "step": 1887000}
{"episode_reward": 126.24434389140254, "episode": 18871.0, "batch_reward": 8.62740707397461, "critic_loss": 489.7804870605469, "actor_loss": -1247.805908203125, "actor_target_entropy": -3.0, "actor_entropy": 1.2139661312103271, "alpha_loss": -0.10987529158592224, "alpha_value": 0.3711571213865792, "duration": 1.645474910736084, "info_normalized_performance_mean": 0.5648849606513977, "info_normalized_performance_final": 0.6913580298423767, "info_performance_mean": 0.5648849606513977, "info_performance_final": 0.6913580298423767, "step": 1887500}
{"episode_reward": 1129.7699214365878, "episode": 18876.0, "batch_reward": 8.819307327270508, "critic_loss": 1862.1265869140625, "actor_loss": -1281.18017578125, "actor_target_entropy": -3.0, "actor_entropy": 1.5077506303787231, "alpha_loss": -0.06636516004800797, "alpha_value": 0.3723356530921377, "duration": 1.6472792625427246, "info_normalized_performance_mean": 0.5230966806411743, "info_normalized_performance_final": 0.6990740895271301, "info_performance_mean": 0.5230966806411743, "info_performance_final": 0.6990740895271301, "step": 1888000}
{"episode_reward": 1046.193415637859, "episode": 18881.0, "batch_reward": 7.92022180557251, "critic_loss": 326.3985900878906, "actor_loss": -1223.598388671875, "actor_target_entropy": -3.0, "actor_entropy": 1.2216683626174927, "alpha_loss": 0.0813717246055603, "alpha_value": 0.3760764950629803, "duration": 1.674781322479248, "info_normalized_performance_mean": 0.3872727155685425, "info_normalized_performance_final": 0.49804261326789856, "info_performance_mean": 0.3872727155685425, "info_performance_final": 0.49804261326789856, "step": 1888500}
{"episode_reward": 774.545454545454, "episode": 18886.0, "batch_reward": 9.145953178405762, "critic_loss": 2374.9775390625, "actor_loss": -1302.88037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.536435604095459, "alpha_loss": -0.23109138011932373, "alpha_value": 0.3771663049410569, "duration": 1.5024020671844482, "info_normalized_performance_mean": 0.5248922109603882, "info_normalized_performance_final": 0.5600907206535339, "info_performance_mean": 0.5248922109603882, "info_performance_final": 0.5600907206535339, "step": 1889000}
{"episode_reward": 1049.7845804988644, "episode": 18891.0, "batch_reward": 8.683494567871094, "critic_loss": 253.94761657714844, "actor_loss": -1244.697998046875, "actor_target_entropy": -3.0, "actor_entropy": 1.510088324546814, "alpha_loss": 0.029901845380663872, "alpha_value": 0.37982275387274095, "duration": 1.4226727485656738, "info_normalized_performance_mean": 0.385892778635025, "info_normalized_performance_final": 0.5785714387893677, "info_performance_mean": 0.385892778635025, "info_performance_final": 0.5785714387893677, "step": 1889500}
{"episode_reward": 771.7857142857138, "episode": 18896.0, "batch_reward": 9.38037395477295, "critic_loss": 2049.4208984375, "actor_loss": -1294.0966796875, "actor_target_entropy": -3.0, "actor_entropy": 1.4861781597137451, "alpha_loss": -0.00706598162651062, "alpha_value": 0.3799098271679224, "step": 1890000}
{"duration": 18.790424346923828, "info_normalized_performance_mean": 0.5925452709197998, "info_normalized_performance_final": 0.6946818828582764, "info_performance_mean": 0.5925452709197998, "info_performance_final": 0.6946818828582764, "step": 1890000}
{"episode_reward": 1185.0902184235526, "episode": 18901.0, "batch_reward": 8.301565170288086, "critic_loss": 876.0810546875, "actor_loss": -1236.8336181640625, "actor_target_entropy": -3.0, "actor_entropy": 1.236206293106079, "alpha_loss": 0.041121818125247955, "alpha_value": 0.3808697499670126, "duration": 1.5015745162963867, "info_normalized_performance_mean": 0.3709411323070526, "info_normalized_performance_final": 0.5270588397979736, "info_performance_mean": 0.3709411323070526, "info_performance_final": 0.5270588397979736, "step": 1890500}
{"episode_reward": 741.8823529411758, "episode": 18906.0, "batch_reward": 8.203892707824707, "critic_loss": 871.0965576171875, "actor_loss": -1233.037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.4932219982147217, "alpha_loss": 0.16802357137203217, "alpha_value": 0.38058640915922654, "duration": 1.4843125343322754, "info_normalized_performance_mean": 0.20591120421886444, "info_normalized_performance_final": 0.24771061539649963, "info_performance_mean": 0.20591120421886444, "info_performance_final": 0.24771061539649963, "step": 1891000}
{"episode_reward": 411.8223443223441, "episode": 18911.0, "batch_reward": 8.276956558227539, "critic_loss": 932.169677734375, "actor_loss": -1226.216552734375, "actor_target_entropy": -3.0, "actor_entropy": 1.5376756191253662, "alpha_loss": -0.08966934680938721, "alpha_value": 0.37901488603094835, "duration": 1.5612645149230957, "info_normalized_performance_mean": 0.5031455159187317, "info_normalized_performance_final": 0.6325549483299255, "info_performance_mean": 0.5031455159187317, "info_performance_final": 0.6325549483299255, "step": 1891500}
{"episode_reward": 1006.2912087912075, "episode": 18916.0, "batch_reward": 7.828998565673828, "critic_loss": 481.0411682128906, "actor_loss": -1219.398681640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1952332258224487, "alpha_loss": -0.0011726468801498413, "alpha_value": 0.3745906361058329, "duration": 1.5970096588134766, "info_normalized_performance_mean": 0.6097561120986938, "info_normalized_performance_final": 0.7219135761260986, "info_performance_mean": 0.6097561120986938, "info_performance_final": 0.7219135761260986, "step": 1892000}
{"episode_reward": 1219.5123456790116, "episode": 18921.0, "batch_reward": 8.613722801208496, "critic_loss": 440.9104309082031, "actor_loss": -1278.1746826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.0686850547790527, "alpha_loss": 0.008230991661548615, "alpha_value": 0.37366397326069256, "duration": 1.5667335987091064, "info_normalized_performance_mean": 0.8158143758773804, "info_normalized_performance_final": 0.8871428370475769, "info_performance_mean": 0.8158143758773804, "info_performance_final": 0.8871428370475769, "step": 1892500}
{"episode_reward": 1631.6285714285746, "episode": 18926.0, "batch_reward": 8.430973052978516, "critic_loss": 1205.66650390625, "actor_loss": -1257.3798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.4586944580078125, "alpha_loss": 0.24155181646347046, "alpha_value": 0.3690452681437686, "duration": 1.4837193489074707, "info_normalized_performance_mean": 0.40911465883255005, "info_normalized_performance_final": 0.6901041865348816, "info_performance_mean": 0.40911465883255005, "info_performance_final": 0.6901041865348816, "step": 1893000}
{"episode_reward": 818.2291666666673, "episode": 18931.0, "batch_reward": 9.282060623168945, "critic_loss": 1289.9891357421875, "actor_loss": -1298.951904296875, "actor_target_entropy": -3.0, "actor_entropy": 1.5111883878707886, "alpha_loss": 0.1316998451948166, "alpha_value": 0.3639170274823603, "duration": 1.4849207401275635, "info_normalized_performance_mean": 0.5549604296684265, "info_normalized_performance_final": 0.60317462682724, "info_performance_mean": 0.5549604296684265, "info_performance_final": 0.60317462682724, "step": 1893500}
{"episode_reward": 1109.9206349206338, "episode": 18936.0, "batch_reward": 9.36502456665039, "critic_loss": 582.7357177734375, "actor_loss": -1289.4169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.733113169670105, "alpha_loss": 0.28819185495376587, "alpha_value": 0.3596381918983782, "duration": 1.4202561378479004, "info_normalized_performance_mean": 0.7210204601287842, "info_normalized_performance_final": 0.7780612111091614, "info_performance_mean": 0.7210204601287842, "info_performance_final": 0.7780612111091614, "step": 1894000}
{"episode_reward": 1442.0408163265295, "episode": 18941.0, "batch_reward": 8.653190612792969, "critic_loss": 938.166015625, "actor_loss": -1284.5467529296875, "actor_target_entropy": -3.0, "actor_entropy": 1.196995496749878, "alpha_loss": 0.05502166599035263, "alpha_value": 0.35480267317816205, "duration": 1.6347849369049072, "info_normalized_performance_mean": 0.5106006860733032, "info_normalized_performance_final": 0.6141975522041321, "info_performance_mean": 0.5106006860733032, "info_performance_final": 0.6141975522041321, "step": 1894500}
{"episode_reward": 1021.2013295346626, "episode": 18946.0, "batch_reward": 8.605409622192383, "critic_loss": 1066.384765625, "actor_loss": -1281.097900390625, "actor_target_entropy": -3.0, "actor_entropy": 1.4420640468597412, "alpha_loss": -0.006906680762767792, "alpha_value": 0.34903325146678726, "duration": 1.648573398590088, "info_normalized_performance_mean": 0.7228901386260986, "info_normalized_performance_final": 0.8445767164230347, "info_performance_mean": 0.7228901386260986, "info_performance_final": 0.8445767164230347, "step": 1895000}
{"episode_reward": 1445.7804232804224, "episode": 18951.0, "batch_reward": 7.117941856384277, "critic_loss": 891.147216796875, "actor_loss": -1200.98486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8772848844528198, "alpha_loss": -0.19997775554656982, "alpha_value": 0.34606335976055635, "duration": 1.657454013824463, "info_normalized_performance_mean": 0.8553083539009094, "info_normalized_performance_final": 0.996666669845581, "info_performance_mean": 0.8553083539009094, "info_performance_final": 0.996666669845581, "step": 1895500}
{"episode_reward": 1710.6166666666675, "episode": 18956.0, "batch_reward": 7.630861282348633, "critic_loss": 1073.050537109375, "actor_loss": -1211.9268798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3482637405395508, "alpha_loss": 0.011763326823711395, "alpha_value": 0.3439391050814672, "duration": 1.466529130935669, "info_normalized_performance_mean": 0.2566199004650116, "info_normalized_performance_final": 0.29804420471191406, "info_performance_mean": 0.2566199004650116, "info_performance_final": 0.29804420471191406, "step": 1896000}
{"episode_reward": 513.2397959183678, "episode": 18961.0, "batch_reward": 8.671932220458984, "critic_loss": 767.3536376953125, "actor_loss": -1295.794677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.1343357563018799, "alpha_loss": -0.03473582863807678, "alpha_value": 0.3405371349343175, "duration": 1.572277545928955, "info_normalized_performance_mean": 0.8095165491104126, "info_normalized_performance_final": 0.8766666650772095, "info_performance_mean": 0.8095165491104126, "info_performance_final": 0.8766666650772095, "step": 1896500}
{"episode_reward": 1619.0333333333317, "episode": 18966.0, "batch_reward": 9.531411170959473, "critic_loss": 1920.0201416015625, "actor_loss": -1312.96240234375, "actor_target_entropy": -3.0, "actor_entropy": 1.412402868270874, "alpha_loss": 0.08913175761699677, "alpha_value": 0.3356596926413516, "duration": 1.5244085788726807, "info_normalized_performance_mean": 0.5511335134506226, "info_normalized_performance_final": 0.596666693687439, "info_performance_mean": 0.5511335134506226, "info_performance_final": 0.596666693687439, "step": 1897000}
{"episode_reward": 1102.2666666666648, "episode": 18971.0, "batch_reward": 8.696349143981934, "critic_loss": 653.726806640625, "actor_loss": -1259.293212890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9337942600250244, "alpha_loss": 0.16742177307605743, "alpha_value": 0.3332792870625154, "duration": 1.5484600067138672, "info_normalized_performance_mean": 0.7709243297576904, "info_normalized_performance_final": 0.8907563090324402, "info_performance_mean": 0.7709243297576904, "info_performance_final": 0.8907563090324402, "step": 1897500}
{"episode_reward": 1541.8487394957963, "episode": 18976.0, "batch_reward": 8.176642417907715, "critic_loss": 1139.9393310546875, "actor_loss": -1268.399169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8791300058364868, "alpha_loss": -0.07991942018270493, "alpha_value": 0.3316101693001245, "duration": 1.6521427631378174, "info_normalized_performance_mean": 0.47557663917541504, "info_normalized_performance_final": 0.6361038684844971, "info_performance_mean": 0.47557663917541504, "info_performance_final": 0.6361038684844971, "step": 1898000}
{"episode_reward": 951.1532467532469, "episode": 18981.0, "batch_reward": 8.972299575805664, "critic_loss": 1522.49609375, "actor_loss": -1328.1739501953125, "actor_target_entropy": -3.0, "actor_entropy": 1.245856523513794, "alpha_loss": 0.06966064870357513, "alpha_value": 0.3289552280880978, "duration": 1.4656968116760254, "info_normalized_performance_mean": 0.38753822445869446, "info_normalized_performance_final": 0.4732142984867096, "info_performance_mean": 0.38753822445869446, "info_performance_final": 0.4732142984867096, "step": 1898500}
{"episode_reward": 775.0765306122447, "episode": 18986.0, "batch_reward": 8.520551681518555, "critic_loss": 4803.8681640625, "actor_loss": -1261.459716796875, "actor_target_entropy": -3.0, "actor_entropy": 1.0777676105499268, "alpha_loss": -0.1825866848230362, "alpha_value": 0.32706762646186466, "duration": 1.7823452949523926, "info_normalized_performance_mean": 0.5217093825340271, "info_normalized_performance_final": 0.6918498277664185, "info_performance_mean": 0.5217093825340271, "info_performance_final": 0.6918498277664185, "step": 1899000}
{"episode_reward": 1043.4188034188041, "episode": 18991.0, "batch_reward": 8.26423454284668, "critic_loss": 1110.229736328125, "actor_loss": -1269.687744140625, "actor_target_entropy": -3.0, "actor_entropy": 1.471207857131958, "alpha_loss": 0.11290945112705231, "alpha_value": 0.3255049884965856, "duration": 1.616283655166626, "info_normalized_performance_mean": 0.5673999190330505, "info_normalized_performance_final": 0.7036363482475281, "info_performance_mean": 0.5673999190330505, "info_performance_final": 0.7036363482475281, "step": 1899500}
{"episode_reward": 1134.800000000001, "episode": 18996.0, "batch_reward": 8.155872344970703, "critic_loss": 1599.3359375, "actor_loss": -1297.676025390625, "actor_target_entropy": -3.0, "actor_entropy": 1.1611675024032593, "alpha_loss": 0.008049719035625458, "alpha_value": 0.3218518322820848, "step": 1900000}
{"duration": 19.136741638183594, "info_normalized_performance_mean": 0.6196479201316833, "info_normalized_performance_final": 0.745039701461792, "info_performance_mean": 0.6196479201316833, "info_performance_final": 0.745039701461792, "step": 1900000}
{"episode_reward": 1239.295634920635, "episode": 19001.0, "batch_reward": 8.930377960205078, "critic_loss": 955.5860595703125, "actor_loss": -1284.93359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2949323654174805, "alpha_loss": 0.13862808048725128, "alpha_value": 0.31715170018371625, "duration": 1.5146715641021729, "info_normalized_performance_mean": 0.3606012761592865, "info_normalized_performance_final": 0.4324970245361328, "info_performance_mean": 0.3606012761592865, "info_performance_final": 0.4324970245361328, "step": 1900500}
{"episode_reward": 721.2027080844293, "episode": 19006.0, "batch_reward": 8.070097923278809, "critic_loss": 548.697021484375, "actor_loss": -1271.986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.9933735728263855, "alpha_loss": -0.0663529634475708, "alpha_value": 0.3139023436391778, "duration": 1.6179277896881104, "info_normalized_performance_mean": 0.6011393070220947, "info_normalized_performance_final": 0.701646089553833, "info_performance_mean": 0.6011393070220947, "info_performance_final": 0.701646089553833, "step": 1901000}
{"episode_reward": 1202.2788065843629, "episode": 19011.0, "batch_reward": 8.745184898376465, "critic_loss": 411.35955810546875, "actor_loss": -1326.671142578125, "actor_target_entropy": -3.0, "actor_entropy": 1.1775363683700562, "alpha_loss": -0.03180143982172012, "alpha_value": 0.3131059265160279, "duration": 1.5919091701507568, "info_normalized_performance_mean": 0.7952856421470642, "info_normalized_performance_final": 0.8500000238418579, "info_performance_mean": 0.7952856421470642, "info_performance_final": 0.8500000238418579, "step": 1901500}
{"episode_reward": 1590.5714285714284, "episode": 19016.0, "batch_reward": 8.825860023498535, "critic_loss": 957.9132080078125, "actor_loss": -1280.30712890625, "actor_target_entropy": -3.0, "actor_entropy": 0.9212093949317932, "alpha_loss": 0.10741451382637024, "alpha_value": 0.31245151479734, "duration": 1.5557010173797607, "info_normalized_performance_mean": 0.776655912399292, "info_normalized_performance_final": 0.8474025726318359, "info_performance_mean": 0.776655912399292, "info_performance_final": 0.8474025726318359, "step": 1902000}
{"episode_reward": 1553.3116883116854, "episode": 19021.0, "batch_reward": 8.38532543182373, "critic_loss": 742.500244140625, "actor_loss": -1265.592041015625, "actor_target_entropy": -3.0, "actor_entropy": 1.0341854095458984, "alpha_loss": 0.06436915695667267, "alpha_value": 0.31083092412470786, "duration": 1.7877564430236816, "info_normalized_performance_mean": 0.5077796578407288, "info_normalized_performance_final": 0.6158614158630371, "info_performance_mean": 0.5077796578407288, "info_performance_final": 0.6158614158630371, "step": 1902500}
{"episode_reward": 1015.5594405594397, "episode": 19026.0, "batch_reward": 9.521060943603516, "critic_loss": 1780.35791015625, "actor_loss": -1313.76220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.3127007484436035, "alpha_loss": 0.2191053181886673, "alpha_value": 0.3084997252377672, "duration": 1.5939843654632568, "info_normalized_performance_mean": 0.6667584180831909, "info_normalized_performance_final": 0.7858333587646484, "info_performance_mean": 0.6667584180831909, "info_performance_final": 0.7858333587646484, "step": 1903000}
{"episode_reward": 1333.5166666666687, "episode": 19031.0, "batch_reward": 8.276567459106445, "critic_loss": 717.2802734375, "actor_loss": -1280.5194091796875, "actor_target_entropy": -3.0, "actor_entropy": 1.3239558935165405, "alpha_loss": 0.1713411808013916, "alpha_value": 0.30648260677897204, "duration": 1.4512202739715576, "info_normalized_performance_mean": 0.60631263256073, "info_normalized_performance_final": 0.7582417726516724, "info_performance_mean": 0.60631263256073, "info_performance_final": 0.7582417726516724, "step": 1903500}
{"episode_reward": 1212.625152625154, "episode": 19036.0, "batch_reward": 9.433789253234863, "critic_loss": 709.7188720703125, "actor_loss": -1298.8955078125, "actor_target_entropy": -3.0, "actor_entropy": 1.1966103315353394, "alpha_loss": 0.044218145310878754, "alpha_value": 0.3036750046340459, "duration": 1.4823312759399414, "info_normalized_performance_mean": 0.45808523893356323, "info_normalized_performance_final": 0.5808531641960144, "info_performance_mean": 0.45808523893356323, "info_performance_final": 0.5808531641960144, "step": 1904000}
{"episode_reward": 916.1706349206358, "episode": 19041.0, "batch_reward": 8.81368637084961, "critic_loss": 1581.7469482421875, "actor_loss": -1273.000244140625, "actor_target_entropy": -3.0, "actor_entropy": 1.0925695896148682, "alpha_loss": 0.10504163056612015, "alpha_value": 0.30047360734808365, "duration": 1.4423091411590576, "info_normalized_performance_mean": 0.29875001311302185, "info_normalized_performance_final": 0.3541666567325592, "info_performance_mean": 0.29875001311302185, "info_performance_final": 0.3541666567325592, "step": 1904500}
{"episode_reward": 597.5, "episode": 19046.0, "batch_reward": 8.536785125732422, "critic_loss": 768.9572143554688, "actor_loss": -1260.26025390625, "actor_target_entropy": -3.0, "actor_entropy": 1.138706088066101, "alpha_loss": 0.028090717270970345, "alpha_value": 0.29761951306157536, "duration": 1.6756558418273926, "info_normalized_performance_mean": 0.5946186780929565, "info_normalized_performance_final": 0.7112500071525574, "info_performance_mean": 0.5946186780929565, "info_performance_final": 0.7112500071525574, "step": 1905000}
{"episode_reward": 1189.2374999999986, "episode": 19051.0, "batch_reward": 9.605470657348633, "critic_loss": 586.4205322265625, "actor_loss": -1319.4521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3226981163024902, "alpha_loss": 0.20894280076026917, "alpha_value": 0.29690732947950266, "duration": 1.5061900615692139, "info_normalized_performance_mean": 0.5016865730285645, "info_normalized_performance_final": 0.5416666865348816, "info_performance_mean": 0.5016865730285645, "info_performance_final": 0.5416666865348816, "step": 1905500}
{"episode_reward": 1003.3730158730173, "episode": 19056.0, "batch_reward": 8.467421531677246, "critic_loss": 749.5947875976562, "actor_loss": -1273.117431640625, "actor_target_entropy": -3.0, "actor_entropy": 1.236856460571289, "alpha_loss": 0.03682931512594223, "alpha_value": 0.2967861088266835, "duration": 1.6896047592163086, "info_normalized_performance_mean": 0.5893999338150024, "info_normalized_performance_final": 0.7250000238418579, "info_performance_mean": 0.5893999338150024, "info_performance_final": 0.7250000238418579, "step": 1906000}
{"episode_reward": 1178.8000000000009, "episode": 19061.0, "batch_reward": 8.655691146850586, "critic_loss": 709.2155151367188, "actor_loss": -1291.1162109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1099762916564941, "alpha_loss": -0.10313248634338379, "alpha_value": 0.29664360430061065, "duration": 1.6846897602081299, "info_normalized_performance_mean": 0.48776867985725403, "info_normalized_performance_final": 0.5983036160469055, "info_performance_mean": 0.48776867985725403, "info_performance_final": 0.5983036160469055, "step": 1906500}
{"episode_reward": 975.5371900826434, "episode": 19066.0, "batch_reward": 8.583442687988281, "critic_loss": 1119.4234619140625, "actor_loss": -1271.22021484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0147382020950317, "alpha_loss": 0.08677750080823898, "alpha_value": 0.29729814133227433, "duration": 1.6417782306671143, "info_normalized_performance_mean": 0.49212196469306946, "info_normalized_performance_final": 0.5902777910232544, "info_performance_mean": 0.49212196469306946, "info_performance_final": 0.5902777910232544, "step": 1907000}
{"episode_reward": 984.2438271604949, "episode": 19071.0, "batch_reward": 8.34127426147461, "critic_loss": 680.5137939453125, "actor_loss": -1252.107421875, "actor_target_entropy": -3.0, "actor_entropy": 0.9293326139450073, "alpha_loss": -0.08110658824443817, "alpha_value": 0.2976098705830844, "duration": 1.5161535739898682, "info_normalized_performance_mean": 0.14969782531261444, "info_normalized_performance_final": 0.18681319057941437, "info_performance_mean": 0.14969782531261444, "info_performance_final": 0.18681319057941437, "step": 1907500}
{"episode_reward": 299.39560439560415, "episode": 19076.0, "batch_reward": 8.161738395690918, "critic_loss": 1768.1558837890625, "actor_loss": -1272.033935546875, "actor_target_entropy": -3.0, "actor_entropy": 0.9264626502990723, "alpha_loss": -0.3479388356208801, "alpha_value": 0.2974602989794963, "duration": 1.574523687362671, "info_normalized_performance_mean": 0.4312364161014557, "info_normalized_performance_final": 0.4609090983867645, "info_performance_mean": 0.4312364161014557, "info_performance_final": 0.4609090983867645, "step": 1908000}
{"episode_reward": 862.4727272727291, "episode": 19081.0, "batch_reward": 8.50508975982666, "critic_loss": 7403.982421875, "actor_loss": -1298.766357421875, "actor_target_entropy": -3.0, "actor_entropy": 1.276660442352295, "alpha_loss": -0.006277047097682953, "alpha_value": 0.2982805744181533, "duration": 1.6106374263763428, "info_normalized_performance_mean": 0.7007142901420593, "info_normalized_performance_final": 0.7666666507720947, "info_performance_mean": 0.7007142901420593, "info_performance_final": 0.7666666507720947, "step": 1908500}
{"episode_reward": 1401.4285714285706, "episode": 19086.0, "batch_reward": 9.153552055358887, "critic_loss": 779.1458740234375, "actor_loss": -1294.261474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.0850732326507568, "alpha_loss": 0.0025339722633361816, "alpha_value": 0.29804552227433606, "duration": 1.567885160446167, "info_normalized_performance_mean": 0.6930907368659973, "info_normalized_performance_final": 0.8392857313156128, "info_performance_mean": 0.6930907368659973, "info_performance_final": 0.8392857313156128, "step": 1909000}
{"episode_reward": 1386.181318681318, "episode": 19091.0, "batch_reward": 9.28754711151123, "critic_loss": 2133.2294921875, "actor_loss": -1264.60205078125, "actor_target_entropy": -3.0, "actor_entropy": 1.2410414218902588, "alpha_loss": 0.21224576234817505, "alpha_value": 0.2953609425636866, "duration": 1.6658332347869873, "info_normalized_performance_mean": 0.6385118961334229, "info_normalized_performance_final": 0.8227513432502747, "info_performance_mean": 0.6385118961334229, "info_performance_final": 0.8227513432502747, "step": 1909500}
{"episode_reward": 1277.0238095238087, "episode": 19096.0, "batch_reward": 8.336777687072754, "critic_loss": 1307.905029296875, "actor_loss": -1286.488037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.3728535175323486, "alpha_loss": 0.05695239081978798, "alpha_value": 0.29238314676123267, "step": 1910000}
{"duration": 19.789272785186768, "info_normalized_performance_mean": 0.6126390099525452, "info_normalized_performance_final": 0.653769850730896, "info_performance_mean": 0.6126390099525452, "info_performance_final": 0.653769850730896, "step": 1910000}
{"episode_reward": 1225.2777777777796, "episode": 19101.0, "batch_reward": 8.54156494140625, "critic_loss": 835.3668212890625, "actor_loss": -1291.10400390625, "actor_target_entropy": -3.0, "actor_entropy": 1.057504415512085, "alpha_loss": -0.18203160166740417, "alpha_value": 0.29028989591572785, "duration": 1.8904592990875244, "info_normalized_performance_mean": 0.6449277997016907, "info_normalized_performance_final": 0.7719017267227173, "info_performance_mean": 0.6449277997016907, "info_performance_final": 0.7719017267227173, "step": 1910500}
{"episode_reward": 1289.8557692307693, "episode": 19106.0, "batch_reward": 8.091650009155273, "critic_loss": 2065.657958984375, "actor_loss": -1234.5323486328125, "actor_target_entropy": -3.0, "actor_entropy": 0.8706320524215698, "alpha_loss": -0.04386631399393082, "alpha_value": 0.28842437649561375, "duration": 1.6374664306640625, "info_normalized_performance_mean": 0.5998372435569763, "info_normalized_performance_final": 0.7107182741165161, "info_performance_mean": 0.5998372435569763, "info_performance_final": 0.7107182741165161, "step": 1911000}
{"episode_reward": 1199.6745230078573, "episode": 19111.0, "batch_reward": 9.16891098022461, "critic_loss": 932.926025390625, "actor_loss": -1287.69921875, "actor_target_entropy": -3.0, "actor_entropy": 1.1639059782028198, "alpha_loss": 0.062345847487449646, "alpha_value": 0.2878346157527836, "duration": 1.6032094955444336, "info_normalized_performance_mean": 0.4540625512599945, "info_normalized_performance_final": 0.4869791567325592, "info_performance_mean": 0.4540625512599945, "info_performance_final": 0.4869791567325592, "step": 1911500}
{"episode_reward": 908.1250000000011, "episode": 19116.0, "batch_reward": 8.467425346374512, "critic_loss": 637.3140869140625, "actor_loss": -1244.3358154296875, "actor_target_entropy": -3.0, "actor_entropy": 0.7857420444488525, "alpha_loss": 0.09071508049964905, "alpha_value": 0.28552431913214715, "duration": 1.5562853813171387, "info_normalized_performance_mean": 0.3617090582847595, "info_normalized_performance_final": 0.3863636255264282, "info_performance_mean": 0.3617090582847595, "info_performance_final": 0.3863636255264282, "step": 1912000}
{"episode_reward": 723.4181818181828, "episode": 19121.0, "batch_reward": 8.453764915466309, "critic_loss": 1409.059814453125, "actor_loss": -1262.365234375, "actor_target_entropy": -3.0, "actor_entropy": 0.2806638777256012, "alpha_loss": -0.09450450539588928, "alpha_value": 0.2836030828253097, "duration": 1.4677135944366455, "info_normalized_performance_mean": 0.5040425658226013, "info_normalized_performance_final": 0.6423611044883728, "info_performance_mean": 0.5040425658226013, "info_performance_final": 0.6423611044883728, "step": 1912500}
{"episode_reward": 1008.0853174603186, "episode": 19126.0, "batch_reward": 8.174620628356934, "critic_loss": 493.1285705566406, "actor_loss": -1276.989501953125, "actor_target_entropy": -3.0, "actor_entropy": 0.6927980780601501, "alpha_loss": -0.10462942719459534, "alpha_value": 0.28015325347225795, "duration": 1.5911664962768555, "info_normalized_performance_mean": 0.5059506893157959, "info_normalized_performance_final": 0.6012986898422241, "info_performance_mean": 0.5059506893157959, "info_performance_final": 0.6012986898422241, "step": 1913000}
{"episode_reward": 1011.9012987012995, "episode": 19131.0, "batch_reward": 9.667984008789062, "critic_loss": 834.4605712890625, "actor_loss": -1303.520263671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9477033615112305, "alpha_loss": 0.23220089077949524, "alpha_value": 0.27738351982573317, "duration": 1.540313720703125, "info_normalized_performance_mean": 0.5938893556594849, "info_normalized_performance_final": 0.7280219793319702, "info_performance_mean": 0.5938893556594849, "info_performance_final": 0.7280219793319702, "step": 1913500}
{"episode_reward": 1187.7786499215065, "episode": 19136.0, "batch_reward": 9.228997230529785, "critic_loss": 1244.922607421875, "actor_loss": -1297.6688232421875, "actor_target_entropy": -3.0, "actor_entropy": 1.2060415744781494, "alpha_loss": 0.1520882397890091, "alpha_value": 0.2761769127553967, "duration": 1.4703710079193115, "info_normalized_performance_mean": 0.49755859375, "info_normalized_performance_final": 0.53515625, "info_performance_mean": 0.49755859375, "info_performance_final": 0.53515625, "step": 1914000}
{"episode_reward": 995.1171875, "episode": 19141.0, "batch_reward": 8.175782203674316, "critic_loss": 1067.979736328125, "actor_loss": -1272.78564453125, "actor_target_entropy": -3.0, "actor_entropy": 0.6070793271064758, "alpha_loss": -0.18915203213691711, "alpha_value": 0.2732564858249733, "duration": 1.572922945022583, "info_normalized_performance_mean": 0.6802213788032532, "info_normalized_performance_final": 0.75, "info_performance_mean": 0.6802213788032532, "info_performance_final": 0.75, "step": 1914500}
{"episode_reward": 1360.442708333333, "episode": 19146.0, "batch_reward": 8.067381858825684, "critic_loss": 841.523681640625, "actor_loss": -1243.636962890625, "actor_target_entropy": -3.0, "actor_entropy": 0.5541310906410217, "alpha_loss": -0.1589544117450714, "alpha_value": 0.2714907360809719, "duration": 1.4751803874969482, "info_normalized_performance_mean": 0.5490430593490601, "info_normalized_performance_final": 0.6909340620040894, "info_performance_mean": 0.5490430593490601, "info_performance_final": 0.6909340620040894, "step": 1915000}
{"episode_reward": 1098.0860805860812, "episode": 19151.0, "batch_reward": 9.113574981689453, "critic_loss": 359.4378662109375, "actor_loss": -1276.653564453125, "actor_target_entropy": -3.0, "actor_entropy": 1.0090464353561401, "alpha_loss": 0.031259503215551376, "alpha_value": 0.2700879584586578, "duration": 1.5598278045654297, "info_normalized_performance_mean": 0.48945701122283936, "info_normalized_performance_final": 0.5864253640174866, "info_performance_mean": 0.48945701122283936, "info_performance_final": 0.5864253640174866, "step": 1915500}
{"episode_reward": 978.9140271493194, "episode": 19156.0, "batch_reward": 9.151117324829102, "critic_loss": 937.9403076171875, "actor_loss": -1294.2308349609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2554287910461426, "alpha_loss": 0.051581017673015594, "alpha_value": 0.26701291532496896, "duration": 1.4765732288360596, "info_normalized_performance_mean": 0.737216055393219, "info_normalized_performance_final": 0.8516483306884766, "info_performance_mean": 0.737216055393219, "info_performance_final": 0.8516483306884766, "step": 1916000}
{"episode_reward": 1474.4322344322327, "episode": 19161.0, "batch_reward": 8.169929504394531, "critic_loss": 588.9535522460938, "actor_loss": -1253.38427734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7475950717926025, "alpha_loss": 0.08409765362739563, "alpha_value": 0.26772217986251173, "duration": 1.6247227191925049, "info_normalized_performance_mean": 0.48994049429893494, "info_normalized_performance_final": 0.5760582089424133, "info_performance_mean": 0.48994049429893494, "info_performance_final": 0.5760582089424133, "step": 1916500}
{"episode_reward": 979.8809523809533, "episode": 19166.0, "batch_reward": 8.841510772705078, "critic_loss": 1332.4986572265625, "actor_loss": -1293.802978515625, "actor_target_entropy": -3.0, "actor_entropy": 1.2443718910217285, "alpha_loss": 0.03193647041916847, "alpha_value": 0.2679895650817611, "duration": 1.5698490142822266, "info_normalized_performance_mean": 0.7810311913490295, "info_normalized_performance_final": 0.8421875238418579, "info_performance_mean": 0.7810311913490295, "info_performance_final": 0.8421875238418579, "step": 1917000}
{"episode_reward": 1562.0625, "episode": 19171.0, "batch_reward": 8.262691497802734, "critic_loss": 1783.002197265625, "actor_loss": -1256.36376953125, "actor_target_entropy": -3.0, "actor_entropy": 1.079807996749878, "alpha_loss": -0.24061733484268188, "alpha_value": 0.2691625907062298, "duration": 1.599365472793579, "info_normalized_performance_mean": 0.5153515338897705, "info_normalized_performance_final": 0.630859375, "info_performance_mean": 0.5153515338897705, "info_performance_final": 0.630859375, "step": 1917500}
{"episode_reward": 1030.7031249999995, "episode": 19176.0, "batch_reward": 8.768776893615723, "critic_loss": 1016.576416015625, "actor_loss": -1284.3599853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.1911978721618652, "alpha_loss": -0.10065505653619766, "alpha_value": 0.27246254595785935, "duration": 1.5009667873382568, "info_normalized_performance_mean": 0.595058798789978, "info_normalized_performance_final": 0.6411764621734619, "info_performance_mean": 0.595058798789978, "info_performance_final": 0.6411764621734619, "step": 1918000}
{"episode_reward": 1190.1176470588243, "episode": 19181.0, "batch_reward": 8.889242172241211, "critic_loss": 1381.130859375, "actor_loss": -1297.237548828125, "actor_target_entropy": -3.0, "actor_entropy": 0.812524676322937, "alpha_loss": -0.18569953739643097, "alpha_value": 0.2774084432157597, "duration": 1.5291626453399658, "info_normalized_performance_mean": 0.509638786315918, "info_normalized_performance_final": 0.6655844449996948, "info_performance_mean": 0.509638786315918, "info_performance_final": 0.6655844449996948, "step": 1918500}
{"episode_reward": 1019.2775974025974, "episode": 19186.0, "batch_reward": 9.28169059753418, "critic_loss": 2636.820556640625, "actor_loss": -1312.144775390625, "actor_target_entropy": -3.0, "actor_entropy": 1.0325278043746948, "alpha_loss": -0.07036112248897552, "alpha_value": 0.28213499476225157, "duration": 1.5111212730407715, "info_normalized_performance_mean": 0.6568254828453064, "info_normalized_performance_final": 0.800595223903656, "info_performance_mean": 0.6568254828453064, "info_performance_final": 0.800595223903656, "step": 1919000}
{"episode_reward": 1313.6507936507944, "episode": 19191.0, "batch_reward": 9.508459091186523, "critic_loss": 948.6063842773438, "actor_loss": -1316.7340087890625, "actor_target_entropy": -3.0, "actor_entropy": 1.147315263748169, "alpha_loss": -0.05597390606999397, "alpha_value": 0.2857311837939751, "duration": 1.4010725021362305, "info_normalized_performance_mean": 0.3983726501464844, "info_normalized_performance_final": 0.42941176891326904, "info_performance_mean": 0.3983726501464844, "info_performance_final": 0.42941176891326904, "step": 1919500}
{"episode_reward": 796.7450980392163, "episode": 19196.0, "batch_reward": 9.206799507141113, "critic_loss": 600.3361206054688, "actor_loss": -1314.44384765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8551943302154541, "alpha_loss": -0.10200711339712143, "alpha_value": 0.289623490380378, "step": 1920000}
{"duration": 18.80363130569458, "info_normalized_performance_mean": 0.4795600473880768, "info_normalized_performance_final": 0.6093189716339111, "info_performance_mean": 0.4795600473880768, "info_performance_final": 0.6093189716339111, "step": 1920000}
{"episode_reward": 959.1202346041052, "episode": 19201.0, "batch_reward": 8.788527488708496, "critic_loss": 582.700927734375, "actor_loss": -1274.1243896484375, "actor_target_entropy": -3.0, "actor_entropy": 0.9832280874252319, "alpha_loss": -0.1441604495048523, "alpha_value": 0.29560391595653507, "duration": 1.544621467590332, "info_normalized_performance_mean": 0.7630495429039001, "info_normalized_performance_final": 0.9052197933197021, "info_performance_mean": 0.7630495429039001, "info_performance_final": 0.9052197933197021, "step": 1920500}
{"episode_reward": 1526.0989010989038, "episode": 19206.0, "batch_reward": 9.761796951293945, "critic_loss": 701.7984619140625, "actor_loss": -1348.241943359375, "actor_target_entropy": -3.0, "actor_entropy": 1.3828959465026855, "alpha_loss": 0.08286549896001816, "alpha_value": 0.29881484906410466, "duration": 1.4812443256378174, "info_normalized_performance_mean": 0.3402727544307709, "info_normalized_performance_final": 0.3672727346420288, "info_performance_mean": 0.3402727544307709, "info_performance_final": 0.3672727346420288, "step": 1921000}
{"episode_reward": 680.545454545456, "episode": 19211.0, "batch_reward": 9.58946704864502, "critic_loss": 353.54547119140625, "actor_loss": -1322.4521484375, "actor_target_entropy": -3.0, "actor_entropy": 1.212416410446167, "alpha_loss": -0.12398258596658707, "alpha_value": 0.2991275007967215, "duration": 1.6498610973358154, "info_normalized_performance_mean": 0.6623679995536804, "info_normalized_performance_final": 0.7840277552604675, "info_performance_mean": 0.6623679995536804, "info_performance_final": 0.7840277552604675, "step": 1921500}
{"episode_reward": 1324.7361111111125, "episode": 19216.0, "batch_reward": 9.635923385620117, "critic_loss": 1195.607177734375, "actor_loss": -1333.474853515625, "actor_target_entropy": -3.0, "actor_entropy": 0.888519287109375, "alpha_loss": -0.3566196858882904, "alpha_value": 0.3001326310741347, "duration": 1.524824619293213, "info_normalized_performance_mean": 0.8122223019599915, "info_normalized_performance_final": 0.8680555820465088, "info_performance_mean": 0.8122223019599915, "info_performance_final": 0.8680555820465088, "step": 1922000}
{"episode_reward": 1624.4444444444425, "episode": 19221.0, "batch_reward": 10.669357299804688, "critic_loss": 570.7925415039062, "actor_loss": -1406.1959228515625, "actor_target_entropy": -3.0, "actor_entropy": 1.3449256420135498, "alpha_loss": 0.20926490426063538, "alpha_value": 0.3003913593508037, "duration": 1.5774030685424805, "info_normalized_performance_mean": 0.45559993386268616, "info_normalized_performance_final": 0.4841666519641876, "info_performance_mean": 0.45559993386268616, "info_performance_final": 0.4841666519641876, "step": 1922500}
{"episode_reward": 911.199999999998, "episode": 19226.0, "batch_reward": 9.73617935180664, "critic_loss": 885.4068603515625, "actor_loss": -1318.5791015625, "actor_target_entropy": -3.0, "actor_entropy": 1.328580617904663, "alpha_loss": -0.06992015242576599, "alpha_value": 0.29737930025841924, "duration": 1.5501339435577393, "info_normalized_performance_mean": 0.4490588307380676, "info_normalized_performance_final": 0.5520362257957458, "info_performance_mean": 0.4490588307380676, "info_performance_final": 0.5520362257957458, "step": 1923000}
{"episode_reward": 898.117647058824, "episode": 19231.0, "batch_reward": 10.46827507019043, "critic_loss": 532.7899780273438, "actor_loss": -1404.839599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3141043186187744, "alpha_loss": 0.192367821931839, "alpha_value": 0.29652448527048314, "duration": 1.5894114971160889, "info_normalized_performance_mean": 0.7225881814956665, "info_normalized_performance_final": 0.8435294032096863, "info_performance_mean": 0.7225881814956665, "info_performance_final": 0.8435294032096863, "step": 1923500}
{"episode_reward": 1445.1764705882329, "episode": 19236.0, "batch_reward": 9.43491268157959, "critic_loss": 612.3270874023438, "actor_loss": -1360.87841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7544862031936646, "alpha_loss": -0.16303260624408722, "alpha_value": 0.29492016155845147, "duration": 1.5006780624389648, "info_normalized_performance_mean": 0.7194271087646484, "info_normalized_performance_final": 0.7847222089767456, "info_performance_mean": 0.7194271087646484, "info_performance_final": 0.7847222089767456, "step": 1924000}
{"episode_reward": 1438.8541666666647, "episode": 19241.0, "batch_reward": 9.359880447387695, "critic_loss": 805.974853515625, "actor_loss": -1332.4298095703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1863322257995605, "alpha_loss": -0.005411820486187935, "alpha_value": 0.29441368303090054, "duration": 1.527050495147705, "info_normalized_performance_mean": 0.3656999170780182, "info_normalized_performance_final": 0.3982684016227722, "info_performance_mean": 0.3656999170780182, "info_performance_final": 0.3982684016227722, "step": 1924500}
{"episode_reward": 731.3997113997111, "episode": 19246.0, "batch_reward": 9.259185791015625, "critic_loss": 648.31982421875, "actor_loss": -1327.6348876953125, "actor_target_entropy": -3.0, "actor_entropy": 1.312112808227539, "alpha_loss": 0.013053670525550842, "alpha_value": 0.29372007419927787, "duration": 1.6573216915130615, "info_normalized_performance_mean": 0.7225462198257446, "info_normalized_performance_final": 0.8664020895957947, "info_performance_mean": 0.7225462198257446, "info_performance_final": 0.8664020895957947, "step": 1925000}
{"episode_reward": 1445.0925925925926, "episode": 19251.0, "batch_reward": 9.516596794128418, "critic_loss": 593.351806640625, "actor_loss": -1361.802490234375, "actor_target_entropy": -3.0, "actor_entropy": 1.1212002038955688, "alpha_loss": -0.06460587680339813, "alpha_value": 0.2949635572890503, "duration": 1.6489968299865723, "info_normalized_performance_mean": 0.8621597290039062, "info_normalized_performance_final": 0.9486111402511597, "info_performance_mean": 0.8621597290039062, "info_performance_final": 0.9486111402511597, "step": 1925500}
{"episode_reward": 1724.3194444444414, "episode": 19256.0, "batch_reward": 9.44141960144043, "critic_loss": 817.6773681640625, "actor_loss": -1366.2890625, "actor_target_entropy": -3.0, "actor_entropy": 1.6091786623001099, "alpha_loss": 0.13567140698432922, "alpha_value": 0.29733059908728127, "duration": 1.7788236141204834, "info_normalized_performance_mean": 0.491374135017395, "info_normalized_performance_final": 0.578659176826477, "info_performance_mean": 0.491374135017395, "info_performance_final": 0.578659176826477, "step": 1926000}
{"episode_reward": 982.7483974358962, "episode": 19261.0, "batch_reward": 9.925477981567383, "critic_loss": 1616.2098388671875, "actor_loss": -1368.571044921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3181788921356201, "alpha_loss": 0.08955591917037964, "alpha_value": 0.2996193707882047, "duration": 1.5019776821136475, "info_normalized_performance_mean": 0.6059091687202454, "info_normalized_performance_final": 0.6509740352630615, "info_performance_mean": 0.6059091687202454, "info_performance_final": 0.6509740352630615, "step": 1926500}
{"episode_reward": 1211.818181818184, "episode": 19266.0, "batch_reward": 9.449468612670898, "critic_loss": 1634.043701171875, "actor_loss": -1392.535888671875, "actor_target_entropy": -3.0, "actor_entropy": 0.9753788709640503, "alpha_loss": -0.08395755290985107, "alpha_value": 0.30334218794783097, "duration": 1.489532232284546, "info_normalized_performance_mean": 0.5939843654632568, "info_normalized_performance_final": 0.6710069179534912, "info_performance_mean": 0.5939843654632568, "info_performance_final": 0.6710069179534912, "step": 1927000}
{"episode_reward": 1187.9687500000016, "episode": 19271.0, "batch_reward": 9.862080574035645, "critic_loss": 1221.428466796875, "actor_loss": -1328.524169921875, "actor_target_entropy": -3.0, "actor_entropy": 1.3824143409729004, "alpha_loss": 0.18199051916599274, "alpha_value": 0.30563368450440354, "duration": 1.5630743503570557, "info_normalized_performance_mean": 0.765999972820282, "info_normalized_performance_final": 0.876953125, "info_performance_mean": 0.765999972820282, "info_performance_final": 0.876953125, "step": 1927500}
{"episode_reward": 1532.0, "episode": 19276.0, "batch_reward": 9.630556106567383, "critic_loss": 789.147216796875, "actor_loss": -1360.52294921875, "actor_target_entropy": -3.0, "actor_entropy": 1.7041600942611694, "alpha_loss": 0.08694478869438171, "alpha_value": 0.3071944201726794, "duration": 1.6365056037902832, "info_normalized_performance_mean": 0.6920707821846008, "info_normalized_performance_final": 0.8019079566001892, "info_performance_mean": 0.6920707821846008, "info_performance_final": 0.8019079566001892, "step": 1928000}
{"episode_reward": 1384.141414141413, "episode": 19281.0, "batch_reward": 9.67928695678711, "critic_loss": 1019.1077880859375, "actor_loss": -1368.061767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2403075695037842, "alpha_loss": -0.22858217358589172, "alpha_value": 0.30858655751538117, "duration": 1.582061529159546, "info_normalized_performance_mean": 0.7291873693466187, "info_normalized_performance_final": 0.8187500238418579, "info_performance_mean": 0.7291873693466187, "info_performance_final": 0.8187500238418579, "step": 1928500}
{"episode_reward": 1458.375, "episode": 19286.0, "batch_reward": 9.104976654052734, "critic_loss": 1975.3797607421875, "actor_loss": -1370.6649169921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8188806176185608, "alpha_loss": -0.0362434908747673, "alpha_value": 0.31030304999058955, "duration": 1.6120703220367432, "info_normalized_performance_mean": 0.41053569316864014, "info_normalized_performance_final": 0.47949734330177307, "info_performance_mean": 0.41053569316864014, "info_performance_final": 0.47949734330177307, "step": 1929000}
{"episode_reward": 821.0714285714283, "episode": 19291.0, "batch_reward": 9.9755859375, "critic_loss": 708.2310791015625, "actor_loss": -1408.565673828125, "actor_target_entropy": -3.0, "actor_entropy": 1.0807642936706543, "alpha_loss": 0.01905117928981781, "alpha_value": 0.311442265915395, "duration": 1.4574532508850098, "info_normalized_performance_mean": 0.15921877324581146, "info_normalized_performance_final": 0.17031249403953552, "info_performance_mean": 0.15921877324581146, "info_performance_final": 0.17031249403953552, "step": 1929500}
{"episode_reward": 318.4375, "episode": 19296.0, "batch_reward": 9.573264122009277, "critic_loss": 697.8385620117188, "actor_loss": -1352.825927734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0257045030593872, "alpha_loss": 0.07249525934457779, "alpha_value": 0.31111223392532195, "step": 1930000}
{"duration": 18.696717739105225, "info_normalized_performance_mean": 0.8387946486473083, "info_normalized_performance_final": 0.890625, "info_performance_mean": 0.8387946486473083, "info_performance_final": 0.890625, "step": 1930000}
{"episode_reward": 1677.5892857142858, "episode": 19301.0, "batch_reward": 9.376779556274414, "critic_loss": 506.9764099121094, "actor_loss": -1359.520263671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1952581405639648, "alpha_loss": -0.04014324024319649, "alpha_value": 0.3113280818811939, "duration": 1.4265265464782715, "info_normalized_performance_mean": 0.42047351598739624, "info_normalized_performance_final": 0.44507575035095215, "info_performance_mean": 0.42047351598739624, "info_performance_final": 0.44507575035095215, "step": 1930500}
{"episode_reward": 840.9469696969683, "episode": 19306.0, "batch_reward": 10.171855926513672, "critic_loss": 1393.6396484375, "actor_loss": -1358.511474609375, "actor_target_entropy": -3.0, "actor_entropy": 1.143690586090088, "alpha_loss": 0.1468673199415207, "alpha_value": 0.31069772566676984, "duration": 1.6422390937805176, "info_normalized_performance_mean": 0.437296599149704, "info_normalized_performance_final": 0.5566188097000122, "info_performance_mean": 0.437296599149704, "info_performance_final": 0.5566188097000122, "step": 1931000}
{"episode_reward": 874.5933014354061, "episode": 19311.0, "batch_reward": 9.77213191986084, "critic_loss": 1255.113525390625, "actor_loss": -1370.65771484375, "actor_target_entropy": -3.0, "actor_entropy": 1.5227035284042358, "alpha_loss": 0.0018753185868263245, "alpha_value": 0.30973329346218853, "duration": 1.5578398704528809, "info_normalized_performance_mean": 0.3283900022506714, "info_normalized_performance_final": 0.35260769724845886, "info_performance_mean": 0.3283900022506714, "info_performance_final": 0.35260769724845886, "step": 1931500}
{"episode_reward": 656.7800453514731, "episode": 19316.0, "batch_reward": 9.455384254455566, "critic_loss": 2816.1630859375, "actor_loss": -1380.9599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.004586935043335, "alpha_loss": 0.01862669736146927, "alpha_value": 0.31067574056797936, "duration": 1.7042083740234375, "info_normalized_performance_mean": 0.6292197108268738, "info_normalized_performance_final": 0.763076901435852, "info_performance_mean": 0.6292197108268738, "info_performance_final": 0.763076901435852, "step": 1932000}
{"episode_reward": 1258.4395604395595, "episode": 19321.0, "batch_reward": 9.107890129089355, "critic_loss": 747.5682983398438, "actor_loss": -1336.2464599609375, "actor_target_entropy": -3.0, "actor_entropy": 1.180418610572815, "alpha_loss": -0.07727722078561783, "alpha_value": 0.3119658916961906, "duration": 1.5566449165344238, "info_normalized_performance_mean": 0.8955631256103516, "info_normalized_performance_final": 0.9915966391563416, "info_performance_mean": 0.8955631256103516, "info_performance_final": 0.9915966391563416, "step": 1932500}
{"episode_reward": 1791.1260504201653, "episode": 19326.0, "batch_reward": 9.602150917053223, "critic_loss": 692.5391845703125, "actor_loss": -1410.970947265625, "actor_target_entropy": -3.0, "actor_entropy": 0.48621922731399536, "alpha_loss": 0.01548738032579422, "alpha_value": 0.3083691842722748, "duration": 1.6148314476013184, "info_normalized_performance_mean": 0.2931326627731323, "info_normalized_performance_final": 0.32870370149612427, "info_performance_mean": 0.2931326627731323, "info_performance_final": 0.32870370149612427, "step": 1933000}
{"episode_reward": 586.2654320987649, "episode": 19331.0, "batch_reward": 10.10853385925293, "critic_loss": 1034.8814697265625, "actor_loss": -1435.450439453125, "actor_target_entropy": -3.0, "actor_entropy": 0.8764284253120422, "alpha_loss": 0.044087279587984085, "alpha_value": 0.3050395667595657, "duration": 1.5479545593261719, "info_normalized_performance_mean": 0.566933274269104, "info_normalized_performance_final": 0.6066666841506958, "info_performance_mean": 0.566933274269104, "info_performance_final": 0.6066666841506958, "step": 1933500}
{"episode_reward": 1133.866666666667, "episode": 19336.0, "batch_reward": 9.403488159179688, "critic_loss": 1296.4173583984375, "actor_loss": -1350.9873046875, "actor_target_entropy": -3.0, "actor_entropy": 1.4232208728790283, "alpha_loss": -0.013503797352313995, "alpha_value": 0.30124446846954783, "duration": 1.5584354400634766, "info_normalized_performance_mean": 0.6793429851531982, "info_normalized_performance_final": 0.7242857217788696, "info_performance_mean": 0.6793429851531982, "info_performance_final": 0.7242857217788696, "step": 1934000}
{"episode_reward": 1358.685714285713, "episode": 19341.0, "batch_reward": 9.525711059570312, "critic_loss": 2027.53857421875, "actor_loss": -1344.9224853515625, "actor_target_entropy": -3.0, "actor_entropy": 1.0280461311340332, "alpha_loss": 0.12754446268081665, "alpha_value": 0.3009314540759273, "duration": 1.470019817352295, "info_normalized_performance_mean": 0.8307144045829773, "info_normalized_performance_final": 0.9017857313156128, "info_performance_mean": 0.8307144045829773, "info_performance_final": 0.9017857313156128, "step": 1934500}
{"episode_reward": 1661.4285714285704, "episode": 19346.0, "batch_reward": 8.818135261535645, "critic_loss": 1202.24365234375, "actor_loss": -1379.3050537109375, "actor_target_entropy": -3.0, "actor_entropy": 0.47939199209213257, "alpha_loss": -0.1736581027507782, "alpha_value": 0.3007432340958778, "duration": 1.479358434677124, "info_normalized_performance_mean": 0.5006250143051147, "info_normalized_performance_final": 0.5329861044883728, "info_performance_mean": 0.5006250143051147, "info_performance_final": 0.5329861044883728, "step": 1935000}
{"episode_reward": 1001.249999999998, "episode": 19351.0, "batch_reward": 8.987247467041016, "critic_loss": 2034.9378662109375, "actor_loss": -1389.1656494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.7538067102432251, "alpha_loss": -0.0822216048836708, "alpha_value": 0.30072012672599413, "duration": 1.557640790939331, "info_normalized_performance_mean": 0.7721923589706421, "info_normalized_performance_final": 0.83315509557724, "info_performance_mean": 0.7721923589706421, "info_performance_final": 0.83315509557724, "step": 1935500}
{"episode_reward": 1544.3850267379696, "episode": 19356.0, "batch_reward": 10.217615127563477, "critic_loss": 1498.701171875, "actor_loss": -1448.18994140625, "actor_target_entropy": -3.0, "actor_entropy": 0.9625719785690308, "alpha_loss": -0.003821268677711487, "alpha_value": 0.2982703656830406, "duration": 1.4538366794586182, "info_normalized_performance_mean": 0.6835678219795227, "info_normalized_performance_final": 0.7395833134651184, "info_performance_mean": 0.6835678219795227, "info_performance_final": 0.7395833134651184, "step": 1936000}
{"episode_reward": 1367.1354166666674, "episode": 19361.0, "batch_reward": 10.681699752807617, "critic_loss": 1179.8880615234375, "actor_loss": -1402.8974609375, "actor_target_entropy": -3.0, "actor_entropy": 1.121609091758728, "alpha_loss": 0.24822752177715302, "alpha_value": 0.2955186507867629, "duration": 1.5179152488708496, "info_normalized_performance_mean": 0.5675088763237, "info_normalized_performance_final": 0.7227678298950195, "info_performance_mean": 0.5675088763237, "info_performance_final": 0.7227678298950195, "step": 1936500}
{"episode_reward": 1135.0178571428573, "episode": 19366.0, "batch_reward": 9.611027717590332, "critic_loss": 664.8305053710938, "actor_loss": -1390.8177490234375, "actor_target_entropy": -3.0, "actor_entropy": 0.7052653431892395, "alpha_loss": -0.056432973593473434, "alpha_value": 0.2922873284052982, "duration": 1.505666971206665, "info_normalized_performance_mean": 0.935229480266571, "info_normalized_performance_final": 0.9948979616165161, "info_performance_mean": 0.935229480266571, "info_performance_final": 0.9948979616165161, "step": 1937000}
{"episode_reward": 1870.4591836734712, "episode": 19371.0, "batch_reward": 9.42323112487793, "critic_loss": 2771.455322265625, "actor_loss": -1365.4189453125, "actor_target_entropy": -3.0, "actor_entropy": 1.011218786239624, "alpha_loss": -0.04532734304666519, "alpha_value": 0.2898590665935081, "duration": 1.7745037078857422, "info_normalized_performance_mean": 0.4862905740737915, "info_normalized_performance_final": 0.6021412014961243, "info_performance_mean": 0.4862905740737915, "info_performance_final": 0.6021412014961243, "step": 1937500}
{"episode_reward": 972.5810185185175, "episode": 19376.0, "batch_reward": 9.962054252624512, "critic_loss": 1060.6846923828125, "actor_loss": -1402.6007080078125, "actor_target_entropy": -3.0, "actor_entropy": 0.6581295728683472, "alpha_loss": 0.016258280724287033, "alpha_value": 0.2885506420407176, "duration": 1.6124532222747803, "info_normalized_performance_mean": 0.024069450795650482, "info_normalized_performance_final": 0.02708333358168602, "info_performance_mean": 0.024069450795650482, "info_performance_final": 0.02708333358168602, "step": 1938000}
{"episode_reward": 48.13888888888885, "episode": 19381.0, "batch_reward": 10.652475357055664, "critic_loss": 678.7232666015625, "actor_loss": -1390.933837890625, "actor_target_entropy": -3.0, "actor_entropy": 0.7849016189575195, "alpha_loss": 0.06953322887420654, "alpha_value": 0.28546167139585504, "duration": 1.5155448913574219, "info_normalized_performance_mean": 0.5801041722297668, "info_normalized_performance_final": 0.6714409589767456, "info_performance_mean": 0.5801041722297668, "info_performance_final": 0.6714409589767456, "step": 1938500}
{"episode_reward": 1160.208333333333, "episode": 19386.0, "batch_reward": 10.285820007324219, "critic_loss": 430.47808837890625, "actor_loss": -1388.6668701171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8774374723434448, "alpha_loss": 0.20500466227531433, "alpha_value": 0.28204045452923526, "duration": 1.5341885089874268, "info_normalized_performance_mean": 0.2711176574230194, "info_normalized_performance_final": 0.5070587992668152, "info_performance_mean": 0.2711176574230194, "info_performance_final": 0.5070587992668152, "step": 1939000}
{"episode_reward": 542.2352941176468, "episode": 19391.0, "batch_reward": 9.084632873535156, "critic_loss": 1366.6845703125, "actor_loss": -1392.406005859375, "actor_target_entropy": -3.0, "actor_entropy": 0.5204236507415771, "alpha_loss": -0.16407553851604462, "alpha_value": 0.2796937794853525, "duration": 1.6224241256713867, "info_normalized_performance_mean": 0.5172144174575806, "info_normalized_performance_final": 0.5493826866149902, "info_performance_mean": 0.5172144174575806, "info_performance_final": 0.5493826866149902, "step": 1939500}
{"episode_reward": 1034.4290123456783, "episode": 19396.0, "batch_reward": 11.105472564697266, "critic_loss": 458.1715087890625, "actor_loss": -1414.746826171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8272213935852051, "alpha_loss": 0.1939079761505127, "alpha_value": 0.2785050357632366, "step": 1940000}
{"duration": 19.053612232208252, "info_normalized_performance_mean": 0.16310712695121765, "info_normalized_performance_final": 0.25357142090797424, "info_performance_mean": 0.16310712695121765, "info_performance_final": 0.25357142090797424, "step": 1940000}
{"episode_reward": 326.2142857142858, "episode": 19401.0, "batch_reward": 10.543416023254395, "critic_loss": 1042.1181640625, "actor_loss": -1409.005615234375, "actor_target_entropy": -3.0, "actor_entropy": 0.9635892510414124, "alpha_loss": 0.09209955483675003, "alpha_value": 0.2779649602957433, "duration": 1.6297874450683594, "info_normalized_performance_mean": 0.7139818072319031, "info_normalized_performance_final": 0.7727272510528564, "info_performance_mean": 0.7139818072319031, "info_performance_final": 0.7727272510528564, "step": 1940500}
{"episode_reward": 1427.9636363636384, "episode": 19406.0, "batch_reward": 9.173487663269043, "critic_loss": 575.79443359375, "actor_loss": -1381.1689453125, "actor_target_entropy": -3.0, "actor_entropy": 0.883316695690155, "alpha_loss": 0.04849842190742493, "alpha_value": 0.2763223982214189, "duration": 1.5524849891662598, "info_normalized_performance_mean": 0.1133531853556633, "info_normalized_performance_final": 0.14153438806533813, "info_performance_mean": 0.1133531853556633, "info_performance_final": 0.14153438806533813, "step": 1941000}
{"episode_reward": 226.70634920634896, "episode": 19411.0, "batch_reward": 8.956567764282227, "critic_loss": 1345.66796875, "actor_loss": -1338.0966796875, "actor_target_entropy": -3.0, "actor_entropy": 0.9430445432662964, "alpha_loss": -0.12860998511314392, "alpha_value": 0.2753571594701161, "duration": 1.516874074935913, "info_normalized_performance_mean": 0.9257292151451111, "info_normalized_performance_final": 1.0, "info_performance_mean": 0.9257292151451111, "info_performance_final": 1.0, "step": 1941500}
{"episode_reward": 1851.4583333333333, "episode": 19416.0, "batch_reward": 10.281270980834961, "critic_loss": 965.4034423828125, "actor_loss": -1404.8638916015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9190679788589478, "alpha_loss": 0.022466396912932396, "alpha_value": 0.2741299511820681, "duration": 1.5104827880859375, "info_normalized_performance_mean": 0.27369996905326843, "info_normalized_performance_final": 0.3081818222999573, "info_performance_mean": 0.27369996905326843, "info_performance_final": 0.3081818222999573, "step": 1942000}
{"episode_reward": 547.4000000000009, "episode": 19421.0, "batch_reward": 10.281654357910156, "critic_loss": 2279.15966796875, "actor_loss": -1386.835205078125, "actor_target_entropy": -3.0, "actor_entropy": 0.8664515018463135, "alpha_loss": 0.12251010537147522, "alpha_value": 0.2710418958317459, "duration": 1.8028090000152588, "info_normalized_performance_mean": 0.5841330885887146, "info_normalized_performance_final": 0.723901093006134, "info_performance_mean": 0.5841330885887146, "info_performance_final": 0.723901093006134, "step": 1942500}
{"episode_reward": 1168.266178266178, "episode": 19426.0, "batch_reward": 9.871244430541992, "critic_loss": 804.1931762695312, "actor_loss": -1399.706298828125, "actor_target_entropy": -3.0, "actor_entropy": 1.0049405097961426, "alpha_loss": 0.12978585064411163, "alpha_value": 0.2693066614866276, "duration": 1.5619311332702637, "info_normalized_performance_mean": 0.7768402695655823, "info_normalized_performance_final": 0.828125, "info_performance_mean": 0.7768402695655823, "info_performance_final": 0.828125, "step": 1943000}
{"episode_reward": 1553.6805555555557, "episode": 19431.0, "batch_reward": 9.776317596435547, "critic_loss": 686.72900390625, "actor_loss": -1361.0634765625, "actor_target_entropy": -3.0, "actor_entropy": 1.2184958457946777, "alpha_loss": -0.1238262951374054, "alpha_value": 0.27105109238343417, "duration": 1.5790319442749023, "info_normalized_performance_mean": 0.39189034700393677, "info_normalized_performance_final": 0.4220779240131378, "info_performance_mean": 0.39189034700393677, "info_performance_final": 0.4220779240131378, "step": 1943500}
{"episode_reward": 783.780663780662, "episode": 19436.0, "batch_reward": 10.852312088012695, "critic_loss": 694.0745239257812, "actor_loss": -1406.283203125, "actor_target_entropy": -3.0, "actor_entropy": 1.248957633972168, "alpha_loss": -0.0033963192254304886, "alpha_value": 0.2735941792444367, "duration": 1.5326910018920898, "info_normalized_performance_mean": 0.36670607328414917, "info_normalized_performance_final": 0.5415770411491394, "info_performance_mean": 0.36670607328414917, "info_performance_final": 0.5415770411491394, "step": 1944000}
{"episode_reward": 733.4121863799278, "episode": 19441.0, "batch_reward": 10.405447006225586, "critic_loss": 828.5203857421875, "actor_loss": -1412.22802734375, "actor_target_entropy": -3.0, "actor_entropy": 0.7411196827888489, "alpha_loss": 0.008262421935796738, "alpha_value": 0.27351099757260616, "duration": 1.617048740386963, "info_normalized_performance_mean": 0.638999879360199, "info_normalized_performance_final": 0.6825000047683716, "info_performance_mean": 0.638999879360199, "info_performance_final": 0.6825000047683716, "step": 1944500}
{"episode_reward": 1278.0000000000005, "episode": 19446.0, "batch_reward": 10.068096160888672, "critic_loss": 562.0958251953125, "actor_loss": -1374.8096923828125, "actor_target_entropy": -3.0, "actor_entropy": 0.786434531211853, "alpha_loss": -0.09606773406267166, "alpha_value": 0.2738632931258524, "duration": 1.459947109222412, "info_normalized_performance_mean": 0.44115614891052246, "info_normalized_performance_final": 0.4749999940395355, "info_performance_mean": 0.44115614891052246, "info_performance_final": 0.4749999940395355, "step": 1945000}
{"episode_reward": 882.3125, "episode": 19451.0, "batch_reward": 8.451744079589844, "critic_loss": 603.1119995117188, "actor_loss": -1342.474365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.0145397186279297, "alpha_loss": -0.1005399152636528, "alpha_value": 0.27342352572612, "duration": 1.561525821685791, "info_normalized_performance_mean": 0.35098129510879517, "info_normalized_performance_final": 0.4826839864253998, "info_performance_mean": 0.35098129510879517, "info_performance_final": 0.4826839864253998, "step": 1945500}
{"episode_reward": 701.9624819624822, "episode": 19456.0, "batch_reward": 9.522634506225586, "critic_loss": 1074.380126953125, "actor_loss": -1356.0548095703125, "actor_target_entropy": -3.0, "actor_entropy": 0.6278804540634155, "alpha_loss": -0.02056623250246048, "alpha_value": 0.2749407584411035, "duration": 1.5741956233978271, "info_normalized_performance_mean": 0.6878623962402344, "info_normalized_performance_final": 0.7400000095367432, "info_performance_mean": 0.6878623962402344, "info_performance_final": 0.7400000095367432, "step": 1946000}
{"episode_reward": 1375.7249999999976, "episode": 19461.0, "batch_reward": 9.431501388549805, "critic_loss": 407.88232421875, "actor_loss": -1368.58544921875, "actor_target_entropy": -3.0, "actor_entropy": 0.8325024843215942, "alpha_loss": 0.040897972881793976, "alpha_value": 0.27586118710306445, "duration": 1.5989677906036377, "info_normalized_performance_mean": 0.818040132522583, "info_normalized_performance_final": 0.8849999904632568, "info_performance_mean": 0.818040132522583, "info_performance_final": 0.8849999904632568, "step": 1946500}
{"episode_reward": 1636.0800000000027, "episode": 19466.0, "batch_reward": 9.163237571716309, "critic_loss": 803.492919921875, "actor_loss": -1377.458740234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8183301091194153, "alpha_loss": -0.16851839423179626, "alpha_value": 0.27770025921350544, "duration": 1.3894309997558594, "info_normalized_performance_mean": 0.28771430253982544, "info_normalized_performance_final": 0.3107142746448517, "info_performance_mean": 0.28771430253982544, "info_performance_final": 0.3107142746448517, "step": 1947000}
{"episode_reward": 575.4285714285713, "episode": 19471.0, "batch_reward": 9.888900756835938, "critic_loss": 2108.378662109375, "actor_loss": -1357.3583984375, "actor_target_entropy": -3.0, "actor_entropy": 1.3115952014923096, "alpha_loss": 0.16284465789794922, "alpha_value": 0.2815003954173632, "duration": 1.5800132751464844, "info_normalized_performance_mean": 0.4849511384963989, "info_normalized_performance_final": 0.5751028656959534, "info_performance_mean": 0.4849511384963989, "info_performance_final": 0.5751028656959534, "step": 1947500}
{"episode_reward": 969.9022633744867, "episode": 19476.0, "batch_reward": 10.421110153198242, "critic_loss": 758.428955078125, "actor_loss": -1361.331787109375, "actor_target_entropy": -3.0, "actor_entropy": 1.1192394495010376, "alpha_loss": 0.025688301771879196, "alpha_value": 0.2835549305324086, "duration": 1.543565273284912, "info_normalized_performance_mean": 0.7510576844215393, "info_normalized_performance_final": 0.8090659379959106, "info_performance_mean": 0.7510576844215393, "info_performance_final": 0.8090659379959106, "step": 1948000}
{"episode_reward": 1502.1153846153861, "episode": 19481.0, "batch_reward": 9.770421028137207, "critic_loss": 1432.636474609375, "actor_loss": -1377.748046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1356394290924072, "alpha_loss": 0.043358463793992996, "alpha_value": 0.28616150617456876, "duration": 1.7455780506134033, "info_normalized_performance_mean": 0.6664553880691528, "info_normalized_performance_final": 0.8203747868537903, "info_performance_mean": 0.6664553880691528, "info_performance_final": 0.8203747868537903, "step": 1948500}
{"episode_reward": 1332.9106858054233, "episode": 19486.0, "batch_reward": 9.75621223449707, "critic_loss": 3087.484130859375, "actor_loss": -1388.1041259765625, "actor_target_entropy": -3.0, "actor_entropy": 1.185036301612854, "alpha_loss": -0.04880973696708679, "alpha_value": 0.2887808896429062, "duration": 1.5776257514953613, "info_normalized_performance_mean": 0.2473899871110916, "info_normalized_performance_final": 0.289000004529953, "info_performance_mean": 0.2473899871110916, "info_performance_final": 0.289000004529953, "step": 1949000}
{"episode_reward": 494.77999999999906, "episode": 19491.0, "batch_reward": 10.26327896118164, "critic_loss": 1512.62255859375, "actor_loss": -1406.9681396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.1500402688980103, "alpha_loss": -0.09678974002599716, "alpha_value": 0.2906544702735188, "duration": 1.4630012512207031, "info_normalized_performance_mean": 0.5699767470359802, "info_normalized_performance_final": 0.6697587966918945, "info_performance_mean": 0.5699767470359802, "info_performance_final": 0.6697587966918945, "step": 1949500}
{"episode_reward": 1139.9536178107587, "episode": 19496.0, "batch_reward": 9.899949073791504, "critic_loss": 605.7969970703125, "actor_loss": -1361.8226318359375, "actor_target_entropy": -3.0, "actor_entropy": 1.151139736175537, "alpha_loss": -0.08384328335523605, "alpha_value": 0.2911315863001572, "step": 1950000}
{"duration": 18.981990337371826, "info_normalized_performance_mean": 0.2334311604499817, "info_normalized_performance_final": 0.2672727406024933, "info_performance_mean": 0.2334311604499817, "info_performance_final": 0.2672727406024933, "step": 1950000}
{"episode_reward": 466.8623376623389, "episode": 19501.0, "batch_reward": 9.586182594299316, "critic_loss": 896.6209716796875, "actor_loss": -1358.84716796875, "actor_target_entropy": -3.0, "actor_entropy": 0.9207264184951782, "alpha_loss": -0.030228614807128906, "alpha_value": 0.29520573984525406, "duration": 1.4514098167419434, "info_normalized_performance_mean": 0.44224607944488525, "info_normalized_performance_final": 0.478515625, "info_performance_mean": 0.44224607944488525, "info_performance_final": 0.478515625, "step": 1950500}
{"episode_reward": 884.4921875, "episode": 19506.0, "batch_reward": 9.473217964172363, "critic_loss": 783.6358032226562, "actor_loss": -1368.537841796875, "actor_target_entropy": -3.0, "actor_entropy": 0.7561885118484497, "alpha_loss": -0.2527816891670227, "alpha_value": 0.29812673928973277, "duration": 1.614353895187378, "info_normalized_performance_mean": 0.668866753578186, "info_normalized_performance_final": 0.7283333539962769, "info_performance_mean": 0.668866753578186, "info_performance_final": 0.7283333539962769, "step": 1951000}
{"episode_reward": 1337.7333333333338, "episode": 19511.0, "batch_reward": 9.761740684509277, "critic_loss": 901.8671875, "actor_loss": -1348.94677734375, "actor_target_entropy": -3.0, "actor_entropy": 1.0131582021713257, "alpha_loss": 0.06934008002281189, "alpha_value": 0.29865797757465484, "duration": 1.4915268421173096, "info_normalized_performance_mean": 0.3708132803440094, "info_normalized_performance_final": 0.4240056872367859, "info_performance_mean": 0.3708132803440094, "info_performance_final": 0.4240056872367859, "step": 1951500}
{"episode_reward": 741.626420454545, "episode": 19516.0, "batch_reward": 10.029074668884277, "critic_loss": 1015.1687622070312, "actor_loss": -1377.7451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.2778642177581787, "alpha_loss": -0.12292710691690445, "alpha_value": 0.29846523005724007, "duration": 1.6112284660339355, "info_normalized_performance_mean": 0.5742424726486206, "info_normalized_performance_final": 0.6190476417541504, "info_performance_mean": 0.5742424726486206, "info_performance_final": 0.6190476417541504, "step": 1952000}
{"episode_reward": 1148.4848484848492, "episode": 19521.0, "batch_reward": 9.289572715759277, "critic_loss": 826.345947265625, "actor_loss": -1349.034423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.150368571281433, "alpha_loss": -0.003355560824275017, "alpha_value": 0.2983587643799538, "duration": 1.6863787174224854, "info_normalized_performance_mean": 0.5534722208976746, "info_normalized_performance_final": 0.7744709253311157, "info_performance_mean": 0.5534722208976746, "info_performance_final": 0.7744709253311157, "step": 1952500}
{"episode_reward": 1106.944444444444, "episode": 19526.0, "batch_reward": 10.205867767333984, "critic_loss": 927.6827392578125, "actor_loss": -1366.553466796875, "actor_target_entropy": -3.0, "actor_entropy": 1.5955568552017212, "alpha_loss": 0.06533563882112503, "alpha_value": 0.2993839319710142, "duration": 1.5985991954803467, "info_normalized_performance_mean": 0.4801546335220337, "info_normalized_performance_final": 0.5816666483879089, "info_performance_mean": 0.4801546335220337, "info_performance_final": 0.5816666483879089, "step": 1953000}
{"episode_reward": 960.3095238095234, "episode": 19531.0, "batch_reward": 10.36798095703125, "critic_loss": 1318.0738525390625, "actor_loss": -1405.3798828125, "actor_target_entropy": -3.0, "actor_entropy": 1.1463799476623535, "alpha_loss": 0.12846437096595764, "alpha_value": 0.30046699709549707, "duration": 1.5454761981964111, "info_normalized_performance_mean": 0.49014005064964294, "info_normalized_performance_final": 0.5329999923706055, "info_performance_mean": 0.49014005064964294, "info_performance_final": 0.5329999923706055, "step": 1953500}
{"episode_reward": 980.2799999999992, "episode": 19536.0, "batch_reward": 9.951931953430176, "critic_loss": 499.36724853515625, "actor_loss": -1401.2138671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1648578643798828, "alpha_loss": -0.14085794985294342, "alpha_value": 0.3008364250401737, "duration": 1.44679856300354, "info_normalized_performance_mean": 0.5762239694595337, "info_normalized_performance_final": 0.625, "info_performance_mean": 0.5762239694595337, "info_performance_final": 0.625, "step": 1954000}
{"episode_reward": 1152.4479166666665, "episode": 19541.0, "batch_reward": 10.145586013793945, "critic_loss": 1238.5537109375, "actor_loss": -1375.5689697265625, "actor_target_entropy": -3.0, "actor_entropy": 1.094541072845459, "alpha_loss": -0.10297495871782303, "alpha_value": 0.3014324725816623, "duration": 1.5182700157165527, "info_normalized_performance_mean": 0.4061545431613922, "info_normalized_performance_final": 0.5394965410232544, "info_performance_mean": 0.4061545431613922, "info_performance_final": 0.5394965410232544, "step": 1954500}
{"episode_reward": 812.3090277777775, "episode": 19546.0, "batch_reward": 10.636272430419922, "critic_loss": 906.5327758789062, "actor_loss": -1374.729248046875, "actor_target_entropy": -3.0, "actor_entropy": 1.4098442792892456, "alpha_loss": 0.15260538458824158, "alpha_value": 0.29878682265303586, "duration": 1.748426914215088, "info_normalized_performance_mean": 0.4181690514087677, "info_normalized_performance_final": 0.5379847288131714, "info_performance_mean": 0.4181690514087677, "info_performance_final": 0.5379847288131714, "step": 1955000}
{"episode_reward": 836.3382072472991, "episode": 19551.0, "batch_reward": 10.266950607299805, "critic_loss": 586.312255859375, "actor_loss": -1380.037109375, "actor_target_entropy": -3.0, "actor_entropy": 1.2276010513305664, "alpha_loss": 0.11676692962646484, "alpha_value": 0.2990199282918301, "duration": 1.4296767711639404, "info_normalized_performance_mean": 0.5468215346336365, "info_normalized_performance_final": 0.5892857313156128, "info_performance_mean": 0.5468215346336365, "info_performance_final": 0.5892857313156128, "step": 1955500}
{"episode_reward": 1093.6428571428587, "episode": 19556.0, "batch_reward": 10.514552116394043, "critic_loss": 532.6444091796875, "actor_loss": -1389.3466796875, "actor_target_entropy": -3.0, "actor_entropy": 1.2499003410339355, "alpha_loss": -0.11184664070606232, "alpha_value": 0.2993263226313752, "duration": 1.6484932899475098, "info_normalized_performance_mean": 0.6108596920967102, "info_normalized_performance_final": 0.7665343880653381, "info_performance_mean": 0.6108596920967102, "info_performance_final": 0.7665343880653381, "step": 1956000}
{"episode_reward": 1221.7195767195756, "episode": 19561.0, "batch_reward": 9.503084182739258, "critic_loss": 519.2186889648438, "actor_loss": -1355.938720703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1939969062805176, "alpha_loss": -0.022532617673277855, "alpha_value": 0.2982924632189286, "duration": 1.4503593444824219, "info_normalized_performance_mean": 0.2712245285511017, "info_normalized_performance_final": 0.3209647536277771, "info_performance_mean": 0.2712245285511017, "info_performance_final": 0.3209647536277771, "step": 1956500}
{"episode_reward": 542.4489795918375, "episode": 19566.0, "batch_reward": 10.083149909973145, "critic_loss": 583.1326904296875, "actor_loss": -1391.652099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.1202566623687744, "alpha_loss": 0.049822848290205, "alpha_value": 0.2936242947549855, "duration": 1.502852439880371, "info_normalized_performance_mean": 0.410594642162323, "info_normalized_performance_final": 0.4986979067325592, "info_performance_mean": 0.410594642162323, "info_performance_final": 0.4986979067325592, "step": 1957000}
{"episode_reward": 821.1892361111118, "episode": 19571.0, "batch_reward": 10.815654754638672, "critic_loss": 930.774658203125, "actor_loss": -1383.080078125, "actor_target_entropy": -3.0, "actor_entropy": 1.1405740976333618, "alpha_loss": 0.05994458496570587, "alpha_value": 0.2932954771886489, "duration": 1.4493191242218018, "info_normalized_performance_mean": 0.7354763150215149, "info_normalized_performance_final": 0.8065476417541504, "info_performance_mean": 0.7354763150215149, "info_performance_final": 0.8065476417541504, "step": 1957500}
{"episode_reward": 1470.9523809523798, "episode": 19576.0, "batch_reward": 10.875391960144043, "critic_loss": 510.50457763671875, "actor_loss": -1396.1864013671875, "actor_target_entropy": -3.0, "actor_entropy": 1.4907540082931519, "alpha_loss": -0.009388210251927376, "alpha_value": 0.2904482927367908, "duration": 1.635972023010254, "info_normalized_performance_mean": 0.6154256463050842, "info_normalized_performance_final": 0.6839826703071594, "info_performance_mean": 0.6154256463050842, "info_performance_final": 0.6839826703071594, "step": 1958000}
{"episode_reward": 1230.8513708513713, "episode": 19581.0, "batch_reward": 10.138998985290527, "critic_loss": 807.03076171875, "actor_loss": -1390.5546875, "actor_target_entropy": -3.0, "actor_entropy": 1.4838690757751465, "alpha_loss": 0.2487872838973999, "alpha_value": 0.2864534207673348, "duration": 1.6255273818969727, "info_normalized_performance_mean": 0.6710270643234253, "info_normalized_performance_final": 0.77048259973526, "info_performance_mean": 0.6710270643234253, "info_performance_final": 0.77048259973526, "step": 1958500}
{"episode_reward": 1342.0538720538702, "episode": 19586.0, "batch_reward": 10.410796165466309, "critic_loss": 423.6004943847656, "actor_loss": -1396.771484375, "actor_target_entropy": -3.0, "actor_entropy": 0.8094381093978882, "alpha_loss": -0.04217896983027458, "alpha_value": 0.2801214653877685, "duration": 1.5364887714385986, "info_normalized_performance_mean": 0.473482221364975, "info_normalized_performance_final": 0.6067994236946106, "info_performance_mean": 0.473482221364975, "info_performance_final": 0.6067994236946106, "step": 1959000}
{"episode_reward": 946.964285714285, "episode": 19591.0, "batch_reward": 10.424081802368164, "critic_loss": 693.3346557617188, "actor_loss": -1371.4034423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.3306021690368652, "alpha_loss": 0.2616899013519287, "alpha_value": 0.2783999775472784, "duration": 1.489579439163208, "info_normalized_performance_mean": 0.5129854083061218, "info_normalized_performance_final": 0.6333705186843872, "info_performance_mean": 0.5129854083061218, "info_performance_final": 0.6333705186843872, "step": 1959500}
{"episode_reward": 1025.9709821428562, "episode": 19596.0, "batch_reward": 11.428104400634766, "critic_loss": 1359.191162109375, "actor_loss": -1388.112060546875, "actor_target_entropy": -3.0, "actor_entropy": 1.27017343044281, "alpha_loss": 0.006042607128620148, "alpha_value": 0.2748880492401995, "step": 1960000}
{"duration": 18.38766121864319, "info_normalized_performance_mean": 0.21359266340732574, "info_normalized_performance_final": 0.26743197441101074, "info_performance_mean": 0.21359266340732574, "info_performance_final": 0.26743197441101074, "step": 1960000}
{"episode_reward": 427.185374149659, "episode": 19601.0, "batch_reward": 10.00803279876709, "critic_loss": 1094.5003662109375, "actor_loss": -1371.338623046875, "actor_target_entropy": -3.0, "actor_entropy": 0.8455636501312256, "alpha_loss": -0.04153004661202431, "alpha_value": 0.27143711690437256, "duration": 1.7259984016418457, "info_normalized_performance_mean": 0.5527990460395813, "info_normalized_performance_final": 0.6872009634971619, "info_performance_mean": 0.5527990460395813, "info_performance_final": 0.6872009634971619, "step": 1960500}
{"episode_reward": 1105.598086124402, "episode": 19606.0, "batch_reward": 11.29987907409668, "critic_loss": 529.4552001953125, "actor_loss": -1412.284423828125, "actor_target_entropy": -3.0, "actor_entropy": 1.2900524139404297, "alpha_loss": 0.16628359258174896, "alpha_value": 0.26788345114254486, "duration": 1.3953332901000977, "info_normalized_performance_mean": 0.7798214554786682, "info_normalized_performance_final": 0.8392857313156128, "info_performance_mean": 0.7798214554786682, "info_performance_final": 0.8392857313156128, "step": 1961000}
{"episode_reward": 1559.6428571428564, "episode": 19611.0, "batch_reward": 10.013803482055664, "critic_loss": 912.6434936523438, "actor_loss": -1378.652587890625, "actor_target_entropy": -3.0, "actor_entropy": 0.8723214864730835, "alpha_loss": -0.1318521797657013, "alpha_value": 0.2639282059328045, "duration": 1.4763703346252441, "info_normalized_performance_mean": 0.42603328824043274, "info_normalized_performance_final": 0.46000000834465027, "info_performance_mean": 0.42603328824043274, "info_performance_final": 0.46000000834465027, "step": 1961500}
{"episode_reward": 852.0666666666679, "episode": 19616.0, "batch_reward": 10.371082305908203, "critic_loss": 2230.5703125, "actor_loss": -1398.9954833984375, "actor_target_entropy": -3.0, "actor_entropy": 0.9566435813903809, "alpha_loss": 0.0761997401714325, "alpha_value": 0.2622560120449512, "duration": 1.586275577545166, "info_normalized_performance_mean": 0.5206085443496704, "info_normalized_performance_final": 0.5820105671882629, "info_performance_mean": 0.5206085443496704, "info_performance_final": 0.5820105671882629, "step": 1962000}
{"episode_reward": 1041.2169312169303, "episode": 19621.0, "batch_reward": 10.706995010375977, "critic_loss": 469.6806945800781, "actor_loss": -1389.107666015625, "actor_target_entropy": -3.0, "actor_entropy": 0.9442691802978516, "alpha_loss": 0.09442437440156937, "alpha_value": 0.2601950694680635, "duration": 1.4842548370361328, "info_normalized_performance_mean": 0.5320022106170654, "info_normalized_performance_final": 0.6655844449996948, "info_performance_mean": 0.5320022106170654, "info_performance_final": 0.6655844449996948, "step": 1962500}
{"episode_reward": 1064.0043290043277, "episode": 19626.0, "batch_reward": 11.266741752624512, "critic_loss": 390.4049377441406, "actor_loss": -1376.2462158203125, "actor_target_entropy": -3.0, "actor_entropy": 1.4399182796478271, "alpha_loss": 0.18466059863567352, "alpha_value": 0.25872285162797, "duration": 1.6269252300262451, "info_normalized_performance_mean": 0.42731744050979614, "info_normalized_performance_final": 0.5337499976158142, "info_performance_mean": 0.42731744050979614, "info_performance_final": 0.5337499976158142, "step": 1963000}
{"episode_reward": 854.6349999999993, "episode": 19631.0, "batch_reward": 11.186067581176758, "critic_loss": 293.8466491699219, "actor_loss": -1372.826171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1007826328277588, "alpha_loss": -0.014500439167022705, "alpha_value": 0.2571787223560809, "duration": 1.5701134204864502, "info_normalized_performance_mean": 0.8803719878196716, "info_normalized_performance_final": 0.9479166865348816, "info_performance_mean": 0.8803719878196716, "info_performance_final": 0.9479166865348816, "step": 1963500}
{"episode_reward": 1760.7440476190454, "episode": 19636.0, "batch_reward": 9.974098205566406, "critic_loss": 740.234130859375, "actor_loss": -1331.056396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.2473886013031006, "alpha_loss": -0.1253816932439804, "alpha_value": 0.2556148430443481, "duration": 1.641181230545044, "info_normalized_performance_mean": 0.5393725037574768, "info_normalized_performance_final": 0.6617500185966492, "info_performance_mean": 0.5393725037574768, "info_performance_final": 0.6617500185966492, "step": 1964000}
{"episode_reward": 1078.7450000000001, "episode": 19641.0, "batch_reward": 10.651554107666016, "critic_loss": 353.312255859375, "actor_loss": -1366.31396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.3345880508422852, "alpha_loss": 0.04204622656106949, "alpha_value": 0.25194041999702804, "duration": 1.6975007057189941, "info_normalized_performance_mean": 0.3982677161693573, "info_normalized_performance_final": 0.4992368817329407, "info_performance_mean": 0.3982677161693573, "info_performance_final": 0.4992368817329407, "step": 1964500}
{"episode_reward": 796.5354090354089, "episode": 19646.0, "batch_reward": 12.015579223632812, "critic_loss": 2570.734619140625, "actor_loss": -1428.74365234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2198445796966553, "alpha_loss": 0.013437196612358093, "alpha_value": 0.24834408955826648, "duration": 1.5655474662780762, "info_normalized_performance_mean": 0.7083929181098938, "info_normalized_performance_final": 0.8146258592605591, "info_performance_mean": 0.7083929181098938, "info_performance_final": 0.8146258592605591, "step": 1965000}
{"episode_reward": 1416.7857142857135, "episode": 19651.0, "batch_reward": 11.390195846557617, "critic_loss": 367.4775695800781, "actor_loss": -1370.392578125, "actor_target_entropy": -3.0, "actor_entropy": 1.2641122341156006, "alpha_loss": 0.1615254431962967, "alpha_value": 0.24581434573984248, "duration": 1.7214841842651367, "info_normalized_performance_mean": 0.3280036449432373, "info_normalized_performance_final": 0.4227716624736786, "info_performance_mean": 0.3280036449432373, "info_performance_final": 0.4227716624736786, "step": 1965500}
{"episode_reward": 656.0073260073258, "episode": 19656.0, "batch_reward": 11.256438255310059, "critic_loss": 368.6471252441406, "actor_loss": -1414.0289306640625, "actor_target_entropy": -3.0, "actor_entropy": 1.1158418655395508, "alpha_loss": 0.08650289475917816, "alpha_value": 0.2435326931036855, "duration": 1.53371000289917, "info_normalized_performance_mean": 0.9181786179542542, "info_normalized_performance_final": 0.9946428537368774, "info_performance_mean": 0.9181786179542542, "info_performance_final": 0.9946428537368774, "step": 1966000}
{"episode_reward": 1836.357142857141, "episode": 19661.0, "batch_reward": 10.465457916259766, "critic_loss": 708.3340454101562, "actor_loss": -1369.4287109375, "actor_target_entropy": -3.0, "actor_entropy": 1.01277494430542, "alpha_loss": 0.01999671757221222, "alpha_value": 0.24139579658278404, "duration": 1.6140868663787842, "info_normalized_performance_mean": 0.6488280296325684, "info_normalized_performance_final": 0.7057291865348816, "info_performance_mean": 0.6488280296325684, "info_performance_final": 0.7057291865348816, "step": 1966500}
{"episode_reward": 1297.6562499999995, "episode": 19666.0, "batch_reward": 10.921314239501953, "critic_loss": 576.7079467773438, "actor_loss": -1375.3671875, "actor_target_entropy": -3.0, "actor_entropy": 1.1942163705825806, "alpha_loss": 0.09859021008014679, "alpha_value": 0.2397206249555381, "duration": 1.6390411853790283, "info_normalized_performance_mean": 0.7392392754554749, "info_normalized_performance_final": 0.8994709253311157, "info_performance_mean": 0.7392392754554749, "info_performance_final": 0.8994709253311157, "step": 1967000}
{"episode_reward": 1478.4788359788365, "episode": 19671.0, "batch_reward": 10.996423721313477, "critic_loss": 1828.97998046875, "actor_loss": -1365.2607421875, "actor_target_entropy": -3.0, "actor_entropy": 1.492121934890747, "alpha_loss": -0.037801314145326614, "alpha_value": 0.23858858886248557, "duration": 1.604189157485962, "info_normalized_performance_mean": 0.5449134707450867, "info_normalized_performance_final": 0.598124086856842, "info_performance_mean": 0.5449134707450867, "info_performance_final": 0.598124086856842, "step": 1967500}
{"episode_reward": 1089.8268398268408, "episode": 19676.0, "batch_reward": 10.595787048339844, "critic_loss": 1717.414794921875, "actor_loss": -1354.731201171875, "actor_target_entropy": -3.0, "actor_entropy": 0.9993591904640198, "alpha_loss": -0.07985662668943405, "alpha_value": 0.23637007723542827, "duration": 1.6358788013458252, "info_normalized_performance_mean": 0.6583068370819092, "info_normalized_performance_final": 0.8320105671882629, "info_performance_mean": 0.6583068370819092, "info_performance_final": 0.8320105671882629, "step": 1968000}
{"episode_reward": 1316.613756613756, "episode": 19681.0, "batch_reward": 10.317793846130371, "critic_loss": 1077.765869140625, "actor_loss": -1334.311767578125, "actor_target_entropy": -3.0, "actor_entropy": 1.0942449569702148, "alpha_loss": 0.1456586718559265, "alpha_value": 0.23446256250765965, "duration": 1.6376874446868896, "info_normalized_performance_mean": 0.4437776803970337, "info_normalized_performance_final": 0.6166666746139526, "info_performance_mean": 0.4437776803970337, "info_performance_final": 0.6166666746139526, "step": 1968500}
{"episode_reward": 887.5555555555562, "episode": 19686.0, "batch_reward": 9.925749778747559, "critic_loss": 943.7628784179688, "actor_loss": -1366.630126953125, "actor_target_entropy": -3.0, "actor_entropy": 0.8895434141159058, "alpha_loss": -0.17137837409973145, "alpha_value": 0.23187031000934982, "duration": 1.5198791027069092, "info_normalized_performance_mean": 0.2350553572177887, "info_normalized_performance_final": 0.2646484375, "info_performance_mean": 0.2350553572177887, "info_performance_final": 0.2646484375, "step": 1969000}
{"episode_reward": 470.11067708333337, "episode": 19691.0, "batch_reward": 10.179895401000977, "critic_loss": 728.9150390625, "actor_loss": -1344.555419921875, "actor_target_entropy": -3.0, "actor_entropy": 1.1353591680526733, "alpha_loss": -0.3030013144016266, "alpha_value": 0.23196611249876575, "duration": 1.511152982711792, "info_normalized_performance_mean": 0.6048710942268372, "info_normalized_performance_final": 0.7584325671195984, "info_performance_mean": 0.6048710942268372, "info_performance_final": 0.7584325671195984, "step": 1969500}
{"episode_reward": 1209.7420634920634, "episode": 19696.0, "batch_reward": 9.99520206451416, "critic_loss": 770.777099609375, "actor_loss": -1331.773193359375, "actor_target_entropy": -3.0, "actor_entropy": 1.1034449338912964, "alpha_loss": -0.013797679916024208, "alpha_value": 0.2306538451824524, "step": 1970000}
{"duration": 18.74934959411621, "info_normalized_performance_mean": 0.33890005946159363, "info_normalized_performance_final": 0.40909090638160706, "info_performance_mean": 0.33890005946159363, "info_performance_final": 0.40909090638160706, "step": 1970000}
{"episode_reward": 677.7999999999989, "episode": 19701.0, "batch_reward": 10.67982006072998, "critic_loss": 2748.724609375, "actor_loss": -1374.6768798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.9204539060592651, "alpha_loss": -0.05356459319591522, "alpha_value": 0.2290138673809432, "duration": 1.6111736297607422, "info_normalized_performance_mean": 0.5085504055023193, "info_normalized_performance_final": 0.5494791865348816, "info_performance_mean": 0.5085504055023193, "info_performance_final": 0.5494791865348816, "step": 1970500}
{"episode_reward": 1017.1006944444458, "episode": 19706.0, "batch_reward": 10.537088394165039, "critic_loss": 775.927978515625, "actor_loss": -1391.8544921875, "actor_target_entropy": -3.0, "actor_entropy": 0.33140555024147034, "alpha_loss": -0.16050972044467926, "alpha_value": 0.22737325057656851, "duration": 1.5449552536010742, "info_normalized_performance_mean": 0.6763871908187866, "info_normalized_performance_final": 0.7953296899795532, "info_performance_mean": 0.6763871908187866, "info_performance_final": 0.7953296899795532, "step": 1971000}
{"episode_reward": 1352.7747252747254, "episode": 19711.0, "batch_reward": 10.028097152709961, "critic_loss": 657.4402465820312, "actor_loss": -1319.440673828125, "actor_target_entropy": -3.0, "actor_entropy": 0.7360625267028809, "alpha_loss": -0.06206953525543213, "alpha_value": 0.22795777839970985, "duration": 1.517322063446045, "info_normalized_performance_mean": 0.4337276518344879, "info_normalized_performance_final": 0.577752947807312, "info_performance_mean": 0.4337276518344879, "info_performance_final": 0.577752947807312, "step": 1971500}
{"episode_reward": 867.4553571428572, "episode": 19716.0, "batch_reward": 10.514528274536133, "critic_loss": 304.8138427734375, "actor_loss": -1350.35986328125, "actor_target_entropy": -3.0, "actor_entropy": 0.4149799942970276, "alpha_loss": -0.11478066444396973, "alpha_value": 0.22676258306489358, "duration": 1.4284331798553467, "info_normalized_performance_mean": 0.2885984480381012, "info_normalized_performance_final": 0.31168830394744873, "info_performance_mean": 0.2885984480381012, "info_performance_final": 0.31168830394744873, "step": 1972000}
{"episode_reward": 577.1969696969701, "episode": 19721.0, "batch_reward": 10.999944686889648, "critic_loss": 441.81884765625, "actor_loss": -1335.88818359375, "actor_target_entropy": -3.0, "actor_entropy": 1.2271926403045654, "alpha_loss": 0.0748407393693924, "alpha_value": 0.2260881045272986, "duration": 1.740121841430664, "info_normalized_performance_mean": 0.23378297686576843, "info_normalized_performance_final": 0.3186061680316925, "info_performance_mean": 0.23378297686576843, "info_performance_final": 0.3186061680316925, "step": 1972500}
{"episode_reward": 467.56607495069, "episode": 19726.0, "batch_reward": 10.425078392028809, "critic_loss": 834.9842529296875, "actor_loss": -1336.4088134765625, "actor_target_entropy": -3.0, "actor_entropy": 0.7251826524734497, "alpha_loss": 0.012841664254665375, "alpha_value": 0.22344300873207343, "duration": 1.6405081748962402, "info_normalized_performance_mean": 0.5236701965332031, "info_normalized_performance_final": 0.6903896331787109, "info_performance_mean": 0.5236701965332031, "info_performance_final": 0.6903896331787109, "step": 1973000}
{"episode_reward": 1047.34025974026, "episode": 19731.0, "batch_reward": 10.85599422454834, "critic_loss": 922.8364868164062, "actor_loss": -1349.969970703125, "actor_target_entropy": -3.0, "actor_entropy": 1.0207571983337402, "alpha_loss": 0.10827645659446716, "alpha_value": 0.22335633711168992, "duration": 1.5733277797698975, "info_normalized_performance_mean": 0.4085902273654938, "info_normalized_performance_final": 0.43958333134651184, "info_performance_mean": 0.4085902273654938, "info_performance_final": 0.43958333134651184, "step": 1973500}
{"episode_reward": 817.1805555555546, "episode": 19736.0, "batch_reward": 11.797515869140625, "critic_loss": 440.95257568359375, "actor_loss": -1390.093994140625, "actor_target_entropy": -3.0, "actor_entropy": 0.8126863241195679, "alpha_loss": -0.030002830550074577, "alpha_value": 0.22199980722564255, "duration": 1.7333195209503174, "info_normalized_performance_mean": 0.3139621615409851, "info_normalized_performance_final": 0.42994505167007446, "info_performance_mean": 0.3139621615409851, "info_performance_final": 0.42994505167007446, "step": 1974000}
{"episode_reward": 627.924297924298, "episode": 19741.0, "batch_reward": 11.409202575683594, "critic_loss": 845.7650146484375, "actor_loss": -1384.335693359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9651308059692383, "alpha_loss": 0.05898932367563248, "alpha_value": 0.22031611574041685, "duration": 1.5247266292572021, "info_normalized_performance_mean": 0.6491568684577942, "info_normalized_performance_final": 0.7058823704719543, "info_performance_mean": 0.6491568684577942, "info_performance_final": 0.7058823704719543, "step": 1974500}
{"episode_reward": 1298.3137254901944, "episode": 19746.0, "batch_reward": 10.829166412353516, "critic_loss": 1660.62744140625, "actor_loss": -1373.6434326171875, "actor_target_entropy": -3.0, "actor_entropy": 0.7043476104736328, "alpha_loss": -0.05252305045723915, "alpha_value": 0.21762540882307785, "duration": 1.5127768516540527, "info_normalized_performance_mean": 0.39479485154151917, "info_normalized_performance_final": 0.509358823299408, "info_performance_mean": 0.39479485154151917, "info_performance_final": 0.509358823299408, "step": 1975000}
{"episode_reward": 789.5898048586216, "episode": 19751.0, "batch_reward": 11.655035018920898, "critic_loss": 371.6220703125, "actor_loss": -1397.7421875, "actor_target_entropy": -3.0, "actor_entropy": 0.713894784450531, "alpha_loss": 0.08001189678907394, "alpha_value": 0.21486000060865176, "duration": 1.5924456119537354, "info_normalized_performance_mean": 0.6674250960350037, "info_normalized_performance_final": 0.7262499928474426, "info_performance_mean": 0.6674250960350037, "info_performance_final": 0.7262499928474426, "step": 1975500}
{"episode_reward": 1334.8500000000008, "episode": 19756.0, "batch_reward": 10.748820304870605, "critic_loss": 1051.53759765625, "actor_loss": -1344.5970458984375, "actor_target_entropy": -3.0, "actor_entropy": 0.7717271447181702, "alpha_loss": 0.0029004085808992386, "alpha_value": 0.21402481352872235, "duration": 1.5090107917785645, "info_normalized_performance_mean": 0.4548313021659851, "info_normalized_performance_final": 0.5247252583503723, "info_performance_mean": 0.4548313021659851, "info_performance_final": 0.5247252583503723, "step": 1976000}
{"episode_reward": 909.6624803767654, "episode": 19761.0, "batch_reward": 10.52767562866211, "critic_loss": 569.02978515625, "actor_loss": -1337.9571533203125, "actor_target_entropy": -3.0, "actor_entropy": 1.002870798110962, "alpha_loss": -0.025269748643040657, "alpha_value": 0.21436050658992764, "duration": 1.5615112781524658, "info_normalized_performance_mean": 0.604310929775238, "info_normalized_performance_final": 0.653333306312561, "info_performance_mean": 0.604310929775238, "info_performance_final": 0.653333306312561, "step": 1976500}
{"episode_reward": 1208.6222222222234, "episode": 19766.0, "batch_reward": 10.474822044372559, "critic_loss": 849.762451171875, "actor_loss": -1327.789306640625, "actor_target_entropy": -3.0, "actor_entropy": 0.91365647315979, "alpha_loss": -0.06516789644956589, "alpha_value": 0.21472071337981027, "duration": 1.5112006664276123, "info_normalized_performance_mean": 0.6261093616485596, "info_normalized_performance_final": 0.6796875, "info_performance_mean": 0.6261093616485596, "info_performance_final": 0.6796875, "step": 1977000}
{"episode_reward": 1252.21875, "episode": 19771.0, "batch_reward": 10.812376976013184, "critic_loss": 592.287353515625, "actor_loss": -1352.1748046875, "actor_target_entropy": -3.0, "actor_entropy": 1.1628828048706055, "alpha_loss": -0.06054268777370453, "alpha_value": 0.21705366408074103, "duration": 1.5945968627929688, "info_normalized_performance_mean": 0.5571999549865723, "info_normalized_performance_final": 0.6075000166893005, "info_performance_mean": 0.5571999549865723, "info_performance_final": 0.6075000166893005, "step": 1977500}
{"episode_reward": 1114.3999999999994, "episode": 19776.0, "batch_reward": 10.7478609085083, "critic_loss": 238.69827270507812, "actor_loss": -1347.5224609375, "actor_target_entropy": -3.0, "actor_entropy": 1.3496668338775635, "alpha_loss": 0.019758127629756927, "alpha_value": 0.21944182458254796, "duration": 1.511101245880127, "info_normalized_performance_mean": 0.5321938395500183, "info_normalized_performance_final": 0.601190447807312, "info_performance_mean": 0.5321938395500183, "info_performance_final": 0.601190447807312, "step": 1978000}
{"episode_reward": 1064.3877551020412, "episode": 19781.0, "batch_reward": 10.485254287719727, "critic_loss": 523.56396484375, "actor_loss": -1341.37451171875, "actor_target_entropy": -3.0, "actor_entropy": 1.0837523937225342, "alpha_loss": -0.07844560593366623, "alpha_value": 0.22224250228322184, "duration": 1.4592750072479248, "info_normalized_performance_mean": 0.5492202639579773, "info_normalized_performance_final": 0.7422618865966797, "info_performance_mean": 0.5492202639579773, "info_performance_final": 0.7422618865966797, "step": 1978500}
{"episode_reward": 1098.440476190476, "episode": 19786.0, "batch_reward": 10.72861099243164, "critic_loss": 363.4744873046875, "actor_loss": -1359.6240234375, "actor_target_entropy": -3.0, "actor_entropy": 0.8192086219787598, "alpha_loss": -0.038212988525629044, "alpha_value": 0.22431694072574818, "duration": 1.4574103355407715, "info_normalized_performance_mean": 0.17739291489124298, "info_normalized_performance_final": 0.20510204136371613, "info_performance_mean": 0.17739291489124298, "info_performance_final": 0.20510204136371613, "step": 1979000}
{"episode_reward": 354.7857142857139, "episode": 19791.0, "batch_reward": 10.222234725952148, "critic_loss": 988.3569946289062, "actor_loss": -1333.9033203125, "actor_target_entropy": -3.0, "actor_entropy": 1.240134596824646, "alpha_loss": -0.0430922769010067, "alpha_value": 0.22842376242215182, "duration": 1.5843231678009033, "info_normalized_performance_mean": 0.4254091680049896, "info_normalized_performance_final": 0.459077388048172, "info_performance_mean": 0.4254091680049896, "info_performance_final": 0.459077388048172, "step": 1979500}
{"episode_reward": 850.8184523809507, "episode": 19796.0, "batch_reward": 10.784416198730469, "critic_loss": 541.8455200195312, "actor_loss": -1377.5780029296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9570713043212891, "alpha_loss": -0.059251680970191956, "alpha_value": 0.23112311045309616, "step": 1980000}
{"duration": 19.425837516784668, "info_normalized_performance_mean": 0.5660958886146545, "info_normalized_performance_final": 0.7142857313156128, "info_performance_mean": 0.5660958886146545, "info_performance_final": 0.7142857313156128, "step": 1980000}
{"episode_reward": 1132.191697191697, "episode": 19801.0, "batch_reward": 11.762588500976562, "critic_loss": 377.89154052734375, "actor_loss": -1432.268798828125, "actor_target_entropy": -3.0, "actor_entropy": 0.8606484532356262, "alpha_loss": -0.38647669553756714, "alpha_value": 0.23569378739312472, "duration": 1.4532246589660645, "info_normalized_performance_mean": 0.23014068603515625, "info_normalized_performance_final": 0.24687500298023224, "info_performance_mean": 0.23014068603515625, "info_performance_final": 0.24687500298023224, "step": 1980500}
{"episode_reward": 460.28125, "episode": 19806.0, "batch_reward": 11.54918384552002, "critic_loss": 663.5331420898438, "actor_loss": -1410.486572265625, "actor_target_entropy": -3.0, "actor_entropy": 0.7313090562820435, "alpha_loss": 0.02347761020064354, "alpha_value": 0.24095706260933467, "duration": 1.5136866569519043, "info_normalized_performance_mean": 0.6858184337615967, "info_normalized_performance_final": 0.8457341194152832, "info_performance_mean": 0.6858184337615967, "info_performance_final": 0.8457341194152832, "step": 1981000}
{"episode_reward": 1371.6369047619066, "episode": 19811.0, "batch_reward": 11.200772285461426, "critic_loss": 1063.354248046875, "actor_loss": -1380.519287109375, "actor_target_entropy": -3.0, "actor_entropy": 0.9316496849060059, "alpha_loss": 0.06928537040948868, "alpha_value": 0.24313984554277282, "duration": 1.4425950050354004, "info_normalized_performance_mean": 0.4371711015701294, "info_normalized_performance_final": 0.49376416206359863, "info_performance_mean": 0.4371711015701294, "info_performance_final": 0.49376416206359863, "step": 1981500}
{"episode_reward": 874.3424036281192, "episode": 19816.0, "batch_reward": 11.158866882324219, "critic_loss": 458.50860595703125, "actor_loss": -1418.18115234375, "actor_target_entropy": -3.0, "actor_entropy": 0.6385495662689209, "alpha_loss": 0.045859381556510925, "alpha_value": 0.24747510471475612, "duration": 1.5731196403503418, "info_normalized_performance_mean": 0.8566499352455139, "info_normalized_performance_final": 0.9287499785423279, "info_performance_mean": 0.8566499352455139, "info_performance_final": 0.9287499785423279, "step": 1982000}
{"episode_reward": 1713.3000000000027, "episode": 19821.0, "batch_reward": 10.894960403442383, "critic_loss": 357.1763916015625, "actor_loss": -1400.91748046875, "actor_target_entropy": -3.0, "actor_entropy": 0.6956644058227539, "alpha_loss": -0.22070693969726562, "alpha_value": 0.25194443366931957, "duration": 1.477050542831421, "info_normalized_performance_mean": 0.2964158058166504, "info_normalized_performance_final": 0.34778910875320435, "info_performance_mean": 0.2964158058166504, "info_performance_final": 0.34778910875320435, "step": 1982500}
{"episode_reward": 592.8316326530618, "episode": 19826.0, "batch_reward": 10.087156295776367, "critic_loss": 1413.5938720703125, "actor_loss": -1346.2486572265625, "actor_target_entropy": -3.0, "actor_entropy": 0.8142609596252441, "alpha_loss": -0.1481381058692932, "alpha_value": 0.256499175145136, "duration": 1.4637062549591064, "info_normalized_performance_mean": 0.8341560363769531, "info_normalized_performance_final": 0.903124988079071, "info_performance_mean": 0.8341560363769531, "info_performance_final": 0.903124988079071, "step": 1983000}
{"episode_reward": 1668.3125, "episode": 19831.0, "batch_reward": 11.165682792663574, "critic_loss": 853.458251953125, "actor_loss": -1393.4010009765625, "actor_target_entropy": -3.0, "actor_entropy": 0.756088137626648, "alpha_loss": -0.15120747685432434, "alpha_value": 0.2595015166065591, "duration": 1.4952328205108643, "info_normalized_performance_mean": 0.8208364844322205, "info_normalized_performance_final": 0.9590964317321777, "info_performance_mean": 0.8208364844322205, "info_performance_final": 0.9590964317321777, "step": 1983500}
{"episode_reward": 1641.6727716727737, "episode": 19836.0, "batch_reward": 12.239198684692383, "critic_loss": 998.1300048828125, "actor_loss": -1437.69189453125, "actor_target_entropy": -3.0, "actor_entropy": 0.4852270781993866, "alpha_loss": -0.023282915353775024, "alpha_value": 0.26113594287037106, "duration": 1.621880054473877, "info_normalized_performance_mean": 0.7313628196716309, "info_normalized_performance_final": 0.7899305820465088, "info_performance_mean": 0.7313628196716309, "info_performance_final": 0.7899305820465088, "step": 1984000}
{"episode_reward": 1462.7256944444425, "episode": 19841.0, "batch_reward": 11.110038757324219, "critic_loss": 661.5562744140625, "actor_loss": -1373.9637451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.8971611261367798, "alpha_loss": 0.08724770694971085, "alpha_value": 0.2611978215688207, "duration": 1.623704433441162, "info_normalized_performance_mean": 0.831753671169281, "info_normalized_performance_final": 0.8984615206718445, "info_performance_mean": 0.831753671169281, "info_performance_final": 0.8984615206718445, "step": 1984500}
{"episode_reward": 1663.5076923076917, "episode": 19846.0, "batch_reward": 11.510479927062988, "critic_loss": 712.488037109375, "actor_loss": -1411.125732421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8856344819068909, "alpha_loss": -0.011584898456931114, "alpha_value": 0.26212435321427985, "duration": 1.552389144897461, "info_normalized_performance_mean": 0.47945311665534973, "info_normalized_performance_final": 0.5625, "info_performance_mean": 0.47945311665534973, "info_performance_final": 0.5625, "step": 1985000}
{"episode_reward": 958.90625, "episode": 19851.0, "batch_reward": 10.185615539550781, "critic_loss": 736.5392456054688, "actor_loss": -1388.7152099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.290116786956787, "alpha_loss": -0.18361029028892517, "alpha_value": 0.26219779164686097, "duration": 1.4887139797210693, "info_normalized_performance_mean": 0.6949512958526611, "info_normalized_performance_final": 0.75, "info_performance_mean": 0.6949512958526611, "info_performance_final": 0.75, "step": 1985500}
{"episode_reward": 1389.9025974025974, "episode": 19856.0, "batch_reward": 10.834684371948242, "critic_loss": 329.68017578125, "actor_loss": -1387.2762451171875, "actor_target_entropy": -3.0, "actor_entropy": 0.9883007407188416, "alpha_loss": -0.0031275786459445953, "alpha_value": 0.26193959102485975, "duration": 1.5884675979614258, "info_normalized_performance_mean": 0.22660622000694275, "info_normalized_performance_final": 0.2943750023841858, "info_performance_mean": 0.22660622000694275, "info_performance_final": 0.2943750023841858, "step": 1986000}
{"episode_reward": 453.21249999999964, "episode": 19861.0, "batch_reward": 11.163578987121582, "critic_loss": 506.2595520019531, "actor_loss": -1396.8746337890625, "actor_target_entropy": -3.0, "actor_entropy": 0.8226287961006165, "alpha_loss": 0.12432605028152466, "alpha_value": 0.2602281706048938, "duration": 1.5626623630523682, "info_normalized_performance_mean": 0.46986615657806396, "info_normalized_performance_final": 0.5875687003135681, "info_performance_mean": 0.46986615657806396, "info_performance_final": 0.5875687003135681, "step": 1986500}
{"episode_reward": 939.7321428571437, "episode": 19866.0, "batch_reward": 10.220924377441406, "critic_loss": 864.683349609375, "actor_loss": -1399.66357421875, "actor_target_entropy": -3.0, "actor_entropy": 0.8007452487945557, "alpha_loss": -0.046996165066957474, "alpha_value": 0.2594584666360003, "duration": 1.5512757301330566, "info_normalized_performance_mean": 0.2834988534450531, "info_normalized_performance_final": 0.34567901492118835, "info_performance_mean": 0.2834988534450531, "info_performance_final": 0.34567901492118835, "step": 1987000}
{"episode_reward": 566.997755331089, "episode": 19871.0, "batch_reward": 10.983807563781738, "critic_loss": 278.4107666015625, "actor_loss": -1415.28515625, "actor_target_entropy": -3.0, "actor_entropy": 0.864249587059021, "alpha_loss": -0.08774847537279129, "alpha_value": 0.25716787026926063, "duration": 1.5783226490020752, "info_normalized_performance_mean": 0.5749640464782715, "info_normalized_performance_final": 0.6733773946762085, "info_performance_mean": 0.5749640464782715, "info_performance_final": 0.6733773946762085, "step": 1987500}
{"episode_reward": 1149.9278846153857, "episode": 19876.0, "batch_reward": 11.491928100585938, "critic_loss": 404.18768310546875, "actor_loss": -1446.549560546875, "actor_target_entropy": -3.0, "actor_entropy": 0.9105175137519836, "alpha_loss": -0.07605735957622528, "alpha_value": 0.25787906766181923, "duration": 1.4515199661254883, "info_normalized_performance_mean": 0.43741294741630554, "info_normalized_performance_final": 0.4711538553237915, "info_performance_mean": 0.43741294741630554, "info_performance_final": 0.4711538553237915, "step": 1988000}
{"episode_reward": 874.8260073260063, "episode": 19881.0, "batch_reward": 10.876450538635254, "critic_loss": 505.2095947265625, "actor_loss": -1440.2095947265625, "actor_target_entropy": -3.0, "actor_entropy": 1.1259888410568237, "alpha_loss": 0.09357335418462753, "alpha_value": 0.25588259538773783, "duration": 1.5872101783752441, "info_normalized_performance_mean": 0.6735409498214722, "info_normalized_performance_final": 0.7235293984413147, "info_performance_mean": 0.6735409498214722, "info_performance_final": 0.7235293984413147, "step": 1988500}
{"episode_reward": 1347.0823529411784, "episode": 19886.0, "batch_reward": 10.999590873718262, "critic_loss": 379.7633361816406, "actor_loss": -1409.418212890625, "actor_target_entropy": -3.0, "actor_entropy": 1.0972132682800293, "alpha_loss": 0.06535304337739944, "alpha_value": 0.25451226901340324, "duration": 1.4823970794677734, "info_normalized_performance_mean": 0.5526608228683472, "info_normalized_performance_final": 0.6357142925262451, "info_performance_mean": 0.5526608228683472, "info_performance_final": 0.6357142925262451, "step": 1989000}
{"episode_reward": 1105.321428571427, "episode": 19891.0, "batch_reward": 11.255502700805664, "critic_loss": 716.40087890625, "actor_loss": -1419.2291259765625, "actor_target_entropy": -3.0, "actor_entropy": 0.9316520690917969, "alpha_loss": 0.06778684258460999, "alpha_value": 0.2545585683546841, "duration": 1.7514982223510742, "info_normalized_performance_mean": 0.47307288646698, "info_normalized_performance_final": 0.5625, "info_performance_mean": 0.47307288646698, "info_performance_final": 0.5625, "step": 1989500}
{"episode_reward": 946.1458333333337, "episode": 19896.0, "batch_reward": 11.015417098999023, "critic_loss": 2192.55078125, "actor_loss": -1423.6549072265625, "actor_target_entropy": -3.0, "actor_entropy": 0.9762686491012573, "alpha_loss": 0.030857142060995102, "alpha_value": 0.25309688378801526, "step": 1990000}
{"duration": 19.11071276664734, "info_normalized_performance_mean": 0.334773451089859, "info_normalized_performance_final": 0.419921875, "info_performance_mean": 0.334773451089859, "info_performance_final": 0.419921875, "step": 1990000}
{"episode_reward": 669.546875, "episode": 19901.0, "batch_reward": 11.615425109863281, "critic_loss": 1383.082275390625, "actor_loss": -1437.0450439453125, "actor_target_entropy": -3.0, "actor_entropy": 1.3231302499771118, "alpha_loss": 0.07275451719760895, "alpha_value": 0.25168884506922995, "duration": 1.5997626781463623, "info_normalized_performance_mean": 0.4041732847690582, "info_normalized_performance_final": 0.5370370149612427, "info_performance_mean": 0.4041732847690582, "info_performance_final": 0.5370370149612427, "step": 1990500}
{"episode_reward": 808.3465608465608, "episode": 19906.0, "batch_reward": 10.420092582702637, "critic_loss": 1501.359130859375, "actor_loss": -1390.0804443359375, "actor_target_entropy": -3.0, "actor_entropy": 0.9638149738311768, "alpha_loss": 0.11507922410964966, "alpha_value": 0.25012678035631436, "duration": 1.6673133373260498, "info_normalized_performance_mean": 0.5348916053771973, "info_normalized_performance_final": 0.6291666626930237, "info_performance_mean": 0.5348916053771973, "info_performance_final": 0.6291666626930237, "step": 1991000}
{"episode_reward": 1069.7833333333342, "episode": 19911.0, "batch_reward": 10.663846969604492, "critic_loss": 429.34002685546875, "actor_loss": -1406.156494140625, "actor_target_entropy": -3.0, "actor_entropy": 0.9413806796073914, "alpha_loss": -0.05838795378804207, "alpha_value": 0.24846825508830223, "duration": 1.5691783428192139, "info_normalized_performance_mean": 0.009263038635253906, "info_normalized_performance_final": 0.010204081423580647, "info_performance_mean": 0.009263038635253906, "info_performance_final": 0.010204081423580647, "step": 1991500}
{"episode_reward": 18.526077097505652, "episode": 19916.0, "batch_reward": 11.25475788116455, "critic_loss": 577.287353515625, "actor_loss": -1434.2554931640625, "actor_target_entropy": -3.0, "actor_entropy": 0.8416277766227722, "alpha_loss": 0.04816920682787895, "alpha_value": 0.24736877610650435, "duration": 1.6010499000549316, "info_normalized_performance_mean": 0.48125898838043213, "info_normalized_performance_final": 0.5447716116905212, "info_performance_mean": 0.48125898838043213, "info_performance_final": 0.5447716116905212, "step": 1992000}
{"episode_reward": 962.5180288461532, "episode": 19921.0, "batch_reward": 10.937612533569336, "critic_loss": 1691.1385498046875, "actor_loss": -1384.760009765625, "actor_target_entropy": -3.0, "actor_entropy": 0.8543378114700317, "alpha_loss": -0.02148863673210144, "alpha_value": 0.24637641855680398, "duration": 1.4923794269561768, "info_normalized_performance_mean": 0.5161159634590149, "info_normalized_performance_final": 0.5535714030265808, "info_performance_mean": 0.5161159634590149, "info_performance_final": 0.5535714030265808, "step": 1992500}
{"episode_reward": 1032.232142857142, "episode": 19926.0, "batch_reward": 10.04668140411377, "critic_loss": 781.0814208984375, "actor_loss": -1395.4940185546875, "actor_target_entropy": -3.0, "actor_entropy": 0.6540408134460449, "alpha_loss": -0.1913730800151825, "alpha_value": 0.24694457894196323, "duration": 1.4751148223876953, "info_normalized_performance_mean": 0.44266173243522644, "info_normalized_performance_final": 0.47647058963775635, "info_performance_mean": 0.44266173243522644, "info_performance_final": 0.47647058963775635, "step": 1993000}
{"episode_reward": 885.3235294117629, "episode": 19931.0, "batch_reward": 11.167427062988281, "critic_loss": 1773.1055908203125, "actor_loss": -1418.905029296875, "actor_target_entropy": -3.0, "actor_entropy": 1.0560623407363892, "alpha_loss": -0.11658107489347458, "alpha_value": 0.24643570022298242, "duration": 1.5154883861541748, "info_normalized_performance_mean": 0.8531920909881592, "info_normalized_performance_final": 0.9174107313156128, "info_performance_mean": 0.8531920909881592, "info_performance_final": 0.9174107313156128, "step": 1993500}
{"episode_reward": 1706.3839285714273, "episode": 19936.0, "batch_reward": 10.538254737854004, "critic_loss": 329.26666259765625, "actor_loss": -1403.983154296875, "actor_target_entropy": -3.0, "actor_entropy": 0.9200267195701599, "alpha_loss": -0.15983304381370544, "alpha_value": 0.24650291289532886, "duration": 1.5693626403808594, "info_normalized_performance_mean": 0.8282501697540283, "info_normalized_performance_final": 0.8928571343421936, "info_performance_mean": 0.8282501697540283, "info_performance_final": 0.8928571343421936, "step": 1994000}
{"episode_reward": 1656.5000000000018, "episode": 19941.0, "batch_reward": 11.635442733764648, "critic_loss": 347.126220703125, "actor_loss": -1463.725830078125, "actor_target_entropy": -3.0, "actor_entropy": 0.9923614263534546, "alpha_loss": 0.07528334856033325, "alpha_value": 0.24830264849596112, "duration": 1.5343258380889893, "info_normalized_performance_mean": 0.5334049463272095, "info_normalized_performance_final": 0.5862630009651184, "info_performance_mean": 0.5334049463272095, "info_performance_final": 0.5862630009651184, "step": 1994500}
{"episode_reward": 1066.8098958333323, "episode": 19946.0, "batch_reward": 10.165943145751953, "critic_loss": 585.5490112304688, "actor_loss": -1376.7802734375, "actor_target_entropy": -3.0, "actor_entropy": 1.2021889686584473, "alpha_loss": -0.062349796295166016, "alpha_value": 0.24978473952337357, "duration": 1.619441270828247, "info_normalized_performance_mean": 0.6681030988693237, "info_normalized_performance_final": 0.7246031761169434, "info_performance_mean": 0.6681030988693237, "info_performance_final": 0.7246031761169434, "step": 1995000}
{"episode_reward": 1336.2063492063469, "episode": 19951.0, "batch_reward": 10.811484336853027, "critic_loss": 1241.6796875, "actor_loss": -1404.9541015625, "actor_target_entropy": -3.0, "actor_entropy": 1.1934630870819092, "alpha_loss": -0.024811163544654846, "alpha_value": 0.2502003979168776, "duration": 1.6134297847747803, "info_normalized_performance_mean": 0.4363058805465698, "info_normalized_performance_final": 0.469696968793869, "info_performance_mean": 0.4363058805465698, "info_performance_final": 0.469696968793869, "step": 1995500}
{"episode_reward": 872.6118326118317, "episode": 19956.0, "batch_reward": 10.607728958129883, "critic_loss": 1205.7197265625, "actor_loss": -1402.181396484375, "actor_target_entropy": -3.0, "actor_entropy": 1.0581090450286865, "alpha_loss": -0.09153833240270615, "alpha_value": 0.2534362553360748, "duration": 1.4809236526489258, "info_normalized_performance_mean": 0.7946022152900696, "info_normalized_performance_final": 0.876893937587738, "info_performance_mean": 0.7946022152900696, "info_performance_final": 0.876893937587738, "step": 1996000}
{"episode_reward": 1589.2045454545437, "episode": 19961.0, "batch_reward": 11.307472229003906, "critic_loss": 535.9820556640625, "actor_loss": -1433.89990234375, "actor_target_entropy": -3.0, "actor_entropy": 1.2167246341705322, "alpha_loss": 0.08204034715890884, "alpha_value": 0.2557415443763699, "duration": 1.4462857246398926, "info_normalized_performance_mean": 0.32534724473953247, "info_normalized_performance_final": 0.3767361044883728, "info_performance_mean": 0.32534724473953247, "info_performance_final": 0.3767361044883728, "step": 1996500}
{"episode_reward": 650.6944444444437, "episode": 19966.0, "batch_reward": 10.97093677520752, "critic_loss": 500.40008544921875, "actor_loss": -1392.0001220703125, "actor_target_entropy": -3.0, "actor_entropy": 1.1531803607940674, "alpha_loss": 0.12013089656829834, "alpha_value": 0.25912083151418397, "duration": 1.4433205127716064, "info_normalized_performance_mean": 0.09231942892074585, "info_normalized_performance_final": 0.09930555522441864, "info_performance_mean": 0.09231942892074585, "info_performance_final": 0.09930555522441864, "step": 1997000}
{"episode_reward": 184.6388888888891, "episode": 19971.0, "batch_reward": 11.512391090393066, "critic_loss": 1100.37109375, "actor_loss": -1430.0106201171875, "actor_target_entropy": -3.0, "actor_entropy": 1.1196742057800293, "alpha_loss": -0.037569571286439896, "alpha_value": 0.2636815065024224, "duration": 1.5469558238983154, "info_normalized_performance_mean": 0.7050778269767761, "info_normalized_performance_final": 0.8177655935287476, "info_performance_mean": 0.7050778269767761, "info_performance_final": 0.8177655935287476, "step": 1997500}
{"episode_reward": 1410.1556776556774, "episode": 19976.0, "batch_reward": 11.84367561340332, "critic_loss": 782.175048828125, "actor_loss": -1439.751220703125, "actor_target_entropy": -3.0, "actor_entropy": 0.8876166343688965, "alpha_loss": -0.15908628702163696, "alpha_value": 0.27044868452372384, "duration": 1.4479873180389404, "info_normalized_performance_mean": 0.5871683955192566, "info_normalized_performance_final": 0.6326530575752258, "info_performance_mean": 0.5871683955192566, "info_performance_final": 0.6326530575752258, "step": 1998000}
{"episode_reward": 1174.3367346938774, "episode": 19981.0, "batch_reward": 10.675378799438477, "critic_loss": 1065.535888671875, "actor_loss": -1417.8912353515625, "actor_target_entropy": -3.0, "actor_entropy": 1.302290916442871, "alpha_loss": -0.14359863102436066, "alpha_value": 0.27756405764714515, "duration": 1.5163791179656982, "info_normalized_performance_mean": 0.24719451367855072, "info_normalized_performance_final": 0.3408276438713074, "info_performance_mean": 0.24719451367855072, "info_performance_final": 0.3408276438713074, "step": 1998500}
{"episode_reward": 494.3890518084072, "episode": 19986.0, "batch_reward": 10.455047607421875, "critic_loss": 741.2269287109375, "actor_loss": -1399.65869140625, "actor_target_entropy": -3.0, "actor_entropy": 1.1885039806365967, "alpha_loss": 0.04863853007555008, "alpha_value": 0.2827961501545459, "duration": 1.6203868389129639, "info_normalized_performance_mean": 0.45282182097435, "info_normalized_performance_final": 0.6437389850616455, "info_performance_mean": 0.45282182097435, "info_performance_final": 0.6437389850616455, "step": 1999000}
{"episode_reward": 905.6437389770718, "episode": 19991.0, "batch_reward": 11.612075805664062, "critic_loss": 1006.8671875, "actor_loss": -1459.7099609375, "actor_target_entropy": -3.0, "actor_entropy": 1.2934805154800415, "alpha_loss": -0.23955176770687103, "alpha_value": 0.28871258853326387, "duration": 1.555466890335083, "info_normalized_performance_mean": 0.24063487350940704, "info_normalized_performance_final": 0.33465608954429626, "info_performance_mean": 0.24063487350940704, "info_performance_final": 0.33465608954429626, "step": 1999500}
